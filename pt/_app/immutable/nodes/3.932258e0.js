import{s as Ke,o as et,n as tt}from"../chunks/scheduler.d586627e.js";import{S as lt,i as ot,g as s,s as n,r as m,A as nt,h as r,f as l,c as a,j as qe,u as c,x as p,k as ze,y as at,a as o,v as T,d as f,t as d,w as u}from"../chunks/index.8589a59c.js";import{T as st}from"../chunks/Tip.84e2336e.js";import{C as K}from"../chunks/CodeBlock.47c46d2c.js";import{H as y}from"../chunks/Heading.a70e045b.js";function rt(te){let i,$=`A partir da versão 2.3.0 o script de conversão agora faz parte do transformers CLI (<strong>transformers-cli</strong>) disponível em qualquer instalação
transformers &gt;= 2.3.0.`,M,_,b="A documentação abaixo reflete o formato do comando <strong>transformers-cli convert</strong>.";return{c(){i=s("p"),i.innerHTML=$,M=n(),_=s("p"),_.innerHTML=b},l(U){i=r(U,"P",{"data-svelte-h":!0}),p(i)!=="svelte-opr9ez"&&(i.innerHTML=$),M=a(U),_=r(U,"P",{"data-svelte-h":!0}),p(_)!=="svelte-12vk8vx"&&(_.innerHTML=b)},m(U,J){o(U,i,J),o(U,M,J),o(U,_,J)},p:tt,d(U){U&&(l(i),l(M),l(_))}}}function pt(te){let i,$,M,_,b,U,J,Pe=`Uma interface de linha de comando é fornecida para converter os checkpoints originais Bert/GPT/GPT-2/Transformer-XL/XLNet/XLM em modelos
que podem ser carregados usando os métodos <code>from_pretrained</code> da biblioteca.`,le,h,oe,w,ne,v,Ne=`Você pode converter qualquer checkpoint do BERT em TensorFlow (em particular <a href="https://github.com/google-research/bert#pre-trained-models" rel="nofollow">os modelos pré-treinados lançados pelo Google</a>) em um arquivo PyTorch usando um
<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py" rel="nofollow">convert_bert_original_tf_checkpoint_to_pytorch.py</a> script.`,ae,V,Xe=`Esta Interface de Linha de Comando (CLI) recebe como entrada um checkpoint do TensorFlow (três arquivos começando com <code>bert_model.ckpt</code>) e o
arquivo de configuração (<code>bert_config.json</code>), e então cria um modelo PyTorch para esta configuração, carrega os pesos
do checkpoint do TensorFlow no modelo PyTorch e salva o modelo resultante em um arquivo PyTorch que pode
ser importado usando <code>from_pretrained()</code> (veja o exemplo em <a href="quicktour">quicktour</a> , <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-classification/run_glue.py" rel="nofollow">run_glue.py</a> ).`,se,C,ke=`Você só precisa executar este script de conversão <strong>uma vez</strong> para obter um modelo PyTorch. Você pode então desconsiderar o checkpoint em
TensorFlow (os três arquivos começando com <code>bert_model.ckpt</code>), mas certifique-se de manter o arquivo de configuração (\\
<code>bert_config.json</code>) e o arquivo de vocabulário (<code>vocab.txt</code>), pois eles também são necessários para o modelo PyTorch.`,re,R,Le="Para executar este script de conversão específico, você precisará ter o TensorFlow e o PyTorch instalados (<code>pip install tensorflow</code>). O resto do repositório requer apenas o PyTorch.",pe,E,je="Aqui está um exemplo do processo de conversão para um modelo <code>BERT-Base Uncased</code> pré-treinado:",ie,I,me,F,Ae='Você pode baixar os modelos pré-treinados do Google para a conversão <a href="https://github.com/google-research/bert#pre-trained-models" rel="nofollow">aqui</a>.',ce,B,Te,g,Se=`Converta os checkpoints do modelo ALBERT em TensorFlow para PyTorch usando o
<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py" rel="nofollow">convert_albert_original_tf_checkpoint_to_pytorch.py</a> script.`,fe,P,Ze=`A Interface de Linha de Comando (CLI) recebe como entrada um checkpoint do TensorFlow (três arquivos começando com <code>model.ckpt-best</code>) e o
arquivo de configuração (<code>albert_config.json</code>), então cria e salva um modelo PyTorch. Para executar esta conversão, você
precisa ter o TensorFlow e o PyTorch instalados.`,de,N,xe="Aqui está um exemplo do processo de conversão para o modelo <code>ALBERT Base</code> pré-treinado:",ue,X,Ue,k,Ge='Você pode baixar os modelos pré-treinados do Google para a conversão <a href="https://github.com/google-research/albert#pre-trained-models" rel="nofollow">aqui</a>.',_e,L,Je,j,Qe=`Aqui está um exemplo do processo de conversão para um modelo OpenAI GPT pré-treinado, supondo que seu checkpoint NumPy
foi salvo com o mesmo formato do modelo pré-treinado OpenAI (veja <a href="https://github.com/openai/finetune-transformer-lm" rel="nofollow">aqui</a>\\
)`,Me,A,be,S,he,Z,He='Aqui está um exemplo do processo de conversão para um modelo OpenAI GPT-2 pré-treinado (consulte <a href="https://github.com/openai/gpt-2" rel="nofollow">aqui</a>)',ye,x,$e,G,we,Q,We="Aqui está um exemplo do processo de conversão para um modelo XLNet pré-treinado:",ve,H,Ve,W,Ce,O,Oe="Aqui está um exemplo do processo de conversão para um modelo XLM pré-treinado:",Re,D,Ee,Y,Ie,q,De="Aqui está um exemplo do processo de conversão para um modelo T5 pré-treinado:",Fe,z,Be,ee,ge;return b=new y({props:{title:"Convertendo checkpoints do TensorFlow para Pytorch",local:"convertendo-checkpoints-do-tensorflow-para-pytorch",headingTag:"h1"}}),h=new st({props:{$$slots:{default:[rt]},$$scope:{ctx:te}}}),w=new y({props:{title:"BERT",local:"bert",headingTag:"h2"}}),I=new K({props:{code:"ZXhwb3J0JTIwQkVSVF9CQVNFX0RJUiUzRCUyRnBhdGglMkZ0byUyRmJlcnQlMkZ1bmNhc2VkX0wtMTJfSC03NjhfQS0xMiUwQSUwQXRyYW5zZm9ybWVycy1jbGklMjBjb252ZXJ0JTIwLS1tb2RlbF90eXBlJTIwYmVydCUyMCU1QyUwQSUyMCUyMC0tdGZfY2hlY2twb2ludCUyMCUyNEJFUlRfQkFTRV9ESVIlMkZiZXJ0X21vZGVsLmNrcHQlMjAlNUMlMEElMjAlMjAtLWNvbmZpZyUyMCUyNEJFUlRfQkFTRV9ESVIlMkZiZXJ0X2NvbmZpZy5qc29uJTIwJTVDJTBBJTIwJTIwLS1weXRvcmNoX2R1bXBfb3V0cHV0JTIwJTI0QkVSVF9CQVNFX0RJUiUyRnB5dG9yY2hfbW9kZWwuYmlu",highlighted:`<span class="hljs-built_in">export</span> BERT_BASE_DIR=/path/to/bert/uncased_L-12_H-768_A-12

transformers-cli convert --model_type bert \\
  --tf_checkpoint <span class="hljs-variable">$BERT_BASE_DIR</span>/bert_model.ckpt \\
  --config <span class="hljs-variable">$BERT_BASE_DIR</span>/bert_config.json \\
  --pytorch_dump_output <span class="hljs-variable">$BERT_BASE_DIR</span>/pytorch_model.bin`,wrap:!1}}),B=new y({props:{title:"ALBERT",local:"albert",headingTag:"h2"}}),X=new K({props:{code:"ZXhwb3J0JTIwQUxCRVJUX0JBU0VfRElSJTNEJTJGcGF0aCUyRnRvJTJGYWxiZXJ0JTJGYWxiZXJ0X2Jhc2UlMEElMEF0cmFuc2Zvcm1lcnMtY2xpJTIwY29udmVydCUyMC0tbW9kZWxfdHlwZSUyMGFsYmVydCUyMCU1QyUwQSUyMCUyMC0tdGZfY2hlY2twb2ludCUyMCUyNEFMQkVSVF9CQVNFX0RJUiUyRm1vZGVsLmNrcHQtYmVzdCUyMCU1QyUwQSUyMCUyMC0tY29uZmlnJTIwJTI0QUxCRVJUX0JBU0VfRElSJTJGYWxiZXJ0X2NvbmZpZy5qc29uJTIwJTVDJTBBJTIwJTIwLS1weXRvcmNoX2R1bXBfb3V0cHV0JTIwJTI0QUxCRVJUX0JBU0VfRElSJTJGcHl0b3JjaF9tb2RlbC5iaW4=",highlighted:`<span class="hljs-built_in">export</span> ALBERT_BASE_DIR=/path/to/albert/albert_base

transformers-cli convert --model_type albert \\
  --tf_checkpoint <span class="hljs-variable">$ALBERT_BASE_DIR</span>/model.ckpt-best \\
  --config <span class="hljs-variable">$ALBERT_BASE_DIR</span>/albert_config.json \\
  --pytorch_dump_output <span class="hljs-variable">$ALBERT_BASE_DIR</span>/pytorch_model.bin`,wrap:!1}}),L=new y({props:{title:"OpenAI GPT",local:"openai-gpt",headingTag:"h2"}}),A=new K({props:{code:"ZXhwb3J0JTIwT1BFTkFJX0dQVF9DSEVDS1BPSU5UX0ZPTERFUl9QQVRIJTNEJTJGcGF0aCUyRnRvJTJGb3BlbmFpJTJGcHJldHJhaW5lZCUyRm51bXB5JTJGd2VpZ2h0cyUwQSUwQXRyYW5zZm9ybWVycy1jbGklMjBjb252ZXJ0JTIwLS1tb2RlbF90eXBlJTIwZ3B0JTIwJTVDJTBBJTIwJTIwLS10Zl9jaGVja3BvaW50JTIwJTI0T1BFTkFJX0dQVF9DSEVDS1BPSU5UX0ZPTERFUl9QQVRIJTIwJTVDJTBBJTIwJTIwLS1weXRvcmNoX2R1bXBfb3V0cHV0JTIwJTI0UFlUT1JDSF9EVU1QX09VVFBVVCUyMCU1QyUwQSUyMCUyMCU1Qi0tY29uZmlnJTIwT1BFTkFJX0dQVF9DT05GSUclNUQlMjAlNUMlMEElMjAlMjAlNUItLWZpbmV0dW5pbmdfdGFza19uYW1lJTIwT1BFTkFJX0dQVF9GSU5FVFVORURfVEFTSyU1RCUyMCU1Qw==",highlighted:`<span class="hljs-built_in">export</span> OPENAI_GPT_CHECKPOINT_FOLDER_PATH=/path/to/openai/pretrained/numpy/weights

transformers-cli convert --model_type gpt \\
  --tf_checkpoint <span class="hljs-variable">$OPENAI_GPT_CHECKPOINT_FOLDER_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--config OPENAI_GPT_CONFIG] \\
  [--finetuning_task_name OPENAI_GPT_FINETUNED_TASK] \\`,wrap:!1}}),S=new y({props:{title:"OpenAI GPT-2",local:"openai-gpt-2",headingTag:"h2"}}),x=new K({props:{code:"ZXhwb3J0JTIwT1BFTkFJX0dQVDJfQ0hFQ0tQT0lOVF9QQVRIJTNEJTJGcGF0aCUyRnRvJTJGb3BlbmFpLWNvbW11bml0eSUyRmdwdDIlMkZwcmV0cmFpbmVkJTJGd2VpZ2h0cyUwQSUwQXRyYW5zZm9ybWVycy1jbGklMjBjb252ZXJ0JTIwLS1tb2RlbF90eXBlJTIwb3BlbmFpLWNvbW11bml0eSUyRmdwdDIlMjAlNUMlMEElMjAlMjAtLXRmX2NoZWNrcG9pbnQlMjAlMjRPUEVOQUlfR1BUMl9DSEVDS1BPSU5UX1BBVEglMjAlNUMlMEElMjAlMjAtLXB5dG9yY2hfZHVtcF9vdXRwdXQlMjAlMjRQWVRPUkNIX0RVTVBfT1VUUFVUJTIwJTVDJTBBJTIwJTIwJTVCLS1jb25maWclMjBPUEVOQUlfR1BUMl9DT05GSUclNUQlMjAlNUMlMEElMjAlMjAlNUItLWZpbmV0dW5pbmdfdGFza19uYW1lJTIwT1BFTkFJX0dQVDJfRklORVRVTkVEX1RBU0slNUQ=",highlighted:`<span class="hljs-built_in">export</span> OPENAI_GPT2_CHECKPOINT_PATH=/path/to/openai-community/gpt2/pretrained/weights

transformers-cli convert --model_type openai-community/gpt2 \\
  --tf_checkpoint <span class="hljs-variable">$OPENAI_GPT2_CHECKPOINT_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--config OPENAI_GPT2_CONFIG] \\
  [--finetuning_task_name OPENAI_GPT2_FINETUNED_TASK]`,wrap:!1}}),G=new y({props:{title:"XLNet",local:"xlnet",headingTag:"h2"}}),H=new K({props:{code:"ZXhwb3J0JTIwVFJBTlNGT19YTF9DSEVDS1BPSU5UX1BBVEglM0QlMkZwYXRoJTJGdG8lMkZ4bG5ldCUyRmNoZWNrcG9pbnQlMEFleHBvcnQlMjBUUkFOU0ZPX1hMX0NPTkZJR19QQVRIJTNEJTJGcGF0aCUyRnRvJTJGeGxuZXQlMkZjb25maWclMEElMEF0cmFuc2Zvcm1lcnMtY2xpJTIwY29udmVydCUyMC0tbW9kZWxfdHlwZSUyMHhsbmV0JTIwJTVDJTBBJTIwJTIwLS10Zl9jaGVja3BvaW50JTIwJTI0VFJBTlNGT19YTF9DSEVDS1BPSU5UX1BBVEglMjAlNUMlMEElMjAlMjAtLWNvbmZpZyUyMCUyNFRSQU5TRk9fWExfQ09ORklHX1BBVEglMjAlNUMlMEElMjAlMjAtLXB5dG9yY2hfZHVtcF9vdXRwdXQlMjAlMjRQWVRPUkNIX0RVTVBfT1VUUFVUJTIwJTVDJTBBJTIwJTIwJTVCLS1maW5ldHVuaW5nX3Rhc2tfbmFtZSUyMFhMTkVUX0ZJTkVUVU5FRF9UQVNLJTVEJTIwJTVD",highlighted:`<span class="hljs-built_in">export</span> TRANSFO_XL_CHECKPOINT_PATH=/path/to/xlnet/checkpoint
<span class="hljs-built_in">export</span> TRANSFO_XL_CONFIG_PATH=/path/to/xlnet/config

transformers-cli convert --model_type xlnet \\
  --tf_checkpoint <span class="hljs-variable">$TRANSFO_XL_CHECKPOINT_PATH</span> \\
  --config <span class="hljs-variable">$TRANSFO_XL_CONFIG_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span> \\
  [--finetuning_task_name XLNET_FINETUNED_TASK] \\`,wrap:!1}}),W=new y({props:{title:"XLM",local:"xlm",headingTag:"h2"}}),D=new K({props:{code:"ZXhwb3J0JTIwWExNX0NIRUNLUE9JTlRfUEFUSCUzRCUyRnBhdGglMkZ0byUyRnhsbSUyRmNoZWNrcG9pbnQlMEElMEF0cmFuc2Zvcm1lcnMtY2xpJTIwY29udmVydCUyMC0tbW9kZWxfdHlwZSUyMHhsbSUyMCU1QyUwQSUyMCUyMC0tdGZfY2hlY2twb2ludCUyMCUyNFhMTV9DSEVDS1BPSU5UX1BBVEglMjAlNUMlMEElMjAlMjAtLXB5dG9yY2hfZHVtcF9vdXRwdXQlMjAlMjRQWVRPUkNIX0RVTVBfT1VUUFVUJTBBJTIwJTVCLS1jb25maWclMjBYTUxfQ09ORklHJTVEJTIwJTVDJTBBJTIwJTVCLS1maW5ldHVuaW5nX3Rhc2tfbmFtZSUyMFhNTF9GSU5FVFVORURfVEFTSyU1RA==",highlighted:`<span class="hljs-built_in">export</span> XLM_CHECKPOINT_PATH=/path/to/xlm/checkpoint

transformers-cli convert --model_type xlm \\
  --tf_checkpoint <span class="hljs-variable">$XLM_CHECKPOINT_PATH</span> \\
  --pytorch_dump_output <span class="hljs-variable">$PYTORCH_DUMP_OUTPUT</span>
 [--config XML_CONFIG] \\
 [--finetuning_task_name XML_FINETUNED_TASK]`,wrap:!1}}),Y=new y({props:{title:"T5",local:"t5",headingTag:"h2"}}),z=new K({props:{code:"ZXhwb3J0JTIwVDUlM0QlMkZwYXRoJTJGdG8lMkZ0NSUyRnVuY2FzZWRfTC0xMl9ILTc2OF9BLTEyJTBBJTBBdHJhbnNmb3JtZXJzLWNsaSUyMGNvbnZlcnQlMjAtLW1vZGVsX3R5cGUlMjB0NSUyMCU1QyUwQSUyMCUyMC0tdGZfY2hlY2twb2ludCUyMCUyNFQ1JTJGdDVfbW9kZWwuY2twdCUyMCU1QyUwQSUyMCUyMC0tY29uZmlnJTIwJTI0VDUlMkZ0NV9jb25maWcuanNvbiUyMCU1QyUwQSUyMCUyMC0tcHl0b3JjaF9kdW1wX291dHB1dCUyMCUyNFQ1JTJGcHl0b3JjaF9tb2RlbC5iaW4=",highlighted:`<span class="hljs-built_in">export</span> T5=/path/to/t5/uncased_L-12_H-768_A-12

transformers-cli convert --model_type t5 \\
  --tf_checkpoint <span class="hljs-variable">$T5</span>/t5_model.ckpt \\
  --config <span class="hljs-variable">$T5</span>/t5_config.json \\
  --pytorch_dump_output <span class="hljs-variable">$T5</span>/pytorch_model.bin`,wrap:!1}}),{c(){i=s("meta"),$=n(),M=s("p"),_=n(),m(b.$$.fragment),U=n(),J=s("p"),J.innerHTML=Pe,le=n(),m(h.$$.fragment),oe=n(),m(w.$$.fragment),ne=n(),v=s("p"),v.innerHTML=Ne,ae=n(),V=s("p"),V.innerHTML=Xe,se=n(),C=s("p"),C.innerHTML=ke,re=n(),R=s("p"),R.innerHTML=Le,pe=n(),E=s("p"),E.innerHTML=je,ie=n(),m(I.$$.fragment),me=n(),F=s("p"),F.innerHTML=Ae,ce=n(),m(B.$$.fragment),Te=n(),g=s("p"),g.innerHTML=Se,fe=n(),P=s("p"),P.innerHTML=Ze,de=n(),N=s("p"),N.innerHTML=xe,ue=n(),m(X.$$.fragment),Ue=n(),k=s("p"),k.innerHTML=Ge,_e=n(),m(L.$$.fragment),Je=n(),j=s("p"),j.innerHTML=Qe,Me=n(),m(A.$$.fragment),be=n(),m(S.$$.fragment),he=n(),Z=s("p"),Z.innerHTML=He,ye=n(),m(x.$$.fragment),$e=n(),m(G.$$.fragment),we=n(),Q=s("p"),Q.textContent=We,ve=n(),m(H.$$.fragment),Ve=n(),m(W.$$.fragment),Ce=n(),O=s("p"),O.textContent=Oe,Re=n(),m(D.$$.fragment),Ee=n(),m(Y.$$.fragment),Ie=n(),q=s("p"),q.textContent=De,Fe=n(),m(z.$$.fragment),Be=n(),ee=s("p"),this.h()},l(e){const t=nt("svelte-u9bgzb",document.head);i=r(t,"META",{name:!0,content:!0}),t.forEach(l),$=a(e),M=r(e,"P",{}),qe(M).forEach(l),_=a(e),c(b.$$.fragment,e),U=a(e),J=r(e,"P",{"data-svelte-h":!0}),p(J)!=="svelte-p2yt92"&&(J.innerHTML=Pe),le=a(e),c(h.$$.fragment,e),oe=a(e),c(w.$$.fragment,e),ne=a(e),v=r(e,"P",{"data-svelte-h":!0}),p(v)!=="svelte-r87t7w"&&(v.innerHTML=Ne),ae=a(e),V=r(e,"P",{"data-svelte-h":!0}),p(V)!=="svelte-cbmmh7"&&(V.innerHTML=Xe),se=a(e),C=r(e,"P",{"data-svelte-h":!0}),p(C)!=="svelte-b84z4n"&&(C.innerHTML=ke),re=a(e),R=r(e,"P",{"data-svelte-h":!0}),p(R)!=="svelte-kemlzt"&&(R.innerHTML=Le),pe=a(e),E=r(e,"P",{"data-svelte-h":!0}),p(E)!=="svelte-10rkvg8"&&(E.innerHTML=je),ie=a(e),c(I.$$.fragment,e),me=a(e),F=r(e,"P",{"data-svelte-h":!0}),p(F)!=="svelte-12fpvhp"&&(F.innerHTML=Ae),ce=a(e),c(B.$$.fragment,e),Te=a(e),g=r(e,"P",{"data-svelte-h":!0}),p(g)!=="svelte-19k3jdm"&&(g.innerHTML=Se),fe=a(e),P=r(e,"P",{"data-svelte-h":!0}),p(P)!=="svelte-zkcyaa"&&(P.innerHTML=Ze),de=a(e),N=r(e,"P",{"data-svelte-h":!0}),p(N)!=="svelte-73nhvy"&&(N.innerHTML=xe),ue=a(e),c(X.$$.fragment,e),Ue=a(e),k=r(e,"P",{"data-svelte-h":!0}),p(k)!=="svelte-1jgcpzg"&&(k.innerHTML=Ge),_e=a(e),c(L.$$.fragment,e),Je=a(e),j=r(e,"P",{"data-svelte-h":!0}),p(j)!=="svelte-15p0tsr"&&(j.innerHTML=Qe),Me=a(e),c(A.$$.fragment,e),be=a(e),c(S.$$.fragment,e),he=a(e),Z=r(e,"P",{"data-svelte-h":!0}),p(Z)!=="svelte-51129x"&&(Z.innerHTML=He),ye=a(e),c(x.$$.fragment,e),$e=a(e),c(G.$$.fragment,e),we=a(e),Q=r(e,"P",{"data-svelte-h":!0}),p(Q)!=="svelte-14ewucc"&&(Q.textContent=We),ve=a(e),c(H.$$.fragment,e),Ve=a(e),c(W.$$.fragment,e),Ce=a(e),O=r(e,"P",{"data-svelte-h":!0}),p(O)!=="svelte-1nhafvs"&&(O.textContent=Oe),Re=a(e),c(D.$$.fragment,e),Ee=a(e),c(Y.$$.fragment,e),Ie=a(e),q=r(e,"P",{"data-svelte-h":!0}),p(q)!=="svelte-5kcfwq"&&(q.textContent=De),Fe=a(e),c(z.$$.fragment,e),Be=a(e),ee=r(e,"P",{}),qe(ee).forEach(l),this.h()},h(){ze(i,"name","hf:doc:metadata"),ze(i,"content",it)},m(e,t){at(document.head,i),o(e,$,t),o(e,M,t),o(e,_,t),T(b,e,t),o(e,U,t),o(e,J,t),o(e,le,t),T(h,e,t),o(e,oe,t),T(w,e,t),o(e,ne,t),o(e,v,t),o(e,ae,t),o(e,V,t),o(e,se,t),o(e,C,t),o(e,re,t),o(e,R,t),o(e,pe,t),o(e,E,t),o(e,ie,t),T(I,e,t),o(e,me,t),o(e,F,t),o(e,ce,t),T(B,e,t),o(e,Te,t),o(e,g,t),o(e,fe,t),o(e,P,t),o(e,de,t),o(e,N,t),o(e,ue,t),T(X,e,t),o(e,Ue,t),o(e,k,t),o(e,_e,t),T(L,e,t),o(e,Je,t),o(e,j,t),o(e,Me,t),T(A,e,t),o(e,be,t),T(S,e,t),o(e,he,t),o(e,Z,t),o(e,ye,t),T(x,e,t),o(e,$e,t),T(G,e,t),o(e,we,t),o(e,Q,t),o(e,ve,t),T(H,e,t),o(e,Ve,t),T(W,e,t),o(e,Ce,t),o(e,O,t),o(e,Re,t),T(D,e,t),o(e,Ee,t),T(Y,e,t),o(e,Ie,t),o(e,q,t),o(e,Fe,t),T(z,e,t),o(e,Be,t),o(e,ee,t),ge=!0},p(e,[t]){const Ye={};t&2&&(Ye.$$scope={dirty:t,ctx:e}),h.$set(Ye)},i(e){ge||(f(b.$$.fragment,e),f(h.$$.fragment,e),f(w.$$.fragment,e),f(I.$$.fragment,e),f(B.$$.fragment,e),f(X.$$.fragment,e),f(L.$$.fragment,e),f(A.$$.fragment,e),f(S.$$.fragment,e),f(x.$$.fragment,e),f(G.$$.fragment,e),f(H.$$.fragment,e),f(W.$$.fragment,e),f(D.$$.fragment,e),f(Y.$$.fragment,e),f(z.$$.fragment,e),ge=!0)},o(e){d(b.$$.fragment,e),d(h.$$.fragment,e),d(w.$$.fragment,e),d(I.$$.fragment,e),d(B.$$.fragment,e),d(X.$$.fragment,e),d(L.$$.fragment,e),d(A.$$.fragment,e),d(S.$$.fragment,e),d(x.$$.fragment,e),d(G.$$.fragment,e),d(H.$$.fragment,e),d(W.$$.fragment,e),d(D.$$.fragment,e),d(Y.$$.fragment,e),d(z.$$.fragment,e),ge=!1},d(e){e&&(l($),l(M),l(_),l(U),l(J),l(le),l(oe),l(ne),l(v),l(ae),l(V),l(se),l(C),l(re),l(R),l(pe),l(E),l(ie),l(me),l(F),l(ce),l(Te),l(g),l(fe),l(P),l(de),l(N),l(ue),l(Ue),l(k),l(_e),l(Je),l(j),l(Me),l(be),l(he),l(Z),l(ye),l($e),l(we),l(Q),l(ve),l(Ve),l(Ce),l(O),l(Re),l(Ee),l(Ie),l(q),l(Fe),l(Be),l(ee)),l(i),u(b,e),u(h,e),u(w,e),u(I,e),u(B,e),u(X,e),u(L,e),u(A,e),u(S,e),u(x,e),u(G,e),u(H,e),u(W,e),u(D,e),u(Y,e),u(z,e)}}}const it='{"title":"Convertendo checkpoints do TensorFlow para Pytorch","local":"convertendo-checkpoints-do-tensorflow-para-pytorch","sections":[{"title":"BERT","local":"bert","sections":[],"depth":2},{"title":"ALBERT","local":"albert","sections":[],"depth":2},{"title":"OpenAI GPT","local":"openai-gpt","sections":[],"depth":2},{"title":"OpenAI GPT-2","local":"openai-gpt-2","sections":[],"depth":2},{"title":"XLNet","local":"xlnet","sections":[],"depth":2},{"title":"XLM","local":"xlm","sections":[],"depth":2},{"title":"T5","local":"t5","sections":[],"depth":2}],"depth":1}';function mt(te){return et(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ut extends lt{constructor(i){super(),ot(this,i,mt,pt,Ke,{})}}export{Ut as component};
