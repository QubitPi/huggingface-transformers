import{s as Ss,o as Os,n as W}from"../chunks/scheduler.d586627e.js";import{S as Ds,i as Ks,g as j,s as i,r as d,A as ea,h as y,f as l,c as m,j as Ys,u as $,x as w,k as Ps,y as ta,a as n,v as g,d as b,t as M,w as h}from"../chunks/index.8589a59c.js";import{T as Pe}from"../chunks/Tip.84e2336e.js";import{Y as Qs}from"../chunks/Youtube.49101e7b.js";import{C as J}from"../chunks/CodeBlock.47c46d2c.js";import{D as sa}from"../chunks/DocNotebookDropdown.43d2c946.js";import{F as Ye,M as V}from"../chunks/Markdown.67fc2fa9.js";import{H as P}from"../chunks/Heading.a70e045b.js";function aa(T){let s,r="Todos os exemplos de c√≥digo apresentados na documenta√ß√£o t√™m um bot√£o no canto superior direito para escolher se voc√™ deseja ocultar ou mostrar o c√≥digo no Pytorch ou no TensorFlow. Caso contr√°rio, √© esperado que funcione para ambos back-ends sem nenhuma altera√ß√£o.";return{c(){s=j("p"),s.textContent=r},l(t){s=y(t,"P",{"data-svelte-h":!0}),w(s)!=="svelte-1ljjkwj"&&(s.textContent=r)},m(t,o){n(t,s,o)},p:W,d(t){t&&l(s)}}}function la(T){let s,r='Para mais detalhes sobre a <code>pipeline()</code> e tarefas associadas, siga a documenta√ß√£o <a href="./main_classes/pipelines">aqui</a>.';return{c(){s=j("p"),s.innerHTML=r},l(t){s=y(t,"P",{"data-svelte-h":!0}),w(s)!=="svelte-1fmvm8q"&&(s.innerHTML=r)},m(t,o){n(t,s,o)},p:W,d(t){t&&l(s)}}}function na(T){let s,r;return s=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRvcmNo",highlighted:"pip install torch",wrap:!1}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p:W,i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function oa(T){let s,r;return s=new V({props:{$$slots:{default:[na]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function ra(T){let s,r;return s=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRlbnNvcmZsb3c=",highlighted:"pip install tensorflow",wrap:!1}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p:W,i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function pa(T){let s,r;return s=new V({props:{$$slots:{default:[ra]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function ia(T){let s,r="Use o <code>AutoModelForSequenceClassification</code> e <code>AutoTokenizer</code> para carregar o modelo pr√©-treinado e seu tokenizer associado (mais em <code>AutoClass</code> abaixo):",t,o,c;return o=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=r,t=i(),d(o.$$.fragment)},l(f){s=y(f,"P",{"data-svelte-h":!0}),w(s)!=="svelte-mrbtrh"&&(s.innerHTML=r),t=m(f),$(o.$$.fragment,f)},m(f,k){n(f,s,k),n(f,t,k),g(o,f,k),c=!0},p:W,i(f){c||(b(o.$$.fragment,f),c=!0)},o(f){M(o.$$.fragment,f),c=!1},d(f){f&&(l(s),l(t)),h(o,f)}}}function ma(T){let s,r;return s=new V({props:{$$slots:{default:[ia]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function ca(T){let s,r="Use o <code>TFAutoModelForSequenceClassification</code> and <code>AutoTokenizer</code> para carregar o modelo pr√©-treinado e o tokenizer associado (mais em <code>TFAutoClass</code> abaixo):",t,o,c;return o=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQobW9kZWxfbmFtZSklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=r,t=i(),d(o.$$.fragment)},l(f){s=y(f,"P",{"data-svelte-h":!0}),w(s)!=="svelte-eex01d"&&(s.innerHTML=r),t=m(f),$(o.$$.fragment,f)},m(f,k){n(f,s,k),n(f,t,k),g(o,f,k),c=!0},p:W,i(f){c||(b(o.$$.fragment,f),c=!0)},o(f){M(o.$$.fragment,f),c=!1},d(f){f&&(l(s),l(t)),h(o,f)}}}function ua(T){let s,r;return s=new V({props:{$$slots:{default:[ca]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function fa(T){let s,r;return s=new J({props:{code:"cHRfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjB0cmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the ü§ó transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p:W,i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function da(T){let s,r;return s=new V({props:{$$slots:{default:[fa]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function $a(T){let s,r;return s=new J({props:{code:"dGZfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p:W,i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function ga(T){let s,r;return s=new V({props:{$$slots:{default:[$a]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function ba(T){let s,r='Veja o <a href="./task_summary">sum√°rio de tarefas</a> para qual classe de <code>AutoModel</code> usar para cada tarefa.';return{c(){s=j("p"),s.innerHTML=r},l(t){s=y(t,"P",{"data-svelte-h":!0}),w(s)!=="svelte-181ssur"&&(s.innerHTML=r)},m(t,o){n(t,s,o)},p:W,d(t){t&&l(s)}}}function Ma(T){let s,r="ü§ó Transformers fornecem uma maneira simples e unificada de carregar inst√¢ncias pr√©-treinadas. Isso significa que voc√™ pode carregar um <code>AutoModel</code> como carregaria um <code>AutoTokenizer</code>. A √∫nica diferen√ßa √© selecionar o <code>AutoModel</code> correto para a tarefa. Como voc√™ est√° fazendo classifica√ß√£o de texto ou sequ√™ncia, carregue <code>AutoModelForSequenceClassification</code>:",t,o,c,f,k,U,Z="Agora voc√™ pode passar seu grupo de entradas pr√©-processadas diretamente para o modelo. Voc√™ apenas tem que descompactar o dicion√°rio usando <code>**</code>:",H,u,_,x,I="O modelo gera as ativa√ß√µes finais no atributo <code>logits</code>. Aplique a fun√ß√£o softmax aos <code>logits</code> para recuperar as probabilidades:",R,C,G;return o=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEFwdF9tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),f=new Pe({props:{$$slots:{default:[ba]},$$scope:{ctx:T}}}),u=new J({props:{code:"cHRfb3V0cHV0cyUyMCUzRCUyMHB0X21vZGVsKCoqcHRfYmF0Y2gp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)',wrap:!1}}),C=new J({props:{code:"ZnJvbSUyMHRvcmNoJTIwaW1wb3J0JTIwbm4lMEElMEFwdF9wcmVkaWN0aW9ucyUyMCUzRCUyMG5uLmZ1bmN0aW9uYWwuc29mdG1heChwdF9vdXRwdXRzLmxvZ2l0cyUyQyUyMGRpbSUzRC0xKSUwQXByaW50KHB0X3ByZWRpY3Rpb25zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=r,t=i(),d(o.$$.fragment),c=i(),d(f.$$.fragment),k=i(),U=j("p"),U.innerHTML=Z,H=i(),d(u.$$.fragment),_=i(),x=j("p"),x.innerHTML=I,R=i(),d(C.$$.fragment)},l(p){s=y(p,"P",{"data-svelte-h":!0}),w(s)!=="svelte-7whysc"&&(s.innerHTML=r),t=m(p),$(o.$$.fragment,p),c=m(p),$(f.$$.fragment,p),k=m(p),U=y(p,"P",{"data-svelte-h":!0}),w(U)!=="svelte-zllcno"&&(U.innerHTML=Z),H=m(p),$(u.$$.fragment,p),_=m(p),x=y(p,"P",{"data-svelte-h":!0}),w(x)!=="svelte-1fy1tor"&&(x.innerHTML=I),R=m(p),$(C.$$.fragment,p)},m(p,v){n(p,s,v),n(p,t,v),g(o,p,v),n(p,c,v),g(f,p,v),n(p,k,v),n(p,U,v),n(p,H,v),g(u,p,v),n(p,_,v),n(p,x,v),n(p,R,v),g(C,p,v),G=!0},p(p,v){const F={};v&2&&(F.$$scope={dirty:v,ctx:p}),f.$set(F)},i(p){G||(b(o.$$.fragment,p),b(f.$$.fragment,p),b(u.$$.fragment,p),b(C.$$.fragment,p),G=!0)},o(p){M(o.$$.fragment,p),M(f.$$.fragment,p),M(u.$$.fragment,p),M(C.$$.fragment,p),G=!1},d(p){p&&(l(s),l(t),l(c),l(k),l(U),l(H),l(_),l(x),l(R)),h(o,p),h(f,p),h(u,p),h(C,p)}}}function ha(T){let s,r;return s=new V({props:{$$slots:{default:[Ma]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function Ta(T){let s,r='Veja o <a href="./task_summary">sum√°rio de tarefas</a> para qual classe de <code>AutoModel</code> usar para cada tarefa.';return{c(){s=j("p"),s.innerHTML=r},l(t){s=y(t,"P",{"data-svelte-h":!0}),w(s)!=="svelte-181ssur"&&(s.innerHTML=r)},m(t,o){n(t,s,o)},p:W,d(t){t&&l(s)}}}function ja(T){let s,r="ü§ó Transformers fornecem uma maneira simples e unificada de carregar inst√¢ncias pr√©-treinadas. Isso significa que voc√™ pode carregar um <code>TFAutoModel</code> como carregaria um <code>AutoTokenizer</code>. A √∫nica diferen√ßa √© selecionar o <code>TFAutoModel</code> correto para a tarefa. Como voc√™ est√° fazendo classifica√ß√£o de texto ou sequ√™ncia, carregue <code>TFAutoModelForSequenceClassification</code>:",t,o,c,f,k,U,Z="Agora voc√™ pode passar seu grupo de entradas pr√©-processadas diretamente para o modelo atrav√©s da passagem de chaves de dicion√°rios ao tensor.",H,u,_,x,I="O modelo gera as ativa√ß√µes finais no atributo <code>logits</code>. Aplique a fun√ß√£o softmax aos <code>logits</code> para recuperar as probabilidades:",R,C,G;return o=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsX25hbWUlMjAlM0QlMjAlMjJubHB0b3duJTJGYmVydC1iYXNlLW11bHRpbGluZ3VhbC11bmNhc2VkLXNlbnRpbWVudCUyMiUwQXRmX21vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),f=new Pe({props:{$$slots:{default:[Ta]},$$scope:{ctx:T}}}),u=new J({props:{code:"dGZfb3V0cHV0cyUyMCUzRCUyMHRmX21vZGVsKHRmX2JhdGNoKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)',wrap:!1}}),C=new J({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9wcmVkaWN0aW9ucyUyMCUzRCUyMHRmLm5uLnNvZnRtYXgodGZfb3V0cHV0cy5sb2dpdHMlMkMlMjBheGlzJTNELTEpJTBBdGZfcHJlZGljdGlvbnM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=r,t=i(),d(o.$$.fragment),c=i(),d(f.$$.fragment),k=i(),U=j("p"),U.textContent=Z,H=i(),d(u.$$.fragment),_=i(),x=j("p"),x.innerHTML=I,R=i(),d(C.$$.fragment)},l(p){s=y(p,"P",{"data-svelte-h":!0}),w(s)!=="svelte-lvio4u"&&(s.innerHTML=r),t=m(p),$(o.$$.fragment,p),c=m(p),$(f.$$.fragment,p),k=m(p),U=y(p,"P",{"data-svelte-h":!0}),w(U)!=="svelte-squwcf"&&(U.textContent=Z),H=m(p),$(u.$$.fragment,p),_=m(p),x=y(p,"P",{"data-svelte-h":!0}),w(x)!=="svelte-1fy1tor"&&(x.innerHTML=I),R=m(p),$(C.$$.fragment,p)},m(p,v){n(p,s,v),n(p,t,v),g(o,p,v),n(p,c,v),g(f,p,v),n(p,k,v),n(p,U,v),n(p,H,v),g(u,p,v),n(p,_,v),n(p,x,v),n(p,R,v),g(C,p,v),G=!0},p(p,v){const F={};v&2&&(F.$$scope={dirty:v,ctx:p}),f.$set(F)},i(p){G||(b(o.$$.fragment,p),b(f.$$.fragment,p),b(u.$$.fragment,p),b(C.$$.fragment,p),G=!0)},o(p){M(o.$$.fragment,p),M(f.$$.fragment,p),M(u.$$.fragment,p),M(C.$$.fragment,p),G=!1},d(p){p&&(l(s),l(t),l(c),l(k),l(U),l(H),l(_),l(x),l(R)),h(o,p),h(f,p),h(u,p),h(C,p)}}}function ya(T){let s,r;return s=new V({props:{$$slots:{default:[ja]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function wa(T){let s,r="Todos os modelos de ü§ó Transformers (PyTorch ou TensorFlow) geram tensores <em>antes</em> da fun√ß√£o de ativa√ß√£o final (como softmax) pois essa fun√ß√£o algumas vezes √© fundida com a perda.";return{c(){s=j("p"),s.innerHTML=r},l(t){s=y(t,"P",{"data-svelte-h":!0}),w(s)!=="svelte-16gt9lp"&&(s.innerHTML=r)},m(t,o){n(t,s,o)},p:W,d(t){t&&l(s)}}}function va(T){let s,r=`As sa√≠das do modelo ü§ó Transformers s√£o classes de dados especiais para que seus atributos sejam preenchidos automaticamente em um IDE.
As sa√≠das do modelo tamb√©m se comportam como uma tupla ou um dicion√°rio (por exemplo, voc√™ pode indexar com um inteiro, uma parte ou uma string), caso em que os atributos <code>None</code> s√£o ignorados.`;return{c(){s=j("p"),s.innerHTML=r},l(t){s=y(t,"P",{"data-svelte-h":!0}),w(s)!=="svelte-xm0x0c"&&(s.innerHTML=r)},m(t,o){n(t,s,o)},p:W,d(t){t&&l(s)}}}function _a(T){let s,r="Uma vez que seu modelo estiver afinado, voc√™ pode salv√°-lo com seu Tokenizer usando <code>PreTrainedModel.save_pretrained()</code>:",t,o,c,f,k="Quando voc√™ estiver pronto para us√°-lo novamente, recarregue com <code>PreTrainedModel.from_pretrained()</code>:",U,Z,H;return o=new J({props:{code:"cHRfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZChwdF9zYXZlX2RpcmVjdG9yeSklMEFwdF9tb2RlbC5zYXZlX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`,wrap:!1}}),Z=new J({props:{code:"cHRfbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)',wrap:!1}}),{c(){s=j("p"),s.innerHTML=r,t=i(),d(o.$$.fragment),c=i(),f=j("p"),f.innerHTML=k,U=i(),d(Z.$$.fragment)},l(u){s=y(u,"P",{"data-svelte-h":!0}),w(s)!=="svelte-4bl5eb"&&(s.innerHTML=r),t=m(u),$(o.$$.fragment,u),c=m(u),f=y(u,"P",{"data-svelte-h":!0}),w(f)!=="svelte-xv8jxg"&&(f.innerHTML=k),U=m(u),$(Z.$$.fragment,u)},m(u,_){n(u,s,_),n(u,t,_),g(o,u,_),n(u,c,_),n(u,f,_),n(u,U,_),g(Z,u,_),H=!0},p:W,i(u){H||(b(o.$$.fragment,u),b(Z.$$.fragment,u),H=!0)},o(u){M(o.$$.fragment,u),M(Z.$$.fragment,u),H=!1},d(u){u&&(l(s),l(t),l(c),l(f),l(U)),h(o,u),h(Z,u)}}}function ka(T){let s,r;return s=new V({props:{$$slots:{default:[_a]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function Ua(T){let s,r="Uma vez que seu modelo estiver afinado, voc√™ pode salv√°-lo com seu Tokenizer usando <code>TFPreTrainedModel.save_pretrained()</code>:",t,o,c,f,k="Quando voc√™ estiver pronto para us√°-lo novamente, recarregue com <code>TFPreTrainedModel.from_pretrained()</code>",U,Z,H;return o=new J({props:{code:"dGZfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGdGZfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZCh0Zl9zYXZlX2RpcmVjdG9yeSklMEF0Zl9tb2RlbC5zYXZlX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`,wrap:!1}}),Z=new J({props:{code:"dGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMi4lMkZ0Zl9zYXZlX3ByZXRyYWluZWQlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)',wrap:!1}}),{c(){s=j("p"),s.innerHTML=r,t=i(),d(o.$$.fragment),c=i(),f=j("p"),f.innerHTML=k,U=i(),d(Z.$$.fragment)},l(u){s=y(u,"P",{"data-svelte-h":!0}),w(s)!=="svelte-8zixed"&&(s.innerHTML=r),t=m(u),$(o.$$.fragment,u),c=m(u),f=y(u,"P",{"data-svelte-h":!0}),w(f)!=="svelte-qousco"&&(f.innerHTML=k),U=m(u),$(Z.$$.fragment,u)},m(u,_){n(u,s,_),n(u,t,_),g(o,u,_),n(u,c,_),n(u,f,_),n(u,U,_),g(Z,u,_),H=!0},p:W,i(u){H||(b(o.$$.fragment,u),b(Z.$$.fragment,u),H=!0)},o(u){M(o.$$.fragment,u),M(Z.$$.fragment,u),H=!1},d(u){u&&(l(s),l(t),l(c),l(f),l(U)),h(o,u),h(Z,u)}}}function Ja(T){let s,r;return s=new V({props:{$$slots:{default:[Ua]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function Za(T){let s,r;return s=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKHRmX3NhdmVfZGlyZWN0b3J5KSUwQXB0X21vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3RvcnklMkMlMjBmcm9tX3RmJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p:W,i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function Ca(T){let s,r;return s=new V({props:{$$slots:{default:[Za]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function Ha(T){let s,r;return s=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3RvcnkpJTBBdGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKHB0X3NhdmVfZGlyZWN0b3J5JTJDJTIwZnJvbV9wdCUzRFRydWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p:W,i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function xa(T){let s,r;return s=new V({props:{$$slots:{default:[Ha]},$$scope:{ctx:T}}}),{c(){d(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,o){g(s,t,o),r=!0},p(t,o){const c={};o&2&&(c.$$scope={dirty:o,ctx:t}),s.$set(c)},i(t){r||(b(s.$$.fragment,t),r=!0)},o(t){M(s.$$.fragment,t),r=!1},d(t){h(s,t)}}}function Wa(T){let s,r,t,o,c,f,k,U,Z,H='Comece a trabalhar com ü§ó Transformers! Comece usando <code>pipeline()</code> para r√°pida infer√™ncia e facilmente carregue um modelo pr√©-treinado e um tokenizer com <a href="./model_doc/auto">AutoClass</a> para resolver tarefas de texto, vis√£o ou √°udio.',u,_,x,I,R,C,G="<code>pipeline()</code> √© a maneira mais f√°cil de usar um modelo pr√©-treinado para uma dada tarefa.",p,v,F,Q,ls="A <code>pipeline()</code> apoia diversas tarefas fora da caixa:",Se,S,ns="<strong>Texto</strong>:",Oe,O,os="<li>An√°lise sentimental: classifica a polaridade de um texto.</li> <li>Gera√ß√£o de texto (em Ingl√™s): gera texto a partir de uma entrada.</li> <li>Reconhecimento de entidade mencionada: legenda cada palavra com uma classe que a representa (pessoa, data, local, etc‚Ä¶)</li> <li>Respostas: extrai uma resposta dado algum contexto e uma quest√£o</li> <li>M√°scara de preenchimento: preenche o espa√ßo, dado um texto com m√°scaras de palavras.</li> <li>Sumariza√ß√£o: gera o resumo de um texto longo ou documento.</li> <li>Tradu√ß√£o: traduz texto para outra l√≠ngua.</li> <li>Extra√ß√£o de caracter√≠sticas: cria um tensor que representa o texto.</li>",De,D,rs="<strong>Imagem</strong>:",Ke,K,ps="<li>Classifica√ß√£o de imagens: classifica uma imagem.</li> <li>Segmenta√ß√£o de imagem: classifica cada pixel da imagem.</li> <li>Detec√ß√£o de objetos: detecta objetos em uma imagem.</li>",et,ee,is="<strong>Audio</strong>:",tt,te,ms="<li>Classfica√ß√£o de √°udio: legenda um trecho de √°udio fornecido.</li> <li>Reconhecimento de fala autom√°tico: transcreve audio em texto.</li>",st,z,at,se,lt,ae,cs="No exemplo a seguir, voc√™ usar√° <code>pipeline()</code> para an√°lise sentimental.",nt,le,us="Instale as seguintes depend√™ncias se voc√™ ainda n√£o o fez:",ot,N,rt,ne,fs="Importe <code>pipeline()</code> e especifique a tarefa que deseja completar:",pt,oe,it,re,ds='A pipeline baixa and armazena um <a href="https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english" rel="nofollow">modelo pr√©-treinado</a> padr√£o e tokenizer para an√°lise sentimental. Agora voc√™ pode usar <code>classifier</code> no texto alvo:',mt,pe,ct,ie,$s="Para mais de uma senten√ßa, passe uma lista para a <code>pipeline()</code>, a qual retornar√° uma lista de dicion√°rios:",ut,me,ft,ce,gs='A <code>pipeline()</code> tamb√©m pode iterar sobre um Dataset inteiro. Comece instalando a biblioteca de <a href="https://huggingface.co/docs/datasets/" rel="nofollow">ü§ó Datasets</a>:',dt,ue,$t,fe,bs="Crie uma <code>pipeline()</code> com a tarefa que deseja resolver e o modelo que deseja usar.",gt,de,bt,$e,Ms='A seguir, carregue uma base de dados (confira a ü§ó <a href="https://huggingface.co/docs/datasets/quickstart" rel="nofollow">Inicia√ß√£o em Datasets</a> para mais detalhes) que voc√™ gostaria de iterar sobre. Por exemplo, vamos carregar o dataset <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a>:',Mt,ge,ht,be,hs="Precisamos garantir que a taxa de amostragem do conjunto de dados corresponda √† taxa de amostragem em que o facebook/wav2vec2-base-960h foi treinado.",Tt,Me,jt,he,Ts=`Os arquivos de √°udio s√£o carregados e re-amostrados automaticamente ao chamar a coluna <code>&quot;audio&quot;</code>.
Vamos extrair as arrays de formas de onda originais das primeiras 4 amostras e pass√°-las como uma lista para o pipeline:`,yt,Te,wt,je,js='Para um conjunto de dados maior onde as entradas s√£o maiores (como em fala ou vis√£o), ser√° necess√°rio passar um gerador em vez de uma lista que carregue todas as entradas na mem√≥ria. Consulte a <a href="./main_classes/pipelines">documenta√ß√£o do pipeline</a> para mais informa√ß√µes.',vt,ye,_t,we,ys='A <code>pipeline()</code> pode acomodar qualquer modelo do <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>, facilitando sua adapta√ß√£o para outros casos de uso. Por exemplo, se voc√™ quiser um modelo capaz de lidar com texto em franc√™s, use as tags no Model Hub para filtrar um modelo apropriado. O principal resultado filtrado retorna um <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment" rel="nofollow">modelo BERT</a> bil√≠ngue ajustado para an√°lise de sentimentos. √ìtimo, vamos usar este modelo!',kt,ve,Ut,q,Jt,_e,ws="Ent√£o voc√™ pode especificar o modelo e o tokenizador na <code>pipeline()</code> e aplicar o <code>classifier</code> no seu texto alvo:",Zt,ke,Ct,Ue,vs='Se voc√™ n√£o conseguir achar um modelo para o seu caso de uso, precisar√° usar fine-tune em um modelo pr√©-treinado nos seus dados. Veja nosso <a href="./training">tutorial de fine-tuning</a> para descobrir como. Finalmente, depois que voc√™ tiver usado esse processo em seu modelo, considere compartilh√°-lo conosco (veja o tutorial <a href="./model_sharing">aqui</a>) na plataforma Model Hub afim de democratizar NLP! ü§ó',Ht,Je,xt,Ze,Wt,Ce,_s='Por baixo dos panos, as classes <code>AutoModelForSequenceClassification</code> e <code>AutoTokenizer</code> trabalham juntas para fortificar o <code>pipeline()</code>. Um <a href="./model_doc/auto">AutoClass</a> √© um atalho que automaticamente recupera a arquitetura de um modelo pr√©-treinado a partir de seu nome ou caminho. Basta selecionar a <code>AutoClass</code> apropriada para sua tarefa e seu tokenizer associado com <code>AutoTokenizer</code>.',Rt,He,ks="Vamos voltar ao nosso exemplo e ver como voc√™ pode usar a <code>AutoClass</code> para replicar os resultados do <code>pipeline()</code>.",It,xe,Gt,We,Us='Um tokenizer √© respons√°vel por pr√©-processar o texto em um formato que seja compreens√≠vel para o modelo. Primeiro, o tokenizer dividir√° o texto em palavras chamadas <em>tokens</em>. Existem v√°rias regras que regem o processo de tokeniza√ß√£o, incluindo como dividir uma palavra e em que n√≠vel (saiba mais sobre tokeniza√ß√£o <a href="./tokenizer_summary">aqui</a>). A coisa mais importante a lembrar, por√©m, √© que voc√™ precisa instanciar o tokenizer com o mesmo nome do modelo para garantir que est√° usando as mesmas regras de tokeniza√ß√£o com as quais um modelo foi pr√©-treinado.',Vt,Re,Js="Carregue um tokenizer com <code>AutoTokenizer</code>:",Ft,Ie,zt,Ge,Zs="Em seguida, o tokenizer converte os tokens em n√∫meros para construir um tensor como entrada para o modelo. Isso √© conhecido como o <em>vocabul√°rio</em> do modelo.",Nt,Ve,Cs="Passe o texto para o tokenizer:",qt,Fe,Xt,ze,Hs="O tokenizer retornar√° um dicion√°rio contendo:",At,Ne,xs='<li><a href="./glossary#input-ids">input_ids</a>: representa√ß√µes num√©ricas de seus tokens.</li> <li><a href=".glossary#attention-mask">atttention_mask</a>: indica quais tokens devem ser atendidos.</li>',Lt,qe,Ws="Assim como o <code>pipeline()</code>, o tokenizer aceitar√° uma lista de entradas. Al√©m disso, o tokenizer tamb√©m pode preencher e truncar o texto para retornar um lote com comprimento uniforme:",Bt,X,Et,Xe,Rs='Leia o tutorial de <a href="./pr%C3%A9-processamento">pr√©-processamento</a> para obter mais detalhes sobre tokeniza√ß√£o.',Yt,Ae,Pt,A,Qt,L,St,Le,Is='Os modelos s√£o um standard <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow"><code>torch.nn.Module</code></a> ou um <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow"><code>tf.keras.Model</code></a> para que voc√™ possa us√°-los em seu loop de treinamento habitual. No entanto, para facilitar as coisas, ü§ó Transformers fornece uma classe <code>Trainer</code> para PyTorch que adiciona funcionalidade para treinamento distribu√≠do, precis√£o mista e muito mais. Para o TensorFlow, voc√™ pode usar o m√©todo <code>fit</code> de <a href="https://keras.io/" rel="nofollow">Keras</a>. Consulte o <a href="./training">tutorial de treinamento</a> para obter mais detalhes.',Ot,B,Dt,Be,Kt,E,es,Ee,Gs="Um recurso particularmente interessante dos ü§ó Transformers √© a capacidade de salvar um modelo e recarreg√°-lo como um modelo PyTorch ou TensorFlow. Use <code>from_pt</code> ou <code>from_tf</code> para converter o modelo de um framework para outro:",ts,Y,ss,Qe,as;return c=new P({props:{title:"Tour r√°pido",local:"tour-r√°pido",headingTag:"h1"}}),k=new sa({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/pt/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/pt/tensorflow/quicktour.ipynb"}]}}),_=new Pe({props:{$$slots:{default:[aa]},$$scope:{ctx:T}}}),I=new P({props:{title:"Pipeline",local:"pipeline",headingTag:"h2"}}),v=new Qs({props:{id:"tiZFewofSLM"}}),z=new Pe({props:{$$slots:{default:[la]},$$scope:{ctx:T}}}),se=new P({props:{title:"Uso da pipeline",local:"uso-da-pipeline",headingTag:"h3"}}),N=new Ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pa],pytorch:[oa]},$$scope:{ctx:T}}}),oe=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnNlbnRpbWVudC1hbmFseXNpcyUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`,wrap:!1}}),pe=new J({props:{code:"Y2xhc3NpZmllciglMjJXZSUyMGFyZSUyMHZlcnklMjBoYXBweSUyMHRvJTIwc2hvdyUyMHlvdSUyMHRoZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycyUyMGxpYnJhcnkuJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`,wrap:!1}}),me=new J({props:{code:"cmVzdWx0cyUyMCUzRCUyMGNsYXNzaWZpZXIoJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCklMEFmb3IlMjByZXN1bHQlMjBpbiUyMHJlc3VsdHMlM0ElMEElMjAlMjAlMjAlMjBwcmludChmJTIybGFiZWwlM0ElMjAlN0JyZXN1bHQlNUInbGFiZWwnJTVEJTdEJTJDJTIwd2l0aCUyMHNjb3JlJTNBJTIwJTdCcm91bmQocmVzdWx0JTVCJ3Njb3JlJyU1RCUyQyUyMDQpJTdEJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`,wrap:!1}}),ue=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRzJTIw",highlighted:"pip install datasets ",wrap:!1}}),de=new J({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwcGlwZWxpbmUlMEElMEFzcGVlY2hfcmVjb2duaXplciUyMCUzRCUyMHBpcGVsaW5lKCUyMmF1dG9tYXRpYy1zcGVlY2gtcmVjb2duaXRpb24lMjIlMkMlMjBtb2RlbCUzRCUyMmZhY2Vib29rJTJGd2F2MnZlYzItYmFzZS05NjBoJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`,wrap:!1}}),ge=new J({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjBuYW1lJTNEJTIyZW4tVVMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),Me=new J({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEc3BlZWNoX3JlY29nbml6ZXIuZmVhdHVyZV9leHRyYWN0b3Iuc2FtcGxpbmdfcmF0ZSkp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',wrap:!1}}),Te=new J({props:{code:"cmVzdWx0JTIwJTNEJTIwc3BlZWNoX3JlY29nbml6ZXIoZGF0YXNldCU1QiUzQTQlNUQlNUIlMjJhdWRpbyUyMiU1RCklMEFwcmludCglNUJkJTVCJTIydGV4dCUyMiU1RCUyMGZvciUyMGQlMjBpbiUyMHJlc3VsdCU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FONDERING HOW I&#x27;D SET UP A JOIN TO HET WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AND I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I TURN A JOIN A COUNT&#x27;</span>]`,wrap:!1}}),ye=new P({props:{title:"Use outro modelo e tokenizer na pipeline",local:"use-outro-modelo-e-tokenizer-na-pipeline",headingTag:"h3"}}),ve=new J({props:{code:"bW9kZWxfbmFtZSUyMCUzRCUyMCUyMm5scHRvd24lMkZiZXJ0LWJhc2UtbXVsdGlsaW5ndWFsLXVuY2FzZWQtc2VudGltZW50JTIy",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>',wrap:!1}}),q=new Ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ua],pytorch:[ma]},$$scope:{ctx:T}}}),ke=new J({props:{code:"Y2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnNlbnRpbWVudC1hbmFseXNpcyUyMiUyQyUyMG1vZGVsJTNEbW9kZWwlMkMlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIpJTBBY2xhc3NpZmllciglMjJOb3VzJTIwc29tbWVzJTIwdHIlQzMlQThzJTIwaGV1cmV1eCUyMGRlJTIwdm91cyUyMHByJUMzJUE5c2VudGVyJTIwbGElMjBiaWJsaW90aCVDMyVBOHF1ZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`,wrap:!1}}),Je=new P({props:{title:"AutoClass",local:"autoclass",headingTag:"h2"}}),Ze=new Qs({props:{id:"AhChOFRegn4"}}),xe=new P({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h3"}}),Ie=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),Fe=new J({props:{code:"ZW5jb2RpbmclMjAlM0QlMjB0b2tlbml6ZXIoJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiklMEFwcmludChlbmNvZGluZyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),X=new Ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ga],pytorch:[da]},$$scope:{ctx:T}}}),Ae=new P({props:{title:"AutoModel",local:"automodel",headingTag:"h3"}}),A=new Ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ya],pytorch:[ha]},$$scope:{ctx:T}}}),L=new Pe({props:{$$slots:{default:[wa]},$$scope:{ctx:T}}}),B=new Pe({props:{$$slots:{default:[va]},$$scope:{ctx:T}}}),Be=new P({props:{title:"Salvar um modelo",local:"salvar-um-modelo",headingTag:"h3"}}),E=new Ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ja],pytorch:[ka]},$$scope:{ctx:T}}}),Y=new Ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[xa],pytorch:[Ca]},$$scope:{ctx:T}}}),{c(){s=j("meta"),r=i(),t=j("p"),o=i(),d(c.$$.fragment),f=i(),d(k.$$.fragment),U=i(),Z=j("p"),Z.innerHTML=H,u=i(),d(_.$$.fragment),x=i(),d(I.$$.fragment),R=i(),C=j("p"),C.innerHTML=G,p=i(),d(v.$$.fragment),F=i(),Q=j("p"),Q.innerHTML=ls,Se=i(),S=j("p"),S.innerHTML=ns,Oe=i(),O=j("ul"),O.innerHTML=os,De=i(),D=j("p"),D.innerHTML=rs,Ke=i(),K=j("ul"),K.innerHTML=ps,et=i(),ee=j("p"),ee.innerHTML=is,tt=i(),te=j("ul"),te.innerHTML=ms,st=i(),d(z.$$.fragment),at=i(),d(se.$$.fragment),lt=i(),ae=j("p"),ae.innerHTML=cs,nt=i(),le=j("p"),le.textContent=us,ot=i(),d(N.$$.fragment),rt=i(),ne=j("p"),ne.innerHTML=fs,pt=i(),d(oe.$$.fragment),it=i(),re=j("p"),re.innerHTML=ds,mt=i(),d(pe.$$.fragment),ct=i(),ie=j("p"),ie.innerHTML=$s,ut=i(),d(me.$$.fragment),ft=i(),ce=j("p"),ce.innerHTML=gs,dt=i(),d(ue.$$.fragment),$t=i(),fe=j("p"),fe.innerHTML=bs,gt=i(),d(de.$$.fragment),bt=i(),$e=j("p"),$e.innerHTML=Ms,Mt=i(),d(ge.$$.fragment),ht=i(),be=j("p"),be.textContent=hs,Tt=i(),d(Me.$$.fragment),jt=i(),he=j("p"),he.innerHTML=Ts,yt=i(),d(Te.$$.fragment),wt=i(),je=j("p"),je.innerHTML=js,vt=i(),d(ye.$$.fragment),_t=i(),we=j("p"),we.innerHTML=ys,kt=i(),d(ve.$$.fragment),Ut=i(),d(q.$$.fragment),Jt=i(),_e=j("p"),_e.innerHTML=ws,Zt=i(),d(ke.$$.fragment),Ct=i(),Ue=j("p"),Ue.innerHTML=vs,Ht=i(),d(Je.$$.fragment),xt=i(),d(Ze.$$.fragment),Wt=i(),Ce=j("p"),Ce.innerHTML=_s,Rt=i(),He=j("p"),He.innerHTML=ks,It=i(),d(xe.$$.fragment),Gt=i(),We=j("p"),We.innerHTML=Us,Vt=i(),Re=j("p"),Re.innerHTML=Js,Ft=i(),d(Ie.$$.fragment),zt=i(),Ge=j("p"),Ge.innerHTML=Zs,Nt=i(),Ve=j("p"),Ve.textContent=Cs,qt=i(),d(Fe.$$.fragment),Xt=i(),ze=j("p"),ze.textContent=Hs,At=i(),Ne=j("ul"),Ne.innerHTML=xs,Lt=i(),qe=j("p"),qe.innerHTML=Ws,Bt=i(),d(X.$$.fragment),Et=i(),Xe=j("p"),Xe.innerHTML=Rs,Yt=i(),d(Ae.$$.fragment),Pt=i(),d(A.$$.fragment),Qt=i(),d(L.$$.fragment),St=i(),Le=j("p"),Le.innerHTML=Is,Ot=i(),d(B.$$.fragment),Dt=i(),d(Be.$$.fragment),Kt=i(),d(E.$$.fragment),es=i(),Ee=j("p"),Ee.innerHTML=Gs,ts=i(),d(Y.$$.fragment),ss=i(),Qe=j("p"),this.h()},l(e){const a=ea("svelte-u9bgzb",document.head);s=y(a,"META",{name:!0,content:!0}),a.forEach(l),r=m(e),t=y(e,"P",{}),Ys(t).forEach(l),o=m(e),$(c.$$.fragment,e),f=m(e),$(k.$$.fragment,e),U=m(e),Z=y(e,"P",{"data-svelte-h":!0}),w(Z)!=="svelte-19ws0vp"&&(Z.innerHTML=H),u=m(e),$(_.$$.fragment,e),x=m(e),$(I.$$.fragment,e),R=m(e),C=y(e,"P",{"data-svelte-h":!0}),w(C)!=="svelte-ap1vxy"&&(C.innerHTML=G),p=m(e),$(v.$$.fragment,e),F=m(e),Q=y(e,"P",{"data-svelte-h":!0}),w(Q)!=="svelte-v1jlo7"&&(Q.innerHTML=ls),Se=m(e),S=y(e,"P",{"data-svelte-h":!0}),w(S)!=="svelte-17b5j97"&&(S.innerHTML=ns),Oe=m(e),O=y(e,"UL",{"data-svelte-h":!0}),w(O)!=="svelte-kofyw6"&&(O.innerHTML=os),De=m(e),D=y(e,"P",{"data-svelte-h":!0}),w(D)!=="svelte-5igosj"&&(D.innerHTML=rs),Ke=m(e),K=y(e,"UL",{"data-svelte-h":!0}),w(K)!=="svelte-1hnvsxe"&&(K.innerHTML=ps),et=m(e),ee=y(e,"P",{"data-svelte-h":!0}),w(ee)!=="svelte-hdckv1"&&(ee.innerHTML=is),tt=m(e),te=y(e,"UL",{"data-svelte-h":!0}),w(te)!=="svelte-18jgspf"&&(te.innerHTML=ms),st=m(e),$(z.$$.fragment,e),at=m(e),$(se.$$.fragment,e),lt=m(e),ae=y(e,"P",{"data-svelte-h":!0}),w(ae)!=="svelte-16z6txq"&&(ae.innerHTML=cs),nt=m(e),le=y(e,"P",{"data-svelte-h":!0}),w(le)!=="svelte-10t8mna"&&(le.textContent=us),ot=m(e),$(N.$$.fragment,e),rt=m(e),ne=y(e,"P",{"data-svelte-h":!0}),w(ne)!=="svelte-mybi9w"&&(ne.innerHTML=fs),pt=m(e),$(oe.$$.fragment,e),it=m(e),re=y(e,"P",{"data-svelte-h":!0}),w(re)!=="svelte-8birgw"&&(re.innerHTML=ds),mt=m(e),$(pe.$$.fragment,e),ct=m(e),ie=y(e,"P",{"data-svelte-h":!0}),w(ie)!=="svelte-sfo6b9"&&(ie.innerHTML=$s),ut=m(e),$(me.$$.fragment,e),ft=m(e),ce=y(e,"P",{"data-svelte-h":!0}),w(ce)!=="svelte-11smqbr"&&(ce.innerHTML=gs),dt=m(e),$(ue.$$.fragment,e),$t=m(e),fe=y(e,"P",{"data-svelte-h":!0}),w(fe)!=="svelte-1vuj1s6"&&(fe.innerHTML=bs),gt=m(e),$(de.$$.fragment,e),bt=m(e),$e=y(e,"P",{"data-svelte-h":!0}),w($e)!=="svelte-3h0a86"&&($e.innerHTML=Ms),Mt=m(e),$(ge.$$.fragment,e),ht=m(e),be=y(e,"P",{"data-svelte-h":!0}),w(be)!=="svelte-1mdt5ng"&&(be.textContent=hs),Tt=m(e),$(Me.$$.fragment,e),jt=m(e),he=y(e,"P",{"data-svelte-h":!0}),w(he)!=="svelte-1khwp8j"&&(he.innerHTML=Ts),yt=m(e),$(Te.$$.fragment,e),wt=m(e),je=y(e,"P",{"data-svelte-h":!0}),w(je)!=="svelte-pfwuti"&&(je.innerHTML=js),vt=m(e),$(ye.$$.fragment,e),_t=m(e),we=y(e,"P",{"data-svelte-h":!0}),w(we)!=="svelte-1244j3j"&&(we.innerHTML=ys),kt=m(e),$(ve.$$.fragment,e),Ut=m(e),$(q.$$.fragment,e),Jt=m(e),_e=y(e,"P",{"data-svelte-h":!0}),w(_e)!=="svelte-u4j80r"&&(_e.innerHTML=ws),Zt=m(e),$(ke.$$.fragment,e),Ct=m(e),Ue=y(e,"P",{"data-svelte-h":!0}),w(Ue)!=="svelte-1so6bl7"&&(Ue.innerHTML=vs),Ht=m(e),$(Je.$$.fragment,e),xt=m(e),$(Ze.$$.fragment,e),Wt=m(e),Ce=y(e,"P",{"data-svelte-h":!0}),w(Ce)!=="svelte-w73gy6"&&(Ce.innerHTML=_s),Rt=m(e),He=y(e,"P",{"data-svelte-h":!0}),w(He)!=="svelte-8mu0lp"&&(He.innerHTML=ks),It=m(e),$(xe.$$.fragment,e),Gt=m(e),We=y(e,"P",{"data-svelte-h":!0}),w(We)!=="svelte-1r7bgf"&&(We.innerHTML=Us),Vt=m(e),Re=y(e,"P",{"data-svelte-h":!0}),w(Re)!=="svelte-htzi7v"&&(Re.innerHTML=Js),Ft=m(e),$(Ie.$$.fragment,e),zt=m(e),Ge=y(e,"P",{"data-svelte-h":!0}),w(Ge)!=="svelte-1ycpucd"&&(Ge.innerHTML=Zs),Nt=m(e),Ve=y(e,"P",{"data-svelte-h":!0}),w(Ve)!=="svelte-1sdhiod"&&(Ve.textContent=Cs),qt=m(e),$(Fe.$$.fragment,e),Xt=m(e),ze=y(e,"P",{"data-svelte-h":!0}),w(ze)!=="svelte-2yg451"&&(ze.textContent=Hs),At=m(e),Ne=y(e,"UL",{"data-svelte-h":!0}),w(Ne)!=="svelte-izgsxz"&&(Ne.innerHTML=xs),Lt=m(e),qe=y(e,"P",{"data-svelte-h":!0}),w(qe)!=="svelte-l3w9xh"&&(qe.innerHTML=Ws),Bt=m(e),$(X.$$.fragment,e),Et=m(e),Xe=y(e,"P",{"data-svelte-h":!0}),w(Xe)!=="svelte-13xfpe5"&&(Xe.innerHTML=Rs),Yt=m(e),$(Ae.$$.fragment,e),Pt=m(e),$(A.$$.fragment,e),Qt=m(e),$(L.$$.fragment,e),St=m(e),Le=y(e,"P",{"data-svelte-h":!0}),w(Le)!=="svelte-ae5w4x"&&(Le.innerHTML=Is),Ot=m(e),$(B.$$.fragment,e),Dt=m(e),$(Be.$$.fragment,e),Kt=m(e),$(E.$$.fragment,e),es=m(e),Ee=y(e,"P",{"data-svelte-h":!0}),w(Ee)!=="svelte-1jeo983"&&(Ee.innerHTML=Gs),ts=m(e),$(Y.$$.fragment,e),ss=m(e),Qe=y(e,"P",{}),Ys(Qe).forEach(l),this.h()},h(){Ps(s,"name","hf:doc:metadata"),Ps(s,"content",Ra)},m(e,a){ta(document.head,s),n(e,r,a),n(e,t,a),n(e,o,a),g(c,e,a),n(e,f,a),g(k,e,a),n(e,U,a),n(e,Z,a),n(e,u,a),g(_,e,a),n(e,x,a),g(I,e,a),n(e,R,a),n(e,C,a),n(e,p,a),g(v,e,a),n(e,F,a),n(e,Q,a),n(e,Se,a),n(e,S,a),n(e,Oe,a),n(e,O,a),n(e,De,a),n(e,D,a),n(e,Ke,a),n(e,K,a),n(e,et,a),n(e,ee,a),n(e,tt,a),n(e,te,a),n(e,st,a),g(z,e,a),n(e,at,a),g(se,e,a),n(e,lt,a),n(e,ae,a),n(e,nt,a),n(e,le,a),n(e,ot,a),g(N,e,a),n(e,rt,a),n(e,ne,a),n(e,pt,a),g(oe,e,a),n(e,it,a),n(e,re,a),n(e,mt,a),g(pe,e,a),n(e,ct,a),n(e,ie,a),n(e,ut,a),g(me,e,a),n(e,ft,a),n(e,ce,a),n(e,dt,a),g(ue,e,a),n(e,$t,a),n(e,fe,a),n(e,gt,a),g(de,e,a),n(e,bt,a),n(e,$e,a),n(e,Mt,a),g(ge,e,a),n(e,ht,a),n(e,be,a),n(e,Tt,a),g(Me,e,a),n(e,jt,a),n(e,he,a),n(e,yt,a),g(Te,e,a),n(e,wt,a),n(e,je,a),n(e,vt,a),g(ye,e,a),n(e,_t,a),n(e,we,a),n(e,kt,a),g(ve,e,a),n(e,Ut,a),g(q,e,a),n(e,Jt,a),n(e,_e,a),n(e,Zt,a),g(ke,e,a),n(e,Ct,a),n(e,Ue,a),n(e,Ht,a),g(Je,e,a),n(e,xt,a),g(Ze,e,a),n(e,Wt,a),n(e,Ce,a),n(e,Rt,a),n(e,He,a),n(e,It,a),g(xe,e,a),n(e,Gt,a),n(e,We,a),n(e,Vt,a),n(e,Re,a),n(e,Ft,a),g(Ie,e,a),n(e,zt,a),n(e,Ge,a),n(e,Nt,a),n(e,Ve,a),n(e,qt,a),g(Fe,e,a),n(e,Xt,a),n(e,ze,a),n(e,At,a),n(e,Ne,a),n(e,Lt,a),n(e,qe,a),n(e,Bt,a),g(X,e,a),n(e,Et,a),n(e,Xe,a),n(e,Yt,a),g(Ae,e,a),n(e,Pt,a),g(A,e,a),n(e,Qt,a),g(L,e,a),n(e,St,a),n(e,Le,a),n(e,Ot,a),g(B,e,a),n(e,Dt,a),g(Be,e,a),n(e,Kt,a),g(E,e,a),n(e,es,a),n(e,Ee,a),n(e,ts,a),g(Y,e,a),n(e,ss,a),n(e,Qe,a),as=!0},p(e,[a]){const Vs={};a&2&&(Vs.$$scope={dirty:a,ctx:e}),_.$set(Vs);const Fs={};a&2&&(Fs.$$scope={dirty:a,ctx:e}),z.$set(Fs);const zs={};a&2&&(zs.$$scope={dirty:a,ctx:e}),N.$set(zs);const Ns={};a&2&&(Ns.$$scope={dirty:a,ctx:e}),q.$set(Ns);const qs={};a&2&&(qs.$$scope={dirty:a,ctx:e}),X.$set(qs);const Xs={};a&2&&(Xs.$$scope={dirty:a,ctx:e}),A.$set(Xs);const As={};a&2&&(As.$$scope={dirty:a,ctx:e}),L.$set(As);const Ls={};a&2&&(Ls.$$scope={dirty:a,ctx:e}),B.$set(Ls);const Bs={};a&2&&(Bs.$$scope={dirty:a,ctx:e}),E.$set(Bs);const Es={};a&2&&(Es.$$scope={dirty:a,ctx:e}),Y.$set(Es)},i(e){as||(b(c.$$.fragment,e),b(k.$$.fragment,e),b(_.$$.fragment,e),b(I.$$.fragment,e),b(v.$$.fragment,e),b(z.$$.fragment,e),b(se.$$.fragment,e),b(N.$$.fragment,e),b(oe.$$.fragment,e),b(pe.$$.fragment,e),b(me.$$.fragment,e),b(ue.$$.fragment,e),b(de.$$.fragment,e),b(ge.$$.fragment,e),b(Me.$$.fragment,e),b(Te.$$.fragment,e),b(ye.$$.fragment,e),b(ve.$$.fragment,e),b(q.$$.fragment,e),b(ke.$$.fragment,e),b(Je.$$.fragment,e),b(Ze.$$.fragment,e),b(xe.$$.fragment,e),b(Ie.$$.fragment,e),b(Fe.$$.fragment,e),b(X.$$.fragment,e),b(Ae.$$.fragment,e),b(A.$$.fragment,e),b(L.$$.fragment,e),b(B.$$.fragment,e),b(Be.$$.fragment,e),b(E.$$.fragment,e),b(Y.$$.fragment,e),as=!0)},o(e){M(c.$$.fragment,e),M(k.$$.fragment,e),M(_.$$.fragment,e),M(I.$$.fragment,e),M(v.$$.fragment,e),M(z.$$.fragment,e),M(se.$$.fragment,e),M(N.$$.fragment,e),M(oe.$$.fragment,e),M(pe.$$.fragment,e),M(me.$$.fragment,e),M(ue.$$.fragment,e),M(de.$$.fragment,e),M(ge.$$.fragment,e),M(Me.$$.fragment,e),M(Te.$$.fragment,e),M(ye.$$.fragment,e),M(ve.$$.fragment,e),M(q.$$.fragment,e),M(ke.$$.fragment,e),M(Je.$$.fragment,e),M(Ze.$$.fragment,e),M(xe.$$.fragment,e),M(Ie.$$.fragment,e),M(Fe.$$.fragment,e),M(X.$$.fragment,e),M(Ae.$$.fragment,e),M(A.$$.fragment,e),M(L.$$.fragment,e),M(B.$$.fragment,e),M(Be.$$.fragment,e),M(E.$$.fragment,e),M(Y.$$.fragment,e),as=!1},d(e){e&&(l(r),l(t),l(o),l(f),l(U),l(Z),l(u),l(x),l(R),l(C),l(p),l(F),l(Q),l(Se),l(S),l(Oe),l(O),l(De),l(D),l(Ke),l(K),l(et),l(ee),l(tt),l(te),l(st),l(at),l(lt),l(ae),l(nt),l(le),l(ot),l(rt),l(ne),l(pt),l(it),l(re),l(mt),l(ct),l(ie),l(ut),l(ft),l(ce),l(dt),l($t),l(fe),l(gt),l(bt),l($e),l(Mt),l(ht),l(be),l(Tt),l(jt),l(he),l(yt),l(wt),l(je),l(vt),l(_t),l(we),l(kt),l(Ut),l(Jt),l(_e),l(Zt),l(Ct),l(Ue),l(Ht),l(xt),l(Wt),l(Ce),l(Rt),l(He),l(It),l(Gt),l(We),l(Vt),l(Re),l(Ft),l(zt),l(Ge),l(Nt),l(Ve),l(qt),l(Xt),l(ze),l(At),l(Ne),l(Lt),l(qe),l(Bt),l(Et),l(Xe),l(Yt),l(Pt),l(Qt),l(St),l(Le),l(Ot),l(Dt),l(Kt),l(es),l(Ee),l(ts),l(ss),l(Qe)),l(s),h(c,e),h(k,e),h(_,e),h(I,e),h(v,e),h(z,e),h(se,e),h(N,e),h(oe,e),h(pe,e),h(me,e),h(ue,e),h(de,e),h(ge,e),h(Me,e),h(Te,e),h(ye,e),h(ve,e),h(q,e),h(ke,e),h(Je,e),h(Ze,e),h(xe,e),h(Ie,e),h(Fe,e),h(X,e),h(Ae,e),h(A,e),h(L,e),h(B,e),h(Be,e),h(E,e),h(Y,e)}}}const Ra='{"title":"Tour r√°pido","local":"tour-r√°pido","sections":[{"title":"Pipeline","local":"pipeline","sections":[{"title":"Uso da pipeline","local":"uso-da-pipeline","sections":[],"depth":3},{"title":"Use outro modelo e tokenizer na pipeline","local":"use-outro-modelo-e-tokenizer-na-pipeline","sections":[],"depth":3}],"depth":2},{"title":"AutoClass","local":"autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":3},{"title":"AutoModel","local":"automodel","sections":[],"depth":3},{"title":"Salvar um modelo","local":"salvar-um-modelo","sections":[],"depth":3}],"depth":2}],"depth":1}';function Ia(T){return Os(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class La extends Ds{constructor(s){super(),Ks(this,s,Ia,Wa,Ss,{})}}export{La as component};
