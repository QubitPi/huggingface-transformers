import{s as ze,o as _e,n as he}from"../chunks/scheduler.987d3921.js";import{S as Ae,i as Fe,g as h,s as p,r as w,A as Je,h as b,f as n,c as m,j as xe,u as v,x as k,k as Ce,y as We,a as l,v as y,d as x,t as C,w as T}from"../chunks/index.c8b1fed4.js";import{T as Te}from"../chunks/Tip.6bc1e794.js";import{C as V}from"../chunks/CodeBlock.18094d58.js";import{F as Ve,M as Ze}from"../chunks/Markdown.10b8ab04.js";import{H as D}from"../chunks/Heading.3fa3b67f.js";function Ge(A){let t,d='Denken Sie daran, dass sich die Architektur auf das Skelett des Modells bezieht und die Checkpoints die Gewichte f√ºr eine bestimmte Architektur sind. Zum Beispiel ist <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a> eine Architektur, w√§hrend <code>google-bert/bert-base-uncased</code> ein Checkpoint ist. Modell ist ein allgemeiner Begriff, der entweder Architektur oder Pr√ºfpunkt bedeuten kann.';return{c(){t=h("p"),t.innerHTML=d},l(a){t=b(a,"P",{"data-svelte-h":!0}),k(t)!=="svelte-1z0q275"&&(t.innerHTML=d)},m(a,i){l(a,t,i)},p:he,d(a){a&&n(t)}}}function Ue(A){let t,d='F√ºr PyTorch-Modelle verwendet die Methode <code>from_pretrained()</code> <code>torch.load()</code>, die intern <code>pickle</code> verwendet und als unsicher bekannt ist. Generell sollte man niemals ein Modell laden, das aus einer nicht vertrauensw√ºrdigen Quelle stammen k√∂nnte, oder das manipuliert worden sein k√∂nnte. Dieses Sicherheitsrisiko wird f√ºr √∂ffentliche Modelle, die auf dem Hugging Face Hub gehostet werden, teilweise gemildert, da diese bei jeder √úbertragung <a href="https://huggingface.co/docs/hub/security-malware" rel="nofollow">auf Malware</a> gescannt werden. Siehe die <a href="https://huggingface.co/docs/hub/security" rel="nofollow">Hub-Dokumentation</a> f√ºr Best Practices wie <a href="https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg" rel="nofollow">signierte Commit-Verifizierung</a> mit GPG.',a,i,c="TensorFlow- und Flax-Checkpoints sind nicht betroffen und k√∂nnen in PyTorch-Architekturen mit den Kwargs <code>from_tf</code> und <code>from_flax</code> f√ºr die Methode <code>from_pretrained</code> geladen werden, um dieses Problem zu umgehen.";return{c(){t=h("p"),t.innerHTML=d,a=p(),i=h("p"),i.innerHTML=c},l(u){t=b(u,"P",{"data-svelte-h":!0}),k(t)!=="svelte-xr6fee"&&(t.innerHTML=d),a=m(u),i=b(u,"P",{"data-svelte-h":!0}),k(i)!=="svelte-1hzsv1f"&&(i.innerHTML=c)},m(u,Z){l(u,t,Z),l(u,a,Z),l(u,i,Z)},p:he,d(u){u&&(n(t),n(a),n(i))}}}function Ee(A){let t,d='Mit den <code>AutoModelFor</code>-Klassen k√∂nnen Sie schlie√ülich ein vortrainiertes Modell f√ºr eine bestimmte Aufgabe laden (siehe <a href="model_doc/auto">hier</a> f√ºr eine vollst√§ndige Liste der verf√ºgbaren Aufgaben). Laden Sie zum Beispiel ein Modell f√ºr die Sequenzklassifikation mit <code>AutoModelForSequenceClassification.from_pretrained()</code>:',a,i,c,u,Z="Sie k√∂nnen denselben Pr√ºfpunkt problemlos wiederverwenden, um eine Architektur f√ºr eine andere Aufgabe zu laden:",F,$,j,g,z,_,o="Im Allgemeinen empfehlen wir die Verwendung der Klasse ‚ÄúAutoTokenizer‚Äù und der Klasse ‚ÄúAutoModelFor‚Äù, um trainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im n√§chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz f√ºr die Feinabstimmung vorzuverarbeiten.",f;return i=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),$=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),g=new Te({props:{warning:!0,$$slots:{default:[Ue]},$$scope:{ctx:A}}}),{c(){t=h("p"),t.innerHTML=d,a=p(),w(i.$$.fragment),c=p(),u=h("p"),u.textContent=Z,F=p(),w($.$$.fragment),j=p(),w(g.$$.fragment),z=p(),_=h("p"),_.textContent=o},l(r){t=b(r,"P",{"data-svelte-h":!0}),k(t)!=="svelte-fxqr85"&&(t.innerHTML=d),a=m(r),v(i.$$.fragment,r),c=m(r),u=b(r,"P",{"data-svelte-h":!0}),k(u)!=="svelte-xf7n9r"&&(u.textContent=Z),F=m(r),v($.$$.fragment,r),j=m(r),v(g.$$.fragment,r),z=m(r),_=b(r,"P",{"data-svelte-h":!0}),k(_)!=="svelte-pbc22c"&&(_.textContent=o)},m(r,M){l(r,t,M),l(r,a,M),y(i,r,M),l(r,c,M),l(r,u,M),l(r,F,M),y($,r,M),l(r,j,M),y(g,r,M),l(r,z,M),l(r,_,M),f=!0},p(r,M){const J={};M&2&&(J.$$scope={dirty:M,ctx:r}),g.$set(J)},i(r){f||(x(i.$$.fragment,r),x($.$$.fragment,r),x(g.$$.fragment,r),f=!0)},o(r){C(i.$$.fragment,r),C($.$$.fragment,r),C(g.$$.fragment,r),f=!1},d(r){r&&(n(t),n(a),n(c),n(u),n(F),n(j),n(z),n(_)),T(i,r),T($,r),T(g,r)}}}function He(A){let t,d;return t=new Ze({props:{$$slots:{default:[Ee]},$$scope:{ctx:A}}}),{c(){w(t.$$.fragment)},l(a){v(t.$$.fragment,a)},m(a,i){y(t,a,i),d=!0},p(a,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:a}),t.$set(c)},i(a){d||(x(t.$$.fragment,a),d=!0)},o(a){C(t.$$.fragment,a),d=!1},d(a){T(t,a)}}}function Re(A){let t,d='Mit den Klassen <code>TFAutoModelFor</code> schlie√ülich k√∂nnen Sie ein vortrainiertes Modell f√ºr eine bestimmte Aufgabe laden (siehe <a href="model_doc/auto">hier</a> f√ºr eine vollst√§ndige Liste der verf√ºgbaren Aufgaben). Laden Sie zum Beispiel ein Modell f√ºr die Sequenzklassifikation mit <code>TFAutoModelForSequenceClassification.from_pretrained()</code>:',a,i,c,u,Z="Sie k√∂nnen denselben Pr√ºfpunkt problemlos wiederverwenden, um eine Architektur f√ºr eine andere Aufgabe zu laden:",F,$,j,g,z="Im Allgemeinen empfehlen wir, die Klasse ‚ÄúAutoTokenizer‚Äù und die Klasse ‚ÄúTFAutoModelFor‚Äù zu verwenden, um vortrainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im n√§chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz f√ºr die Feinabstimmung vorzuverarbeiten.",_;return i=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),$=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){t=h("p"),t.innerHTML=d,a=p(),w(i.$$.fragment),c=p(),u=h("p"),u.textContent=Z,F=p(),w($.$$.fragment),j=p(),g=h("p"),g.textContent=z},l(o){t=b(o,"P",{"data-svelte-h":!0}),k(t)!=="svelte-149f2oa"&&(t.innerHTML=d),a=m(o),v(i.$$.fragment,o),c=m(o),u=b(o,"P",{"data-svelte-h":!0}),k(u)!=="svelte-xf7n9r"&&(u.textContent=Z),F=m(o),v($.$$.fragment,o),j=m(o),g=b(o,"P",{"data-svelte-h":!0}),k(g)!=="svelte-qh4bp5"&&(g.textContent=z)},m(o,f){l(o,t,f),l(o,a,f),y(i,o,f),l(o,c,f),l(o,u,f),l(o,F,f),y($,o,f),l(o,j,f),l(o,g,f),_=!0},p:he,i(o){_||(x(i.$$.fragment,o),x($.$$.fragment,o),_=!0)},o(o){C(i.$$.fragment,o),C($.$$.fragment,o),_=!1},d(o){o&&(n(t),n(a),n(c),n(u),n(F),n(j),n(g)),T(i,o),T($,o)}}}function Le(A){let t,d;return t=new Ze({props:{$$slots:{default:[Re]},$$scope:{ctx:A}}}),{c(){w(t.$$.fragment)},l(a){v(t.$$.fragment,a)},m(a,i){y(t,a,i),d=!0},p(a,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:a}),t.$set(c)},i(a){d||(x(t.$$.fragment,a),d=!0)},o(a){C(t.$$.fragment,a),d=!1},d(a){T(t,a)}}}function Xe(A){let t,d,a,i,c,u,Z,F="Bei so vielen verschiedenen Transformator-Architekturen kann es eine Herausforderung sein, eine f√ºr Ihren Checkpoint zu erstellen. Als Teil der ü§ó Transformers Kernphilosophie, die Bibliothek leicht, einfach und flexibel nutzbar zu machen, leitet eine <code>AutoClass</code> automatisch die richtige Architektur aus einem gegebenen Checkpoint ab und l√§dt sie. Mit der Methode <code>from_pretrained()</code> kann man schnell ein vortrainiertes Modell f√ºr eine beliebige Architektur laden, so dass man keine Zeit und Ressourcen aufwenden muss, um ein Modell von Grund auf zu trainieren. Die Erstellung dieser Art von Checkpoint-agnostischem Code bedeutet, dass Ihr Code, wenn er f√ºr einen Checkpoint funktioniert, auch mit einem anderen Checkpoint funktionieren wird - solange er f√ºr eine √§hnliche Aufgabe trainiert wurde - selbst wenn die Architektur unterschiedlich ist.",$,j,g,z,_="In dieser Anleitung lernen Sie, wie man:",o,f,r="<li>Einen vortrainierten Tokenizer l√§dt.</li> <li>Einen vortrainierten Merkmalsextraktor l√§dt.</li> <li>Einen vortrainierten Prozessor l√§dt.</li> <li>Ein vortrainiertes Modell l√§dt.</li>",M,J,K,G,be="Nahezu jede NLP-Aufgabe beginnt mit einem Tokenizer. Ein Tokenizer wandelt Ihre Eingabe in ein Format um, das vom Modell verarbeitet werden kann.",O,U,ge="Laden Sie einen Tokenizer mit <code>AutoTokenizer.from_pretrained()</code>:",ee,E,te,H,$e="Dann tokenisieren Sie Ihre Eingabe wie unten gezeigt:",ne,R,se,L,le,X,Me="F√ºr Audio- und Bildverarbeitungsaufgaben verarbeitet ein Merkmalsextraktor das Audiosignal oder Bild in das richtige Eingabeformat.",ae,P,ke="Laden Sie einen Merkmalsextraktor mit <code>AutoFeatureExtractor.from_pretrained()</code>:",re,S,ie,I,oe,Y,je='Multimodale Aufgaben erfordern einen Prozessor, der zwei Arten von Vorverarbeitungswerkzeugen kombiniert. Das Modell <a href="model_doc/layoutlmv2">LayoutLMV2</a> beispielsweise ben√∂tigt einen Feature-Extraktor f√ºr Bilder und einen Tokenizer f√ºr Text; ein Prozessor kombiniert beide.',pe,N,we="Laden Sie einen Prozessor mit <code>AutoProcessor.from_pretrained()</code>:",me,B,ue,q,de,W,ce,Q,fe;return c=new D({props:{title:"Vortrainierte Instanzen mit einer AutoClass laden",local:"vortrainierte-instanzen-mit-einer-autoclass-laden",headingTag:"h1"}}),j=new Te({props:{$$slots:{default:[Ge]},$$scope:{ctx:A}}}),J=new D({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h2"}}),E=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),R=new V({props:{code:"c2VxdWVuY2UlMjAlM0QlMjAlMjJJbiUyMGElMjBob2xlJTIwaW4lMjB0aGUlMjBncm91bmQlMjB0aGVyZSUyMGxpdmVkJTIwYSUyMGhvYmJpdC4lMjIlMEFwcmludCh0b2tlbml6ZXIoc2VxdWVuY2UpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),L=new D({props:{title:"AutoFeatureExtractor",local:"autofeatureextractor",headingTag:"h2"}}),S=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZWhjYWxhYnJlcyUyRndhdjJ2ZWMyLWxnLXhsc3ItZW4tc3BlZWNoLWVtb3Rpb24tcmVjb2duaXRpb24lMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),I=new D({props:{title:"AutoProcessor",local:"autoprocessor",headingTag:"h2"}}),B=new V({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZsYXlvdXRsbXYyLWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`,wrap:!1}}),q=new D({props:{title:"AutoModel",local:"automodel",headingTag:"h2"}}),W=new Ve({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Le],pytorch:[He]},$$scope:{ctx:A}}}),{c(){t=h("meta"),d=p(),a=h("p"),i=p(),w(c.$$.fragment),u=p(),Z=h("p"),Z.innerHTML=F,$=p(),w(j.$$.fragment),g=p(),z=h("p"),z.textContent=_,o=p(),f=h("ul"),f.innerHTML=r,M=p(),w(J.$$.fragment),K=p(),G=h("p"),G.textContent=be,O=p(),U=h("p"),U.innerHTML=ge,ee=p(),w(E.$$.fragment),te=p(),H=h("p"),H.textContent=$e,ne=p(),w(R.$$.fragment),se=p(),w(L.$$.fragment),le=p(),X=h("p"),X.textContent=Me,ae=p(),P=h("p"),P.innerHTML=ke,re=p(),w(S.$$.fragment),ie=p(),w(I.$$.fragment),oe=p(),Y=h("p"),Y.innerHTML=je,pe=p(),N=h("p"),N.innerHTML=we,me=p(),w(B.$$.fragment),ue=p(),w(q.$$.fragment),de=p(),w(W.$$.fragment),ce=p(),Q=h("p"),this.h()},l(e){const s=Je("svelte-u9bgzb",document.head);t=b(s,"META",{name:!0,content:!0}),s.forEach(n),d=m(e),a=b(e,"P",{}),xe(a).forEach(n),i=m(e),v(c.$$.fragment,e),u=m(e),Z=b(e,"P",{"data-svelte-h":!0}),k(Z)!=="svelte-b78d51"&&(Z.innerHTML=F),$=m(e),v(j.$$.fragment,e),g=m(e),z=b(e,"P",{"data-svelte-h":!0}),k(z)!=="svelte-16h7s5e"&&(z.textContent=_),o=m(e),f=b(e,"UL",{"data-svelte-h":!0}),k(f)!=="svelte-6zpbwl"&&(f.innerHTML=r),M=m(e),v(J.$$.fragment,e),K=m(e),G=b(e,"P",{"data-svelte-h":!0}),k(G)!=="svelte-oqwj9p"&&(G.textContent=be),O=m(e),U=b(e,"P",{"data-svelte-h":!0}),k(U)!=="svelte-1wk2x8m"&&(U.innerHTML=ge),ee=m(e),v(E.$$.fragment,e),te=m(e),H=b(e,"P",{"data-svelte-h":!0}),k(H)!=="svelte-1xmdplx"&&(H.textContent=$e),ne=m(e),v(R.$$.fragment,e),se=m(e),v(L.$$.fragment,e),le=m(e),X=b(e,"P",{"data-svelte-h":!0}),k(X)!=="svelte-bcjn9"&&(X.textContent=Me),ae=m(e),P=b(e,"P",{"data-svelte-h":!0}),k(P)!=="svelte-86xnmm"&&(P.innerHTML=ke),re=m(e),v(S.$$.fragment,e),ie=m(e),v(I.$$.fragment,e),oe=m(e),Y=b(e,"P",{"data-svelte-h":!0}),k(Y)!=="svelte-y5lfxn"&&(Y.innerHTML=je),pe=m(e),N=b(e,"P",{"data-svelte-h":!0}),k(N)!=="svelte-x1tt3f"&&(N.innerHTML=we),me=m(e),v(B.$$.fragment,e),ue=m(e),v(q.$$.fragment,e),de=m(e),v(W.$$.fragment,e),ce=m(e),Q=b(e,"P",{}),xe(Q).forEach(n),this.h()},h(){Ce(t,"name","hf:doc:metadata"),Ce(t,"content",Pe)},m(e,s){We(document.head,t),l(e,d,s),l(e,a,s),l(e,i,s),y(c,e,s),l(e,u,s),l(e,Z,s),l(e,$,s),y(j,e,s),l(e,g,s),l(e,z,s),l(e,o,s),l(e,f,s),l(e,M,s),y(J,e,s),l(e,K,s),l(e,G,s),l(e,O,s),l(e,U,s),l(e,ee,s),y(E,e,s),l(e,te,s),l(e,H,s),l(e,ne,s),y(R,e,s),l(e,se,s),y(L,e,s),l(e,le,s),l(e,X,s),l(e,ae,s),l(e,P,s),l(e,re,s),y(S,e,s),l(e,ie,s),y(I,e,s),l(e,oe,s),l(e,Y,s),l(e,pe,s),l(e,N,s),l(e,me,s),y(B,e,s),l(e,ue,s),y(q,e,s),l(e,de,s),y(W,e,s),l(e,ce,s),l(e,Q,s),fe=!0},p(e,[s]){const ve={};s&2&&(ve.$$scope={dirty:s,ctx:e}),j.$set(ve);const ye={};s&2&&(ye.$$scope={dirty:s,ctx:e}),W.$set(ye)},i(e){fe||(x(c.$$.fragment,e),x(j.$$.fragment,e),x(J.$$.fragment,e),x(E.$$.fragment,e),x(R.$$.fragment,e),x(L.$$.fragment,e),x(S.$$.fragment,e),x(I.$$.fragment,e),x(B.$$.fragment,e),x(q.$$.fragment,e),x(W.$$.fragment,e),fe=!0)},o(e){C(c.$$.fragment,e),C(j.$$.fragment,e),C(J.$$.fragment,e),C(E.$$.fragment,e),C(R.$$.fragment,e),C(L.$$.fragment,e),C(S.$$.fragment,e),C(I.$$.fragment,e),C(B.$$.fragment,e),C(q.$$.fragment,e),C(W.$$.fragment,e),fe=!1},d(e){e&&(n(d),n(a),n(i),n(u),n(Z),n($),n(g),n(z),n(o),n(f),n(M),n(K),n(G),n(O),n(U),n(ee),n(te),n(H),n(ne),n(se),n(le),n(X),n(ae),n(P),n(re),n(ie),n(oe),n(Y),n(pe),n(N),n(me),n(ue),n(de),n(ce),n(Q)),n(t),T(c,e),T(j,e),T(J,e),T(E,e),T(R,e),T(L,e),T(S,e),T(I,e),T(B,e),T(q,e),T(W,e)}}}const Pe='{"title":"Vortrainierte Instanzen mit einer AutoClass laden","local":"vortrainierte-instanzen-mit-einer-autoclass-laden","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":2},{"title":"AutoFeatureExtractor","local":"autofeatureextractor","sections":[],"depth":2},{"title":"AutoProcessor","local":"autoprocessor","sections":[],"depth":2},{"title":"AutoModel","local":"automodel","sections":[],"depth":2}],"depth":1}';function Se(A){return _e(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class De extends Ae{constructor(t){super(),Fe(this,t,Se,Xe,ze,{})}}export{De as component};
