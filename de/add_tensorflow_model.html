<meta charset="utf-8" /><meta name="hf:doc:metadata" content="{&quot;title&quot;:&quot;Wie konvertiert man ein ü§ó Transformers-Modell in TensorFlow?&quot;,&quot;local&quot;:&quot;wie-konvertiert-man-ein--transformers-modell-in-tensorflow&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Schritt-f√ºr-Schritt-Anleitung zum Hinzuf√ºgen von TensorFlow-Modellarchitektur-Code&quot;,&quot;local&quot;:&quot;schritt-f√ºr-schritt-anleitung-zum-hinzuf√ºgen-von-tensorflow-modellarchitektur-code&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;1.-3. Bereiten Sie Ihren Modellbeitrag vor&quot;,&quot;local&quot;:&quot;1-3-bereiten-sie-ihren-modellbeitrag-vor&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;4. Implementierung des Modells&quot;,&quot;local&quot;:&quot;4-implementierung-des-modells&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;5. Modell-Tests hinzuf√ºgen&quot;,&quot;local&quot;:&quot;5-modell-tests-hinzuf√ºgen&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;6.-7. Stellen Sie sicher, dass jeder Ihr Modell verwenden kann&quot;,&quot;local&quot;:&quot;6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3}],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Hinzuf√ºgen von TensorFlow-Gewichten zum ü§ó Hub&quot;,&quot;local&quot;:&quot;hinzuf√ºgen-von-tensorflow-gewichten-zum--hub&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Fehlersuche in verschiedenen ML-Frameworks üêõ&quot;,&quot;local&quot;:&quot;fehlersuche-in-verschiedenen-ml-frameworks-&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}">
		<link href="/docs/transformers/main/de/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/entry/start.155de6db.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/scheduler.987d3921.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/singletons.0701d17e.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/index.42b1abb7.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/paths.f9b25ae7.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/entry/app.e6ae5761.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/index.c8b1fed4.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/nodes/0.8cbb324c.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/each.e59479a4.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/nodes/5.001e98ea.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/Tip.6bc1e794.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/CodeBlock.18094d58.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/Heading.3fa3b67f.js"><!-- HEAD_svelte-u9bgzb_START --><meta name="hf:doc:metadata" content="{&quot;title&quot;:&quot;Wie konvertiert man ein ü§ó Transformers-Modell in TensorFlow?&quot;,&quot;local&quot;:&quot;wie-konvertiert-man-ein--transformers-modell-in-tensorflow&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Schritt-f√ºr-Schritt-Anleitung zum Hinzuf√ºgen von TensorFlow-Modellarchitektur-Code&quot;,&quot;local&quot;:&quot;schritt-f√ºr-schritt-anleitung-zum-hinzuf√ºgen-von-tensorflow-modellarchitektur-code&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;1.-3. Bereiten Sie Ihren Modellbeitrag vor&quot;,&quot;local&quot;:&quot;1-3-bereiten-sie-ihren-modellbeitrag-vor&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;4. Implementierung des Modells&quot;,&quot;local&quot;:&quot;4-implementierung-des-modells&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;5. Modell-Tests hinzuf√ºgen&quot;,&quot;local&quot;:&quot;5-modell-tests-hinzuf√ºgen&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;6.-7. Stellen Sie sicher, dass jeder Ihr Modell verwenden kann&quot;,&quot;local&quot;:&quot;6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3}],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Hinzuf√ºgen von TensorFlow-Gewichten zum ü§ó Hub&quot;,&quot;local&quot;:&quot;hinzuf√ºgen-von-tensorflow-gewichten-zum--hub&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Fehlersuche in verschiedenen ML-Frameworks üêõ&quot;,&quot;local&quot;:&quot;fehlersuche-in-verschiedenen-ml-frameworks-&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}"><!-- HEAD_svelte-u9bgzb_END -->      <p></p>   <h1 class="relative group"><a id="wie-konvertiert-man-ein--transformers-modell-in-tensorflow" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#wie-konvertiert-man-ein--transformers-modell-in-tensorflow"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Wie konvertiert man ein ü§ó Transformers-Modell in TensorFlow?</span></h1> <p data-svelte-h="svelte-1ht4dl">Die Tatsache, dass mehrere Frameworks f√ºr die Verwendung mit ü§ó Transformers zur Verf√ºgung stehen, gibt Ihnen die Flexibilit√§t, deren St√§rken beim Entwurf Ihrer Anwendung auszuspielen.
Ihre Anwendung zu entwerfen, aber das bedeutet auch, dass die Kompatibilit√§t f√ºr jedes Modell einzeln hinzugef√ºgt werden muss. Die gute Nachricht ist, dass
das Hinzuf√ºgen von TensorFlow-Kompatibilit√§t zu einem bestehenden Modell einfacher ist als <a href="add_new_model">das Hinzuf√ºgen eines neuen Modells von Grund auf</a>!
Ob Sie ein tieferes Verst√§ndnis f√ºr gro√üe TensorFlow-Modelle haben m√∂chten, einen wichtigen Open-Source-Beitrag leisten oder
TensorFlow f√ºr das Modell Ihrer Wahl aktivieren wollen, dieser Leitfaden ist f√ºr Sie.</p> <p data-svelte-h="svelte-195iua3">Dieser Leitfaden bef√§higt Sie, ein Mitglied unserer Gemeinschaft, TensorFlow-Modellgewichte und/oder
Architekturen beizusteuern, die in ü§ó Transformers verwendet werden sollen, und zwar mit minimaler Betreuung durch das Hugging Face Team. Das Schreiben eines neuen Modells
ist keine Kleinigkeit, aber ich hoffe, dass dieser Leitfaden dazu beitr√§gt, dass es weniger eine Achterbahnfahrt üé¢ und mehr ein Spaziergang im Park üö∂ ist.
Die Nutzung unserer kollektiven Erfahrungen ist absolut entscheidend, um diesen Prozess immer einfacher zu machen, und deshalb m√∂chten wir
ermutigen Sie daher, Verbesserungsvorschl√§ge f√ºr diesen Leitfaden zu machen!</p> <p data-svelte-h="svelte-pl5slc">Bevor Sie tiefer eintauchen, empfehlen wir Ihnen, die folgenden Ressourcen zu lesen, wenn Sie neu in ü§ó Transformers sind:</p> <ul data-svelte-h="svelte-10qxdc2"><li><a href="add_new_model#general-overview-of-transformers">Allgemeiner √úberblick √ºber ü§ó Transformers</a></li> <li><a href="https://huggingface.co/blog/tensorflow-philosophy" rel="nofollow">Die TensorFlow-Philosophie von Hugging Face</a></li></ul> <p data-svelte-h="svelte-1fyrz1">Im Rest dieses Leitfadens werden Sie lernen, was n√∂tig ist, um eine neue TensorFlow Modellarchitektur hinzuzuf√ºgen, die
Verfahren zur Konvertierung von PyTorch in TensorFlow-Modellgewichte und wie Sie Unstimmigkeiten zwischen ML
Frameworks. Legen Sie los!</p>  <div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400"><p data-svelte-h="svelte-olarmn">Sind Sie unsicher, ob das Modell, das Sie verwenden m√∂chten, bereits eine entsprechende TensorFlow-Architektur hat?</p> <p data-svelte-h="svelte-1cdgjs8">¬†</p> <p data-svelte-h="svelte-emag10">√úberpr√ºfen Sie das Feld <code>model_type</code> in der <code>config.json</code> des Modells Ihrer Wahl
(<a href="https://huggingface.co/google-bert/bert-base-uncased/blob/main/config.json#L14" rel="nofollow">Beispiel</a>). Wenn der entsprechende Modellordner in
ü§ó Transformers eine Datei hat, deren Name mit ‚Äúmodeling_tf‚Äù beginnt, bedeutet dies, dass es eine entsprechende TensorFlow
Architektur hat (<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert" rel="nofollow">Beispiel</a>).</p></div>  <h2 class="relative group"><a id="schritt-f√ºr-schritt-anleitung-zum-hinzuf√ºgen-von-tensorflow-modellarchitektur-code" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#schritt-f√ºr-schritt-anleitung-zum-hinzuf√ºgen-von-tensorflow-modellarchitektur-code"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Schritt-f√ºr-Schritt-Anleitung zum Hinzuf√ºgen von TensorFlow-Modellarchitektur-Code</span></h2> <p data-svelte-h="svelte-1apyhwg">Es gibt viele M√∂glichkeiten, eine gro√üe Modellarchitektur zu entwerfen, und viele M√∂glichkeiten, diesen Entwurf zu implementieren. Wie auch immer,
Sie erinnern sich vielleicht an unseren <a href="add_new_model#general-overview-of-transformers">allgemeinen √úberblick √ºber ü§ó Transformers</a>
wissen, dass wir ein meinungsfreudiger Haufen sind - die Benutzerfreundlichkeit von ü§ó Transformers h√§ngt von konsistenten Designentscheidungen ab. Aus
Erfahrung k√∂nnen wir Ihnen ein paar wichtige Dinge √ºber das Hinzuf√ºgen von TensorFlow-Modellen sagen:</p> <ul data-svelte-h="svelte-j498kv"><li>Erfinden Sie das Rad nicht neu! In den meisten F√§llen gibt es mindestens zwei Referenzimplementierungen, die Sie √ºberpr√ºfen sollten: das
PyTorch-√Ñquivalent des Modells, das Sie implementieren, und andere TensorFlow-Modelle f√ºr dieselbe Klasse von Problemen.</li> <li>Gute Modellimplementierungen √ºberleben den Test der Zeit. Dies geschieht nicht, weil der Code h√ºbsch ist, sondern eher
sondern weil der Code klar, einfach zu debuggen und darauf aufzubauen ist. Wenn Sie den Maintainern das Leben mit Ihrer
TensorFlow-Implementierung leicht machen, indem Sie die gleichen Muster wie in anderen TensorFlow-Modellen nachbilden und die Abweichung
zur PyTorch-Implementierung minimieren, stellen Sie sicher, dass Ihr Beitrag lange Bestand haben wird.</li> <li>Bitten Sie um Hilfe, wenn Sie nicht weiterkommen! Das ü§ó Transformers-Team ist da, um zu helfen, und wir haben wahrscheinlich L√∂sungen f√ºr die gleichen
Probleme gefunden, vor denen Sie stehen.</li></ul> <p data-svelte-h="svelte-19ofyge">Hier finden Sie einen √úberblick √ºber die Schritte, die zum Hinzuf√ºgen einer TensorFlow-Modellarchitektur erforderlich sind:</p> <ol data-svelte-h="svelte-49ahbp"><li>W√§hlen Sie das Modell, das Sie konvertieren m√∂chten</li> <li>Bereiten Sie die Transformers-Entwicklungsumgebung vor.</li> <li>(Optional) Verstehen Sie die theoretischen Aspekte und die bestehende Implementierung</li> <li>Implementieren Sie die Modellarchitektur</li> <li>Implementieren Sie Modelltests</li> <li>Reichen Sie den Pull-Antrag ein</li> <li>(Optional) Erstellen Sie Demos und teilen Sie diese mit der Welt</li></ol>  <h3 class="relative group"><a id="1-3-bereiten-sie-ihren-modellbeitrag-vor" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#1-3-bereiten-sie-ihren-modellbeitrag-vor"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>1.-3. Bereiten Sie Ihren Modellbeitrag vor</span></h3> <p data-svelte-h="svelte-16h96ya"><strong>1. W√§hlen Sie das Modell, das Sie konvertieren m√∂chten</strong></p> <p data-svelte-h="svelte-1fkb5qr">Beginnen wir mit den Grundlagen: Als erstes m√ºssen Sie die Architektur kennen, die Sie konvertieren m√∂chten. Wenn Sie
Sie sich nicht auf eine bestimmte Architektur festgelegt haben, ist es eine gute M√∂glichkeit, das ü§ó Transformers-Team um Vorschl√§ge zu bitten.
Wir werden Sie zu den wichtigsten Architekturen f√ºhren, die auf der TensorFlow-Seite noch fehlen.
Seite fehlen. Wenn das spezifische Modell, das Sie mit TensorFlow verwenden m√∂chten, bereits eine Implementierung der TensorFlow-Architektur in
ü§ó Transformers, aber es fehlen Gewichte, k√∂nnen Sie direkt in den
Abschnitt <a href="#hinzuf%C3%BCgen-von-tensorflow-gewichten-zum--hub">Gewichtskonvertierung</a>
auf dieser Seite.</p> <p data-svelte-h="svelte-j04nbk">Der Einfachheit halber wird im Rest dieser Anleitung davon ausgegangen, dass Sie sich entschieden haben, mit der TensorFlow-Version von
<em>BrandNewBert</em> (dasselbe Beispiel wie in der <a href="add_new_model">Anleitung</a>, um ein neues Modell von Grund auf hinzuzuf√ºgen).</p>  <div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400"><p data-svelte-h="svelte-dzw3pi">Bevor Sie mit der Arbeit an einer TensorFlow-Modellarchitektur beginnen, sollten Sie sich vergewissern, dass es keine laufenden Bem√ºhungen in dieser Richtung gibt.
Sie k√∂nnen nach <code>BrandNewBert</code> auf der
<a href="https://github.com/huggingface/transformers/pulls?q=is%3Apr" rel="nofollow">pull request GitHub page</a>, um zu best√§tigen, dass es keine
TensorFlow-bezogene Pull-Anfrage gibt.</p></div> <p data-svelte-h="svelte-do7bnr"><strong>2. Transformers-Entwicklungsumgebung vorbereiten</strong></p> <p data-svelte-h="svelte-jlox09">Nachdem Sie die Modellarchitektur ausgew√§hlt haben, √∂ffnen Sie einen PR-Entwurf, um Ihre Absicht zu signalisieren, daran zu arbeiten. Folgen Sie den
Anweisungen, um Ihre Umgebung einzurichten und einen PR-Entwurf zu √∂ffnen.</p> <ol data-svelte-h="svelte-v4wfpl"><li><p>Forken Sie das <a href="https://github.com/huggingface/transformers" rel="nofollow">repository</a>, indem Sie auf der Seite des Repositorys auf die Schaltfl√§che ‚ÄòFork‚Äô klicken.
Seite des Repositorys klicken. Dadurch wird eine Kopie des Codes unter Ihrem GitHub-Benutzerkonto erstellt.</p></li> <li><p>Klonen Sie Ihren <code>transformers</code> Fork auf Ihre lokale Festplatte und f√ºgen Sie das Basis-Repository als Remote hinzu:</p></li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git <span class="hljs-built_in">clone</span> https://github.com/[your Github handle]/transformers.git
<span class="hljs-built_in">cd</span> transformers
git remote add upstream https://github.com/huggingface/transformers.git<!-- HTML_TAG_END --></pre></div> <ol start="3" data-svelte-h="svelte-oahl5t"><li>Richten Sie eine Entwicklungsumgebung ein, indem Sie z.B. den folgenden Befehl ausf√ºhren:</li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->python -m venv .<span class="hljs-built_in">env</span>
<span class="hljs-built_in">source</span> .<span class="hljs-built_in">env</span>/bin/activate
pip install -e <span class="hljs-string">&quot;.[dev]&quot;</span><!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1wzcf5d">Abh√§ngig von Ihrem Betriebssystem und da die Anzahl der optionalen Abh√§ngigkeiten von Transformers w√§chst, kann es sein, dass Sie bei diesem Befehl einen
Fehler mit diesem Befehl erhalten. Wenn das der Fall ist, stellen Sie sicher, dass Sie TensorFlow installieren und dann ausf√ºhren:</p> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->pip install -e <span class="hljs-string">&quot;.[quality]&quot;</span><!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1t59a26"><strong>Hinweis:</strong> Sie m√ºssen CUDA nicht installiert haben. Es reicht aus, das neue Modell auf der CPU laufen zu lassen.</p> <ol start="4" data-svelte-h="svelte-3zwnfl"><li>Erstellen Sie eine Verzweigung mit einem beschreibenden Namen von Ihrer Hauptverzweigung</li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git checkout -b add_tf_brand_new_bert<!-- HTML_TAG_END --></pre></div> <ol start="5" data-svelte-h="svelte-x058iw"><li>Abrufen und zur√ºcksetzen auf die aktuelle Hauptversion</li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git fetch upstream
git rebase upstream/main<!-- HTML_TAG_END --></pre></div> <ol start="6" data-svelte-h="svelte-7ts89o"><li><p>F√ºgen Sie eine leere <code>.py</code> Datei in <code>transformers/src/models/brandnewbert/</code> mit dem Namen <code>modeling_tf_brandnewbert.py</code> hinzu. Dies wird
Ihre TensorFlow-Modelldatei sein.</p></li> <li><p>√úbertragen Sie die √Ñnderungen auf Ihr Konto mit:</p></li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git add .
git commit -m <span class="hljs-string">&quot;initial commit&quot;</span>
git push -u origin add_tf_brand_new_bert<!-- HTML_TAG_END --></pre></div> <ol start="8" data-svelte-h="svelte-1a2kv3l"><li><p>Wenn Sie zufrieden sind, gehen Sie auf die Webseite Ihrer Abspaltung auf GitHub. Klicken Sie auf ‚ÄúPull request‚Äù. Stellen Sie sicher, dass Sie das
GitHub-Handle einiger Mitglieder des Hugging Face-Teams als Reviewer hinzuzuf√ºgen, damit das Hugging Face-Team √ºber zuk√ºnftige √Ñnderungen informiert wird.
zuk√ºnftige √Ñnderungen benachrichtigt wird.</p></li> <li><p>√Ñndern Sie den PR in einen Entwurf, indem Sie auf der rechten Seite der GitHub-Pull-Request-Webseite auf ‚ÄúIn Entwurf umwandeln‚Äù klicken.</p></li></ol> <p data-svelte-h="svelte-1jgt5f">Jetzt haben Sie eine Entwicklungsumgebung eingerichtet, um <em>BrandNewBert</em> nach TensorFlow in ü§ó Transformers zu portieren.</p> <p data-svelte-h="svelte-n0bn3l"><strong>3. (Optional) Verstehen Sie die theoretischen Aspekte und die bestehende Implementierung</strong></p> <p data-svelte-h="svelte-1sjq4zv">Sie sollten sich etwas Zeit nehmen, um die Arbeit von <em>BrandNewBert</em> zu lesen, falls eine solche Beschreibung existiert. M√∂glicherweise gibt es gro√üe
Abschnitte des Papiers, die schwer zu verstehen sind. Wenn das der Fall ist, ist das in Ordnung - machen Sie sich keine Sorgen! Das Ziel ist
ist es nicht, ein tiefes theoretisches Verst√§ndnis des Papiers zu erlangen, sondern die notwendigen Informationen zu extrahieren, um
das Modell mit Hilfe von TensorFlow effektiv in ü§ó Transformers neu zu implementieren. Das hei√üt, Sie m√ºssen nicht zu viel Zeit auf die
viel Zeit auf die theoretischen Aspekte verwenden, sondern sich lieber auf die praktischen Aspekte konzentrieren, n√§mlich auf die bestehende Modelldokumentation
Seite (z.B. <a href="model_doc/bert">model docs for BERT</a>).</p> <p data-svelte-h="svelte-1u71zen">Nachdem Sie die Grundlagen der Modelle, die Sie implementieren wollen, verstanden haben, ist es wichtig, die bestehende
Implementierung zu verstehen. Dies ist eine gute Gelegenheit, sich zu vergewissern, dass eine funktionierende Implementierung mit Ihren Erwartungen an das
Modell entspricht, und um technische Herausforderungen auf der TensorFlow-Seite vorauszusehen.</p> <p data-svelte-h="svelte-1lhg56c">Es ist ganz nat√ºrlich, dass Sie sich von der Menge an Informationen, die Sie gerade aufgesogen haben, √ºberw√§ltigt f√ºhlen. Es ist
Es ist definitiv nicht erforderlich, dass Sie in dieser Phase alle Facetten des Modells verstehen. Dennoch empfehlen wir Ihnen dringend
ermutigen wir Sie, alle dringenden Fragen in unserem <a href="https://discuss.huggingface.co/" rel="nofollow">Forum</a> zu kl√§ren.</p>  <h3 class="relative group"><a id="4-implementierung-des-modells" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#4-implementierung-des-modells"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>4. Implementierung des Modells</span></h3> <p data-svelte-h="svelte-ibj99d">Jetzt ist es an der Zeit, endlich mit dem Programmieren zu beginnen. Als Ausgangspunkt empfehlen wir die PyTorch-Datei selbst: Kopieren Sie den Inhalt von
<code>modeling_brand_new_bert.py</code> in <code>src/transformers/models/brand_new_bert/</code> nach
<code>modeling_tf_brand_new_bert.py</code>. Das Ziel dieses Abschnitts ist es, die Datei zu √§ndern und die Importstruktur von
ü§ó Transformers zu aktualisieren, so dass Sie <code>TFBrandNewBert</code> und
<code>TFBrandNewBert.from_pretrained(model_repo, from_pt=True)</code> erfolgreich ein funktionierendes TensorFlow <em>BrandNewBert</em> Modell l√§dt.</p> <p data-svelte-h="svelte-zbdywb">Leider gibt es kein Rezept, um ein PyTorch-Modell in TensorFlow zu konvertieren. Sie k√∂nnen jedoch unsere Auswahl an
Tipps befolgen, um den Prozess so reibungslos wie m√∂glich zu gestalten:</p> <ul data-svelte-h="svelte-n1buib"><li>Stellen Sie <code>TF</code> dem Namen aller Klassen voran (z.B. wird <code>BrandNewBert</code> zu <code>TFBrandNewBert</code>).</li> <li>Die meisten PyTorch-Operationen haben einen direkten TensorFlow-Ersatz. Zum Beispiel entspricht <code>torch.nn.Linear</code> der Klasse
<code>tf.keras.layers.Dense</code>, <code>torch.nn.Dropout</code> entspricht <code>tf.keras.layers.Dropout</code>, usw. Wenn Sie sich nicht sicher sind
√ºber eine bestimmte Operation nicht sicher sind, k√∂nnen Sie die <a href="https://www.tensorflow.org/api_docs/python/tf" rel="nofollow">TensorFlow-Dokumentation</a>
oder die <a href="https://pytorch.org/docs/stable/" rel="nofollow">PyTorch-Dokumentation</a>.</li> <li>Suchen Sie nach Mustern in der Codebasis von ü§ó Transformers. Wenn Sie auf eine bestimmte Operation sto√üen, f√ºr die es keinen direkten Ersatz gibt
Ersatz hat, stehen die Chancen gut, dass jemand anderes bereits das gleiche Problem hatte.</li> <li>Behalten Sie standardm√§√üig die gleichen Variablennamen und die gleiche Struktur wie in PyTorch bei. Dies erleichtert die Fehlersuche, die Verfolgung von
Probleme zu verfolgen und sp√§tere Korrekturen vorzunehmen.</li> <li>Einige Ebenen haben in jedem Framework unterschiedliche Standardwerte. Ein bemerkenswertes Beispiel ist die Schicht f√ºr die Batch-Normalisierung
epsilon (<code>1e-5</code> in <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" rel="nofollow">PyTorch</a>
und <code>1e-3</code> in <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" rel="nofollow">TensorFlow</a>).
Pr√ºfen Sie die Dokumentation genau!</li> <li>Die Variablen <code>nn.Parameter</code> von PyTorch m√ºssen in der Regel innerhalb von TF Layer‚Äôs <code>build()</code> initialisiert werden. Siehe das folgende
Beispiel: <a href="https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_vit_mae.py#L212" rel="nofollow">PyTorch</a> /
<a href="https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_tf_vit_mae.py#L220" rel="nofollow">TensorFlow</a></li> <li>Wenn das PyTorch-Modell ein <code>#copied from ...</code> am Anfang einer Funktion hat, stehen die Chancen gut, dass Ihr TensorFlow-Modell diese Funktion auch
diese Funktion von der Architektur ausleihen kann, von der sie kopiert wurde, vorausgesetzt, es hat eine TensorFlow-Architektur.</li> <li>Die korrekte Zuweisung des Attributs <code>name</code> in TensorFlow-Funktionen ist entscheidend, um das <code>from_pt=True</code> Gewicht zu erreichen
Cross-Loading. Name‚Äù ist fast immer der Name der entsprechenden Variablen im PyTorch-Code. Wenn <code>name</code> nicht
nicht richtig gesetzt ist, sehen Sie dies in der Fehlermeldung beim Laden der Modellgewichte.</li> <li>Die Logik der Basismodellklasse, <code>BrandNewBertModel</code>, befindet sich in <code>TFBrandNewBertMainLayer</code>, einer Keras
Schicht-Unterklasse (<a href="https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L719" rel="nofollow">Beispiel</a>).
TFBrandNewBertModel‚Äù ist lediglich ein Wrapper f√ºr diese Schicht.</li> <li>Keras-Modelle m√ºssen erstellt werden, um die vorher trainierten Gewichte zu laden. Aus diesem Grund muss <code>TFBrandNewBertPreTrainedModel</code>
ein Beispiel f√ºr die Eingaben in das Modell enthalten, die <code>dummy_inputs</code>
(<a href="https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L916" rel="nofollow">Beispiel</a>).</li> <li>Wenn Sie nicht weiterkommen, fragen Sie nach Hilfe - wir sind f√ºr Sie da! ü§ó</li></ul> <p data-svelte-h="svelte-wos2m4">Neben der Modelldatei selbst m√ºssen Sie auch die Verweise auf die Modellklassen und die zugeh√∂rigen
Dokumentationsseiten hinzuf√ºgen. Sie k√∂nnen diesen Teil ganz nach den Mustern in anderen PRs erledigen
(<a href="https://github.com/huggingface/transformers/pull/18020/files" rel="nofollow">Beispiel</a>). Hier ist eine Liste der erforderlichen manuellen
√Ñnderungen:</p> <ul data-svelte-h="svelte-zsubiu"><li>F√ºgen Sie alle √∂ffentlichen Klassen von <em>BrandNewBert</em> in <code>src/transformers/__init__.py</code> ein.</li> <li>F√ºgen Sie <em>BrandNewBert</em> Klassen zu den entsprechenden Auto Klassen in <code>src/transformers/models/auto/modeling_tf_auto.py</code> hinzu.</li> <li>F√ºgen Sie die <em>BrandNewBert</em> zugeh√∂rigen Klassen f√ºr tr√§ges Laden in <code>src/transformers/utils/dummy_tf_objects.py</code> hinzu.</li> <li>Aktualisieren Sie die Importstrukturen f√ºr die √∂ffentlichen Klassen in <code>src/transformers/models/brand_new_bert/__init__.py</code>.</li> <li>F√ºgen Sie die Dokumentationszeiger auf die √∂ffentlichen Methoden von <em>BrandNewBert</em> in <code>docs/source/de/model_doc/brand_new_bert.md</code> hinzu.</li> <li>F√ºgen Sie sich selbst zur Liste der Mitwirkenden an <em>BrandNewBert</em> in <code>docs/source/de/model_doc/brand_new_bert.md</code> hinzu.</li> <li>F√ºgen Sie schlie√ülich ein gr√ºnes H√§kchen ‚úÖ in der TensorFlow-Spalte von <em>BrandNewBert</em> in <code>docs/source/de/index.md</code> hinzu.</li></ul> <p data-svelte-h="svelte-vqns4z">Wenn Sie mit Ihrer Implementierung zufrieden sind, f√ºhren Sie die folgende Checkliste aus, um zu best√§tigen, dass Ihre Modellarchitektur
fertig ist:</p> <ol data-svelte-h="svelte-1h2udl1"><li>Alle Schichten, die sich zur Trainingszeit anders verhalten (z.B. Dropout), werden mit einem <code>Training</code> Argument aufgerufen, das
von den Top-Level-Klassen weitergegeben wird</li> <li>Sie haben <code>#copied from ...</code> verwendet, wann immer es m√∂glich war.</li> <li>Die Funktion <code>TFBrandNewBertMainLayer</code> und alle Klassen, die sie verwenden, haben ihre Funktion <code>call</code> mit <code>@unpack_inputs</code> dekoriert</li> <li><code>TFBrandNewBertMainLayer</code> ist mit <code>@keras_serializable</code> dekoriert</li> <li>Ein TensorFlow-Modell kann aus PyTorch-Gewichten mit <code>TFBrandNewBert.from_pretrained(model_repo, from_pt=True)</code> geladen werden.</li> <li>Sie k√∂nnen das TensorFlow Modell mit dem erwarteten Eingabeformat aufrufen</li></ol>  <h3 class="relative group"><a id="5-modell-tests-hinzuf√ºgen" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#5-modell-tests-hinzuf√ºgen"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>5. Modell-Tests hinzuf√ºgen</span></h3> <p data-svelte-h="svelte-4bapov">Hurra, Sie haben ein TensorFlow-Modell implementiert! Jetzt ist es an der Zeit, Tests hinzuzuf√ºgen, um sicherzustellen, dass sich Ihr Modell wie erwartet verh√§lt.
erwartet. Wie im vorigen Abschnitt schlagen wir vor, dass Sie zun√§chst die Datei <code>test_modeling_brand_new_bert.py</code> in
<code>tests/models/brand_new_bert/</code> in die Datei <code>test_modeling_tf_brand_new_bert.py</code> zu kopieren und dann die notwendigen
TensorFlow-Ersetzungen vornehmen. F√ºr den Moment sollten Sie in allen Aufrufen von <code>.from_pretrained()</code> das Flag <code>from_pt=True</code> verwenden, um die
die vorhandenen PyTorch-Gewichte zu laden.</p> <p data-svelte-h="svelte-10tx4b2">Wenn Sie damit fertig sind, kommt der Moment der Wahrheit: F√ºhren Sie die Tests durch! üò¨</p> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->NVIDIA_TF32_OVERRIDE=0 RUN_SLOW=1 RUN_PT_TF_CROSS_TESTS=1 \
py.test -vv tests/models/brand_new_bert/test_modeling_tf_brand_new_bert.py<!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1oc8amp">Das wahrscheinlichste Ergebnis ist, dass Sie eine Reihe von Fehlern sehen werden. Machen Sie sich keine Sorgen, das ist zu erwarten! Das Debuggen von ML-Modellen ist
notorisch schwierig, und der Schl√ºssel zum Erfolg ist Geduld (und <code>breakpoint()</code>). Nach unserer Erfahrung sind die schwierigsten
Probleme aus subtilen Unstimmigkeiten zwischen ML-Frameworks, zu denen wir am Ende dieses Leitfadens ein paar Hinweise geben.
In anderen F√§llen kann es sein, dass ein allgemeiner Test nicht direkt auf Ihr Modell anwendbar ist; in diesem Fall empfehlen wir eine √úberschreibung
auf der Ebene der Modelltestklasse. Z√∂gern Sie nicht, in Ihrem Entwurf einer Pull-Anfrage um Hilfe zu bitten, wenn
Sie nicht weiterkommen.</p> <p data-svelte-h="svelte-1lds98i">Wenn alle Tests erfolgreich waren, k√∂nnen Sie Ihr Modell in die ü§ó Transformers-Bibliothek aufnehmen! üéâ</p>  <h3 class="relative group"><a id="6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>6.-7. Stellen Sie sicher, dass jeder Ihr Modell verwenden kann</span></h3> <p data-svelte-h="svelte-16s891n"><strong>6. Reichen Sie den Pull Request ein</strong></p> <p data-svelte-h="svelte-ncji3h">Sobald Sie mit der Implementierung und den Tests fertig sind, ist es an der Zeit, eine Pull-Anfrage einzureichen. Bevor Sie Ihren Code einreichen,
f√ºhren Sie unser Dienstprogramm zur Codeformatierung, <code>make fixup</code> ü™Ñ, aus. Damit werden automatisch alle Formatierungsfehler behoben, die dazu f√ºhren w√ºrden, dass
unsere automatischen Pr√ºfungen fehlschlagen w√ºrden.</p> <p data-svelte-h="svelte-149uemf">Nun ist es an der Zeit, Ihren Entwurf einer Pull-Anfrage in eine echte Pull-Anfrage umzuwandeln. Klicken Sie dazu auf die Schaltfl√§che ‚ÄúBereit f√ºr
Review‚Äù und f√ºgen Sie Joao (<code>@gante</code>) und Matt (<code>@Rocketknight1</code>) als Reviewer hinzu. Eine Modell-Pull-Anfrage ben√∂tigt
mindestens 3 Reviewer, aber sie werden sich darum k√ºmmern, geeignete zus√§tzliche Reviewer f√ºr Ihr Modell zu finden.</p> <p data-svelte-h="svelte-14jmds5">Nachdem alle Gutachter mit dem Stand Ihres PR zufrieden sind, entfernen Sie als letzten Aktionspunkt das Flag <code>from_pt=True</code> in
.from_pretrained()-Aufrufen zu entfernen. Da es keine TensorFlow-Gewichte gibt, m√ºssen Sie sie hinzuf√ºgen! Lesen Sie den Abschnitt
unten, um zu erfahren, wie Sie dies tun k√∂nnen.</p> <p data-svelte-h="svelte-jizgya">Wenn schlie√ülich die TensorFlow-Gewichte zusammengef√ºhrt werden, Sie mindestens 3 Genehmigungen von Pr√ºfern haben und alle CI-Checks gr√ºn sind
gr√ºn sind, √ºberpr√ºfen Sie die Tests ein letztes Mal lokal</p> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->NVIDIA_TF32_OVERRIDE=0 RUN_SLOW=1 RUN_PT_TF_CROSS_TESTS=1 \
py.test -vv tests/models/brand_new_bert/test_modeling_tf_brand_new_bert.py<!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1dj6cka">und wir werden Ihren PR zusammenf√ºhren! Herzlichen Gl√ºckwunsch zu dem Meilenstein üéâ.</p> <p data-svelte-h="svelte-1p8z3oj"><strong>7. (Optional) Erstellen Sie Demos und teilen Sie sie mit der Welt</strong></p> <p data-svelte-h="svelte-1fjxyf5">Eine der schwierigsten Aufgaben bei Open-Source ist die Entdeckung. Wie k√∂nnen die anderen Benutzer von der Existenz Ihres
fabelhaften TensorFlow-Beitrags erfahren? Mit der richtigen Kommunikation, nat√ºrlich! üì£</p> <p data-svelte-h="svelte-3927l5">Es gibt vor allem zwei M√∂glichkeiten, Ihr Modell mit der Community zu teilen:</p> <ul data-svelte-h="svelte-rm7h9v"><li>Erstellen Sie Demos. Dazu geh√∂ren Gradio-Demos, Notebooks und andere unterhaltsame M√∂glichkeiten, Ihr Modell vorzuf√ºhren. Wir raten Ihnen
ermutigen Sie, ein Notizbuch zu unseren <a href="https://huggingface.co/docs/transformers/community" rel="nofollow">community-driven demos</a> hinzuzuf√ºgen.</li> <li>Teilen Sie Geschichten in sozialen Medien wie Twitter und LinkedIn. Sie sollten stolz auf Ihre Arbeit sein und sie mit der
Ihre Leistung mit der Community teilen - Ihr Modell kann nun von Tausenden von Ingenieuren und Forschern auf der ganzen Welt genutzt werden
der Welt genutzt werden üåç! Wir werden Ihre Beitr√§ge gerne retweeten und Ihnen helfen, Ihre Arbeit mit der Community zu teilen.</li></ul>  <h2 class="relative group"><a id="hinzuf√ºgen-von-tensorflow-gewichten-zum--hub" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#hinzuf√ºgen-von-tensorflow-gewichten-zum--hub"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Hinzuf√ºgen von TensorFlow-Gewichten zum ü§ó Hub</span></h2> <p data-svelte-h="svelte-1vw1dmv">Unter der Annahme, dass die TensorFlow-Modellarchitektur in ü§ó Transformers verf√ºgbar ist, ist die Umwandlung von PyTorch-Gewichten in
TensorFlow-Gewichte ist ein Kinderspiel!</p> <p data-svelte-h="svelte-kj8wzd">Hier sehen Sie, wie es geht:</p> <ol data-svelte-h="svelte-1k58r6i"><li>Stellen Sie sicher, dass Sie in Ihrem Terminal bei Ihrem Hugging Face Konto angemeldet sind. Sie k√∂nnen sich mit dem folgenden Befehl anmelden
<code>huggingface-cli login</code> (Ihre Zugangstoken finden Sie <a href="https://huggingface.co/settings/tokens" rel="nofollow">hier</a>)</li> <li>F√ºhren Sie <code>transformers-cli pt-to-tf --model-name foo/bar</code> aus, wobei <code>foo/bar</code> der Name des Modell-Repositorys ist
ist, das die PyTorch-Gewichte enth√§lt, die Sie konvertieren m√∂chten.</li> <li>Markieren Sie <code>@joaogante</code> und <code>@Rocketknight1</code> in dem ü§ó Hub PR, den der obige Befehl gerade erstellt hat</li></ol> <p data-svelte-h="svelte-ql0dng">Das war‚Äôs! üéâ</p>  <h2 class="relative group"><a id="fehlersuche-in-verschiedenen-ml-frameworks-" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#fehlersuche-in-verschiedenen-ml-frameworks-"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Fehlersuche in verschiedenen ML-Frameworks üêõ</span></h2> <p data-svelte-h="svelte-141uv0b">Irgendwann, wenn Sie eine neue Architektur hinzuf√ºgen oder TensorFlow-Gewichte f√ºr eine bestehende Architektur erstellen, werden Sie
sto√üen Sie vielleicht auf Fehler, die sich √ºber Unstimmigkeiten zwischen PyTorch und TensorFlow beschweren. Sie k√∂nnten sich sogar dazu entschlie√üen, den
Modellarchitektur-Code f√ºr die beiden Frameworks zu √∂ffnen, und stellen fest, dass sie identisch aussehen. Was ist denn da los? ü§î</p> <p data-svelte-h="svelte-1cdbit1">Lassen Sie uns zun√§chst dar√ºber sprechen, warum es wichtig ist, diese Diskrepanzen zu verstehen. Viele Community-Mitglieder werden ü§ó
Transformers-Modelle und vertrauen darauf, dass sich unsere Modelle wie erwartet verhalten. Wenn es eine gro√üe Diskrepanz gibt
zwischen den beiden Frameworks auftritt, bedeutet dies, dass das Modell nicht der Referenzimplementierung f√ºr mindestens eines der Frameworks folgt.
der Frameworks folgt. Dies kann zu stillen Fehlern f√ºhren, bei denen das Modell zwar l√§uft, aber eine schlechte Leistung aufweist. Dies ist
wohl schlimmer als ein Modell, das √ºberhaupt nicht l√§uft! Aus diesem Grund streben wir an, dass die Abweichung zwischen den Frameworks kleiner als
1e-5‚Äù in allen Phasen des Modells.</p> <p data-svelte-h="svelte-1m5tplt">Wie bei anderen numerischen Problemen auch, steckt der Teufel im Detail. Und wie bei jedem detailorientierten Handwerk ist die geheime
Zutat hier Geduld. Hier ist unser Vorschlag f√ºr den Arbeitsablauf, wenn Sie auf diese Art von Problemen sto√üen:</p> <ol data-svelte-h="svelte-964so5"><li>Lokalisieren Sie die Quelle der Abweichungen. Das Modell, das Sie konvertieren, hat wahrscheinlich bis zu einem gewissen Punkt nahezu identische innere Variablen.
bestimmten Punkt. Platzieren Sie <code>Breakpoint()</code>-Anweisungen in den Architekturen der beiden Frameworks und vergleichen Sie die Werte der
numerischen Variablen von oben nach unten, bis Sie die Quelle der Probleme gefunden haben.</li> <li>Nachdem Sie nun die Ursache des Problems gefunden haben, setzen Sie sich mit dem ü§ó Transformers-Team in Verbindung. Es ist m√∂glich
dass wir ein √§hnliches Problem schon einmal gesehen haben und umgehend eine L√∂sung anbieten k√∂nnen. Als Ausweichm√∂glichkeit k√∂nnen Sie beliebte Seiten
wie StackOverflow und GitHub-Probleme.</li> <li>Wenn keine L√∂sung in Sicht ist, bedeutet das, dass Sie tiefer gehen m√ºssen. Die gute Nachricht ist, dass Sie das Problem gefunden haben.
Problem ausfindig gemacht haben, so dass Sie sich auf die problematische Anweisung konzentrieren und den Rest des Modells ausblenden k√∂nnen! Die schlechte Nachricht ist
dass Sie sich in die Quellimplementierung der besagten Anweisung einarbeiten m√ºssen. In manchen F√§llen finden Sie vielleicht ein
Problem mit einer Referenzimplementierung - verzichten Sie nicht darauf, ein Problem im Upstream-Repository zu √∂ffnen.</li></ol> <p data-svelte-h="svelte-5elsy9">In einigen F√§llen k√∂nnen wir nach R√ºcksprache mit dem ü§ó Transformers-Team zu dem Schluss kommen, dass die Behebung der Abweichung nicht machbar ist.
Wenn die Abweichung in den Ausgabeschichten des Modells sehr klein ist (aber m√∂glicherweise gro√ü in den versteckten Zust√§nden), k√∂nnen wir
k√∂nnten wir beschlie√üen, sie zu ignorieren und das Modell zu verteilen. Die oben erw√§hnte CLI <code>pt-to-tf</code> hat ein <code>--max-error</code>
Flag, um die Fehlermeldung bei der Gewichtskonvertierung zu √ºberschreiben.</p>  <p></p> 
			
			<script>
				{
					__sveltekit_1n35apo = {
						assets: "/docs/transformers/main/de",
						base: "/docs/transformers/main/de",
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("/docs/transformers/main/de/_app/immutable/entry/start.155de6db.js"),
						import("/docs/transformers/main/de/_app/immutable/entry/app.e6ae5761.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 5],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		
