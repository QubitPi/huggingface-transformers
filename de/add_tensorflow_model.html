<meta charset="utf-8" /><meta name="hf:doc:metadata" content="{&quot;title&quot;:&quot;Wie konvertiert man ein 🤗 Transformers-Modell in TensorFlow?&quot;,&quot;local&quot;:&quot;wie-konvertiert-man-ein--transformers-modell-in-tensorflow&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Schritt-für-Schritt-Anleitung zum Hinzufügen von TensorFlow-Modellarchitektur-Code&quot;,&quot;local&quot;:&quot;schritt-für-schritt-anleitung-zum-hinzufügen-von-tensorflow-modellarchitektur-code&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;1.-3. Bereiten Sie Ihren Modellbeitrag vor&quot;,&quot;local&quot;:&quot;1-3-bereiten-sie-ihren-modellbeitrag-vor&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;4. Implementierung des Modells&quot;,&quot;local&quot;:&quot;4-implementierung-des-modells&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;5. Modell-Tests hinzufügen&quot;,&quot;local&quot;:&quot;5-modell-tests-hinzufügen&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;6.-7. Stellen Sie sicher, dass jeder Ihr Modell verwenden kann&quot;,&quot;local&quot;:&quot;6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3}],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Hinzufügen von TensorFlow-Gewichten zum 🤗 Hub&quot;,&quot;local&quot;:&quot;hinzufügen-von-tensorflow-gewichten-zum--hub&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Fehlersuche in verschiedenen ML-Frameworks 🐛&quot;,&quot;local&quot;:&quot;fehlersuche-in-verschiedenen-ml-frameworks-&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}">
		<link href="/docs/transformers/main/de/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/entry/start.155de6db.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/scheduler.987d3921.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/singletons.0701d17e.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/index.42b1abb7.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/paths.f9b25ae7.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/entry/app.e6ae5761.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/index.c8b1fed4.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/nodes/0.8cbb324c.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/each.e59479a4.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/nodes/5.001e98ea.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/Tip.6bc1e794.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/CodeBlock.18094d58.js">
		<link rel="modulepreload" href="/docs/transformers/main/de/_app/immutable/chunks/Heading.3fa3b67f.js"><!-- HEAD_svelte-u9bgzb_START --><meta name="hf:doc:metadata" content="{&quot;title&quot;:&quot;Wie konvertiert man ein 🤗 Transformers-Modell in TensorFlow?&quot;,&quot;local&quot;:&quot;wie-konvertiert-man-ein--transformers-modell-in-tensorflow&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Schritt-für-Schritt-Anleitung zum Hinzufügen von TensorFlow-Modellarchitektur-Code&quot;,&quot;local&quot;:&quot;schritt-für-schritt-anleitung-zum-hinzufügen-von-tensorflow-modellarchitektur-code&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;1.-3. Bereiten Sie Ihren Modellbeitrag vor&quot;,&quot;local&quot;:&quot;1-3-bereiten-sie-ihren-modellbeitrag-vor&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;4. Implementierung des Modells&quot;,&quot;local&quot;:&quot;4-implementierung-des-modells&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;5. Modell-Tests hinzufügen&quot;,&quot;local&quot;:&quot;5-modell-tests-hinzufügen&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3},{&quot;title&quot;:&quot;6.-7. Stellen Sie sicher, dass jeder Ihr Modell verwenden kann&quot;,&quot;local&quot;:&quot;6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann&quot;,&quot;sections&quot;:[],&quot;depth&quot;:3}],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Hinzufügen von TensorFlow-Gewichten zum 🤗 Hub&quot;,&quot;local&quot;:&quot;hinzufügen-von-tensorflow-gewichten-zum--hub&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Fehlersuche in verschiedenen ML-Frameworks 🐛&quot;,&quot;local&quot;:&quot;fehlersuche-in-verschiedenen-ml-frameworks-&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}"><!-- HEAD_svelte-u9bgzb_END -->      <p></p>   <h1 class="relative group"><a id="wie-konvertiert-man-ein--transformers-modell-in-tensorflow" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#wie-konvertiert-man-ein--transformers-modell-in-tensorflow"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Wie konvertiert man ein 🤗 Transformers-Modell in TensorFlow?</span></h1> <p data-svelte-h="svelte-1ht4dl">Die Tatsache, dass mehrere Frameworks für die Verwendung mit 🤗 Transformers zur Verfügung stehen, gibt Ihnen die Flexibilität, deren Stärken beim Entwurf Ihrer Anwendung auszuspielen.
Ihre Anwendung zu entwerfen, aber das bedeutet auch, dass die Kompatibilität für jedes Modell einzeln hinzugefügt werden muss. Die gute Nachricht ist, dass
das Hinzufügen von TensorFlow-Kompatibilität zu einem bestehenden Modell einfacher ist als <a href="add_new_model">das Hinzufügen eines neuen Modells von Grund auf</a>!
Ob Sie ein tieferes Verständnis für große TensorFlow-Modelle haben möchten, einen wichtigen Open-Source-Beitrag leisten oder
TensorFlow für das Modell Ihrer Wahl aktivieren wollen, dieser Leitfaden ist für Sie.</p> <p data-svelte-h="svelte-195iua3">Dieser Leitfaden befähigt Sie, ein Mitglied unserer Gemeinschaft, TensorFlow-Modellgewichte und/oder
Architekturen beizusteuern, die in 🤗 Transformers verwendet werden sollen, und zwar mit minimaler Betreuung durch das Hugging Face Team. Das Schreiben eines neuen Modells
ist keine Kleinigkeit, aber ich hoffe, dass dieser Leitfaden dazu beiträgt, dass es weniger eine Achterbahnfahrt 🎢 und mehr ein Spaziergang im Park 🚶 ist.
Die Nutzung unserer kollektiven Erfahrungen ist absolut entscheidend, um diesen Prozess immer einfacher zu machen, und deshalb möchten wir
ermutigen Sie daher, Verbesserungsvorschläge für diesen Leitfaden zu machen!</p> <p data-svelte-h="svelte-pl5slc">Bevor Sie tiefer eintauchen, empfehlen wir Ihnen, die folgenden Ressourcen zu lesen, wenn Sie neu in 🤗 Transformers sind:</p> <ul data-svelte-h="svelte-10qxdc2"><li><a href="add_new_model#general-overview-of-transformers">Allgemeiner Überblick über 🤗 Transformers</a></li> <li><a href="https://huggingface.co/blog/tensorflow-philosophy" rel="nofollow">Die TensorFlow-Philosophie von Hugging Face</a></li></ul> <p data-svelte-h="svelte-1fyrz1">Im Rest dieses Leitfadens werden Sie lernen, was nötig ist, um eine neue TensorFlow Modellarchitektur hinzuzufügen, die
Verfahren zur Konvertierung von PyTorch in TensorFlow-Modellgewichte und wie Sie Unstimmigkeiten zwischen ML
Frameworks. Legen Sie los!</p>  <div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400"><p data-svelte-h="svelte-olarmn">Sind Sie unsicher, ob das Modell, das Sie verwenden möchten, bereits eine entsprechende TensorFlow-Architektur hat?</p> <p data-svelte-h="svelte-1cdgjs8"> </p> <p data-svelte-h="svelte-emag10">Überprüfen Sie das Feld <code>model_type</code> in der <code>config.json</code> des Modells Ihrer Wahl
(<a href="https://huggingface.co/google-bert/bert-base-uncased/blob/main/config.json#L14" rel="nofollow">Beispiel</a>). Wenn der entsprechende Modellordner in
🤗 Transformers eine Datei hat, deren Name mit “modeling_tf” beginnt, bedeutet dies, dass es eine entsprechende TensorFlow
Architektur hat (<a href="https://github.com/huggingface/transformers/tree/main/src/transformers/models/bert" rel="nofollow">Beispiel</a>).</p></div>  <h2 class="relative group"><a id="schritt-für-schritt-anleitung-zum-hinzufügen-von-tensorflow-modellarchitektur-code" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#schritt-für-schritt-anleitung-zum-hinzufügen-von-tensorflow-modellarchitektur-code"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Schritt-für-Schritt-Anleitung zum Hinzufügen von TensorFlow-Modellarchitektur-Code</span></h2> <p data-svelte-h="svelte-1apyhwg">Es gibt viele Möglichkeiten, eine große Modellarchitektur zu entwerfen, und viele Möglichkeiten, diesen Entwurf zu implementieren. Wie auch immer,
Sie erinnern sich vielleicht an unseren <a href="add_new_model#general-overview-of-transformers">allgemeinen Überblick über 🤗 Transformers</a>
wissen, dass wir ein meinungsfreudiger Haufen sind - die Benutzerfreundlichkeit von 🤗 Transformers hängt von konsistenten Designentscheidungen ab. Aus
Erfahrung können wir Ihnen ein paar wichtige Dinge über das Hinzufügen von TensorFlow-Modellen sagen:</p> <ul data-svelte-h="svelte-j498kv"><li>Erfinden Sie das Rad nicht neu! In den meisten Fällen gibt es mindestens zwei Referenzimplementierungen, die Sie überprüfen sollten: das
PyTorch-Äquivalent des Modells, das Sie implementieren, und andere TensorFlow-Modelle für dieselbe Klasse von Problemen.</li> <li>Gute Modellimplementierungen überleben den Test der Zeit. Dies geschieht nicht, weil der Code hübsch ist, sondern eher
sondern weil der Code klar, einfach zu debuggen und darauf aufzubauen ist. Wenn Sie den Maintainern das Leben mit Ihrer
TensorFlow-Implementierung leicht machen, indem Sie die gleichen Muster wie in anderen TensorFlow-Modellen nachbilden und die Abweichung
zur PyTorch-Implementierung minimieren, stellen Sie sicher, dass Ihr Beitrag lange Bestand haben wird.</li> <li>Bitten Sie um Hilfe, wenn Sie nicht weiterkommen! Das 🤗 Transformers-Team ist da, um zu helfen, und wir haben wahrscheinlich Lösungen für die gleichen
Probleme gefunden, vor denen Sie stehen.</li></ul> <p data-svelte-h="svelte-19ofyge">Hier finden Sie einen Überblick über die Schritte, die zum Hinzufügen einer TensorFlow-Modellarchitektur erforderlich sind:</p> <ol data-svelte-h="svelte-49ahbp"><li>Wählen Sie das Modell, das Sie konvertieren möchten</li> <li>Bereiten Sie die Transformers-Entwicklungsumgebung vor.</li> <li>(Optional) Verstehen Sie die theoretischen Aspekte und die bestehende Implementierung</li> <li>Implementieren Sie die Modellarchitektur</li> <li>Implementieren Sie Modelltests</li> <li>Reichen Sie den Pull-Antrag ein</li> <li>(Optional) Erstellen Sie Demos und teilen Sie diese mit der Welt</li></ol>  <h3 class="relative group"><a id="1-3-bereiten-sie-ihren-modellbeitrag-vor" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#1-3-bereiten-sie-ihren-modellbeitrag-vor"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>1.-3. Bereiten Sie Ihren Modellbeitrag vor</span></h3> <p data-svelte-h="svelte-16h96ya"><strong>1. Wählen Sie das Modell, das Sie konvertieren möchten</strong></p> <p data-svelte-h="svelte-1fkb5qr">Beginnen wir mit den Grundlagen: Als erstes müssen Sie die Architektur kennen, die Sie konvertieren möchten. Wenn Sie
Sie sich nicht auf eine bestimmte Architektur festgelegt haben, ist es eine gute Möglichkeit, das 🤗 Transformers-Team um Vorschläge zu bitten.
Wir werden Sie zu den wichtigsten Architekturen führen, die auf der TensorFlow-Seite noch fehlen.
Seite fehlen. Wenn das spezifische Modell, das Sie mit TensorFlow verwenden möchten, bereits eine Implementierung der TensorFlow-Architektur in
🤗 Transformers, aber es fehlen Gewichte, können Sie direkt in den
Abschnitt <a href="#hinzuf%C3%BCgen-von-tensorflow-gewichten-zum--hub">Gewichtskonvertierung</a>
auf dieser Seite.</p> <p data-svelte-h="svelte-j04nbk">Der Einfachheit halber wird im Rest dieser Anleitung davon ausgegangen, dass Sie sich entschieden haben, mit der TensorFlow-Version von
<em>BrandNewBert</em> (dasselbe Beispiel wie in der <a href="add_new_model">Anleitung</a>, um ein neues Modell von Grund auf hinzuzufügen).</p>  <div class="course-tip  bg-gradient-to-br dark:bg-gradient-to-r before:border-green-500 dark:before:border-green-800 from-green-50 dark:from-gray-900 to-white dark:to-gray-950 border border-green-50 text-green-700 dark:text-gray-400"><p data-svelte-h="svelte-dzw3pi">Bevor Sie mit der Arbeit an einer TensorFlow-Modellarchitektur beginnen, sollten Sie sich vergewissern, dass es keine laufenden Bemühungen in dieser Richtung gibt.
Sie können nach <code>BrandNewBert</code> auf der
<a href="https://github.com/huggingface/transformers/pulls?q=is%3Apr" rel="nofollow">pull request GitHub page</a>, um zu bestätigen, dass es keine
TensorFlow-bezogene Pull-Anfrage gibt.</p></div> <p data-svelte-h="svelte-do7bnr"><strong>2. Transformers-Entwicklungsumgebung vorbereiten</strong></p> <p data-svelte-h="svelte-jlox09">Nachdem Sie die Modellarchitektur ausgewählt haben, öffnen Sie einen PR-Entwurf, um Ihre Absicht zu signalisieren, daran zu arbeiten. Folgen Sie den
Anweisungen, um Ihre Umgebung einzurichten und einen PR-Entwurf zu öffnen.</p> <ol data-svelte-h="svelte-v4wfpl"><li><p>Forken Sie das <a href="https://github.com/huggingface/transformers" rel="nofollow">repository</a>, indem Sie auf der Seite des Repositorys auf die Schaltfläche ‘Fork’ klicken.
Seite des Repositorys klicken. Dadurch wird eine Kopie des Codes unter Ihrem GitHub-Benutzerkonto erstellt.</p></li> <li><p>Klonen Sie Ihren <code>transformers</code> Fork auf Ihre lokale Festplatte und fügen Sie das Basis-Repository als Remote hinzu:</p></li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git <span class="hljs-built_in">clone</span> https://github.com/[your Github handle]/transformers.git
<span class="hljs-built_in">cd</span> transformers
git remote add upstream https://github.com/huggingface/transformers.git<!-- HTML_TAG_END --></pre></div> <ol start="3" data-svelte-h="svelte-oahl5t"><li>Richten Sie eine Entwicklungsumgebung ein, indem Sie z.B. den folgenden Befehl ausführen:</li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->python -m venv .<span class="hljs-built_in">env</span>
<span class="hljs-built_in">source</span> .<span class="hljs-built_in">env</span>/bin/activate
pip install -e <span class="hljs-string">&quot;.[dev]&quot;</span><!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1wzcf5d">Abhängig von Ihrem Betriebssystem und da die Anzahl der optionalen Abhängigkeiten von Transformers wächst, kann es sein, dass Sie bei diesem Befehl einen
Fehler mit diesem Befehl erhalten. Wenn das der Fall ist, stellen Sie sicher, dass Sie TensorFlow installieren und dann ausführen:</p> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->pip install -e <span class="hljs-string">&quot;.[quality]&quot;</span><!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1t59a26"><strong>Hinweis:</strong> Sie müssen CUDA nicht installiert haben. Es reicht aus, das neue Modell auf der CPU laufen zu lassen.</p> <ol start="4" data-svelte-h="svelte-3zwnfl"><li>Erstellen Sie eine Verzweigung mit einem beschreibenden Namen von Ihrer Hauptverzweigung</li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git checkout -b add_tf_brand_new_bert<!-- HTML_TAG_END --></pre></div> <ol start="5" data-svelte-h="svelte-x058iw"><li>Abrufen und zurücksetzen auf die aktuelle Hauptversion</li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git fetch upstream
git rebase upstream/main<!-- HTML_TAG_END --></pre></div> <ol start="6" data-svelte-h="svelte-7ts89o"><li><p>Fügen Sie eine leere <code>.py</code> Datei in <code>transformers/src/models/brandnewbert/</code> mit dem Namen <code>modeling_tf_brandnewbert.py</code> hinzu. Dies wird
Ihre TensorFlow-Modelldatei sein.</p></li> <li><p>Übertragen Sie die Änderungen auf Ihr Konto mit:</p></li></ol> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->git add .
git commit -m <span class="hljs-string">&quot;initial commit&quot;</span>
git push -u origin add_tf_brand_new_bert<!-- HTML_TAG_END --></pre></div> <ol start="8" data-svelte-h="svelte-1a2kv3l"><li><p>Wenn Sie zufrieden sind, gehen Sie auf die Webseite Ihrer Abspaltung auf GitHub. Klicken Sie auf “Pull request”. Stellen Sie sicher, dass Sie das
GitHub-Handle einiger Mitglieder des Hugging Face-Teams als Reviewer hinzuzufügen, damit das Hugging Face-Team über zukünftige Änderungen informiert wird.
zukünftige Änderungen benachrichtigt wird.</p></li> <li><p>Ändern Sie den PR in einen Entwurf, indem Sie auf der rechten Seite der GitHub-Pull-Request-Webseite auf “In Entwurf umwandeln” klicken.</p></li></ol> <p data-svelte-h="svelte-1jgt5f">Jetzt haben Sie eine Entwicklungsumgebung eingerichtet, um <em>BrandNewBert</em> nach TensorFlow in 🤗 Transformers zu portieren.</p> <p data-svelte-h="svelte-n0bn3l"><strong>3. (Optional) Verstehen Sie die theoretischen Aspekte und die bestehende Implementierung</strong></p> <p data-svelte-h="svelte-1sjq4zv">Sie sollten sich etwas Zeit nehmen, um die Arbeit von <em>BrandNewBert</em> zu lesen, falls eine solche Beschreibung existiert. Möglicherweise gibt es große
Abschnitte des Papiers, die schwer zu verstehen sind. Wenn das der Fall ist, ist das in Ordnung - machen Sie sich keine Sorgen! Das Ziel ist
ist es nicht, ein tiefes theoretisches Verständnis des Papiers zu erlangen, sondern die notwendigen Informationen zu extrahieren, um
das Modell mit Hilfe von TensorFlow effektiv in 🤗 Transformers neu zu implementieren. Das heißt, Sie müssen nicht zu viel Zeit auf die
viel Zeit auf die theoretischen Aspekte verwenden, sondern sich lieber auf die praktischen Aspekte konzentrieren, nämlich auf die bestehende Modelldokumentation
Seite (z.B. <a href="model_doc/bert">model docs for BERT</a>).</p> <p data-svelte-h="svelte-1u71zen">Nachdem Sie die Grundlagen der Modelle, die Sie implementieren wollen, verstanden haben, ist es wichtig, die bestehende
Implementierung zu verstehen. Dies ist eine gute Gelegenheit, sich zu vergewissern, dass eine funktionierende Implementierung mit Ihren Erwartungen an das
Modell entspricht, und um technische Herausforderungen auf der TensorFlow-Seite vorauszusehen.</p> <p data-svelte-h="svelte-1lhg56c">Es ist ganz natürlich, dass Sie sich von der Menge an Informationen, die Sie gerade aufgesogen haben, überwältigt fühlen. Es ist
Es ist definitiv nicht erforderlich, dass Sie in dieser Phase alle Facetten des Modells verstehen. Dennoch empfehlen wir Ihnen dringend
ermutigen wir Sie, alle dringenden Fragen in unserem <a href="https://discuss.huggingface.co/" rel="nofollow">Forum</a> zu klären.</p>  <h3 class="relative group"><a id="4-implementierung-des-modells" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#4-implementierung-des-modells"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>4. Implementierung des Modells</span></h3> <p data-svelte-h="svelte-ibj99d">Jetzt ist es an der Zeit, endlich mit dem Programmieren zu beginnen. Als Ausgangspunkt empfehlen wir die PyTorch-Datei selbst: Kopieren Sie den Inhalt von
<code>modeling_brand_new_bert.py</code> in <code>src/transformers/models/brand_new_bert/</code> nach
<code>modeling_tf_brand_new_bert.py</code>. Das Ziel dieses Abschnitts ist es, die Datei zu ändern und die Importstruktur von
🤗 Transformers zu aktualisieren, so dass Sie <code>TFBrandNewBert</code> und
<code>TFBrandNewBert.from_pretrained(model_repo, from_pt=True)</code> erfolgreich ein funktionierendes TensorFlow <em>BrandNewBert</em> Modell lädt.</p> <p data-svelte-h="svelte-zbdywb">Leider gibt es kein Rezept, um ein PyTorch-Modell in TensorFlow zu konvertieren. Sie können jedoch unsere Auswahl an
Tipps befolgen, um den Prozess so reibungslos wie möglich zu gestalten:</p> <ul data-svelte-h="svelte-n1buib"><li>Stellen Sie <code>TF</code> dem Namen aller Klassen voran (z.B. wird <code>BrandNewBert</code> zu <code>TFBrandNewBert</code>).</li> <li>Die meisten PyTorch-Operationen haben einen direkten TensorFlow-Ersatz. Zum Beispiel entspricht <code>torch.nn.Linear</code> der Klasse
<code>tf.keras.layers.Dense</code>, <code>torch.nn.Dropout</code> entspricht <code>tf.keras.layers.Dropout</code>, usw. Wenn Sie sich nicht sicher sind
über eine bestimmte Operation nicht sicher sind, können Sie die <a href="https://www.tensorflow.org/api_docs/python/tf" rel="nofollow">TensorFlow-Dokumentation</a>
oder die <a href="https://pytorch.org/docs/stable/" rel="nofollow">PyTorch-Dokumentation</a>.</li> <li>Suchen Sie nach Mustern in der Codebasis von 🤗 Transformers. Wenn Sie auf eine bestimmte Operation stoßen, für die es keinen direkten Ersatz gibt
Ersatz hat, stehen die Chancen gut, dass jemand anderes bereits das gleiche Problem hatte.</li> <li>Behalten Sie standardmäßig die gleichen Variablennamen und die gleiche Struktur wie in PyTorch bei. Dies erleichtert die Fehlersuche, die Verfolgung von
Probleme zu verfolgen und spätere Korrekturen vorzunehmen.</li> <li>Einige Ebenen haben in jedem Framework unterschiedliche Standardwerte. Ein bemerkenswertes Beispiel ist die Schicht für die Batch-Normalisierung
epsilon (<code>1e-5</code> in <a href="https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html#torch.nn.BatchNorm2d" rel="nofollow">PyTorch</a>
und <code>1e-3</code> in <a href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization" rel="nofollow">TensorFlow</a>).
Prüfen Sie die Dokumentation genau!</li> <li>Die Variablen <code>nn.Parameter</code> von PyTorch müssen in der Regel innerhalb von TF Layer’s <code>build()</code> initialisiert werden. Siehe das folgende
Beispiel: <a href="https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_vit_mae.py#L212" rel="nofollow">PyTorch</a> /
<a href="https://github.com/huggingface/transformers/blob/655f72a6896c0533b1bdee519ed65a059c2425ac/src/transformers/models/vit_mae/modeling_tf_vit_mae.py#L220" rel="nofollow">TensorFlow</a></li> <li>Wenn das PyTorch-Modell ein <code>#copied from ...</code> am Anfang einer Funktion hat, stehen die Chancen gut, dass Ihr TensorFlow-Modell diese Funktion auch
diese Funktion von der Architektur ausleihen kann, von der sie kopiert wurde, vorausgesetzt, es hat eine TensorFlow-Architektur.</li> <li>Die korrekte Zuweisung des Attributs <code>name</code> in TensorFlow-Funktionen ist entscheidend, um das <code>from_pt=True</code> Gewicht zu erreichen
Cross-Loading. Name” ist fast immer der Name der entsprechenden Variablen im PyTorch-Code. Wenn <code>name</code> nicht
nicht richtig gesetzt ist, sehen Sie dies in der Fehlermeldung beim Laden der Modellgewichte.</li> <li>Die Logik der Basismodellklasse, <code>BrandNewBertModel</code>, befindet sich in <code>TFBrandNewBertMainLayer</code>, einer Keras
Schicht-Unterklasse (<a href="https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L719" rel="nofollow">Beispiel</a>).
TFBrandNewBertModel” ist lediglich ein Wrapper für diese Schicht.</li> <li>Keras-Modelle müssen erstellt werden, um die vorher trainierten Gewichte zu laden. Aus diesem Grund muss <code>TFBrandNewBertPreTrainedModel</code>
ein Beispiel für die Eingaben in das Modell enthalten, die <code>dummy_inputs</code>
(<a href="https://github.com/huggingface/transformers/blob/4fd32a1f499e45f009c2c0dea4d81c321cba7e02/src/transformers/models/bert/modeling_tf_bert.py#L916" rel="nofollow">Beispiel</a>).</li> <li>Wenn Sie nicht weiterkommen, fragen Sie nach Hilfe - wir sind für Sie da! 🤗</li></ul> <p data-svelte-h="svelte-wos2m4">Neben der Modelldatei selbst müssen Sie auch die Verweise auf die Modellklassen und die zugehörigen
Dokumentationsseiten hinzufügen. Sie können diesen Teil ganz nach den Mustern in anderen PRs erledigen
(<a href="https://github.com/huggingface/transformers/pull/18020/files" rel="nofollow">Beispiel</a>). Hier ist eine Liste der erforderlichen manuellen
Änderungen:</p> <ul data-svelte-h="svelte-zsubiu"><li>Fügen Sie alle öffentlichen Klassen von <em>BrandNewBert</em> in <code>src/transformers/__init__.py</code> ein.</li> <li>Fügen Sie <em>BrandNewBert</em> Klassen zu den entsprechenden Auto Klassen in <code>src/transformers/models/auto/modeling_tf_auto.py</code> hinzu.</li> <li>Fügen Sie die <em>BrandNewBert</em> zugehörigen Klassen für träges Laden in <code>src/transformers/utils/dummy_tf_objects.py</code> hinzu.</li> <li>Aktualisieren Sie die Importstrukturen für die öffentlichen Klassen in <code>src/transformers/models/brand_new_bert/__init__.py</code>.</li> <li>Fügen Sie die Dokumentationszeiger auf die öffentlichen Methoden von <em>BrandNewBert</em> in <code>docs/source/de/model_doc/brand_new_bert.md</code> hinzu.</li> <li>Fügen Sie sich selbst zur Liste der Mitwirkenden an <em>BrandNewBert</em> in <code>docs/source/de/model_doc/brand_new_bert.md</code> hinzu.</li> <li>Fügen Sie schließlich ein grünes Häkchen ✅ in der TensorFlow-Spalte von <em>BrandNewBert</em> in <code>docs/source/de/index.md</code> hinzu.</li></ul> <p data-svelte-h="svelte-vqns4z">Wenn Sie mit Ihrer Implementierung zufrieden sind, führen Sie die folgende Checkliste aus, um zu bestätigen, dass Ihre Modellarchitektur
fertig ist:</p> <ol data-svelte-h="svelte-1h2udl1"><li>Alle Schichten, die sich zur Trainingszeit anders verhalten (z.B. Dropout), werden mit einem <code>Training</code> Argument aufgerufen, das
von den Top-Level-Klassen weitergegeben wird</li> <li>Sie haben <code>#copied from ...</code> verwendet, wann immer es möglich war.</li> <li>Die Funktion <code>TFBrandNewBertMainLayer</code> und alle Klassen, die sie verwenden, haben ihre Funktion <code>call</code> mit <code>@unpack_inputs</code> dekoriert</li> <li><code>TFBrandNewBertMainLayer</code> ist mit <code>@keras_serializable</code> dekoriert</li> <li>Ein TensorFlow-Modell kann aus PyTorch-Gewichten mit <code>TFBrandNewBert.from_pretrained(model_repo, from_pt=True)</code> geladen werden.</li> <li>Sie können das TensorFlow Modell mit dem erwarteten Eingabeformat aufrufen</li></ol>  <h3 class="relative group"><a id="5-modell-tests-hinzufügen" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#5-modell-tests-hinzufügen"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>5. Modell-Tests hinzufügen</span></h3> <p data-svelte-h="svelte-4bapov">Hurra, Sie haben ein TensorFlow-Modell implementiert! Jetzt ist es an der Zeit, Tests hinzuzufügen, um sicherzustellen, dass sich Ihr Modell wie erwartet verhält.
erwartet. Wie im vorigen Abschnitt schlagen wir vor, dass Sie zunächst die Datei <code>test_modeling_brand_new_bert.py</code> in
<code>tests/models/brand_new_bert/</code> in die Datei <code>test_modeling_tf_brand_new_bert.py</code> zu kopieren und dann die notwendigen
TensorFlow-Ersetzungen vornehmen. Für den Moment sollten Sie in allen Aufrufen von <code>.from_pretrained()</code> das Flag <code>from_pt=True</code> verwenden, um die
die vorhandenen PyTorch-Gewichte zu laden.</p> <p data-svelte-h="svelte-10tx4b2">Wenn Sie damit fertig sind, kommt der Moment der Wahrheit: Führen Sie die Tests durch! 😬</p> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->NVIDIA_TF32_OVERRIDE=0 RUN_SLOW=1 RUN_PT_TF_CROSS_TESTS=1 \
py.test -vv tests/models/brand_new_bert/test_modeling_tf_brand_new_bert.py<!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1oc8amp">Das wahrscheinlichste Ergebnis ist, dass Sie eine Reihe von Fehlern sehen werden. Machen Sie sich keine Sorgen, das ist zu erwarten! Das Debuggen von ML-Modellen ist
notorisch schwierig, und der Schlüssel zum Erfolg ist Geduld (und <code>breakpoint()</code>). Nach unserer Erfahrung sind die schwierigsten
Probleme aus subtilen Unstimmigkeiten zwischen ML-Frameworks, zu denen wir am Ende dieses Leitfadens ein paar Hinweise geben.
In anderen Fällen kann es sein, dass ein allgemeiner Test nicht direkt auf Ihr Modell anwendbar ist; in diesem Fall empfehlen wir eine Überschreibung
auf der Ebene der Modelltestklasse. Zögern Sie nicht, in Ihrem Entwurf einer Pull-Anfrage um Hilfe zu bitten, wenn
Sie nicht weiterkommen.</p> <p data-svelte-h="svelte-1lds98i">Wenn alle Tests erfolgreich waren, können Sie Ihr Modell in die 🤗 Transformers-Bibliothek aufnehmen! 🎉</p>  <h3 class="relative group"><a id="6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#6-7-stellen-sie-sicher-dass-jeder-ihr-modell-verwenden-kann"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>6.-7. Stellen Sie sicher, dass jeder Ihr Modell verwenden kann</span></h3> <p data-svelte-h="svelte-16s891n"><strong>6. Reichen Sie den Pull Request ein</strong></p> <p data-svelte-h="svelte-ncji3h">Sobald Sie mit der Implementierung und den Tests fertig sind, ist es an der Zeit, eine Pull-Anfrage einzureichen. Bevor Sie Ihren Code einreichen,
führen Sie unser Dienstprogramm zur Codeformatierung, <code>make fixup</code> 🪄, aus. Damit werden automatisch alle Formatierungsfehler behoben, die dazu führen würden, dass
unsere automatischen Prüfungen fehlschlagen würden.</p> <p data-svelte-h="svelte-149uemf">Nun ist es an der Zeit, Ihren Entwurf einer Pull-Anfrage in eine echte Pull-Anfrage umzuwandeln. Klicken Sie dazu auf die Schaltfläche “Bereit für
Review” und fügen Sie Joao (<code>@gante</code>) und Matt (<code>@Rocketknight1</code>) als Reviewer hinzu. Eine Modell-Pull-Anfrage benötigt
mindestens 3 Reviewer, aber sie werden sich darum kümmern, geeignete zusätzliche Reviewer für Ihr Modell zu finden.</p> <p data-svelte-h="svelte-14jmds5">Nachdem alle Gutachter mit dem Stand Ihres PR zufrieden sind, entfernen Sie als letzten Aktionspunkt das Flag <code>from_pt=True</code> in
.from_pretrained()-Aufrufen zu entfernen. Da es keine TensorFlow-Gewichte gibt, müssen Sie sie hinzufügen! Lesen Sie den Abschnitt
unten, um zu erfahren, wie Sie dies tun können.</p> <p data-svelte-h="svelte-jizgya">Wenn schließlich die TensorFlow-Gewichte zusammengeführt werden, Sie mindestens 3 Genehmigungen von Prüfern haben und alle CI-Checks grün sind
grün sind, überprüfen Sie die Tests ein letztes Mal lokal</p> <div class="code-block relative"><div class="absolute top-2.5 right-4"><button class="inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5   text-gray-600 " title="code excerpt" type="button"><svg class="" xmlns="http://www.w3.org/2000/svg" aria-hidden="true" fill="currentColor" focusable="false" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 32 32"><path d="M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z" transform="translate(0)"></path><path d="M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z" transform="translate(0)"></path><rect fill="none" width="32" height="32"></rect></svg> <div class="absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0"><div class="absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0" style="border-left-color: transparent; border-right-color: transparent; "></div> Copied</div></button></div> <pre class=""><!-- HTML_TAG_START -->NVIDIA_TF32_OVERRIDE=0 RUN_SLOW=1 RUN_PT_TF_CROSS_TESTS=1 \
py.test -vv tests/models/brand_new_bert/test_modeling_tf_brand_new_bert.py<!-- HTML_TAG_END --></pre></div> <p data-svelte-h="svelte-1dj6cka">und wir werden Ihren PR zusammenführen! Herzlichen Glückwunsch zu dem Meilenstein 🎉.</p> <p data-svelte-h="svelte-1p8z3oj"><strong>7. (Optional) Erstellen Sie Demos und teilen Sie sie mit der Welt</strong></p> <p data-svelte-h="svelte-1fjxyf5">Eine der schwierigsten Aufgaben bei Open-Source ist die Entdeckung. Wie können die anderen Benutzer von der Existenz Ihres
fabelhaften TensorFlow-Beitrags erfahren? Mit der richtigen Kommunikation, natürlich! 📣</p> <p data-svelte-h="svelte-3927l5">Es gibt vor allem zwei Möglichkeiten, Ihr Modell mit der Community zu teilen:</p> <ul data-svelte-h="svelte-rm7h9v"><li>Erstellen Sie Demos. Dazu gehören Gradio-Demos, Notebooks und andere unterhaltsame Möglichkeiten, Ihr Modell vorzuführen. Wir raten Ihnen
ermutigen Sie, ein Notizbuch zu unseren <a href="https://huggingface.co/docs/transformers/community" rel="nofollow">community-driven demos</a> hinzuzufügen.</li> <li>Teilen Sie Geschichten in sozialen Medien wie Twitter und LinkedIn. Sie sollten stolz auf Ihre Arbeit sein und sie mit der
Ihre Leistung mit der Community teilen - Ihr Modell kann nun von Tausenden von Ingenieuren und Forschern auf der ganzen Welt genutzt werden
der Welt genutzt werden 🌍! Wir werden Ihre Beiträge gerne retweeten und Ihnen helfen, Ihre Arbeit mit der Community zu teilen.</li></ul>  <h2 class="relative group"><a id="hinzufügen-von-tensorflow-gewichten-zum--hub" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#hinzufügen-von-tensorflow-gewichten-zum--hub"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Hinzufügen von TensorFlow-Gewichten zum 🤗 Hub</span></h2> <p data-svelte-h="svelte-1vw1dmv">Unter der Annahme, dass die TensorFlow-Modellarchitektur in 🤗 Transformers verfügbar ist, ist die Umwandlung von PyTorch-Gewichten in
TensorFlow-Gewichte ist ein Kinderspiel!</p> <p data-svelte-h="svelte-kj8wzd">Hier sehen Sie, wie es geht:</p> <ol data-svelte-h="svelte-1k58r6i"><li>Stellen Sie sicher, dass Sie in Ihrem Terminal bei Ihrem Hugging Face Konto angemeldet sind. Sie können sich mit dem folgenden Befehl anmelden
<code>huggingface-cli login</code> (Ihre Zugangstoken finden Sie <a href="https://huggingface.co/settings/tokens" rel="nofollow">hier</a>)</li> <li>Führen Sie <code>transformers-cli pt-to-tf --model-name foo/bar</code> aus, wobei <code>foo/bar</code> der Name des Modell-Repositorys ist
ist, das die PyTorch-Gewichte enthält, die Sie konvertieren möchten.</li> <li>Markieren Sie <code>@joaogante</code> und <code>@Rocketknight1</code> in dem 🤗 Hub PR, den der obige Befehl gerade erstellt hat</li></ol> <p data-svelte-h="svelte-ql0dng">Das war’s! 🎉</p>  <h2 class="relative group"><a id="fehlersuche-in-verschiedenen-ml-frameworks-" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#fehlersuche-in-verschiedenen-ml-frameworks-"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Fehlersuche in verschiedenen ML-Frameworks 🐛</span></h2> <p data-svelte-h="svelte-141uv0b">Irgendwann, wenn Sie eine neue Architektur hinzufügen oder TensorFlow-Gewichte für eine bestehende Architektur erstellen, werden Sie
stoßen Sie vielleicht auf Fehler, die sich über Unstimmigkeiten zwischen PyTorch und TensorFlow beschweren. Sie könnten sich sogar dazu entschließen, den
Modellarchitektur-Code für die beiden Frameworks zu öffnen, und stellen fest, dass sie identisch aussehen. Was ist denn da los? 🤔</p> <p data-svelte-h="svelte-1cdbit1">Lassen Sie uns zunächst darüber sprechen, warum es wichtig ist, diese Diskrepanzen zu verstehen. Viele Community-Mitglieder werden 🤗
Transformers-Modelle und vertrauen darauf, dass sich unsere Modelle wie erwartet verhalten. Wenn es eine große Diskrepanz gibt
zwischen den beiden Frameworks auftritt, bedeutet dies, dass das Modell nicht der Referenzimplementierung für mindestens eines der Frameworks folgt.
der Frameworks folgt. Dies kann zu stillen Fehlern führen, bei denen das Modell zwar läuft, aber eine schlechte Leistung aufweist. Dies ist
wohl schlimmer als ein Modell, das überhaupt nicht läuft! Aus diesem Grund streben wir an, dass die Abweichung zwischen den Frameworks kleiner als
1e-5” in allen Phasen des Modells.</p> <p data-svelte-h="svelte-1m5tplt">Wie bei anderen numerischen Problemen auch, steckt der Teufel im Detail. Und wie bei jedem detailorientierten Handwerk ist die geheime
Zutat hier Geduld. Hier ist unser Vorschlag für den Arbeitsablauf, wenn Sie auf diese Art von Problemen stoßen:</p> <ol data-svelte-h="svelte-964so5"><li>Lokalisieren Sie die Quelle der Abweichungen. Das Modell, das Sie konvertieren, hat wahrscheinlich bis zu einem gewissen Punkt nahezu identische innere Variablen.
bestimmten Punkt. Platzieren Sie <code>Breakpoint()</code>-Anweisungen in den Architekturen der beiden Frameworks und vergleichen Sie die Werte der
numerischen Variablen von oben nach unten, bis Sie die Quelle der Probleme gefunden haben.</li> <li>Nachdem Sie nun die Ursache des Problems gefunden haben, setzen Sie sich mit dem 🤗 Transformers-Team in Verbindung. Es ist möglich
dass wir ein ähnliches Problem schon einmal gesehen haben und umgehend eine Lösung anbieten können. Als Ausweichmöglichkeit können Sie beliebte Seiten
wie StackOverflow und GitHub-Probleme.</li> <li>Wenn keine Lösung in Sicht ist, bedeutet das, dass Sie tiefer gehen müssen. Die gute Nachricht ist, dass Sie das Problem gefunden haben.
Problem ausfindig gemacht haben, so dass Sie sich auf die problematische Anweisung konzentrieren und den Rest des Modells ausblenden können! Die schlechte Nachricht ist
dass Sie sich in die Quellimplementierung der besagten Anweisung einarbeiten müssen. In manchen Fällen finden Sie vielleicht ein
Problem mit einer Referenzimplementierung - verzichten Sie nicht darauf, ein Problem im Upstream-Repository zu öffnen.</li></ol> <p data-svelte-h="svelte-5elsy9">In einigen Fällen können wir nach Rücksprache mit dem 🤗 Transformers-Team zu dem Schluss kommen, dass die Behebung der Abweichung nicht machbar ist.
Wenn die Abweichung in den Ausgabeschichten des Modells sehr klein ist (aber möglicherweise groß in den versteckten Zuständen), können wir
könnten wir beschließen, sie zu ignorieren und das Modell zu verteilen. Die oben erwähnte CLI <code>pt-to-tf</code> hat ein <code>--max-error</code>
Flag, um die Fehlermeldung bei der Gewichtskonvertierung zu überschreiben.</p>  <p></p> 
			
			<script>
				{
					__sveltekit_1n35apo = {
						assets: "/docs/transformers/main/de",
						base: "/docs/transformers/main/de",
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("/docs/transformers/main/de/_app/immutable/entry/start.155de6db.js"),
						import("/docs/transformers/main/de/_app/immutable/entry/app.e6ae5761.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 5],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		
