import{s as wn,o as Jn,n as W}from"../chunks/scheduler.36a0863c.js";import{S as $n,i as Un,g as r,s,r as c,A as Cn,h as p,f as l,c as n,j as gn,u as m,x as d,k as Tn,y as vn,a,v as u,d as M,t as f,w as y}from"../chunks/index.f891bdb2.js";import{T as Gt}from"../chunks/Tip.a8272f7f.js";import{C as T}from"../chunks/CodeBlock.3ec784ea.js";import{F as xn,M as hn}from"../chunks/Markdown.4127c891.js";import{H as $}from"../chunks/Heading.3fb90772.js";function Zn(w){let o,b,i,g=`Una vez que se guarda el checkpoint, podemos exportarlo a ONNX usando el argumento <code>--model</code>
del paquete <code>transformers.onnx</code> al directorio deseado:`,h,J,U;return o=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uJTBBJTBBJTIzJTIwTG9hZCUyMHRva2VuaXplciUyMGFuZCUyMFB5VG9yY2glMjB3ZWlnaHRzJTIwZm9ybSUyMHRoZSUyMEh1YiUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMiklMEFwdF9tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMiklMEElMjMlMjBTYXZlJTIwdG8lMjBkaXNrJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZCglMjJsb2NhbC1wdC1jaGVja3BvaW50JTIyKSUwQXB0X21vZGVsLnNhdmVfcHJldHJhaW5lZCglMjJsb2NhbC1wdC1jaGVja3BvaW50JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and PyTorch weights form the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;local-pt-checkpoint&quot;</span>)`,wrap:!1}}),J=new T({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0Rsb2NhbC1wdC1jaGVja3BvaW50JTIwb25ueCUyRg==",highlighted:"python -m transformers.onnx --model=local-pt-checkpoint onnx/",wrap:!1}}),{c(){c(o.$$.fragment),b=s(),i=r("p"),i.innerHTML=g,h=s(),c(J.$$.fragment)},l(j){m(o.$$.fragment,j),b=n(j),i=p(j,"P",{"data-svelte-h":!0}),d(i)!=="svelte-c1bn59"&&(i.innerHTML=g),h=n(j),m(J.$$.fragment,j)},m(j,C){u(o,j,C),a(j,b,C),a(j,i,C),a(j,h,C),u(J,j,C),U=!0},p:W,i(j){U||(M(o.$$.fragment,j),M(J.$$.fragment,j),U=!0)},o(j){f(o.$$.fragment,j),f(J.$$.fragment,j),U=!1},d(j){j&&(l(b),l(i),l(h)),y(o,j),y(J,j)}}}function Bn(w){let o,b;return o=new hn({props:{$$slots:{default:[Zn]},$$scope:{ctx:w}}}),{c(){c(o.$$.fragment)},l(i){m(o.$$.fragment,i)},m(i,g){u(o,i,g),b=!0},p(i,g){const h={};g&2&&(h.$$scope={dirty:g,ctx:i}),o.$set(h)},i(i){b||(M(o.$$.fragment,i),b=!0)},o(i){f(o.$$.fragment,i),b=!1},d(i){y(o,i)}}}function In(w){let o,b,i,g=`Una vez que se guarda el checkpoint, podemos exportarlo a ONNX usando el argumento <code>--model</code>
del paquete <code>transformers.onnx</code> al directorio deseado:`,h,J,U;return o=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEElMjMlMjBMb2FkJTIwdG9rZW5pemVyJTIwYW5kJTIwVGVuc29yRmxvdyUyMHdlaWdodHMlMjBmcm9tJTIwdGhlJTIwSHViJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGJlcnQtYmFzZS11bmNhc2VkJTIyKSUwQXRmX21vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBJTIzJTIwU2F2ZSUyMHRvJTIwZGlzayUwQXRva2VuaXplci5zYXZlX3ByZXRyYWluZWQoJTIybG9jYWwtdGYtY2hlY2twb2ludCUyMiklMEF0Zl9tb2RlbC5zYXZlX3ByZXRyYWluZWQoJTIybG9jYWwtdGYtY2hlY2twb2ludCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load tokenizer and TensorFlow weights from the Hub</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save to disk</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;local-tf-checkpoint&quot;</span>)`,wrap:!1}}),J=new T({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0Rsb2NhbC10Zi1jaGVja3BvaW50JTIwb25ueCUyRg==",highlighted:"python -m transformers.onnx --model=local-tf-checkpoint onnx/",wrap:!1}}),{c(){c(o.$$.fragment),b=s(),i=r("p"),i.innerHTML=g,h=s(),c(J.$$.fragment)},l(j){m(o.$$.fragment,j),b=n(j),i=p(j,"P",{"data-svelte-h":!0}),d(i)!=="svelte-c1bn59"&&(i.innerHTML=g),h=n(j),m(J.$$.fragment,j)},m(j,C){u(o,j,C),a(j,b,C),a(j,i,C),a(j,h,C),u(J,j,C),U=!0},p:W,i(j){U||(M(o.$$.fragment,j),M(J.$$.fragment,j),U=!0)},o(j){f(o.$$.fragment,j),f(J.$$.fragment,j),U=!1},d(j){j&&(l(b),l(i),l(h)),y(o,j),y(J,j)}}}function kn(w){let o,b;return o=new hn({props:{$$slots:{default:[In]},$$scope:{ctx:w}}}),{c(){c(o.$$.fragment)},l(i){m(o.$$.fragment,i)},m(i,g){u(o,i,g),b=!0},p(i,g){const h={};g&2&&(h.$$scope={dirty:g,ctx:i}),o.$set(h)},i(i){b||(M(o.$$.fragment,i),b=!0)},o(i){f(o.$$.fragment,i),b=!1},d(i){y(o,i)}}}function _n(w){let o,b=`Las caracter√≠sticas que tienen un sufijo ‚Äòwith-past‚Äô (por ejemplo, ‚Äòcausal-lm-with-past‚Äô) corresponden a topolog√≠as
de modelo con estados ocultos precalculados (clave y valores en los bloques de atenci√≥n) que se pueden usar para una
decodificaci√≥n autorregresiva m√°s r√°pida.`;return{c(){o=r("p"),o.textContent=b},l(i){o=p(i,"P",{"data-svelte-h":!0}),d(o)!=="svelte-1d2ttlc"&&(o.textContent=b)},m(i,g){a(i,o,g)},p:W,d(i){i&&l(o)}}}function Wn(w){let o,b=`Una buena manera de implementar una configuraci√≥n personalizada en ONNX es observar la implementaci√≥n
existente en el archivo <code>configuration_&lt;model_name&gt;.py</code> de una arquitectura similar.`;return{c(){o=r("p"),o.innerHTML=b},l(i){o=p(i,"P",{"data-svelte-h":!0}),d(o)!=="svelte-1nire10"&&(o.innerHTML=b)},m(i,g){a(i,o,g)},p:W,d(i){i&&l(o)}}}function Xn(w){let o,b=`Observa que la propiedad <code>inputs</code> para <code>DistilBertOnnxConfig</code> devuelve un <code>OrderedDict</code>.
Esto nos asegura que las entradas coincidan con su posici√≥n relativa dentro del m√©todo
<code>PreTrainedModel.forward()</code> al rastrear el grafo. Recomendamos usar un <code>OrderedDict</code>
para las propiedades <code>inputs</code> y <code>outputs</code> al implementar configuraciones ONNX personalizadas.`;return{c(){o=r("p"),o.innerHTML=b},l(i){o=p(i,"P",{"data-svelte-h":!0}),d(o)!=="svelte-1tas9p7"&&(o.innerHTML=b)},m(i,g){a(i,o,g)},p:W,d(i){i&&l(o)}}}function Nn(w){let o,b=`Todas las propiedades base y m√©todos asociados con <code>OnnxConfig</code> y las
otras clases de configuraci√≥n se pueden sobreescribir si es necesario.
Consulte <code>BartOnnxConfig</code> para ver un ejemplo avanzado.`;return{c(){o=r("p"),o.innerHTML=b},l(i){o=p(i,"P",{"data-svelte-h":!0}),d(o)!=="svelte-ggia3t"&&(o.innerHTML=b)},m(i,g){a(i,o,g)},p:W,d(i){i&&l(o)}}}function An(w){let o,b=`Si tu modelo tiene m√°s de 2GB, ver√°s que se crean muchos archivos adicionales durante la exportaci√≥n.
Esto es <em>esperado</em> porque ONNX usa <a href="https://developers.google.com/protocol-buffers/" rel="nofollow">B√∫feres de protocolo</a>
para almacenar el modelo y √©stos tienen un l√≠mite de tama√±o de 2 GB. Consulta la
<a href="https://github.com/onnx/onnx/blob/master/docs/ExternalData.md" rel="nofollow">documentaci√≥n de ONNX</a> para obtener
instrucciones sobre c√≥mo cargar modelos con datos externos.`;return{c(){o=r("p"),o.innerHTML=b},l(i){o=p(i,"P",{"data-svelte-h":!0}),d(o)!=="svelte-1ms6fox"&&(o.innerHTML=b)},m(i,g){a(i,o,g)},p:W,d(i){i&&l(o)}}}function Gn(w){let o,b=`Este es el comienzo de nuestros experimentos con TorchScript y todav√≠a estamos explorando sus capacidades con modelos de
tama√±o de entrada variable. Es un tema de inter√©s y profundizaremos nuestro an√°lisis en las pr√≥ximas
versiones,  con m√°s ejemplos de c√≥digo, una implementaci√≥n m√°s flexible y puntos de referencia que comparen c√≥digos
basados en Python con TorchScript compilado.`;return{c(){o=r("p"),o.textContent=b},l(i){o=p(i,"P",{"data-svelte-h":!0}),d(o)!=="svelte-1u0h9mk"&&(o.textContent=b)},m(i,g){a(i,o,g)},p:W,d(i){i&&l(o)}}}function Rn(w){let o,b,i,g,h,J,U,j=`Si necesitas implementar modelos ü§ó Transformers en entornos de producci√≥n, te
recomendamos exportarlos a un formato serializado que se pueda cargar y ejecutar
en tiempos de ejecuci√≥n y hardware especializados. En esta gu√≠a, te mostraremos c√≥mo
exportar modelos ü§ó Transformers en dos formatos ampliamente utilizados: ONNX y TorchScript.`,C,X,Oa=`Una vez exportado, un modelo puede optimizarse para la inferencia a trav√©s de t√©cnicas
como la cuantizaci√≥n y <em>pruning</em>. Si est√°s interesado en optimizar tus modelos para
que funcionen con la m√°xima eficiencia, consulta la
<a href="https://github.com/huggingface/optimum" rel="nofollow">biblioteca de ü§ó Optimum</a>.`,Et,N,Vt,A,Da=`El proyecto <a href="http://onnx.ai" rel="nofollow">ONNX (Open Neural Network eXchange)</a> es un
est√°ndar abierto que define un conjunto com√∫n de operadores y un formato
de archivo com√∫n para representar modelos de aprendizaje profundo en una
amplia variedad de <em>frameworks</em>, incluidos PyTorch y TensorFlow. Cuando un modelo
se exporta al formato ONNX, estos operadores se usan para construir un
grafo computacional (a menudo llamado <em>representaci√≥n intermedia</em>) que
representa el flujo de datos a trav√©s de la red neuronal.`,Ht,G,Ka=`Al exponer un grafo con operadores y tipos de datos estandarizados, ONNX facilita
el cambio entre frameworks. Por ejemplo, un modelo entrenado en PyTorch se puede
exportar a formato ONNX y luego importar en TensorFlow (y viceversa).`,qt,R,es=`ü§ó Transformers proporciona un paquete llamado <code>transformers.onnx</code>, el cual permite convertir
los checkpoints de un modelo en un grafo ONNX aprovechando los objetos de configuraci√≥n.
Estos objetos de configuraci√≥n est√°n hechos a la medida de diferentes arquitecturas de modelos
y est√°n dise√±ados para ser f√°cilmente extensibles a otras arquitecturas.`,zt,E,ts="Las configuraciones a la medida incluyen las siguientes arquitecturas:",Lt,V,ls="<li>ALBERT</li> <li>BART</li> <li>BEiT</li> <li>BERT</li> <li>BigBird</li> <li>BigBird-Pegasus</li> <li>Blenderbot</li> <li>BlenderbotSmall</li> <li>BLOOM</li> <li>CamemBERT</li> <li>CLIP</li> <li>CodeGen</li> <li>ConvBERT</li> <li>ConvNeXT</li> <li>ConvNeXTV2</li> <li>Data2VecText</li> <li>Data2VecVision</li> <li>DeBERTa</li> <li>DeBERTa-v2</li> <li>DeiT</li> <li>DETR</li> <li>DistilBERT</li> <li>ELECTRA</li> <li>FlauBERT</li> <li>GPT Neo</li> <li>GPT-J</li> <li>I-BERT</li> <li>LayoutLM</li> <li>LayoutLMv3</li> <li>LeViT</li> <li>LongT5</li> <li>M2M100</li> <li>Marian</li> <li>mBART</li> <li>MobileBERT</li> <li>MobileViT</li> <li>MT5</li> <li>OpenAI GPT-2</li> <li>Perceiver</li> <li>PLBart</li> <li>ResNet</li> <li>RoBERTa</li> <li>RoFormer</li> <li>SqueezeBERT</li> <li>T5</li> <li>ViT</li> <li>XLM</li> <li>XLM-RoBERTa</li> <li>XLM-RoBERTa-XL</li> <li>YOLOS</li>",Qt,H,as="En las pr√≥ximas dos secciones, te mostraremos c√≥mo:",St,q,ss="<li>Exportar un modelo compatible utilizando el paquete <code>transformers.onnx</code>.</li> <li>Exportar un modelo personalizado para una arquitectura no compatible.</li>",Ft,z,Yt,L,ns=`Para exportar un modelo ü§ó Transformers a ONNX, tienes que instalar primero algunas
dependencias extra:`,Pt,Q,Ot,S,os="El paquete <code>transformers.onnx</code> puede ser usado luego como un m√≥dulo de Python:",Dt,F,Kt,Y,is="Exportar un checkpoint usando una configuraci√≥n a la medida se puede hacer de la siguiente manera:",el,P,tl,O,rs="que deber√≠a mostrar los siguientes registros:",ll,D,al,K,ps=`Esto exporta un grafo ONNX del checkpoint definido por el argumento <code>--model</code>.
En este ejemplo, es un modelo <code>distilbert/distilbert-base-uncased</code>, pero puede ser cualquier
checkpoint en Hugging Face Hub o que est√© almacenado localmente.`,sl,ee,ds=`El archivo <code>model.onnx</code> resultante se puede ejecutar en uno de los
<a href="https://onnx.ai/supported-tools.html#deployModel" rel="nofollow">muchos aceleradores</a>
que admiten el est√°ndar ONNX. Por ejemplo, podemos cargar y ejecutar el
modelo con <a href="https://onnxruntime.ai/" rel="nofollow">ONNX Runtime</a> de la siguiente manera:`,nl,te,ol,le,cs=`Los nombres necesarios de salida (es decir, <code>[&quot;last_hidden_state&quot;]</code>) se pueden obtener
echando un vistazo a la configuraci√≥n ONNX de cada modelo. Por ejemplo, para DistilBERT tenemos:`,il,ae,rl,se,ms=`El proceso es id√©ntico para los checkpoints de TensorFlow en Hub.
Por ejemplo, podemos exportar un checkpoint puro de TensorFlow desde
<a href="https://huggingface.co/keras-io" rel="nofollow">Keras</a> de la siguiente manera:`,pl,ne,dl,oe,us=`Para exportar un modelo que est√° almacenado localmente, deber√°s tener los pesos
y tokenizadores del modelo almacenados en un directorio. Por ejemplo, podemos cargar
y guardar un checkpoint de la siguiente manera:`,cl,v,ml,ie,ul,re,Ms=`Cada configuraci√≥n a la medida viene con un conjunto de <em>caracter√≠sticas</em> que te permiten exportar
modelos para diferentes tipos de topolog√≠as o tareas. Como se muestra en la siguiente tabla, cada
funci√≥n est√° asociada con una auto-clase de autom√≥vil diferente:`,Ml,pe,fs="<thead><tr><th>Feature</th> <th>Auto Class</th></tr></thead> <tbody><tr><td><code>causal-lm</code>, <code>causal-lm-with-past</code></td> <td><code>AutoModelForCausalLM</code></td></tr> <tr><td><code>default</code>, <code>default-with-past</code></td> <td><code>AutoModel</code></td></tr> <tr><td><code>masked-lm</code></td> <td><code>AutoModelForMaskedLM</code></td></tr> <tr><td><code>question-answering</code></td> <td><code>AutoModelForQuestionAnswering</code></td></tr> <tr><td><code>seq2seq-lm</code>, <code>seq2seq-lm-with-past</code></td> <td><code>AutoModelForSeq2SeqLM</code></td></tr> <tr><td><code>sequence-classification</code></td> <td><code>AutoModelForSequenceClassification</code></td></tr> <tr><td><code>token-classification</code></td> <td><code>AutoModelForTokenClassification</code></td></tr></tbody>",fl,de,ys=`Para cada configuraci√≥n, puedes encontrar la lista de funciones admitidas a trav√©s de <code>FeaturesManager</code>.
Por ejemplo, para DistilBERT tenemos:`,yl,ce,jl,me,js=`Le puedes pasar una de estas caracter√≠sticas al argumento <code>--feature</code> en el paquete <code>transformers.onnx</code>.
Por ejemplo, para exportar un modelo de clasificaci√≥n de texto, podemos elegir un modelo ya ajustado del Hub y ejecutar:`,bl,ue,gl,Me,bs="que mostrar√° los siguientes registros:",Tl,fe,hl,ye,gs=`Ten en cuenta que, en este caso, los nombres de salida del modelo ajustado son <code>logits</code> en lugar de <code>last_hidden_state</code>
que vimos anteriormente con el checkpoint <code>distilbert/distilbert-base-uncased</code>. Esto es de esperarse ya que el modelo ajustado
tiene un cabezal de clasificaci√≥n secuencial.`,wl,x,Jl,je,$l,be,Ts=`Si deseas exportar un modelo cuya arquitectura no es compatible de forma nativa
con la biblioteca, debes seguir tres pasos principales:`,Ul,ge,hs="<li>Implementa una configuraci√≥n personalizada en ONNX.</li> <li>Exporta el modelo a ONNX.</li> <li>Valide los resultados de PyTorch y los modelos exportados.</li>",Cl,Te,ws=`En esta secci√≥n, veremos c√≥mo se implement√≥ la serializaci√≥n de DistilBERT
para mostrar lo que implica cada paso.`,vl,he,xl,we,Js=`Comencemos con el objeto de configuraci√≥n de ONNX. Proporcionamos tres clases abstractas
de las que debe heredar, seg√∫n el tipo de arquitectura del modelo que quieras exportar:`,Zl,Je,$s="<li>Modelos basados en el <em>Encoder</em> inherente de <code>OnnxConfig</code></li> <li>Modelos basados en el <em>Decoder</em> inherente de <code>OnnxConfigWithPast</code></li> <li>Modelos <em>Encoder-decoder</em> inherente de <code>OnnxSeq2SeqConfigWithPast</code></li>",Bl,Z,Il,$e,Us="Dado que DistilBERT es un modelo de tipo <em>encoder</em>, su configuraci√≥n se hereda de <code>OnnxConfig</code>:",kl,Ue,_l,Ce,Cs=`Cada objeto de configuraci√≥n debe implementar la propiedad <code>inputs</code> y devolver un mapeo,
donde cada llave corresponde a una entrada esperada y cada valor indica el eje de esa entrada.
Para DistilBERT, podemos ver que se requieren dos entradas: <code>input_ids</code> y <code>attention_mask</code>.
Estas entradas tienen la misma forma de <code>(batch_size, sequence_length)</code>, es por lo que vemos
los mismos ejes utilizados en la configuraci√≥n.`,Wl,B,Xl,ve,vs=`Una vez que hayas implementado una configuraci√≥n ONNX, puedes crear una
instancia proporcionando la configuraci√≥n del modelo base de la siguiente manera:`,Nl,xe,Al,Ze,xs=`El objeto resultante tiene varias propiedades √∫tiles. Por ejemplo, puedes ver el conjunto de operadores ONNX que se
utilizar√° durante la exportaci√≥n:`,Gl,Be,Rl,Ie,Zs="Tambi√©n puedes ver los resultados asociados con el modelo de la siguiente manera:",El,ke,Vl,_e,Bs=`Observa que la propiedad de salidas sigue la misma estructura que las entradas;
devuelve un objecto <code>OrderedDict</code> de salidas nombradas y sus formas. La estructura
de salida est√° vinculada a la elecci√≥n de la funci√≥n con la que se inicializa la configuraci√≥n.
Por defecto, la configuraci√≥n de ONNX se inicializa con la funci√≥n <code>default</code> que
corresponde a exportar un modelo cargado con la clase <code>AutoModel</code>. Si quieres exportar
una topolog√≠a de modelo diferente, simplemente proporciona una caracter√≠stica diferente
al argumento <code>task</code> cuando inicialices la configuraci√≥n de ONNX. Por ejemplo, si quisi√©ramos
exportar DistilBERT con un cabezal de clasificaci√≥n de secuencias, podr√≠amos usar:`,Hl,We,ql,I,zl,Xe,Ll,Ne,Is=`Una vez que hayas implementado la configuraci√≥n de ONNX, el siguiente paso es exportar el modelo.
Aqu√≠ podemos usar la funci√≥n <code>export()</code> proporcionada por el paquete <code>transformers.onnx</code>.
Esta funci√≥n espera la configuraci√≥n de ONNX, junto con el modelo base y el tokenizador,
y la ruta para guardar el archivo exportado:`,Ql,Ae,Sl,Ge,ks=`Los objetos <code>onnx_inputs</code> y <code>onnx_outputs</code> devueltos por la funci√≥n <code>export()</code>
son listas de llaves definidas en las propiedades <code>inputs</code> y <code>outputs</code> de la configuraci√≥n.
Una vez exportado el modelo, puedes probar que el modelo est√° bien formado de la siguiente manera:`,Fl,Re,Yl,k,Pl,Ee,Ol,Ve,_s=`El paso final es validar que los resultados del modelo base y exportado coincidan dentro
de cierta tolerancia absoluta. Aqu√≠ podemos usar la funci√≥n <code>validate_model_outputs()</code>
proporcionada por el paquete <code>transformers.onnx</code> de la siguiente manera:`,Dl,He,Kl,qe,Ws=`Esta funci√≥n usa el m√©todo <code>OnnxConfig.generate_dummy_inputs()</code> para generar entradas para el modelo base
y exportado, y la tolerancia absoluta se puede definir en la configuraci√≥n. En general, encontramos una
concordancia num√©rica en el rango de 1e-6 a 1e-4, aunque es probable que cualquier valor menor que 1e-3 est√© bien.`,ea,ze,ta,Le,Xs=`¬°Estamos buscando expandir el conjunto de configuraciones a la medida para usar y agradecemos las contribuciones de la comunidad!
Si deseas contribuir con su colaboraci√≥n a la biblioteca, deber√°s:`,la,Qe,Ns="<li>Implementa la configuraci√≥n de ONNX en el archivo <code>configuration_&lt;model_name&gt;.py</code> correspondiente</li> <li>Incluye la arquitectura del modelo y las caracter√≠sticas correspondientes en <code>~onnx.features.FeatureManager</code></li> <li>Agrega tu arquitectura de modelo a las pruebas en <code>test_onnx_v2.py</code></li>",aa,Se,As=`Revisa c√≥mo fue la contribuci√≥n para la <a href="https://github.com/huggingface/transformers/pull/14868/files" rel="nofollow">configuraci√≥n de IBERT</a>
y as√≠ tener una idea de lo que necesito.`,sa,Fe,na,_,oa,Ye,Gs=`Seg√∫n la documentaci√≥n de PyTorch: ‚ÄúTorchScript es una forma de crear modelos serializables y optimizables a partir del
c√≥digo de PyTorch‚Äù. Los dos m√≥dulos de Pytorch <a href="https://pytorch.org/docs/stable/jit.html" rel="nofollow">JIT y TRACE</a> permiten al
desarrollador exportar su modelo para reutilizarlo  en otros programas, como los programas C++ orientados a la eficiencia.`,ia,Pe,Rs=`Hemos proporcionado una interfaz que permite exportar modelos de ü§ó Transformers a TorchScript para que puedan reutilizarse
en un entorno diferente  al de un programa Python basado en PyTorch. Aqu√≠ explicamos c√≥mo exportar y usar nuestros modelos
usando TorchScript.`,ra,Oe,Es="Exportar un modelo requiere de dos cosas:",pa,De,Vs="<li>un pase hacia adelante con entradas ficticias.</li> <li>instanciaci√≥n del modelo con la indicador <code>torchscript</code>.</li>",da,Ke,Hs="Estas necesidades implican varias cosas con las que los desarrolladores deben tener cuidado. √âstas se detallan a continuaci√≥n.",ca,et,ma,tt,qs=`Este indicador es necesario porque la mayor√≠a de los modelos de lenguaje en este repositorio tienen pesos vinculados entre su capa
de <code>Embedding</code> y su capa de <code>Decoding</code>. TorchScript no permite la exportaci√≥n de modelos que tengan pesos atados, por lo que es
necesario desvincular y clonar los pesos previamente.`,ua,lt,zs=`Esto implica que los modelos instanciados con el indicador <code>torchscript</code> tienen su capa <code>Embedding</code> y <code>Decoding</code> separadas,
lo que significa que no deben entrenarse m√°s adelante. El entrenamiento desincronizar√≠a las dos capas, lo que generar√≠a
resultados inesperados.`,Ma,at,Ls=`Este no es el caso de los modelos que no tienen un cabezal de modelo de lenguaje, ya que no tienen pesos atados.
Estos modelos se pueden exportar de forma segura sin el indicador <code>torchscript</code>.`,fa,st,ya,nt,Qs=`Las entradas ficticias se utilizan para crear un modelo de pase hacia adelante. Mientras los valores de las entradas se
propagan a trav√©s de las capas, PyTorch realiza un seguimiento de las diferentes operaciones ejecutadas en cada tensor.
Estas operaciones registradas se utilizan luego para crear el ‚Äúrastro‚Äù del modelo.`,ja,ot,Ss=`El rastro se crea en relaci√≥n con las dimensiones de las entradas. Por lo tanto, est√° limitado por las dimensiones de la
entrada ficticia y no funcionar√° para ninguna otra longitud de secuencia o tama√±o de lote. Al intentar con un tama√±o diferente,
un error como:`,ba,it,Fs="<code>The expanded size of the tensor (3) must match the existing size (7) at non-singleton dimension 2</code>",ga,rt,Ys=`aparecer√°. Por lo tanto, se recomienda rastrear el modelo con un tama√±o de entrada ficticia al menos tan grande como la
entrada m√°s  grande que se alimentar√° al modelo durante la inferencia. El <em>padding</em> se puede realizar para completar los
valores que faltan.  Sin embargo, como el modelo se habr√° rastreado con un tama√±o de entrada grande, las dimensiones de
las diferentes matrices tambi√©n ser√°n grandes, lo que dar√° como resultado m√°s c√°lculos.`,Ta,pt,Ps=`Se recomienda tener cuidado con el n√∫mero total de operaciones realizadas en cada entrada y seguir de cerca el rendimiento
al exportar modelos de longitud de secuencia variable.`,ha,dt,wa,ct,Os="A continuaci√≥n se muestra un ejemplo que muestra c√≥mo guardar, cargar modelos y c√≥mo usar el rastreo para la inferencia.",Ja,mt,$a,ut,Ds=`Este fragmento muestra c√≥mo usar TorchScript para exportar un <code>BertModel</code>. Aqu√≠, el <code>BertModel</code> se instancia de acuerdo
con la clase <code>BertConfig</code> y luego se guarda en el disco con el nombre de archivo <code>traced_bert.pt</code>`,Ua,Mt,Ca,ft,va,yt,Ks=`Este fragmento muestra c√≥mo cargar el <code>BertModel</code> que se guard√≥ previamente en el disco con el nombre <code>traced_bert.pt</code>.
Estamos reutilizando el <code>dummy_input</code> previamente inicializado.`,xa,jt,Za,bt,Ba,gt,en="Usar el modelo rastreado para la inferencia es tan simple como usar su m√©todo <code>__call__</code>:",Ia,Tt,ka,ht,_a,wt,tn=`AWS present√≥ la familia de instancias <a href="https://aws.amazon.com/ec2/instance-types/inf1/" rel="nofollow">Amazon EC2 Inf1</a> para la inferencia
de aprendizaje autom√°tico de bajo costo y  alto rendimiento en la nube. Las instancias Inf1 funcionan con el chip AWS
Inferentia, un acelerador de hardware personalizado,  que se especializa en cargas de trabajo de inferencia de aprendizaje
profundo. <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/#" rel="nofollow">AWS Neuron</a> es el kit de desarrollo para  Inferentia
que admite el rastreo y la optimizaci√≥n de modelos de  transformers para su implementaci√≥n en Inf1. El SDK de Neuron proporciona:`,Wa,Jt,ln=`<li>API f√°cil de usar con una l√≠nea de cambio de c√≥digo para rastrear y optimizar un modelo de TorchScript para la inferencia en la nube.</li> <li>Optimizaciones de rendimiento listas para usar con un <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/benchmark/%3E" rel="nofollow">costo-rendimiento mejorado</a></li> <li>Soporte para modelos HuggingFace Transformers construidos con <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/bert_tutorial/tutorial_pretrained_bert.html" rel="nofollow">PyTorch</a>
o <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/tensorflow/huggingface_bert/huggingface_bert.html" rel="nofollow">TensorFlow</a>.</li>`,Xa,$t,Na,Ut,an=`Los modelos Transformers basados en la arquitectura
<a href="https://huggingface.co/docs/transformers/main/model_doc/bert" rel="nofollow">BERT (Representaciones de <em>Enconder</em> bidireccional de Transformers)</a>,
o sus variantes, como <a href="https://huggingface.co/docs/transformers/main/model_doc/distilbert" rel="nofollow">distilBERT</a> y
<a href="https://huggingface.co/docs/transformers/main/model_doc/roberta" rel="nofollow">roBERTa</a>, se ejecutar√°n mejor en Inf1 para tareas no
generativas, como la respuesta extractiva de preguntas, la clasificaci√≥n de secuencias y la clasificaci√≥n de tokens.
Como alternativa, las tareas de generaci√≥n de texto se pueden adaptar para ejecutarse en Inf1, seg√∫n este
<a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/src/examples/pytorch/transformers-marianmt.html" rel="nofollow">tutorial de AWS Neuron MarianMT</a>.
Puedes encontrar m√°s informaci√≥n sobre los modelos que est√°n listos para usarse en Inferentia en la
<a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/models/models-inferentia.html#models-inferentia" rel="nofollow">secci√≥n <em>Model Architecture Fit</em> de la documentaci√≥n de Neuron</a>.`,Aa,Ct,Ga,vt,sn="Usar AWS Neuron para convertir modelos requiere las siguientes dependencias y entornos:",Ra,xt,nn=`<li>Un <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/neuron-guide/neuron-frameworks/pytorch-neuron/index.html#installation-guide" rel="nofollow">entorno Neuron SDK</a>,
que viene preconfigurado en <a href="https://docs.aws.amazon.com/dlami/latest/devguide/tutorial-inferentia-launching.html" rel="nofollow">AWS Deep Learning AMI</a>.</li>`,Ea,Zt,Va,Bt,on=`Con el mismo script usado en <a href="https://huggingface.co/docs/transformers/main/es/serialization#using-torchscript-in-python" rel="nofollow">Uso de TorchScript en Python</a>
para rastrear un ‚ÄúBertModel‚Äù, puedes importar la extensi√≥n del <em>framework</em> <code>torch.neuron</code> para acceder a los componentes
del SDK de Neuron a trav√©s de una API de Python.`,Ha,It,qa,kt,rn="Y modificando la l√≠nea de c√≥digo de rastreo de:",za,_t,La,Wt,pn="con lo siguiente:",Qa,Xt,Sa,Nt,dn="Este cambio permite a Neuron SDK rastrear el modelo y optimizarlo para ejecutarse en instancias Inf1.",Fa,At,cn=`Para obtener m√°s informaci√≥n sobre las funciones, las herramientas, los tutoriales de ejemplo y las √∫ltimas actualizaciones
de AWS Neuron SDK, consulte la <a href="https://awsdocs-neuron.readthedocs-hosted.com/en/latest/index.html" rel="nofollow">documentaci√≥n de AWS NeuronSDK</a>.`,Ya,Rt,Pa;return h=new $({props:{title:"Exportar modelos ü§ó Transformers",local:"exportar-modelos--transformers",headingTag:"h1"}}),N=new $({props:{title:"ONNX",local:"onnx",headingTag:"h2"}}),z=new $({props:{title:"Exportar un model a ONNX",local:"exportar-un-model-a-onnx",headingTag:"h3"}}),Q=new T({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyU1Qm9ubnglNUQ=",highlighted:"pip install transformers[onnx]",wrap:!1}}),F=new T({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0taGVscCUwQSUwQXVzYWdlJTNBJTIwSHVnZ2luZyUyMEZhY2UlMjBUcmFuc2Zvcm1lcnMlMjBPTk5YJTIwZXhwb3J0ZXIlMjAlNUItaCU1RCUyMC1tJTIwTU9ERUwlMjAlNUItLWZlYXR1cmUlMjAlN0JjYXVzYWwtbG0lMkMlMjAuLi4lN0QlNUQlMjAlNUItLW9wc2V0JTIwT1BTRVQlNUQlMjAlNUItLWF0b2wlMjBBVE9MJTVEJTIwb3V0cHV0JTBBJTBBcG9zaXRpb25hbCUyMGFyZ3VtZW50cyUzQSUwQSUyMCUyMG91dHB1dCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMFBhdGglMjBpbmRpY2F0aW5nJTIwd2hlcmUlMjB0byUyMHN0b3JlJTIwZ2VuZXJhdGVkJTIwT05OWCUyMG1vZGVsLiUwQSUwQW9wdGlvbmFsJTIwYXJndW1lbnRzJTNBJTBBJTIwJTIwLWglMkMlMjAtLWhlbHAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBzaG93JTIwdGhpcyUyMGhlbHAlMjBtZXNzYWdlJTIwYW5kJTIwZXhpdCUwQSUyMCUyMC1tJTIwTU9ERUwlMkMlMjAtLW1vZGVsJTIwTU9ERUwlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBNb2RlbCUyMElEJTIwb24lMjBodWdnaW5nZmFjZS5jbyUyMG9yJTIwcGF0aCUyMG9uJTIwZGlzayUyMHRvJTIwbG9hZCUyMG1vZGVsJTIwZnJvbS4lMEElMjAlMjAtLWZlYXR1cmUlMjAlN0JjYXVzYWwtbG0lMkMlMjAuLi4lN0QlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBUaGUlMjB0eXBlJTIwb2YlMjBmZWF0dXJlcyUyMHRvJTIwZXhwb3J0JTIwdGhlJTIwbW9kZWwlMjB3aXRoLiUwQSUyMCUyMC0tb3BzZXQlMjBPUFNFVCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyME9OTlglMjBvcHNldCUyMHZlcnNpb24lMjB0byUyMGV4cG9ydCUyMHRoZSUyMG1vZGVsJTIwd2l0aC4lMEElMjAlMjAtLWF0b2wlMjBBVE9MJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwQWJzb2x1dGUlMjBkaWZmZXJlbmNlJTIwdG9sZXJlbmNlJTIwd2hlbiUyMHZhbGlkYXRpbmclMjB0aGUlMjBtb2RlbC4=",highlighted:`python -m transformers.onnx --<span class="hljs-built_in">help</span>

usage: Hugging Face Transformers ONNX exporter [-h] -m MODEL [--feature {causal-lm, ...}] [--opset OPSET] [--atol ATOL] output

positional arguments:
  output                Path indicating <span class="hljs-built_in">where</span> to store generated ONNX model.

optional arguments:
  -h, --<span class="hljs-built_in">help</span>            show this <span class="hljs-built_in">help</span> message and <span class="hljs-built_in">exit</span>
  -m MODEL, --model MODEL
                        Model ID on huggingface.co or path on disk to load model from.
  --feature {causal-lm, ...}
                        The <span class="hljs-built_in">type</span> of features to <span class="hljs-built_in">export</span> the model with.
  --opset OPSET         ONNX opset version to <span class="hljs-built_in">export</span> the model with.
  --atol ATOL           Absolute difference tolerence when validating the model.`,wrap:!1}}),P=new T({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0RkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjBvbm54JTJG",highlighted:"python -m transformers.onnx --model=distilbert/distilbert-base-uncased onnx/",wrap:!1}}),D=new T({props:{code:"VmFsaWRhdGluZyUyME9OTlglMjBtb2RlbC4uLiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC0lNUIlRTIlOUMlOTMlNUQlMjBPTk5YJTIwbW9kZWwlMjBvdXRwdXQlMjBuYW1lcyUyMG1hdGNoJTIwcmVmZXJlbmNlJTIwbW9kZWwlMjAoJTdCJ2xhc3RfaGlkZGVuX3N0YXRlJyU3RCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAtJTIwVmFsaWRhdGluZyUyME9OTlglMjBNb2RlbCUyMG91dHB1dCUyMCUyMmxhc3RfaGlkZGVuX3N0YXRlJTIyJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLSU1QiVFMiU5QyU5MyU1RCUyMCgyJTJDJTIwOCUyQyUyMDc2OCklMjBtYXRjaGVzJTIwKDIlMkMlMjA4JTJDJTIwNzY4KSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC0lNUIlRTIlOUMlOTMlNUQlMjBhbGwlMjB2YWx1ZXMlMjBjbG9zZSUyMChhdG9sJTNBJTIwMWUtMDUpJTBBQWxsJTIwZ29vZCUyQyUyMG1vZGVsJTIwc2F2ZWQlMjBhdCUzQSUyMG9ubnglMkZtb2RlbC5vbm54",highlighted:`Validating ONNX model...
        -[‚úì] ONNX model output names match reference model ({<span class="hljs-string">&#x27;last_hidden_state&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;last_hidden_state&quot;</span>:
                -[‚úì] (2, 8, 768) matches (2, 8, 768)
                -[‚úì] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,wrap:!1}}),te=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEFmcm9tJTIwb25ueHJ1bnRpbWUlMjBpbXBvcnQlMjBJbmZlcmVuY2VTZXNzaW9uJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGJlcnQtYmFzZS11bmNhc2VkJTIyKSUwQXNlc3Npb24lMjAlM0QlMjBJbmZlcmVuY2VTZXNzaW9uKCUyMm9ubnglMkZtb2RlbC5vbm54JTIyKSUwQSUyMyUyME9OTlglMjBSdW50aW1lJTIwZXhwZWN0cyUyME51bVB5JTIwYXJyYXlzJTIwYXMlMjBpbnB1dCUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplciglMjJVc2luZyUyMERpc3RpbEJFUlQlMjB3aXRoJTIwT05OWCUyMFJ1bnRpbWUhJTIyJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJucCUyMiklMEFvdXRwdXRzJTIwJTNEJTIwc2Vzc2lvbi5ydW4ob3V0cHV0X25hbWVzJTNEJTVCJTIybGFzdF9oaWRkZW5fc3RhdGUlMjIlNUQlMkMlMjBpbnB1dF9mZWVkJTNEZGljdChpbnB1dHMpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> onnxruntime <span class="hljs-keyword">import</span> InferenceSession

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>session = InferenceSession(<span class="hljs-string">&quot;onnx/model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ONNX Runtime expects NumPy arrays as input</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = session.run(output_names=[<span class="hljs-string">&quot;last_hidden_state&quot;</span>], input_feed=<span class="hljs-built_in">dict</span>(inputs))`,wrap:!1}}),ae=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbHMuZGlzdGlsYmVydCUyMGltcG9ydCUyMERpc3RpbEJlcnRDb25maWclMkMlMjBEaXN0aWxCZXJ0T25ueENvbmZpZyUwQSUwQWNvbmZpZyUyMCUzRCUyMERpc3RpbEJlcnRDb25maWcoKSUwQW9ubnhfY29uZmlnJTIwJTNEJTIwRGlzdGlsQmVydE9ubnhDb25maWcoY29uZmlnKSUwQXByaW50KGxpc3Qob25ueF9jb25maWcub3V0cHV0cy5rZXlzKCkpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.models.distilbert <span class="hljs-keyword">import</span> DistilBertConfig, DistilBertOnnxConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(onnx_config.outputs.keys()))
[<span class="hljs-string">&quot;last_hidden_state&quot;</span>]s`,wrap:!1}}),ne=new T({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0RrZXJhcy1pbyUyRnRyYW5zZm9ybWVycy1xYSUyMG9ubnglMkY=",highlighted:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/",wrap:!1}}),v=new xn({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[kn],pytorch:[Bn]},$$scope:{ctx:w}}}),ie=new $({props:{title:"Seleccionar caracter√≠sticas para diferentes topolog√≠as de un modelo",local:"seleccionar-caracter√≠sticas-para-diferentes-topolog√≠as-de-un-modelo",headingTag:"h3"}}),ce=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5vbm54LmZlYXR1cmVzJTIwaW1wb3J0JTIwRmVhdHVyZXNNYW5hZ2VyJTBBJTBBZGlzdGlsYmVydF9mZWF0dXJlcyUyMCUzRCUyMGxpc3QoRmVhdHVyZXNNYW5hZ2VyLmdldF9zdXBwb3J0ZWRfZmVhdHVyZXNfZm9yX21vZGVsX3R5cGUoJTIyZGlzdGlsYmVydCUyMikua2V5cygpKSUwQXByaW50KGRpc3RpbGJlcnRfZmVhdHVyZXMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx.features <span class="hljs-keyword">import</span> FeaturesManager

<span class="hljs-meta">&gt;&gt;&gt; </span>distilbert_features = <span class="hljs-built_in">list</span>(FeaturesManager.get_supported_features_for_model_type(<span class="hljs-string">&quot;distilbert&quot;</span>).keys())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(distilbert_features)
[<span class="hljs-string">&quot;default&quot;</span>, <span class="hljs-string">&quot;masked-lm&quot;</span>, <span class="hljs-string">&quot;causal-lm&quot;</span>, <span class="hljs-string">&quot;sequence-classification&quot;</span>, <span class="hljs-string">&quot;token-classification&quot;</span>, <span class="hljs-string">&quot;question-answering&quot;</span>]`,wrap:!1}}),ue=new T({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0RkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQtZmluZXR1bmVkLXNzdC0yLWVuZ2xpc2glMjAlNUMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAtLWZlYXR1cmUlM0RzZXF1ZW5jZS1jbGFzc2lmaWNhdGlvbiUyMG9ubnglMkY=",highlighted:`python -m transformers.onnx --model=distilbert/distilbert-base-uncased-finetuned-sst-2-english \\
                            --feature=sequence-classification onnx/`,wrap:!1}}),fe=new T({props:{code:"VmFsaWRhdGluZyUyME9OTlglMjBtb2RlbC4uLiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMC0lNUIlRTIlOUMlOTMlNUQlMjBPTk5YJTIwbW9kZWwlMjBvdXRwdXQlMjBuYW1lcyUyMG1hdGNoJTIwcmVmZXJlbmNlJTIwbW9kZWwlMjAoJTdCJ2xvZ2l0cyclN0QpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLSUyMFZhbGlkYXRpbmclMjBPTk5YJTIwTW9kZWwlMjBvdXRwdXQlMjAlMjJsb2dpdHMlMjIlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAtJTVCJUUyJTlDJTkzJTVEJTIwKDIlMkMlMjAyKSUyMG1hdGNoZXMlMjAoMiUyQyUyMDIpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwLSU1QiVFMiU5QyU5MyU1RCUyMGFsbCUyMHZhbHVlcyUyMGNsb3NlJTIwKGF0b2wlM0ElMjAxZS0wNSklMEFBbGwlMjBnb29kJTJDJTIwbW9kZWwlMjBzYXZlZCUyMGF0JTNBJTIwb25ueCUyRm1vZGVsLm9ubng=",highlighted:`Validating ONNX model...
        -[‚úì] ONNX model output names match reference model ({<span class="hljs-string">&#x27;logits&#x27;</span>})
        - Validating ONNX Model output <span class="hljs-string">&quot;logits&quot;</span>:
                -[‚úì] (2, 2) matches (2, 2)
                -[‚úì] all values close (atol: 1e-05)
All good, model saved at: onnx/model.onnx`,wrap:!1}}),x=new Gt({props:{$$slots:{default:[_n]},$$scope:{ctx:w}}}),je=new $({props:{title:"Exportar un modelo para una arquitectura no compatible",local:"exportar-un-modelo-para-una-arquitectura-no-compatible",headingTag:"h3"}}),he=new $({props:{title:"Implementar una configuraci√≥n personalizada en ONNX",local:"implementar-una-configuraci√≥n-personalizada-en-onnx",headingTag:"h4"}}),Z=new Gt({props:{$$slots:{default:[Wn]},$$scope:{ctx:w}}}),Ue=new T({props:{code:"ZnJvbSUyMHR5cGluZyUyMGltcG9ydCUyME1hcHBpbmclMkMlMjBPcmRlcmVkRGljdCUwQWZyb20lMjB0cmFuc2Zvcm1lcnMub25ueCUyMGltcG9ydCUyME9ubnhDb25maWclMEElMEElMEFjbGFzcyUyMERpc3RpbEJlcnRPbm54Q29uZmlnKE9ubnhDb25maWcpJTNBJTBBJTIwJTIwJTIwJTIwJTQwcHJvcGVydHklMEElMjAlMjAlMjAlMjBkZWYlMjBpbnB1dHMoc2VsZiklMjAtJTNFJTIwTWFwcGluZyU1QnN0ciUyQyUyME1hcHBpbmclNUJpbnQlMkMlMjBzdHIlNUQlNUQlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjByZXR1cm4lMjBPcmRlcmVkRGljdCglMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlNUIlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAoJTIyaW5wdXRfaWRzJTIyJTJDJTIwJTdCMCUzQSUyMCUyMmJhdGNoJTIyJTJDJTIwMSUzQSUyMCUyMnNlcXVlbmNlJTIyJTdEKSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCglMjJhdHRlbnRpb25fbWFzayUyMiUyQyUyMCU3QjAlM0ElMjAlMjJiYXRjaCUyMiUyQyUyMDElM0ElMjAlMjJzZXF1ZW5jZSUyMiU3RCklMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlNUQlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> Mapping, OrderedDict
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> OnnxConfig


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DistilBertOnnxConfig</span>(<span class="hljs-title class_ inherited__">OnnxConfig</span>):
<span class="hljs-meta">... </span>    @<span class="hljs-built_in">property</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inputs</span>(<span class="hljs-params">self</span>) -&gt; Mapping[<span class="hljs-built_in">str</span>, Mapping[<span class="hljs-built_in">int</span>, <span class="hljs-built_in">str</span>]]:
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> OrderedDict(
<span class="hljs-meta">... </span>            [
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;input_ids&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>                (<span class="hljs-string">&quot;attention_mask&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>}),
<span class="hljs-meta">... </span>            ]
<span class="hljs-meta">... </span>        )`,wrap:!1}}),B=new Gt({props:{$$slots:{default:[Xn]},$$scope:{ctx:w}}}),xe=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Db25maWclMEElMEFjb25maWclMjAlM0QlMjBBdXRvQ29uZmlnLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBb25ueF9jb25maWclMjAlM0QlMjBEaXN0aWxCZXJ0T25ueENvbmZpZyhjb25maWcp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)`,wrap:!1}}),Be=new T({props:{code:"cHJpbnQob25ueF9jb25maWcuZGVmYXVsdF9vbm54X29wc2V0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.default_onnx_opset)
<span class="hljs-number">11</span>`,wrap:!1}}),ke=new T({props:{code:"cHJpbnQob25ueF9jb25maWcub3V0cHV0cyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config.outputs)
OrderedDict([(<span class="hljs-string">&quot;last_hidden_state&quot;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;batch&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;sequence&quot;</span>})])`,wrap:!1}}),We=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Db25maWclMEElMEFjb25maWclMjAlM0QlMjBBdXRvQ29uZmlnLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBb25ueF9jb25maWdfZm9yX3NlcV9jbGYlMjAlM0QlMjBEaXN0aWxCZXJ0T25ueENvbmZpZyhjb25maWclMkMlMjB0YXNrJTNEJTIyc2VxdWVuY2UtY2xhc3NpZmljYXRpb24lMjIpJTBBcHJpbnQob25ueF9jb25maWdfZm9yX3NlcV9jbGYub3V0cHV0cyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=<span class="hljs-string">&quot;sequence-classification&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(onnx_config_for_seq_clf.outputs)
OrderedDict([(<span class="hljs-string">&#x27;logits&#x27;</span>, {<span class="hljs-number">0</span>: <span class="hljs-string">&#x27;batch&#x27;</span>})])`,wrap:!1}}),I=new Gt({props:{$$slots:{default:[Nn]},$$scope:{ctx:w}}}),Xe=new $({props:{title:"Exportar el modelo",local:"exportar-el-modelo",headingTag:"h4"}}),Ae=new T({props:{code:"ZnJvbSUyMHBhdGhsaWIlMjBpbXBvcnQlMjBQYXRoJTBBZnJvbSUyMHRyYW5zZm9ybWVycy5vbm54JTIwaW1wb3J0JTIwZXhwb3J0JTBBZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWwlMEElMEFvbm54X3BhdGglMjAlM0QlMjBQYXRoKCUyMm1vZGVsLm9ubnglMjIpJTBBbW9kZWxfY2twdCUyMCUzRCUyMCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMiUwQWJhc2VfbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWwuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2NrcHQpJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQobW9kZWxfY2twdCklMEElMEFvbm54X2lucHV0cyUyQyUyMG9ubnhfb3V0cHV0cyUyMCUzRCUyMGV4cG9ydCh0b2tlbml6ZXIlMkMlMjBiYXNlX21vZGVsJTJDJTIwb25ueF9jb25maWclMkMlMjBvbm54X2NvbmZpZy5kZWZhdWx0X29ubnhfb3BzZXQlMkMlMjBvbm54X3BhdGgp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> export
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_path = Path(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model_ckpt = <span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>base_model = AutoModel.from_pretrained(model_ckpt)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_inputs, onnx_outputs = export(tokenizer, base_model, onnx_config, onnx_config.default_onnx_opset, onnx_path)`,wrap:!1}}),Re=new T({props:{code:"aW1wb3J0JTIwb25ueCUwQSUwQW9ubnhfbW9kZWwlMjAlM0QlMjBvbm54LmxvYWQoJTIybW9kZWwub25ueCUyMiklMEFvbm54LmNoZWNrZXIuY2hlY2tfbW9kZWwob25ueF9tb2RlbCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> onnx

<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_model = onnx.load(<span class="hljs-string">&quot;model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx.checker.check_model(onnx_model)`,wrap:!1}}),k=new Gt({props:{$$slots:{default:[An]},$$scope:{ctx:w}}}),Ee=new $({props:{title:"Validar los resultados del modelo",local:"validar-los-resultados-del-modelo",headingTag:"h4"}}),He=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5vbm54JTIwaW1wb3J0JTIwdmFsaWRhdGVfbW9kZWxfb3V0cHV0cyUwQSUwQXZhbGlkYXRlX21vZGVsX291dHB1dHMoJTBBJTIwJTIwJTIwJTIwb25ueF9jb25maWclMkMlMjB0b2tlbml6ZXIlMkMlMjBiYXNlX21vZGVsJTJDJTIwb25ueF9wYXRoJTJDJTIwb25ueF9vdXRwdXRzJTJDJTIwb25ueF9jb25maWcuYXRvbF9mb3JfdmFsaWRhdGlvbiUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.onnx <span class="hljs-keyword">import</span> validate_model_outputs

<span class="hljs-meta">&gt;&gt;&gt; </span>validate_model_outputs(
<span class="hljs-meta">... </span>    onnx_config, tokenizer, base_model, onnx_path, onnx_outputs, onnx_config.atol_for_validation
<span class="hljs-meta">... </span>)`,wrap:!1}}),ze=new $({props:{title:"Contribuir con una nueva configuraci√≥n a ü§ó Transformers",local:"contribuir-con-una-nueva-configuraci√≥n-a--transformers",headingTag:"h3"}}),Fe=new $({props:{title:"TorchScript",local:"torchscript",headingTag:"h2"}}),_=new Gt({props:{$$slots:{default:[Gn]},$$scope:{ctx:w}}}),et=new $({props:{title:"Indicador de TorchScript y pesos atados",local:"indicador-de-torchscript-y-pesos-atados",headingTag:"h3"}}),st=new $({props:{title:"Entradas ficticias y longitudes est√°ndar",local:"entradas-ficticias-y-longitudes-est√°ndar",headingTag:"h3"}}),dt=new $({props:{title:"Usar TorchScript en Python",local:"usar-torchscript-en-python",headingTag:"h3"}}),mt=new $({props:{title:"Guardando un modelo",local:"guardando-un-modelo",headingTag:"h4"}}),Mt=new T({props:{code:"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",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel, BertTokenizer, BertConfig
<span class="hljs-keyword">import</span> torch

enc = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)

<span class="hljs-comment"># Tokenizing input text</span>
text = <span class="hljs-string">&quot;[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]&quot;</span>
tokenized_text = enc.tokenize(text)

<span class="hljs-comment"># Masking one of the input tokens</span>
masked_index = <span class="hljs-number">8</span>
tokenized_text[masked_index] = <span class="hljs-string">&quot;[MASK]&quot;</span>
indexed_tokens = enc.convert_tokens_to_ids(tokenized_text)
segments_ids = [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]

<span class="hljs-comment"># Creating a dummy input</span>
tokens_tensor = torch.tensor([indexed_tokens])
segments_tensors = torch.tensor([segments_ids])
dummy_input = [tokens_tensor, segments_tensors]

<span class="hljs-comment"># Initializing the model with the torchscript flag</span>
<span class="hljs-comment"># Flag set to True even though it is not necessary as this model does not have an LM Head.</span>
config = BertConfig(
    vocab_size_or_config_json_file=<span class="hljs-number">32000</span>,
    hidden_size=<span class="hljs-number">768</span>,
    num_hidden_layers=<span class="hljs-number">12</span>,
    num_attention_heads=<span class="hljs-number">12</span>,
    intermediate_size=<span class="hljs-number">3072</span>,
    torchscript=<span class="hljs-literal">True</span>,
)

<span class="hljs-comment"># Instantiating the model</span>
model = BertModel(config)

<span class="hljs-comment"># The model needs to be in evaluation mode</span>
model.<span class="hljs-built_in">eval</span>()

<span class="hljs-comment"># If you are instantiating the model with *from_pretrained* you can also easily set the TorchScript flag</span>
model = BertModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>, torchscript=<span class="hljs-literal">True</span>)

<span class="hljs-comment"># Creating the trace</span>
traced_model = torch.jit.trace(model, [tokens_tensor, segments_tensors])
torch.jit.save(traced_model, <span class="hljs-string">&quot;traced_bert.pt&quot;</span>)`,wrap:!1}}),ft=new $({props:{title:"Cargar un modelo",local:"cargar-un-modelo",headingTag:"h4"}}),jt=new T({props:{code:"bG9hZGVkX21vZGVsJTIwJTNEJTIwdG9yY2guaml0LmxvYWQoJTIydHJhY2VkX2JlcnQucHQlMjIpJTBBbG9hZGVkX21vZGVsLmV2YWwoKSUwQSUwQWFsbF9lbmNvZGVyX2xheWVycyUyQyUyMHBvb2xlZF9vdXRwdXQlMjAlM0QlMjBsb2FkZWRfbW9kZWwoKmR1bW15X2lucHV0KQ==",highlighted:`loaded_model = torch.jit.load(<span class="hljs-string">&quot;traced_bert.pt&quot;</span>)
loaded_model.<span class="hljs-built_in">eval</span>()

all_encoder_layers, pooled_output = loaded_model(*dummy_input)`,wrap:!1}}),bt=new $({props:{title:"Usar un modelo rastreado para la inferencia",local:"usar-un-modelo-rastreado-para-la-inferencia",headingTag:"h4"}}),Tt=new T({props:{code:"dHJhY2VkX21vZGVsKHRva2Vuc190ZW5zb3IlMkMlMjBzZWdtZW50c190ZW5zb3JzKQ==",highlighted:"traced_model(tokens_tensor, segments_tensors)",wrap:!1}}),ht=new $({props:{title:"Implementar los modelos HuggingFace TorchScript en AWS mediante Neuron SDK",local:"implementar-los-modelos-huggingface-torchscript-en-aws-mediante-neuron-sdk",headingTag:"h3"}}),$t=new $({props:{title:"Implicaciones",local:"implicaciones",headingTag:"h4"}}),Ct=new $({props:{title:"Dependencias",local:"dependencias",headingTag:"h4"}}),Zt=new $({props:{title:"Convertir un modelo a AWS Neuron",local:"convertir-un-modelo-a-aws-neuron",headingTag:"h4"}}),It=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEJlcnRNb2RlbCUyQyUyMEJlcnRUb2tlbml6ZXIlMkMlMjBCZXJ0Q29uZmlnJTBBaW1wb3J0JTIwdG9yY2glMEFpbXBvcnQlMjB0b3JjaC5uZXVyb24=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> BertModel, BertTokenizer, BertConfig
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.neuron`,wrap:!1}}),_t=new T({props:{code:"dG9yY2guaml0LnRyYWNlKG1vZGVsJTJDJTIwJTVCdG9rZW5zX3RlbnNvciUyQyUyMHNlZ21lbnRzX3RlbnNvcnMlNUQp",highlighted:"torch.jit.trace(model, [tokens_tensor, segments_tensors])",wrap:!1}}),Xt=new T({props:{code:"dG9yY2gubmV1cm9uLnRyYWNlKG1vZGVsJTJDJTIwJTVCdG9rZW5fdGVuc29yJTJDJTIwc2VnbWVudHNfdGVuc29ycyU1RCk=",highlighted:"torch.neuron.trace(model, [token_tensor, segments_tensors])",wrap:!1}}),{c(){o=r("meta"),b=s(),i=r("p"),g=s(),c(h.$$.fragment),J=s(),U=r("p"),U.textContent=j,C=s(),X=r("p"),X.innerHTML=Oa,Et=s(),c(N.$$.fragment),Vt=s(),A=r("p"),A.innerHTML=Da,Ht=s(),G=r("p"),G.textContent=Ka,qt=s(),R=r("p"),R.innerHTML=es,zt=s(),E=r("p"),E.textContent=ts,Lt=s(),V=r("ul"),V.innerHTML=ls,Qt=s(),H=r("p"),H.textContent=as,St=s(),q=r("ul"),q.innerHTML=ss,Ft=s(),c(z.$$.fragment),Yt=s(),L=r("p"),L.textContent=ns,Pt=s(),c(Q.$$.fragment),Ot=s(),S=r("p"),S.innerHTML=os,Dt=s(),c(F.$$.fragment),Kt=s(),Y=r("p"),Y.textContent=is,el=s(),c(P.$$.fragment),tl=s(),O=r("p"),O.textContent=rs,ll=s(),c(D.$$.fragment),al=s(),K=r("p"),K.innerHTML=ps,sl=s(),ee=r("p"),ee.innerHTML=ds,nl=s(),c(te.$$.fragment),ol=s(),le=r("p"),le.innerHTML=cs,il=s(),c(ae.$$.fragment),rl=s(),se=r("p"),se.innerHTML=ms,pl=s(),c(ne.$$.fragment),dl=s(),oe=r("p"),oe.textContent=us,cl=s(),c(v.$$.fragment),ml=s(),c(ie.$$.fragment),ul=s(),re=r("p"),re.innerHTML=Ms,Ml=s(),pe=r("table"),pe.innerHTML=fs,fl=s(),de=r("p"),de.innerHTML=ys,yl=s(),c(ce.$$.fragment),jl=s(),me=r("p"),me.innerHTML=js,bl=s(),c(ue.$$.fragment),gl=s(),Me=r("p"),Me.textContent=bs,Tl=s(),c(fe.$$.fragment),hl=s(),ye=r("p"),ye.innerHTML=gs,wl=s(),c(x.$$.fragment),Jl=s(),c(je.$$.fragment),$l=s(),be=r("p"),be.textContent=Ts,Ul=s(),ge=r("ol"),ge.innerHTML=hs,Cl=s(),Te=r("p"),Te.textContent=ws,vl=s(),c(he.$$.fragment),xl=s(),we=r("p"),we.textContent=Js,Zl=s(),Je=r("ul"),Je.innerHTML=$s,Bl=s(),c(Z.$$.fragment),Il=s(),$e=r("p"),$e.innerHTML=Us,kl=s(),c(Ue.$$.fragment),_l=s(),Ce=r("p"),Ce.innerHTML=Cs,Wl=s(),c(B.$$.fragment),Xl=s(),ve=r("p"),ve.textContent=vs,Nl=s(),c(xe.$$.fragment),Al=s(),Ze=r("p"),Ze.textContent=xs,Gl=s(),c(Be.$$.fragment),Rl=s(),Ie=r("p"),Ie.textContent=Zs,El=s(),c(ke.$$.fragment),Vl=s(),_e=r("p"),_e.innerHTML=Bs,Hl=s(),c(We.$$.fragment),ql=s(),c(I.$$.fragment),zl=s(),c(Xe.$$.fragment),Ll=s(),Ne=r("p"),Ne.innerHTML=Is,Ql=s(),c(Ae.$$.fragment),Sl=s(),Ge=r("p"),Ge.innerHTML=ks,Fl=s(),c(Re.$$.fragment),Yl=s(),c(k.$$.fragment),Pl=s(),c(Ee.$$.fragment),Ol=s(),Ve=r("p"),Ve.innerHTML=_s,Dl=s(),c(He.$$.fragment),Kl=s(),qe=r("p"),qe.innerHTML=Ws,ea=s(),c(ze.$$.fragment),ta=s(),Le=r("p"),Le.textContent=Xs,la=s(),Qe=r("ul"),Qe.innerHTML=Ns,aa=s(),Se=r("p"),Se.innerHTML=As,sa=s(),c(Fe.$$.fragment),na=s(),c(_.$$.fragment),oa=s(),Ye=r("p"),Ye.innerHTML=Gs,ia=s(),Pe=r("p"),Pe.textContent=Rs,ra=s(),Oe=r("p"),Oe.textContent=Es,pa=s(),De=r("ul"),De.innerHTML=Vs,da=s(),Ke=r("p"),Ke.textContent=Hs,ca=s(),c(et.$$.fragment),ma=s(),tt=r("p"),tt.innerHTML=qs,ua=s(),lt=r("p"),lt.innerHTML=zs,Ma=s(),at=r("p"),at.innerHTML=Ls,fa=s(),c(st.$$.fragment),ya=s(),nt=r("p"),nt.textContent=Qs,ja=s(),ot=r("p"),ot.textContent=Ss,ba=s(),it=r("p"),it.innerHTML=Fs,ga=s(),rt=r("p"),rt.innerHTML=Ys,Ta=s(),pt=r("p"),pt.textContent=Ps,ha=s(),c(dt.$$.fragment),wa=s(),ct=r("p"),ct.textContent=Os,Ja=s(),c(mt.$$.fragment),$a=s(),ut=r("p"),ut.innerHTML=Ds,Ua=s(),c(Mt.$$.fragment),Ca=s(),c(ft.$$.fragment),va=s(),yt=r("p"),yt.innerHTML=Ks,xa=s(),c(jt.$$.fragment),Za=s(),c(bt.$$.fragment),Ba=s(),gt=r("p"),gt.innerHTML=en,Ia=s(),c(Tt.$$.fragment),ka=s(),c(ht.$$.fragment),_a=s(),wt=r("p"),wt.innerHTML=tn,Wa=s(),Jt=r("ol"),Jt.innerHTML=ln,Xa=s(),c($t.$$.fragment),Na=s(),Ut=r("p"),Ut.innerHTML=an,Aa=s(),c(Ct.$$.fragment),Ga=s(),vt=r("p"),vt.textContent=sn,Ra=s(),xt=r("ul"),xt.innerHTML=nn,Ea=s(),c(Zt.$$.fragment),Va=s(),Bt=r("p"),Bt.innerHTML=on,Ha=s(),c(It.$$.fragment),qa=s(),kt=r("p"),kt.textContent=rn,za=s(),c(_t.$$.fragment),La=s(),Wt=r("p"),Wt.textContent=pn,Qa=s(),c(Xt.$$.fragment),Sa=s(),Nt=r("p"),Nt.textContent=dn,Fa=s(),At=r("p"),At.innerHTML=cn,Ya=s(),Rt=r("p"),this.h()},l(e){const t=Cn("svelte-u9bgzb",document.head);o=p(t,"META",{name:!0,content:!0}),t.forEach(l),b=n(e),i=p(e,"P",{}),gn(i).forEach(l),g=n(e),m(h.$$.fragment,e),J=n(e),U=p(e,"P",{"data-svelte-h":!0}),d(U)!=="svelte-1fx3vq8"&&(U.textContent=j),C=n(e),X=p(e,"P",{"data-svelte-h":!0}),d(X)!=="svelte-v0pjtx"&&(X.innerHTML=Oa),Et=n(e),m(N.$$.fragment,e),Vt=n(e),A=p(e,"P",{"data-svelte-h":!0}),d(A)!=="svelte-8kqvys"&&(A.innerHTML=Da),Ht=n(e),G=p(e,"P",{"data-svelte-h":!0}),d(G)!=="svelte-7p5plo"&&(G.textContent=Ka),qt=n(e),R=p(e,"P",{"data-svelte-h":!0}),d(R)!=="svelte-rxyuqc"&&(R.innerHTML=es),zt=n(e),E=p(e,"P",{"data-svelte-h":!0}),d(E)!=="svelte-b7160f"&&(E.textContent=ts),Lt=n(e),V=p(e,"UL",{"data-svelte-h":!0}),d(V)!=="svelte-vz4lhh"&&(V.innerHTML=ls),Qt=n(e),H=p(e,"P",{"data-svelte-h":!0}),d(H)!=="svelte-194migv"&&(H.textContent=as),St=n(e),q=p(e,"UL",{"data-svelte-h":!0}),d(q)!=="svelte-1223amv"&&(q.innerHTML=ss),Ft=n(e),m(z.$$.fragment,e),Yt=n(e),L=p(e,"P",{"data-svelte-h":!0}),d(L)!=="svelte-1rezqc2"&&(L.textContent=ns),Pt=n(e),m(Q.$$.fragment,e),Ot=n(e),S=p(e,"P",{"data-svelte-h":!0}),d(S)!=="svelte-5qhi33"&&(S.innerHTML=os),Dt=n(e),m(F.$$.fragment,e),Kt=n(e),Y=p(e,"P",{"data-svelte-h":!0}),d(Y)!=="svelte-1xn293m"&&(Y.textContent=is),el=n(e),m(P.$$.fragment,e),tl=n(e),O=p(e,"P",{"data-svelte-h":!0}),d(O)!=="svelte-1ekqtp"&&(O.textContent=rs),ll=n(e),m(D.$$.fragment,e),al=n(e),K=p(e,"P",{"data-svelte-h":!0}),d(K)!=="svelte-olsb8t"&&(K.innerHTML=ps),sl=n(e),ee=p(e,"P",{"data-svelte-h":!0}),d(ee)!=="svelte-tcdasa"&&(ee.innerHTML=ds),nl=n(e),m(te.$$.fragment,e),ol=n(e),le=p(e,"P",{"data-svelte-h":!0}),d(le)!=="svelte-1hbp2km"&&(le.innerHTML=cs),il=n(e),m(ae.$$.fragment,e),rl=n(e),se=p(e,"P",{"data-svelte-h":!0}),d(se)!=="svelte-1h30j8i"&&(se.innerHTML=ms),pl=n(e),m(ne.$$.fragment,e),dl=n(e),oe=p(e,"P",{"data-svelte-h":!0}),d(oe)!=="svelte-1xwvftw"&&(oe.textContent=us),cl=n(e),m(v.$$.fragment,e),ml=n(e),m(ie.$$.fragment,e),ul=n(e),re=p(e,"P",{"data-svelte-h":!0}),d(re)!=="svelte-p07qxg"&&(re.innerHTML=Ms),Ml=n(e),pe=p(e,"TABLE",{"data-svelte-h":!0}),d(pe)!=="svelte-19g4mid"&&(pe.innerHTML=fs),fl=n(e),de=p(e,"P",{"data-svelte-h":!0}),d(de)!=="svelte-z84cjd"&&(de.innerHTML=ys),yl=n(e),m(ce.$$.fragment,e),jl=n(e),me=p(e,"P",{"data-svelte-h":!0}),d(me)!=="svelte-1q0ce7p"&&(me.innerHTML=js),bl=n(e),m(ue.$$.fragment,e),gl=n(e),Me=p(e,"P",{"data-svelte-h":!0}),d(Me)!=="svelte-4a0cb6"&&(Me.textContent=bs),Tl=n(e),m(fe.$$.fragment,e),hl=n(e),ye=p(e,"P",{"data-svelte-h":!0}),d(ye)!=="svelte-4svxy9"&&(ye.innerHTML=gs),wl=n(e),m(x.$$.fragment,e),Jl=n(e),m(je.$$.fragment,e),$l=n(e),be=p(e,"P",{"data-svelte-h":!0}),d(be)!=="svelte-6zjh54"&&(be.textContent=Ts),Ul=n(e),ge=p(e,"OL",{"data-svelte-h":!0}),d(ge)!=="svelte-utsrgp"&&(ge.innerHTML=hs),Cl=n(e),Te=p(e,"P",{"data-svelte-h":!0}),d(Te)!=="svelte-uz65rl"&&(Te.textContent=ws),vl=n(e),m(he.$$.fragment,e),xl=n(e),we=p(e,"P",{"data-svelte-h":!0}),d(we)!=="svelte-1fjrnj0"&&(we.textContent=Js),Zl=n(e),Je=p(e,"UL",{"data-svelte-h":!0}),d(Je)!=="svelte-1oias2v"&&(Je.innerHTML=$s),Bl=n(e),m(Z.$$.fragment,e),Il=n(e),$e=p(e,"P",{"data-svelte-h":!0}),d($e)!=="svelte-j69ur5"&&($e.innerHTML=Us),kl=n(e),m(Ue.$$.fragment,e),_l=n(e),Ce=p(e,"P",{"data-svelte-h":!0}),d(Ce)!=="svelte-1b9fj7y"&&(Ce.innerHTML=Cs),Wl=n(e),m(B.$$.fragment,e),Xl=n(e),ve=p(e,"P",{"data-svelte-h":!0}),d(ve)!=="svelte-19vxzwm"&&(ve.textContent=vs),Nl=n(e),m(xe.$$.fragment,e),Al=n(e),Ze=p(e,"P",{"data-svelte-h":!0}),d(Ze)!=="svelte-2qbtlm"&&(Ze.textContent=xs),Gl=n(e),m(Be.$$.fragment,e),Rl=n(e),Ie=p(e,"P",{"data-svelte-h":!0}),d(Ie)!=="svelte-1ahh71r"&&(Ie.textContent=Zs),El=n(e),m(ke.$$.fragment,e),Vl=n(e),_e=p(e,"P",{"data-svelte-h":!0}),d(_e)!=="svelte-nurpeo"&&(_e.innerHTML=Bs),Hl=n(e),m(We.$$.fragment,e),ql=n(e),m(I.$$.fragment,e),zl=n(e),m(Xe.$$.fragment,e),Ll=n(e),Ne=p(e,"P",{"data-svelte-h":!0}),d(Ne)!=="svelte-1e9iy9f"&&(Ne.innerHTML=Is),Ql=n(e),m(Ae.$$.fragment,e),Sl=n(e),Ge=p(e,"P",{"data-svelte-h":!0}),d(Ge)!=="svelte-i9ugge"&&(Ge.innerHTML=ks),Fl=n(e),m(Re.$$.fragment,e),Yl=n(e),m(k.$$.fragment,e),Pl=n(e),m(Ee.$$.fragment,e),Ol=n(e),Ve=p(e,"P",{"data-svelte-h":!0}),d(Ve)!=="svelte-1cws23w"&&(Ve.innerHTML=_s),Dl=n(e),m(He.$$.fragment,e),Kl=n(e),qe=p(e,"P",{"data-svelte-h":!0}),d(qe)!=="svelte-e8b61v"&&(qe.innerHTML=Ws),ea=n(e),m(ze.$$.fragment,e),ta=n(e),Le=p(e,"P",{"data-svelte-h":!0}),d(Le)!=="svelte-gmawhv"&&(Le.textContent=Xs),la=n(e),Qe=p(e,"UL",{"data-svelte-h":!0}),d(Qe)!=="svelte-1l017x9"&&(Qe.innerHTML=Ns),aa=n(e),Se=p(e,"P",{"data-svelte-h":!0}),d(Se)!=="svelte-5jmim9"&&(Se.innerHTML=As),sa=n(e),m(Fe.$$.fragment,e),na=n(e),m(_.$$.fragment,e),oa=n(e),Ye=p(e,"P",{"data-svelte-h":!0}),d(Ye)!=="svelte-jnclu5"&&(Ye.innerHTML=Gs),ia=n(e),Pe=p(e,"P",{"data-svelte-h":!0}),d(Pe)!=="svelte-1tbohqs"&&(Pe.textContent=Rs),ra=n(e),Oe=p(e,"P",{"data-svelte-h":!0}),d(Oe)!=="svelte-14y3y0y"&&(Oe.textContent=Es),pa=n(e),De=p(e,"UL",{"data-svelte-h":!0}),d(De)!=="svelte-1pnqwfl"&&(De.innerHTML=Vs),da=n(e),Ke=p(e,"P",{"data-svelte-h":!0}),d(Ke)!=="svelte-1xnblp0"&&(Ke.textContent=Hs),ca=n(e),m(et.$$.fragment,e),ma=n(e),tt=p(e,"P",{"data-svelte-h":!0}),d(tt)!=="svelte-oteso6"&&(tt.innerHTML=qs),ua=n(e),lt=p(e,"P",{"data-svelte-h":!0}),d(lt)!=="svelte-16q5iky"&&(lt.innerHTML=zs),Ma=n(e),at=p(e,"P",{"data-svelte-h":!0}),d(at)!=="svelte-1z0i5sf"&&(at.innerHTML=Ls),fa=n(e),m(st.$$.fragment,e),ya=n(e),nt=p(e,"P",{"data-svelte-h":!0}),d(nt)!=="svelte-1g52tin"&&(nt.textContent=Qs),ja=n(e),ot=p(e,"P",{"data-svelte-h":!0}),d(ot)!=="svelte-1k2z473"&&(ot.textContent=Ss),ba=n(e),it=p(e,"P",{"data-svelte-h":!0}),d(it)!=="svelte-w9fo8c"&&(it.innerHTML=Fs),ga=n(e),rt=p(e,"P",{"data-svelte-h":!0}),d(rt)!=="svelte-d0488i"&&(rt.innerHTML=Ys),Ta=n(e),pt=p(e,"P",{"data-svelte-h":!0}),d(pt)!=="svelte-1udnc8x"&&(pt.textContent=Ps),ha=n(e),m(dt.$$.fragment,e),wa=n(e),ct=p(e,"P",{"data-svelte-h":!0}),d(ct)!=="svelte-z2sk6s"&&(ct.textContent=Os),Ja=n(e),m(mt.$$.fragment,e),$a=n(e),ut=p(e,"P",{"data-svelte-h":!0}),d(ut)!=="svelte-f2qgin"&&(ut.innerHTML=Ds),Ua=n(e),m(Mt.$$.fragment,e),Ca=n(e),m(ft.$$.fragment,e),va=n(e),yt=p(e,"P",{"data-svelte-h":!0}),d(yt)!=="svelte-cu3t2j"&&(yt.innerHTML=Ks),xa=n(e),m(jt.$$.fragment,e),Za=n(e),m(bt.$$.fragment,e),Ba=n(e),gt=p(e,"P",{"data-svelte-h":!0}),d(gt)!=="svelte-j4u541"&&(gt.innerHTML=en),Ia=n(e),m(Tt.$$.fragment,e),ka=n(e),m(ht.$$.fragment,e),_a=n(e),wt=p(e,"P",{"data-svelte-h":!0}),d(wt)!=="svelte-y13wnz"&&(wt.innerHTML=tn),Wa=n(e),Jt=p(e,"OL",{"data-svelte-h":!0}),d(Jt)!=="svelte-j8267o"&&(Jt.innerHTML=ln),Xa=n(e),m($t.$$.fragment,e),Na=n(e),Ut=p(e,"P",{"data-svelte-h":!0}),d(Ut)!=="svelte-17gv1st"&&(Ut.innerHTML=an),Aa=n(e),m(Ct.$$.fragment,e),Ga=n(e),vt=p(e,"P",{"data-svelte-h":!0}),d(vt)!=="svelte-xgquje"&&(vt.textContent=sn),Ra=n(e),xt=p(e,"UL",{"data-svelte-h":!0}),d(xt)!=="svelte-ctgjcu"&&(xt.innerHTML=nn),Ea=n(e),m(Zt.$$.fragment,e),Va=n(e),Bt=p(e,"P",{"data-svelte-h":!0}),d(Bt)!=="svelte-rrgk4r"&&(Bt.innerHTML=on),Ha=n(e),m(It.$$.fragment,e),qa=n(e),kt=p(e,"P",{"data-svelte-h":!0}),d(kt)!=="svelte-17bbjt2"&&(kt.textContent=rn),za=n(e),m(_t.$$.fragment,e),La=n(e),Wt=p(e,"P",{"data-svelte-h":!0}),d(Wt)!=="svelte-157z9d8"&&(Wt.textContent=pn),Qa=n(e),m(Xt.$$.fragment,e),Sa=n(e),Nt=p(e,"P",{"data-svelte-h":!0}),d(Nt)!=="svelte-nhaqqn"&&(Nt.textContent=dn),Fa=n(e),At=p(e,"P",{"data-svelte-h":!0}),d(At)!=="svelte-rtq77g"&&(At.innerHTML=cn),Ya=n(e),Rt=p(e,"P",{}),gn(Rt).forEach(l),this.h()},h(){Tn(o,"name","hf:doc:metadata"),Tn(o,"content",En)},m(e,t){vn(document.head,o),a(e,b,t),a(e,i,t),a(e,g,t),u(h,e,t),a(e,J,t),a(e,U,t),a(e,C,t),a(e,X,t),a(e,Et,t),u(N,e,t),a(e,Vt,t),a(e,A,t),a(e,Ht,t),a(e,G,t),a(e,qt,t),a(e,R,t),a(e,zt,t),a(e,E,t),a(e,Lt,t),a(e,V,t),a(e,Qt,t),a(e,H,t),a(e,St,t),a(e,q,t),a(e,Ft,t),u(z,e,t),a(e,Yt,t),a(e,L,t),a(e,Pt,t),u(Q,e,t),a(e,Ot,t),a(e,S,t),a(e,Dt,t),u(F,e,t),a(e,Kt,t),a(e,Y,t),a(e,el,t),u(P,e,t),a(e,tl,t),a(e,O,t),a(e,ll,t),u(D,e,t),a(e,al,t),a(e,K,t),a(e,sl,t),a(e,ee,t),a(e,nl,t),u(te,e,t),a(e,ol,t),a(e,le,t),a(e,il,t),u(ae,e,t),a(e,rl,t),a(e,se,t),a(e,pl,t),u(ne,e,t),a(e,dl,t),a(e,oe,t),a(e,cl,t),u(v,e,t),a(e,ml,t),u(ie,e,t),a(e,ul,t),a(e,re,t),a(e,Ml,t),a(e,pe,t),a(e,fl,t),a(e,de,t),a(e,yl,t),u(ce,e,t),a(e,jl,t),a(e,me,t),a(e,bl,t),u(ue,e,t),a(e,gl,t),a(e,Me,t),a(e,Tl,t),u(fe,e,t),a(e,hl,t),a(e,ye,t),a(e,wl,t),u(x,e,t),a(e,Jl,t),u(je,e,t),a(e,$l,t),a(e,be,t),a(e,Ul,t),a(e,ge,t),a(e,Cl,t),a(e,Te,t),a(e,vl,t),u(he,e,t),a(e,xl,t),a(e,we,t),a(e,Zl,t),a(e,Je,t),a(e,Bl,t),u(Z,e,t),a(e,Il,t),a(e,$e,t),a(e,kl,t),u(Ue,e,t),a(e,_l,t),a(e,Ce,t),a(e,Wl,t),u(B,e,t),a(e,Xl,t),a(e,ve,t),a(e,Nl,t),u(xe,e,t),a(e,Al,t),a(e,Ze,t),a(e,Gl,t),u(Be,e,t),a(e,Rl,t),a(e,Ie,t),a(e,El,t),u(ke,e,t),a(e,Vl,t),a(e,_e,t),a(e,Hl,t),u(We,e,t),a(e,ql,t),u(I,e,t),a(e,zl,t),u(Xe,e,t),a(e,Ll,t),a(e,Ne,t),a(e,Ql,t),u(Ae,e,t),a(e,Sl,t),a(e,Ge,t),a(e,Fl,t),u(Re,e,t),a(e,Yl,t),u(k,e,t),a(e,Pl,t),u(Ee,e,t),a(e,Ol,t),a(e,Ve,t),a(e,Dl,t),u(He,e,t),a(e,Kl,t),a(e,qe,t),a(e,ea,t),u(ze,e,t),a(e,ta,t),a(e,Le,t),a(e,la,t),a(e,Qe,t),a(e,aa,t),a(e,Se,t),a(e,sa,t),u(Fe,e,t),a(e,na,t),u(_,e,t),a(e,oa,t),a(e,Ye,t),a(e,ia,t),a(e,Pe,t),a(e,ra,t),a(e,Oe,t),a(e,pa,t),a(e,De,t),a(e,da,t),a(e,Ke,t),a(e,ca,t),u(et,e,t),a(e,ma,t),a(e,tt,t),a(e,ua,t),a(e,lt,t),a(e,Ma,t),a(e,at,t),a(e,fa,t),u(st,e,t),a(e,ya,t),a(e,nt,t),a(e,ja,t),a(e,ot,t),a(e,ba,t),a(e,it,t),a(e,ga,t),a(e,rt,t),a(e,Ta,t),a(e,pt,t),a(e,ha,t),u(dt,e,t),a(e,wa,t),a(e,ct,t),a(e,Ja,t),u(mt,e,t),a(e,$a,t),a(e,ut,t),a(e,Ua,t),u(Mt,e,t),a(e,Ca,t),u(ft,e,t),a(e,va,t),a(e,yt,t),a(e,xa,t),u(jt,e,t),a(e,Za,t),u(bt,e,t),a(e,Ba,t),a(e,gt,t),a(e,Ia,t),u(Tt,e,t),a(e,ka,t),u(ht,e,t),a(e,_a,t),a(e,wt,t),a(e,Wa,t),a(e,Jt,t),a(e,Xa,t),u($t,e,t),a(e,Na,t),a(e,Ut,t),a(e,Aa,t),u(Ct,e,t),a(e,Ga,t),a(e,vt,t),a(e,Ra,t),a(e,xt,t),a(e,Ea,t),u(Zt,e,t),a(e,Va,t),a(e,Bt,t),a(e,Ha,t),u(It,e,t),a(e,qa,t),a(e,kt,t),a(e,za,t),u(_t,e,t),a(e,La,t),a(e,Wt,t),a(e,Qa,t),u(Xt,e,t),a(e,Sa,t),a(e,Nt,t),a(e,Fa,t),a(e,At,t),a(e,Ya,t),a(e,Rt,t),Pa=!0},p(e,[t]){const mn={};t&2&&(mn.$$scope={dirty:t,ctx:e}),v.$set(mn);const un={};t&2&&(un.$$scope={dirty:t,ctx:e}),x.$set(un);const Mn={};t&2&&(Mn.$$scope={dirty:t,ctx:e}),Z.$set(Mn);const fn={};t&2&&(fn.$$scope={dirty:t,ctx:e}),B.$set(fn);const yn={};t&2&&(yn.$$scope={dirty:t,ctx:e}),I.$set(yn);const jn={};t&2&&(jn.$$scope={dirty:t,ctx:e}),k.$set(jn);const bn={};t&2&&(bn.$$scope={dirty:t,ctx:e}),_.$set(bn)},i(e){Pa||(M(h.$$.fragment,e),M(N.$$.fragment,e),M(z.$$.fragment,e),M(Q.$$.fragment,e),M(F.$$.fragment,e),M(P.$$.fragment,e),M(D.$$.fragment,e),M(te.$$.fragment,e),M(ae.$$.fragment,e),M(ne.$$.fragment,e),M(v.$$.fragment,e),M(ie.$$.fragment,e),M(ce.$$.fragment,e),M(ue.$$.fragment,e),M(fe.$$.fragment,e),M(x.$$.fragment,e),M(je.$$.fragment,e),M(he.$$.fragment,e),M(Z.$$.fragment,e),M(Ue.$$.fragment,e),M(B.$$.fragment,e),M(xe.$$.fragment,e),M(Be.$$.fragment,e),M(ke.$$.fragment,e),M(We.$$.fragment,e),M(I.$$.fragment,e),M(Xe.$$.fragment,e),M(Ae.$$.fragment,e),M(Re.$$.fragment,e),M(k.$$.fragment,e),M(Ee.$$.fragment,e),M(He.$$.fragment,e),M(ze.$$.fragment,e),M(Fe.$$.fragment,e),M(_.$$.fragment,e),M(et.$$.fragment,e),M(st.$$.fragment,e),M(dt.$$.fragment,e),M(mt.$$.fragment,e),M(Mt.$$.fragment,e),M(ft.$$.fragment,e),M(jt.$$.fragment,e),M(bt.$$.fragment,e),M(Tt.$$.fragment,e),M(ht.$$.fragment,e),M($t.$$.fragment,e),M(Ct.$$.fragment,e),M(Zt.$$.fragment,e),M(It.$$.fragment,e),M(_t.$$.fragment,e),M(Xt.$$.fragment,e),Pa=!0)},o(e){f(h.$$.fragment,e),f(N.$$.fragment,e),f(z.$$.fragment,e),f(Q.$$.fragment,e),f(F.$$.fragment,e),f(P.$$.fragment,e),f(D.$$.fragment,e),f(te.$$.fragment,e),f(ae.$$.fragment,e),f(ne.$$.fragment,e),f(v.$$.fragment,e),f(ie.$$.fragment,e),f(ce.$$.fragment,e),f(ue.$$.fragment,e),f(fe.$$.fragment,e),f(x.$$.fragment,e),f(je.$$.fragment,e),f(he.$$.fragment,e),f(Z.$$.fragment,e),f(Ue.$$.fragment,e),f(B.$$.fragment,e),f(xe.$$.fragment,e),f(Be.$$.fragment,e),f(ke.$$.fragment,e),f(We.$$.fragment,e),f(I.$$.fragment,e),f(Xe.$$.fragment,e),f(Ae.$$.fragment,e),f(Re.$$.fragment,e),f(k.$$.fragment,e),f(Ee.$$.fragment,e),f(He.$$.fragment,e),f(ze.$$.fragment,e),f(Fe.$$.fragment,e),f(_.$$.fragment,e),f(et.$$.fragment,e),f(st.$$.fragment,e),f(dt.$$.fragment,e),f(mt.$$.fragment,e),f(Mt.$$.fragment,e),f(ft.$$.fragment,e),f(jt.$$.fragment,e),f(bt.$$.fragment,e),f(Tt.$$.fragment,e),f(ht.$$.fragment,e),f($t.$$.fragment,e),f(Ct.$$.fragment,e),f(Zt.$$.fragment,e),f(It.$$.fragment,e),f(_t.$$.fragment,e),f(Xt.$$.fragment,e),Pa=!1},d(e){e&&(l(b),l(i),l(g),l(J),l(U),l(C),l(X),l(Et),l(Vt),l(A),l(Ht),l(G),l(qt),l(R),l(zt),l(E),l(Lt),l(V),l(Qt),l(H),l(St),l(q),l(Ft),l(Yt),l(L),l(Pt),l(Ot),l(S),l(Dt),l(Kt),l(Y),l(el),l(tl),l(O),l(ll),l(al),l(K),l(sl),l(ee),l(nl),l(ol),l(le),l(il),l(rl),l(se),l(pl),l(dl),l(oe),l(cl),l(ml),l(ul),l(re),l(Ml),l(pe),l(fl),l(de),l(yl),l(jl),l(me),l(bl),l(gl),l(Me),l(Tl),l(hl),l(ye),l(wl),l(Jl),l($l),l(be),l(Ul),l(ge),l(Cl),l(Te),l(vl),l(xl),l(we),l(Zl),l(Je),l(Bl),l(Il),l($e),l(kl),l(_l),l(Ce),l(Wl),l(Xl),l(ve),l(Nl),l(Al),l(Ze),l(Gl),l(Rl),l(Ie),l(El),l(Vl),l(_e),l(Hl),l(ql),l(zl),l(Ll),l(Ne),l(Ql),l(Sl),l(Ge),l(Fl),l(Yl),l(Pl),l(Ol),l(Ve),l(Dl),l(Kl),l(qe),l(ea),l(ta),l(Le),l(la),l(Qe),l(aa),l(Se),l(sa),l(na),l(oa),l(Ye),l(ia),l(Pe),l(ra),l(Oe),l(pa),l(De),l(da),l(Ke),l(ca),l(ma),l(tt),l(ua),l(lt),l(Ma),l(at),l(fa),l(ya),l(nt),l(ja),l(ot),l(ba),l(it),l(ga),l(rt),l(Ta),l(pt),l(ha),l(wa),l(ct),l(Ja),l($a),l(ut),l(Ua),l(Ca),l(va),l(yt),l(xa),l(Za),l(Ba),l(gt),l(Ia),l(ka),l(_a),l(wt),l(Wa),l(Jt),l(Xa),l(Na),l(Ut),l(Aa),l(Ga),l(vt),l(Ra),l(xt),l(Ea),l(Va),l(Bt),l(Ha),l(qa),l(kt),l(za),l(La),l(Wt),l(Qa),l(Sa),l(Nt),l(Fa),l(At),l(Ya),l(Rt)),l(o),y(h,e),y(N,e),y(z,e),y(Q,e),y(F,e),y(P,e),y(D,e),y(te,e),y(ae,e),y(ne,e),y(v,e),y(ie,e),y(ce,e),y(ue,e),y(fe,e),y(x,e),y(je,e),y(he,e),y(Z,e),y(Ue,e),y(B,e),y(xe,e),y(Be,e),y(ke,e),y(We,e),y(I,e),y(Xe,e),y(Ae,e),y(Re,e),y(k,e),y(Ee,e),y(He,e),y(ze,e),y(Fe,e),y(_,e),y(et,e),y(st,e),y(dt,e),y(mt,e),y(Mt,e),y(ft,e),y(jt,e),y(bt,e),y(Tt,e),y(ht,e),y($t,e),y(Ct,e),y(Zt,e),y(It,e),y(_t,e),y(Xt,e)}}}const En='{"title":"Exportar modelos ü§ó Transformers","local":"exportar-modelos--transformers","sections":[{"title":"ONNX","local":"onnx","sections":[{"title":"Exportar un model a ONNX","local":"exportar-un-model-a-onnx","sections":[],"depth":3},{"title":"Seleccionar caracter√≠sticas para diferentes topolog√≠as de un modelo","local":"seleccionar-caracter√≠sticas-para-diferentes-topolog√≠as-de-un-modelo","sections":[],"depth":3},{"title":"Exportar un modelo para una arquitectura no compatible","local":"exportar-un-modelo-para-una-arquitectura-no-compatible","sections":[{"title":"Implementar una configuraci√≥n personalizada en ONNX","local":"implementar-una-configuraci√≥n-personalizada-en-onnx","sections":[],"depth":4},{"title":"Exportar el modelo","local":"exportar-el-modelo","sections":[],"depth":4},{"title":"Validar los resultados del modelo","local":"validar-los-resultados-del-modelo","sections":[],"depth":4}],"depth":3},{"title":"Contribuir con una nueva configuraci√≥n a ü§ó Transformers","local":"contribuir-con-una-nueva-configuraci√≥n-a--transformers","sections":[],"depth":3}],"depth":2},{"title":"TorchScript","local":"torchscript","sections":[{"title":"Indicador de TorchScript y pesos atados","local":"indicador-de-torchscript-y-pesos-atados","sections":[],"depth":3},{"title":"Entradas ficticias y longitudes est√°ndar","local":"entradas-ficticias-y-longitudes-est√°ndar","sections":[],"depth":3},{"title":"Usar TorchScript en Python","local":"usar-torchscript-en-python","sections":[{"title":"Guardando un modelo","local":"guardando-un-modelo","sections":[],"depth":4},{"title":"Cargar un modelo","local":"cargar-un-modelo","sections":[],"depth":4},{"title":"Usar un modelo rastreado para la inferencia","local":"usar-un-modelo-rastreado-para-la-inferencia","sections":[],"depth":4}],"depth":3},{"title":"Implementar los modelos HuggingFace TorchScript en AWS mediante Neuron SDK","local":"implementar-los-modelos-huggingface-torchscript-en-aws-mediante-neuron-sdk","sections":[{"title":"Implicaciones","local":"implicaciones","sections":[],"depth":4},{"title":"Dependencias","local":"dependencias","sections":[],"depth":4},{"title":"Convertir un modelo a AWS Neuron","local":"convertir-un-modelo-a-aws-neuron","sections":[],"depth":4}],"depth":3}],"depth":2}],"depth":1}';function Vn(w){return Jn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fn extends $n{constructor(o){super(),Un(this,o,Vn,Rn,wn,{})}}export{Fn as component};
