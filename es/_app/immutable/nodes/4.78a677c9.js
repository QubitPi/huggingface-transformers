import{s as Te,o as _e,n as fe}from"../chunks/scheduler.36a0863c.js";import{S as qe,i as Je,g as $,s as p,r as j,A as We,h as g,f as s,c,j as xe,u as y,x,k as Ze,y as Ue,a as l,v as M,d as C,t as k,w as v}from"../chunks/index.f891bdb2.js";import{T as Fe}from"../chunks/Tip.a8272f7f.js";import{C as W}from"../chunks/CodeBlock.3ec784ea.js";import{F as Ge,M as we}from"../chunks/Markdown.4127c891.js";import{H as B}from"../chunks/Heading.3fb90772.js";function Ve(q){let n,u='Recuerda, la arquitectura se refiere al esqueleto del modelo y los checkpoints son los pesos para una arquitectura dada. Por ejemplo, <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a> es una arquitectura, mientras que <code>google-bert/bert-base-uncased</code> es un checkpoint. Modelo es un t√©rmino general que puede significar una arquitectura o un checkpoint.';return{c(){n=$("p"),n.innerHTML=u},l(r){n=g(r,"P",{"data-svelte-h":!0}),x(n)!=="svelte-5pvtx4"&&(n.innerHTML=u)},m(r,o){l(r,n,o)},p:fe,d(r){r&&s(n)}}}function ze(q){let n,u='Finalmente, las clases <code>AutoModelFor</code> te permiten cargar un modelo preentrenado para una tarea dada (revisa <a href="model_doc/auto">aqu√≠</a> para conocer la lista completa de tareas disponibles). Por ejemplo, cargue un modelo para clasificaci√≥n de secuencias con <code>AutoModelForSequenceClassification.from_pretrained()</code>:',r,o,m,d,Z="Reutiliza f√°cilmente el mismo checkpoint para cargar una aquitectura para alguna tarea diferente:",T,f,h,b,w='Generalmente recomendamos utilizar las clases <code>AutoTokenizer</code> y <code>AutoModelFor</code> para cargar instancias pre-entrenadas de modelos. √âsto asegurar√° que cargues la arquitectura correcta en cada ocasi√≥n. En el siguiente <a href="preprocessing">tutorial</a>, aprende a usar tu tokenizador reci√©n cargado, el extractor de caracter√≠sticas y el procesador para preprocesar un dataset para fine-tuning.',_;return o=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),f=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){n=$("p"),n.innerHTML=u,r=p(),j(o.$$.fragment),m=p(),d=$("p"),d.textContent=Z,T=p(),j(f.$$.fragment),h=p(),b=$("p"),b.innerHTML=w},l(a){n=g(a,"P",{"data-svelte-h":!0}),x(n)!=="svelte-3za6zf"&&(n.innerHTML=u),r=c(a),y(o.$$.fragment,a),m=c(a),d=g(a,"P",{"data-svelte-h":!0}),x(d)!=="svelte-17xqunq"&&(d.textContent=Z),T=c(a),y(f.$$.fragment,a),h=c(a),b=g(a,"P",{"data-svelte-h":!0}),x(b)!=="svelte-6eqqlh"&&(b.innerHTML=w)},m(a,i){l(a,n,i),l(a,r,i),M(o,a,i),l(a,m,i),l(a,d,i),l(a,T,i),M(f,a,i),l(a,h,i),l(a,b,i),_=!0},p:fe,i(a){_||(C(o.$$.fragment,a),C(f.$$.fragment,a),_=!0)},o(a){k(o.$$.fragment,a),k(f.$$.fragment,a),_=!1},d(a){a&&(s(n),s(r),s(m),s(d),s(T),s(h),s(b)),v(o,a),v(f,a)}}}function Re(q){let n,u;return n=new we({props:{$$slots:{default:[ze]},$$scope:{ctx:q}}}),{c(){j(n.$$.fragment)},l(r){y(n.$$.fragment,r)},m(r,o){M(n,r,o),u=!0},p(r,o){const m={};o&2&&(m.$$scope={dirty:o,ctx:r}),n.$set(m)},i(r){u||(C(n.$$.fragment,r),u=!0)},o(r){k(n.$$.fragment,r),u=!1},d(r){v(n,r)}}}function Ee(q){let n,u='Finalmente, la clase <code>TFAutoModelFor</code> te permite cargar tu modelo pre-entrenado para una tarea dada (revisa <a href="model_doc/auto">aqu√≠</a> para conocer la lista completa de tareas disponibles). Por ejemplo, carga un modelo para clasificaci√≥n de secuencias con <code>TFAutoModelForSequenceClassification.from_pretrained()</code>:',r,o,m,d,Z="Reutiliza f√°cilmente el mismo checkpoint para cargar una aquitectura para alguna tarea diferente:",T,f,h,b,w='Generalmente recomendamos utilizar las clases <code>AutoTokenizer</code> y <code>TFAutoModelFor</code> para cargar instancias de modelos pre-entrenados. √âsto asegurar√° que cargues la arquitectura correcta cada vez. En el siguiente <a href="preprocessing">tutorial</a>, aprende a usar tu tokenizador reci√©n cargado, el extractor de caracter√≠sticas y el procesador para preprocesar un dataset para fine-tuning.',_;return o=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),f=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){n=$("p"),n.innerHTML=u,r=p(),j(o.$$.fragment),m=p(),d=$("p"),d.textContent=Z,T=p(),j(f.$$.fragment),h=p(),b=$("p"),b.innerHTML=w},l(a){n=g(a,"P",{"data-svelte-h":!0}),x(n)!=="svelte-6xkpop"&&(n.innerHTML=u),r=c(a),y(o.$$.fragment,a),m=c(a),d=g(a,"P",{"data-svelte-h":!0}),x(d)!=="svelte-17xqunq"&&(d.textContent=Z),T=c(a),y(f.$$.fragment,a),h=c(a),b=g(a,"P",{"data-svelte-h":!0}),x(b)!=="svelte-1ujd6p5"&&(b.innerHTML=w)},m(a,i){l(a,n,i),l(a,r,i),M(o,a,i),l(a,m,i),l(a,d,i),l(a,T,i),M(f,a,i),l(a,h,i),l(a,b,i),_=!0},p:fe,i(a){_||(C(o.$$.fragment,a),C(f.$$.fragment,a),_=!0)},o(a){k(o.$$.fragment,a),k(f.$$.fragment,a),_=!1},d(a){a&&(s(n),s(r),s(m),s(d),s(T),s(h),s(b)),v(o,a),v(f,a)}}}function Xe(q){let n,u;return n=new we({props:{$$slots:{default:[Ee]},$$scope:{ctx:q}}}),{c(){j(n.$$.fragment)},l(r){y(n.$$.fragment,r)},m(r,o){M(n,r,o),u=!0},p(r,o){const m={};o&2&&(m.$$scope={dirty:o,ctx:r}),n.$set(m)},i(r){u||(C(n.$$.fragment,r),u=!0)},o(r){k(n.$$.fragment,r),u=!1},d(r){v(n,r)}}}function He(q){let n,u,r,o,m,d,Z,T="Con tantas arquitecturas diferentes de Transformer puede ser retador crear una para tu checkpoint. Como parte de la filosof√≠a central de ü§ó Transformers para hacer que la biblioteca sea f√°cil, simple y flexible de usar; una <code>AutoClass</code> autom√°ticamente infiere y carga la arquitectura correcta desde un checkpoint dado. El m√©todo <code>from_pretrained</code> te permite cargar r√°pidamente un modelo preentrenado para cualquier arquitectura, por lo que no tendr√°s que dedicar tiempo y recursos para entrenar uno desde cero. Producir este tipo de c√≥digo con checkpoint implica que si funciona con uno, funcionar√° tambi√©n con otro (siempre que haya sido entrenado para una tarea similar) incluso si la arquitectura es distinta.",f,h,b,w,_="En este tutorial, aprender√°s a:",a,i,be="<li>Cargar un tokenizador pre-entrenado.</li> <li>Cargar un extractor de caracter√≠sticas (feature extractor en ingl√©s) pre-entrenado.</li> <li>Cargar un procesador pre-entrenado.</li> <li>Cargar un modelo pre-entrenado.</li>",S,U,K,F,$e="Casi cualquier tarea de Procesamiento de Lenguaje Natural comienza con un tokenizador. Un tokenizador convierte tu input a un formato que puede ser procesado por el modelo.",D,G,ge="Carga un tokenizador con <code>AutoTokenizer.from_pretrained()</code>:",O,V,ee,z,he="Luego tokeniza tu input como lo mostrado a continuaci√≥n:",ae,R,te,E,se,X,je="Para tareas de audio y visi√≥n, un extractor de caracter√≠sticas procesa la se√±al de audio o imagen al formato de input correcto.",ne,H,ye="Carga un extractor de caracter√≠sticas con <code>AutoFeatureExtractor.from_pretrained()</code>:",le,A,re,L,oe,Y,Me='Las tareas multimodales requieren un procesador que combine dos tipos de herramientas de preprocesamiento. Por ejemplo, el modelo <a href="model_doc/layoutlmv2">LayoutLMV2</a> requiere que un extractor de caracter√≠sticas maneje las im√°genes y que un tokenizador maneje el texto; un procesador combina ambas.',pe,N,Ce="Carga un procesador con <code>AutoProcessor.from_pretrained()</code>:",ce,P,ie,Q,ue,J,me,I,de;return m=new B({props:{title:"Carga instancias preentrenadas con un AutoClass",local:"carga-instancias-preentrenadas-con-un-autoclass",headingTag:"h1"}}),h=new Fe({props:{$$slots:{default:[Ve]},$$scope:{ctx:q}}}),U=new B({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h2"}}),V=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),R=new W({props:{code:"c2VxdWVuY2UlMjAlM0QlMjAlMjJJbiUyMGElMjBob2xlJTIwaW4lMjB0aGUlMjBncm91bmQlMjB0aGVyZSUyMGxpdmVkJTIwYSUyMGhvYmJpdC4lMjIlMEFwcmludCh0b2tlbml6ZXIoc2VxdWVuY2UpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),E=new B({props:{title:"AutoFeatureExtractor",local:"autofeatureextractor",headingTag:"h2"}}),A=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZWhjYWxhYnJlcyUyRndhdjJ2ZWMyLWxnLXhsc3ItZW4tc3BlZWNoLWVtb3Rpb24tcmVjb2duaXRpb24lMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),L=new B({props:{title:"AutoProcessor",local:"autoprocessor",headingTag:"h2"}}),P=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZsYXlvdXRsbXYyLWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`,wrap:!1}}),Q=new B({props:{title:"AutoModel",local:"automodel",headingTag:"h2"}}),J=new Ge({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Xe],pytorch:[Re]},$$scope:{ctx:q}}}),{c(){n=$("meta"),u=p(),r=$("p"),o=p(),j(m.$$.fragment),d=p(),Z=$("p"),Z.innerHTML=T,f=p(),j(h.$$.fragment),b=p(),w=$("p"),w.textContent=_,a=p(),i=$("ul"),i.innerHTML=be,S=p(),j(U.$$.fragment),K=p(),F=$("p"),F.textContent=$e,D=p(),G=$("p"),G.innerHTML=ge,O=p(),j(V.$$.fragment),ee=p(),z=$("p"),z.textContent=he,ae=p(),j(R.$$.fragment),te=p(),j(E.$$.fragment),se=p(),X=$("p"),X.textContent=je,ne=p(),H=$("p"),H.innerHTML=ye,le=p(),j(A.$$.fragment),re=p(),j(L.$$.fragment),oe=p(),Y=$("p"),Y.innerHTML=Me,pe=p(),N=$("p"),N.innerHTML=Ce,ce=p(),j(P.$$.fragment),ie=p(),j(Q.$$.fragment),ue=p(),j(J.$$.fragment),me=p(),I=$("p"),this.h()},l(e){const t=We("svelte-u9bgzb",document.head);n=g(t,"META",{name:!0,content:!0}),t.forEach(s),u=c(e),r=g(e,"P",{}),xe(r).forEach(s),o=c(e),y(m.$$.fragment,e),d=c(e),Z=g(e,"P",{"data-svelte-h":!0}),x(Z)!=="svelte-hslbe0"&&(Z.innerHTML=T),f=c(e),y(h.$$.fragment,e),b=c(e),w=g(e,"P",{"data-svelte-h":!0}),x(w)!=="svelte-1we4q6g"&&(w.textContent=_),a=c(e),i=g(e,"UL",{"data-svelte-h":!0}),x(i)!=="svelte-16w73us"&&(i.innerHTML=be),S=c(e),y(U.$$.fragment,e),K=c(e),F=g(e,"P",{"data-svelte-h":!0}),x(F)!=="svelte-1mbad6z"&&(F.textContent=$e),D=c(e),G=g(e,"P",{"data-svelte-h":!0}),x(G)!=="svelte-13gubso"&&(G.innerHTML=ge),O=c(e),y(V.$$.fragment,e),ee=c(e),z=g(e,"P",{"data-svelte-h":!0}),x(z)!=="svelte-ld3d8d"&&(z.textContent=he),ae=c(e),y(R.$$.fragment,e),te=c(e),y(E.$$.fragment,e),se=c(e),X=g(e,"P",{"data-svelte-h":!0}),x(X)!=="svelte-1ieyatv"&&(X.textContent=je),ne=c(e),H=g(e,"P",{"data-svelte-h":!0}),x(H)!=="svelte-2gx43z"&&(H.innerHTML=ye),le=c(e),y(A.$$.fragment,e),re=c(e),y(L.$$.fragment,e),oe=c(e),Y=g(e,"P",{"data-svelte-h":!0}),x(Y)!=="svelte-k24vuj"&&(Y.innerHTML=Me),pe=c(e),N=g(e,"P",{"data-svelte-h":!0}),x(N)!=="svelte-1v0y89d"&&(N.innerHTML=Ce),ce=c(e),y(P.$$.fragment,e),ie=c(e),y(Q.$$.fragment,e),ue=c(e),y(J.$$.fragment,e),me=c(e),I=g(e,"P",{}),xe(I).forEach(s),this.h()},h(){Ze(n,"name","hf:doc:metadata"),Ze(n,"content",Ae)},m(e,t){Ue(document.head,n),l(e,u,t),l(e,r,t),l(e,o,t),M(m,e,t),l(e,d,t),l(e,Z,t),l(e,f,t),M(h,e,t),l(e,b,t),l(e,w,t),l(e,a,t),l(e,i,t),l(e,S,t),M(U,e,t),l(e,K,t),l(e,F,t),l(e,D,t),l(e,G,t),l(e,O,t),M(V,e,t),l(e,ee,t),l(e,z,t),l(e,ae,t),M(R,e,t),l(e,te,t),M(E,e,t),l(e,se,t),l(e,X,t),l(e,ne,t),l(e,H,t),l(e,le,t),M(A,e,t),l(e,re,t),M(L,e,t),l(e,oe,t),l(e,Y,t),l(e,pe,t),l(e,N,t),l(e,ce,t),M(P,e,t),l(e,ie,t),M(Q,e,t),l(e,ue,t),M(J,e,t),l(e,me,t),l(e,I,t),de=!0},p(e,[t]){const ke={};t&2&&(ke.$$scope={dirty:t,ctx:e}),h.$set(ke);const ve={};t&2&&(ve.$$scope={dirty:t,ctx:e}),J.$set(ve)},i(e){de||(C(m.$$.fragment,e),C(h.$$.fragment,e),C(U.$$.fragment,e),C(V.$$.fragment,e),C(R.$$.fragment,e),C(E.$$.fragment,e),C(A.$$.fragment,e),C(L.$$.fragment,e),C(P.$$.fragment,e),C(Q.$$.fragment,e),C(J.$$.fragment,e),de=!0)},o(e){k(m.$$.fragment,e),k(h.$$.fragment,e),k(U.$$.fragment,e),k(V.$$.fragment,e),k(R.$$.fragment,e),k(E.$$.fragment,e),k(A.$$.fragment,e),k(L.$$.fragment,e),k(P.$$.fragment,e),k(Q.$$.fragment,e),k(J.$$.fragment,e),de=!1},d(e){e&&(s(u),s(r),s(o),s(d),s(Z),s(f),s(b),s(w),s(a),s(i),s(S),s(K),s(F),s(D),s(G),s(O),s(ee),s(z),s(ae),s(te),s(se),s(X),s(ne),s(H),s(le),s(re),s(oe),s(Y),s(pe),s(N),s(ce),s(ie),s(ue),s(me),s(I)),s(n),v(m,e),v(h,e),v(U,e),v(V,e),v(R,e),v(E,e),v(A,e),v(L,e),v(P,e),v(Q,e),v(J,e)}}}const Ae='{"title":"Carga instancias preentrenadas con un AutoClass","local":"carga-instancias-preentrenadas-con-un-autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":2},{"title":"AutoFeatureExtractor","local":"autofeatureextractor","sections":[],"depth":2},{"title":"AutoProcessor","local":"autoprocessor","sections":[],"depth":2},{"title":"AutoModel","local":"automodel","sections":[],"depth":2}],"depth":1}';function Le(q){return _e(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Se extends qe{constructor(n){super(),Je(this,n,Le,He,Te,{})}}export{Se as component};
