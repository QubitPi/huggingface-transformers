import{s as ca,o as da,n as Ne}from"../chunks/scheduler.36a0863c.js";import{S as fa,i as ua,g as o,s as l,r,A as ga,h as m,f as s,c as n,j as ma,u as c,x as M,k as ra,y as Ma,a as t,v as d,d as f,t as u,w as g}from"../chunks/index.f891bdb2.js";import{T as Ye}from"../chunks/Tip.a8272f7f.js";import{Y as ya}from"../chunks/Youtube.0cbacd3d.js";import{C as h}from"../chunks/CodeBlock.3ec784ea.js";import{H as Be}from"../chunks/Heading.3fb90772.js";function ha(J){let p,y='Consulta la <a href="https://huggingface.co/tasks/audio-classification" rel="nofollow">p치gina de la tarea</a> de clasificaci칩n de im치genes para obtener m치s informaci칩n sobre sus modelos, datasets y m칠tricas asociadas.';return{c(){p=o("p"),p.innerHTML=y},l(i){p=m(i,"P",{"data-svelte-h":!0}),M(p)!=="svelte-x2f51r"&&(p.innerHTML=y)},m(i,b){t(i,p,b)},p:Ne,d(i){i&&s(p)}}}function ba(J){let p,y='Si no est치s familiarizado con el fine-tuning de un modelo con el <code>Trainer</code>, echa un vistazo al tutorial b치sico <a href="../training#finetune-with-trainer">aqu칤</a>!';return{c(){p=o("p"),p.innerHTML=y},l(i){p=m(i,"P",{"data-svelte-h":!0}),M(p)!=="svelte-vd1d0s"&&(p.innerHTML=y)},m(i,b){t(i,p,b)},p:Ne,d(i){i&&s(p)}}}function Ja(J){let p,y='Para ver un ejemplo m치s a profundidad de c칩mo hacer fine-tune a un modelo para clasificaci칩n de im치genes, echa un vistazo al correspondiente <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb" rel="nofollow">PyTorch notebook</a>.';return{c(){p=o("p"),p.innerHTML=y},l(i){p=m(i,"P",{"data-svelte-h":!0}),M(p)!=="svelte-1qqa7s7"&&(p.innerHTML=y)},m(i,b){t(i,p,b)},p:Ne,d(i){i&&s(p)}}}function $a(J){let p,y,i,b,T,le,w,ne,C,Xe="La clasificaci칩n de im치genes asigna una etiqueta o clase a una imagen. A diferencia de la clasificaci칩n de texto o audio, las entradas son los valores de los p칤xeles que representan una imagen. La clasificaci칩n de im치genes tiene muchos usos, como la detecci칩n de da침os tras una cat치strofe, el control de la salud de los cultivos o la b칰squeda de signos de enfermedad en im치genes m칠dicas.",pe,v,He='Esta gu칤a te mostrar치 como hacer fine-tune al <a href="https://huggingface.co/docs/transformers/v4.16.2/en/model_doc/vit" rel="nofollow">ViT</a> en el dataset <a href="https://huggingface.co/datasets/food101" rel="nofollow">Food-101</a> para clasificar un alimento en una imagen.',ie,$,oe,Z,me,_,qe="Carga solo las primeras 5000 im치genes del dataset Food-101 de la biblioteca 游뱅 de Datasets ya que es bastante grande:",re,I,ce,x,Se="Divide el dataset en un train y un test set:",de,G,fe,W,Ae="A continuaci칩n, observa un ejemplo:",ue,z,ge,R,Le="El campo <code>image</code> contiene una imagen PIL, y cada <code>label</code> es un n칰mero entero que representa una clase. Crea un diccionario que asigne un nombre de label a un entero y viceversa. El mapeo ayudar치 al modelo a recuperar el nombre de label a partir del n칰mero de la misma:",Me,k,ye,Q,De="Ahora puedes convertir el n칰mero de label en un nombre de label para obtener m치s informaci칩n:",he,E,be,V,Pe="Cada clase de alimento - o label - corresponde a un n칰mero; <code>79</code> indica una costilla de primera en el ejemplo anterior.",Je,F,$e,B,Ke="Carga el image processor de ViT para procesar la imagen en un tensor:",Ue,Y,je,N,Oe='Aplica varias transformaciones de imagen al dataset para hacer el modelo m치s robusto contra el overfitting. En este caso se utilizar치 el m칩dulo <a href="https://pytorch.org/vision/stable/transforms.html" rel="nofollow"><code>transforms</code></a> de torchvision. Recorta una parte aleatoria de la imagen, cambia su tama침o y normal칤zala con la media y la desviaci칩n est치ndar de la imagen:',Te,X,we,H,ea="Crea una funci칩n de preprocesamiento que aplique las transformaciones y devuelva los <code>pixel_values</code> - los inputs al modelo - de la imagen:",Ce,q,ve,S,aa='Utiliza el m칠todo <a href="https://huggingface.co/docs/datasets/package_reference/main_classes?#datasets.Dataset.with_transform" rel="nofollow"><code>with_transform</code></a> de 游뱅 Dataset para aplicar las transformaciones sobre todo el dataset. Las transformaciones se aplican sobre la marcha cuando se carga un elemento del dataset:',Ze,A,_e,L,sa="Utiliza <code>DefaultDataCollator</code> para crear un batch de ejemplos. A diferencia de otros data collators en 游뱅 Transformers, el DefaultDataCollator no aplica un preprocesamiento adicional como el padding.",Ie,D,xe,P,Ge,K,ta="Carga ViT con <code>AutoModelForImageClassification</code>. Especifica el n칰mero de labels, y pasa al modelo el mapping entre el n칰mero de label y la clase de label:",We,O,ze,U,Re,ee,la="Al llegar a este punto, solo quedan tres pasos:",ke,ae,na="<li>Define tus hiperpar치metros de entrenamiento en <code>TrainingArguments</code>. Es importante que no elimines las columnas que no se utilicen, ya que esto har치 que desaparezca la columna <code>image</code>. Sin la columna <code>image</code> no puedes crear <code>pixel_values</code>. Establece <code>remove_unused_columns=False</code> para evitar este comportamiento.</li> <li>Pasa los training arguments al <code>Trainer</code> junto con el modelo, los datasets, tokenizer y data collator.</li> <li>Llama <code>train()</code> para hacer fine-tune de tu modelo.</li>",Qe,se,Ee,j,Ve,te,Fe;return T=new Be({props:{title:"Clasificaci칩n de im치genes",local:"clasificaci칩n-de-im치genes",headingTag:"h1"}}),w=new ya({props:{id:"tjAIM7BOYhw"}}),$=new Ye({props:{$$slots:{default:[ha]},$$scope:{ctx:J}}}),Z=new Be({props:{title:"Carga el dataset Food-101",local:"carga-el-dataset-food-101",headingTag:"h2"}}),I=new h({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZm9vZCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJmb29kMTAxJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiU1QiUzQTUwMDAlNUQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>food = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:5000]&quot;</span>)`,wrap:!1}}),G=new h({props:{code:"Zm9vZCUyMCUzRCUyMGZvb2QudHJhaW5fdGVzdF9zcGxpdCh0ZXN0X3NpemUlM0QwLjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>food = food.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),z=new h({props:{code:"Zm9vZCU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>food[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at <span class="hljs-number">0x7F52AFC8AC50</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">79</span>}`,wrap:!1}}),k=new h({props:{code:"bGFiZWxzJTIwJTNEJTIwZm9vZCU1QiUyMnRyYWluJTIyJTVELmZlYXR1cmVzJTVCJTIybGFiZWwlMjIlNUQubmFtZXMlMEFsYWJlbDJpZCUyQyUyMGlkMmxhYmVsJTIwJTNEJTIwZGljdCgpJTJDJTIwZGljdCgpJTBBZm9yJTIwaSUyQyUyMGxhYmVsJTIwaW4lMjBlbnVtZXJhdGUobGFiZWxzKSUzQSUwQSUyMCUyMCUyMCUyMGxhYmVsMmlkJTVCbGFiZWwlNUQlMjAlM0QlMjBzdHIoaSklMEElMjAlMjAlMjAlMjBpZDJsYWJlbCU1QnN0cihpKSU1RCUyMCUzRCUyMGxhYmVs",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = food[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;label&quot;</span>].names
<span class="hljs-meta">&gt;&gt;&gt; </span>label2id, id2label = <span class="hljs-built_in">dict</span>(), <span class="hljs-built_in">dict</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):
<span class="hljs-meta">... </span>    label2id[label] = <span class="hljs-built_in">str</span>(i)
<span class="hljs-meta">... </span>    id2label[<span class="hljs-built_in">str</span>(i)] = label`,wrap:!1}}),E=new h({props:{code:"aWQybGFiZWwlNUJzdHIoNzkpJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>id2label[<span class="hljs-built_in">str</span>(<span class="hljs-number">79</span>)]
<span class="hljs-string">&#x27;prime_rib&#x27;</span>`,wrap:!1}}),F=new Be({props:{title:"Preprocesa",local:"preprocesa",headingTag:"h2"}}),Y=new h({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGdml0LWJhc2UtcGF0Y2gxNi0yMjQtaW4yMWslMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>)`,wrap:!1}}),X=new h({props:{code:"ZnJvbSUyMHRvcmNodmlzaW9uLnRyYW5zZm9ybXMlMjBpbXBvcnQlMjBSYW5kb21SZXNpemVkQ3JvcCUyQyUyMENvbXBvc2UlMkMlMjBOb3JtYWxpemUlMkMlMjBUb1RlbnNvciUwQSUwQW5vcm1hbGl6ZSUyMCUzRCUyME5vcm1hbGl6ZShtZWFuJTNEaW1hZ2VfcHJvY2Vzc29yLmltYWdlX21lYW4lMkMlMjBzdGQlM0RpbWFnZV9wcm9jZXNzb3IuaW1hZ2Vfc3RkKSUwQV90cmFuc2Zvcm1zJTIwJTNEJTIwQ29tcG9zZSglNUJSYW5kb21SZXNpemVkQ3JvcChpbWFnZV9wcm9jZXNzb3Iuc2l6ZSU1QiUyMmhlaWdodCUyMiU1RCklMkMlMjBUb1RlbnNvcigpJTJDJTIwbm9ybWFsaXplJTVEKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> RandomResizedCrop, Compose, Normalize, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
<span class="hljs-meta">&gt;&gt;&gt; </span>_transforms = Compose([RandomResizedCrop(image_processor.size[<span class="hljs-string">&quot;height&quot;</span>]), ToTensor(), normalize])`,wrap:!1}}),q=new h({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1Ql90cmFuc2Zvcm1zKGltZy5jb252ZXJ0KCUyMlJHQiUyMikpJTIwZm9yJTIwaW1nJTIwaW4lMjBleGFtcGxlcyU1QiUyMmltYWdlJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwZGVsJTIwZXhhbXBsZXMlNUIlMjJpbWFnZSUyMiU1RCUwQSUyMCUyMCUyMCUyMHJldHVybiUyMGV4YW1wbGVz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [_transforms(img.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> img <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">del</span> examples[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`,wrap:!1}}),A=new h({props:{code:"Zm9vZCUyMCUzRCUyMGZvb2Qud2l0aF90cmFuc2Zvcm0odHJhbnNmb3Jtcyk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>food = food.with_transform(transforms)',wrap:!1}}),D=new h({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator()`,wrap:!1}}),P=new Be({props:{title:"Entrena",local:"entrena",headingTag:"h2"}}),O=new h({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24lMkMlMjBUcmFpbmluZ0FyZ3VtZW50cyUyQyUyMFRyYWluZXIlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMmdvb2dsZSUyRnZpdC1iYXNlLXBhdGNoMTYtMjI0LWluMjFrJTIyJTJDJTBBJTIwJTIwJTIwJTIwbnVtX2xhYmVscyUzRGxlbihsYWJlbHMpJTJDJTBBJTIwJTIwJTIwJTIwaWQybGFiZWwlM0RpZDJsYWJlbCUyQyUwQSUyMCUyMCUyMCUyMGxhYmVsMmlkJTNEbGFiZWwyaWQlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForImageClassification, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>,
<span class="hljs-meta">... </span>    num_labels=<span class="hljs-built_in">len</span>(labels),
<span class="hljs-meta">... </span>    id2label=id2label,
<span class="hljs-meta">... </span>    label2id=label2id,
<span class="hljs-meta">... </span>)`,wrap:!1}}),U=new Ye({props:{$$slots:{default:[ba]},$$scope:{ctx:J}}}),se=new h({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjIuJTJGcmVzdWx0cyUyMiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwZXZhbHVhdGlvbl9zdHJhdGVneSUzRCUyMnN0ZXBzJTIyJTJDJTBBJTIwJTIwJTIwJTIwbnVtX3RyYWluX2Vwb2NocyUzRDQlMkMlMEElMjAlMjAlMjAlMjBmcDE2JTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHNhdmVfc3RlcHMlM0QxMDAlMkMlMEElMjAlMjAlMjAlMjBldmFsX3N0ZXBzJTNEMTAwJTJDJTBBJTIwJTIwJTIwJTIwbG9nZ2luZ19zdGVwcyUzRDEwJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTQlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3RvdGFsX2xpbWl0JTNEMiUyQyUwQSUyMCUyMCUyMCUyMHJlbW92ZV91bnVzZWRfY29sdW1ucyUzREZhbHNlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMGRhdGFfY29sbGF0b3IlM0RkYXRhX2NvbGxhdG9yJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRGZvb2QlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfZGF0YXNldCUzRGZvb2QlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwdG9rZW5pemVyJTNEaW1hZ2VfcHJvY2Vzc29yJTJDJTBBKSUwQSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;./results&quot;</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    fp16=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    save_steps=<span class="hljs-number">100</span>,
<span class="hljs-meta">... </span>    eval_steps=<span class="hljs-number">100</span>,
<span class="hljs-meta">... </span>    logging_steps=<span class="hljs-number">10</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-4</span>,
<span class="hljs-meta">... </span>    save_total_limit=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>    remove_unused_columns=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>    train_dataset=food[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=food[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=image_processor,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),j=new Ye({props:{$$slots:{default:[Ja]},$$scope:{ctx:J}}}),{c(){p=o("meta"),y=l(),i=o("p"),b=l(),r(T.$$.fragment),le=l(),r(w.$$.fragment),ne=l(),C=o("p"),C.textContent=Xe,pe=l(),v=o("p"),v.innerHTML=He,ie=l(),r($.$$.fragment),oe=l(),r(Z.$$.fragment),me=l(),_=o("p"),_.textContent=qe,re=l(),r(I.$$.fragment),ce=l(),x=o("p"),x.textContent=Se,de=l(),r(G.$$.fragment),fe=l(),W=o("p"),W.textContent=Ae,ue=l(),r(z.$$.fragment),ge=l(),R=o("p"),R.innerHTML=Le,Me=l(),r(k.$$.fragment),ye=l(),Q=o("p"),Q.textContent=De,he=l(),r(E.$$.fragment),be=l(),V=o("p"),V.innerHTML=Pe,Je=l(),r(F.$$.fragment),$e=l(),B=o("p"),B.textContent=Ke,Ue=l(),r(Y.$$.fragment),je=l(),N=o("p"),N.innerHTML=Oe,Te=l(),r(X.$$.fragment),we=l(),H=o("p"),H.innerHTML=ea,Ce=l(),r(q.$$.fragment),ve=l(),S=o("p"),S.innerHTML=aa,Ze=l(),r(A.$$.fragment),_e=l(),L=o("p"),L.innerHTML=sa,Ie=l(),r(D.$$.fragment),xe=l(),r(P.$$.fragment),Ge=l(),K=o("p"),K.innerHTML=ta,We=l(),r(O.$$.fragment),ze=l(),r(U.$$.fragment),Re=l(),ee=o("p"),ee.textContent=la,ke=l(),ae=o("ol"),ae.innerHTML=na,Qe=l(),r(se.$$.fragment),Ee=l(),r(j.$$.fragment),Ve=l(),te=o("p"),this.h()},l(e){const a=ga("svelte-u9bgzb",document.head);p=m(a,"META",{name:!0,content:!0}),a.forEach(s),y=n(e),i=m(e,"P",{}),ma(i).forEach(s),b=n(e),c(T.$$.fragment,e),le=n(e),c(w.$$.fragment,e),ne=n(e),C=m(e,"P",{"data-svelte-h":!0}),M(C)!=="svelte-1in2i61"&&(C.textContent=Xe),pe=n(e),v=m(e,"P",{"data-svelte-h":!0}),M(v)!=="svelte-16asmdu"&&(v.innerHTML=He),ie=n(e),c($.$$.fragment,e),oe=n(e),c(Z.$$.fragment,e),me=n(e),_=m(e,"P",{"data-svelte-h":!0}),M(_)!=="svelte-1i4xr2v"&&(_.textContent=qe),re=n(e),c(I.$$.fragment,e),ce=n(e),x=m(e,"P",{"data-svelte-h":!0}),M(x)!=="svelte-welj5e"&&(x.textContent=Se),de=n(e),c(G.$$.fragment,e),fe=n(e),W=m(e,"P",{"data-svelte-h":!0}),M(W)!=="svelte-1ccba5i"&&(W.textContent=Ae),ue=n(e),c(z.$$.fragment,e),ge=n(e),R=m(e,"P",{"data-svelte-h":!0}),M(R)!=="svelte-1cy1r9x"&&(R.innerHTML=Le),Me=n(e),c(k.$$.fragment,e),ye=n(e),Q=m(e,"P",{"data-svelte-h":!0}),M(Q)!=="svelte-dj6pq1"&&(Q.textContent=De),he=n(e),c(E.$$.fragment,e),be=n(e),V=m(e,"P",{"data-svelte-h":!0}),M(V)!=="svelte-1enyby9"&&(V.innerHTML=Pe),Je=n(e),c(F.$$.fragment,e),$e=n(e),B=m(e,"P",{"data-svelte-h":!0}),M(B)!=="svelte-b7wzno"&&(B.textContent=Ke),Ue=n(e),c(Y.$$.fragment,e),je=n(e),N=m(e,"P",{"data-svelte-h":!0}),M(N)!=="svelte-oh33tg"&&(N.innerHTML=Oe),Te=n(e),c(X.$$.fragment,e),we=n(e),H=m(e,"P",{"data-svelte-h":!0}),M(H)!=="svelte-1tpprs0"&&(H.innerHTML=ea),Ce=n(e),c(q.$$.fragment,e),ve=n(e),S=m(e,"P",{"data-svelte-h":!0}),M(S)!=="svelte-838aua"&&(S.innerHTML=aa),Ze=n(e),c(A.$$.fragment,e),_e=n(e),L=m(e,"P",{"data-svelte-h":!0}),M(L)!=="svelte-1qktm8g"&&(L.innerHTML=sa),Ie=n(e),c(D.$$.fragment,e),xe=n(e),c(P.$$.fragment,e),Ge=n(e),K=m(e,"P",{"data-svelte-h":!0}),M(K)!=="svelte-1lx22e"&&(K.innerHTML=ta),We=n(e),c(O.$$.fragment,e),ze=n(e),c(U.$$.fragment,e),Re=n(e),ee=m(e,"P",{"data-svelte-h":!0}),M(ee)!=="svelte-yip3uv"&&(ee.textContent=la),ke=n(e),ae=m(e,"OL",{"data-svelte-h":!0}),M(ae)!=="svelte-2mt88g"&&(ae.innerHTML=na),Qe=n(e),c(se.$$.fragment,e),Ee=n(e),c(j.$$.fragment,e),Ve=n(e),te=m(e,"P",{}),ma(te).forEach(s),this.h()},h(){ra(p,"name","hf:doc:metadata"),ra(p,"content",Ua)},m(e,a){Ma(document.head,p),t(e,y,a),t(e,i,a),t(e,b,a),d(T,e,a),t(e,le,a),d(w,e,a),t(e,ne,a),t(e,C,a),t(e,pe,a),t(e,v,a),t(e,ie,a),d($,e,a),t(e,oe,a),d(Z,e,a),t(e,me,a),t(e,_,a),t(e,re,a),d(I,e,a),t(e,ce,a),t(e,x,a),t(e,de,a),d(G,e,a),t(e,fe,a),t(e,W,a),t(e,ue,a),d(z,e,a),t(e,ge,a),t(e,R,a),t(e,Me,a),d(k,e,a),t(e,ye,a),t(e,Q,a),t(e,he,a),d(E,e,a),t(e,be,a),t(e,V,a),t(e,Je,a),d(F,e,a),t(e,$e,a),t(e,B,a),t(e,Ue,a),d(Y,e,a),t(e,je,a),t(e,N,a),t(e,Te,a),d(X,e,a),t(e,we,a),t(e,H,a),t(e,Ce,a),d(q,e,a),t(e,ve,a),t(e,S,a),t(e,Ze,a),d(A,e,a),t(e,_e,a),t(e,L,a),t(e,Ie,a),d(D,e,a),t(e,xe,a),d(P,e,a),t(e,Ge,a),t(e,K,a),t(e,We,a),d(O,e,a),t(e,ze,a),d(U,e,a),t(e,Re,a),t(e,ee,a),t(e,ke,a),t(e,ae,a),t(e,Qe,a),d(se,e,a),t(e,Ee,a),d(j,e,a),t(e,Ve,a),t(e,te,a),Fe=!0},p(e,[a]){const pa={};a&2&&(pa.$$scope={dirty:a,ctx:e}),$.$set(pa);const ia={};a&2&&(ia.$$scope={dirty:a,ctx:e}),U.$set(ia);const oa={};a&2&&(oa.$$scope={dirty:a,ctx:e}),j.$set(oa)},i(e){Fe||(f(T.$$.fragment,e),f(w.$$.fragment,e),f($.$$.fragment,e),f(Z.$$.fragment,e),f(I.$$.fragment,e),f(G.$$.fragment,e),f(z.$$.fragment,e),f(k.$$.fragment,e),f(E.$$.fragment,e),f(F.$$.fragment,e),f(Y.$$.fragment,e),f(X.$$.fragment,e),f(q.$$.fragment,e),f(A.$$.fragment,e),f(D.$$.fragment,e),f(P.$$.fragment,e),f(O.$$.fragment,e),f(U.$$.fragment,e),f(se.$$.fragment,e),f(j.$$.fragment,e),Fe=!0)},o(e){u(T.$$.fragment,e),u(w.$$.fragment,e),u($.$$.fragment,e),u(Z.$$.fragment,e),u(I.$$.fragment,e),u(G.$$.fragment,e),u(z.$$.fragment,e),u(k.$$.fragment,e),u(E.$$.fragment,e),u(F.$$.fragment,e),u(Y.$$.fragment,e),u(X.$$.fragment,e),u(q.$$.fragment,e),u(A.$$.fragment,e),u(D.$$.fragment,e),u(P.$$.fragment,e),u(O.$$.fragment,e),u(U.$$.fragment,e),u(se.$$.fragment,e),u(j.$$.fragment,e),Fe=!1},d(e){e&&(s(y),s(i),s(b),s(le),s(ne),s(C),s(pe),s(v),s(ie),s(oe),s(me),s(_),s(re),s(ce),s(x),s(de),s(fe),s(W),s(ue),s(ge),s(R),s(Me),s(ye),s(Q),s(he),s(be),s(V),s(Je),s($e),s(B),s(Ue),s(je),s(N),s(Te),s(we),s(H),s(Ce),s(ve),s(S),s(Ze),s(_e),s(L),s(Ie),s(xe),s(Ge),s(K),s(We),s(ze),s(Re),s(ee),s(ke),s(ae),s(Qe),s(Ee),s(Ve),s(te)),s(p),g(T,e),g(w,e),g($,e),g(Z,e),g(I,e),g(G,e),g(z,e),g(k,e),g(E,e),g(F,e),g(Y,e),g(X,e),g(q,e),g(A,e),g(D,e),g(P,e),g(O,e),g(U,e),g(se,e),g(j,e)}}}const Ua='{"title":"Clasificaci칩n de im치genes","local":"clasificaci칩n-de-im치genes","sections":[{"title":"Carga el dataset Food-101","local":"carga-el-dataset-food-101","sections":[],"depth":2},{"title":"Preprocesa","local":"preprocesa","sections":[],"depth":2},{"title":"Entrena","local":"entrena","sections":[],"depth":2}],"depth":1}';function ja(J){return da(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ia extends fa{constructor(p){super(),ua(this,p,ja,$a,ca,{})}}export{Ia as component};
