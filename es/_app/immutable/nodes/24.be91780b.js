import{s as Qs,o as Ps,n as R}from"../chunks/scheduler.36a0863c.js";import{S as Ss,i as Ds,g as j,s as i,r as f,A as Ks,h as w,f as n,c,j as As,u as $,x as T,k as Ns,y as Os,a as l,v as g,d as b,t as h,w as M,m as ea,n as ta}from"../chunks/index.f891bdb2.js";import{T as Ee}from"../chunks/Tip.a8272f7f.js";import{Y as Es}from"../chunks/Youtube.0cbacd3d.js";import{C as U}from"../chunks/CodeBlock.3ec784ea.js";import{D as sa}from"../chunks/DocNotebookDropdown.81c1f0fb.js";import{F as Ne,M as z}from"../chunks/Markdown.4127c891.js";import{H as Q}from"../chunks/Heading.3fb90772.js";function aa(y){let s,o=`Todos los ejemplos de c√≥digo presentados en la documentaci√≥n tienen un bot√≥n arriba a la derecha para elegir si quieres ocultar o mostrar el c√≥digo en Pytorch o TensorFlow.
Si no fuese as√≠, se espera que el c√≥digo funcione para ambos backends sin ning√∫n cambio.`;return{c(){s=j("p"),s.textContent=o},l(t){s=w(t,"P",{"data-svelte-h":!0}),T(s)!=="svelte-ubzhvb"&&(s.textContent=o)},m(t,r){l(t,s,r)},p:R,d(t){t&&n(s)}}}function na(y){let s,o='Para m√°s detalles acerca del <code>pipeline()</code> y tareas asociadas, consulta la documentaci√≥n <a href="./main_classes/pipelines">aqu√≠</a>.';return{c(){s=j("p"),s.innerHTML=o},l(t){s=w(t,"P",{"data-svelte-h":!0}),T(s)!=="svelte-8qvcir"&&(s.innerHTML=o)},m(t,r){l(t,s,r)},p:R,d(t){t&&n(s)}}}function la(y){let s,o;return s=new U({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRvcmNo",highlighted:"pip install torch",wrap:!1}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p:R,i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function ra(y){let s,o;return s=new z({props:{$$slots:{default:[la]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function oa(y){let s,o;return s=new U({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRlbnNvcmZsb3c=",highlighted:"pip install tensorflow",wrap:!1}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p:R,i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function pa(y){let s,o;return s=new z({props:{$$slots:{default:[oa]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function ia(y){let s,o="Usa <code>AutoModelForSequenceClassification</code> y [‚ÄòAutoTokenizer‚Äô] para cargar un modelo preentrenado y un tokenizador asociado (m√°s en un <code>AutoClass</code> debajo):",t,r,m;return r=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=o,t=i(),f(r.$$.fragment)},l(d){s=w(d,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1ww6j0w"&&(s.innerHTML=o),t=c(d),$(r.$$.fragment,d)},m(d,k){l(d,s,k),l(d,t,k),g(r,d,k),m=!0},p:R,i(d){m||(b(r.$$.fragment,d),m=!0)},o(d){h(r.$$.fragment,d),m=!1},d(d){d&&(n(s),n(t)),M(r,d)}}}function ca(y){let s,o;return s=new z({props:{$$slots:{default:[ia]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function ma(y){let s,o="Usa <code>TFAutoModelForSequenceClassification</code> y [‚ÄòAutoTokenizer‚Äô] para cargar un modelo preentrenado y un tokenizador asociado (m√°s en un <code>TFAutoClass</code> debajo):",t,r,m;return r=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQobW9kZWxfbmFtZSklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=o,t=i(),f(r.$$.fragment)},l(d){s=w(d,"P",{"data-svelte-h":!0}),T(s)!=="svelte-q5tubc"&&(s.innerHTML=o),t=c(d),$(r.$$.fragment,d)},m(d,k){l(d,s,k),l(d,t,k),g(r,d,k),m=!0},p:R,i(d){m||(b(r.$$.fragment,d),m=!0)},o(d){h(r.$$.fragment,d),m=!1},d(d){d&&(n(s),n(t)),M(r,d)}}}function ua(y){let s,o;return s=new z({props:{$$slots:{default:[ma]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function da(y){let s,o;return s=new U({props:{code:"cHRfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p:R,i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function fa(y){let s,o;return s=new z({props:{$$slots:{default:[da]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function $a(y){let s,o;return s=new U({props:{code:"dGZfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the ü§ó Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p:R,i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function ga(y){let s,o;return s=new z({props:{$$slots:{default:[$a]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function ba(y){let s,o='Ve el <a href="./task_summary">task summary</a> para revisar qu√© clase del <code>AutoModel</code> deber√≠as usar para cada tarea.';return{c(){s=j("p"),s.innerHTML=o},l(t){s=w(t,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1v9xsb6"&&(s.innerHTML=o)},m(t,r){l(t,s,r)},p:R,d(t){t&&n(s)}}}function ha(y){let s,o="ü§ó Transformers provee una forma simple y unificada de cargar tus instancias preentrenadas. Esto significa que puedes cargar un <code>AutoModel</code> como cargar√≠as un <code>AutoTokenizer</code>. La √∫nica diferencia es seleccionar el <code>AutoModel</code> correcto para la tarea. Ya que est√°s clasificando texto, o secuencias, carga <code>AutoModelForSequenceClassification</code>:",t,r,m,d,k,J,Z="Ahora puedes pasar tu lote (batch) preprocesado de inputs directamente al modelo. Solo tienes que desempacar el diccionario a√±adiendo <code>**</code>:",x,u,v,W,H="El modelo producir√° las activaciones finales en el atributo <code>logits</code>. Aplica la funci√≥n softmax a <code>logits</code> para obtener las probabilidades:",G,C,V;return r=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEFwdF9tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),d=new Ee({props:{$$slots:{default:[ba]},$$scope:{ctx:y}}}),u=new U({props:{code:"cHRfb3V0cHV0cyUyMCUzRCUyMHB0X21vZGVsKCoqcHRfYmF0Y2gp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)',wrap:!1}}),C=new U({props:{code:"ZnJvbSUyMHRvcmNoJTIwaW1wb3J0JTIwbm4lMEElMEFwdF9wcmVkaWN0aW9ucyUyMCUzRCUyMG5uLmZ1bmN0aW9uYWwuc29mdG1heChwdF9vdXRwdXRzLmxvZ2l0cyUyQyUyMGRpbSUzRC0xKSUwQXByaW50KHB0X3ByZWRpY3Rpb25zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=o,t=i(),f(r.$$.fragment),m=i(),f(d.$$.fragment),k=i(),J=j("p"),J.innerHTML=Z,x=i(),f(u.$$.fragment),v=i(),W=j("p"),W.innerHTML=H,G=i(),f(C.$$.fragment)},l(p){s=w(p,"P",{"data-svelte-h":!0}),T(s)!=="svelte-8sxnf5"&&(s.innerHTML=o),t=c(p),$(r.$$.fragment,p),m=c(p),$(d.$$.fragment,p),k=c(p),J=w(p,"P",{"data-svelte-h":!0}),T(J)!=="svelte-wyf0m2"&&(J.innerHTML=Z),x=c(p),$(u.$$.fragment,p),v=c(p),W=w(p,"P",{"data-svelte-h":!0}),T(W)!=="svelte-90e2r5"&&(W.innerHTML=H),G=c(p),$(C.$$.fragment,p)},m(p,_){l(p,s,_),l(p,t,_),g(r,p,_),l(p,m,_),g(d,p,_),l(p,k,_),l(p,J,_),l(p,x,_),g(u,p,_),l(p,v,_),l(p,W,_),l(p,G,_),g(C,p,_),V=!0},p(p,_){const q={};_&2&&(q.$$scope={dirty:_,ctx:p}),d.$set(q)},i(p){V||(b(r.$$.fragment,p),b(d.$$.fragment,p),b(u.$$.fragment,p),b(C.$$.fragment,p),V=!0)},o(p){h(r.$$.fragment,p),h(d.$$.fragment,p),h(u.$$.fragment,p),h(C.$$.fragment,p),V=!1},d(p){p&&(n(s),n(t),n(m),n(k),n(J),n(x),n(v),n(W),n(G)),M(r,p),M(d,p),M(u,p),M(C,p)}}}function Ma(y){let s,o;return s=new z({props:{$$slots:{default:[ha]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function ya(y){let s;return{c(){s=ea("Ve el [task summary](./task_summary) para revisar qu√© clase del `AutoModel`\n  deber√≠as usar para cada tarea.")},l(o){s=ta(o,"Ve el [task summary](./task_summary) para revisar qu√© clase del `AutoModel`\n  deber√≠as usar para cada tarea.")},m(o,t){l(o,s,t)},d(o){o&&n(s)}}}function ja(y){let s,o="ü§ó Transformers provee una forma simple y unificada de cargar tus instancias preentrenadas. Esto significa que puedes cargar un <code>TFAutoModel</code> como cargar√≠as un <code>AutoTokenizer</code>. La √∫nica diferencia es seleccionar el <code>TFAutoModel</code> correcto para la tarea. Ya que est√°s clasificando texto, o secuencias, carga <code>TFAutoModelForSequenceClassification</code>:",t,r,m,d,k,J,Z="Ahora puedes pasar tu lote preprocesado de inputs directamente al modelo pasando las llaves del diccionario directamente a los tensores:",x,u,v,W,H="El modelo producir√° las activaciones finales en el atributo <code>logits</code>. Aplica la funci√≥n softmax a <code>logits</code> para obtener las probabilidades:",G,C,V;return r=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsX25hbWUlMjAlM0QlMjAlMjJubHB0b3duJTJGYmVydC1iYXNlLW11bHRpbGluZ3VhbC11bmNhc2VkLXNlbnRpbWVudCUyMiUwQXRmX21vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),d=new Ee({props:{$$slots:{default:[ya]},$$scope:{ctx:y}}}),u=new U({props:{code:"dGZfb3V0cHV0cyUyMCUzRCUyMHRmX21vZGVsKHRmX2JhdGNoKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)',wrap:!1}}),C=new U({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9wcmVkaWN0aW9ucyUyMCUzRCUyMHRmLm5uLnNvZnRtYXgodGZfb3V0cHV0cy5sb2dpdHMlMkMlMjBheGlzJTNELTEpJTBBcHJpbnQodGYubWF0aC5yb3VuZCh0Zl9wcmVkaWN0aW9ucyUyMColMjAxMCoqNCklMjAlMkYlMjAxMCoqNCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tf.math.<span class="hljs-built_in">round</span>(tf_predictions * <span class="hljs-number">10</span>**<span class="hljs-number">4</span>) / <span class="hljs-number">10</span>**<span class="hljs-number">4</span>)
tf.Tensor(
[[<span class="hljs-number">0.0021</span> <span class="hljs-number">0.0018</span> <span class="hljs-number">0.0116</span> <span class="hljs-number">0.2121</span> <span class="hljs-number">0.7725</span>]
 [<span class="hljs-number">0.2084</span> <span class="hljs-number">0.1826</span> <span class="hljs-number">0.1969</span> <span class="hljs-number">0.1755</span>  <span class="hljs-number">0.2365</span>]], shape=(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>), dtype=float32)`,wrap:!1}}),{c(){s=j("p"),s.innerHTML=o,t=i(),f(r.$$.fragment),m=i(),f(d.$$.fragment),k=i(),J=j("p"),J.textContent=Z,x=i(),f(u.$$.fragment),v=i(),W=j("p"),W.innerHTML=H,G=i(),f(C.$$.fragment)},l(p){s=w(p,"P",{"data-svelte-h":!0}),T(s)!=="svelte-a5lo33"&&(s.innerHTML=o),t=c(p),$(r.$$.fragment,p),m=c(p),$(d.$$.fragment,p),k=c(p),J=w(p,"P",{"data-svelte-h":!0}),T(J)!=="svelte-1xsw1lh"&&(J.textContent=Z),x=c(p),$(u.$$.fragment,p),v=c(p),W=w(p,"P",{"data-svelte-h":!0}),T(W)!=="svelte-90e2r5"&&(W.innerHTML=H),G=c(p),$(C.$$.fragment,p)},m(p,_){l(p,s,_),l(p,t,_),g(r,p,_),l(p,m,_),g(d,p,_),l(p,k,_),l(p,J,_),l(p,x,_),g(u,p,_),l(p,v,_),l(p,W,_),l(p,G,_),g(C,p,_),V=!0},p(p,_){const q={};_&2&&(q.$$scope={dirty:_,ctx:p}),d.$set(q)},i(p){V||(b(r.$$.fragment,p),b(d.$$.fragment,p),b(u.$$.fragment,p),b(C.$$.fragment,p),V=!0)},o(p){h(r.$$.fragment,p),h(d.$$.fragment,p),h(u.$$.fragment,p),h(C.$$.fragment,p),V=!1},d(p){p&&(n(s),n(t),n(m),n(k),n(J),n(x),n(v),n(W),n(G)),M(r,p),M(d,p),M(u,p),M(C,p)}}}function wa(y){let s,o;return s=new z({props:{$$slots:{default:[ja]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function Ta(y){let s,o=`Todos los modelos de ü§ó Transformers (PyTorch o TensorFlow) producir√°n los tensores <em>antes</em> de la funci√≥n de activaci√≥n
final (como softmax) porque la funci√≥n de activaci√≥n final es com√∫nmente fusionada con la p√©rdida.`;return{c(){s=j("p"),s.innerHTML=o},l(t){s=w(t,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1yx0z3s"&&(s.innerHTML=o)},m(t,r){l(t,s,r)},p:R,d(t){t&&n(s)}}}function _a(y){let s,o=`Los outputs del modelo de ü§ó Transformers son dataclasses especiales por lo que sus atributos pueden ser completados en un IDE.
Los outputs del modelo tambi√©n se comportan como tuplas o diccionarios (e.g., puedes indexar con un entero, un slice o una cadena) en cuyo caso los atributos que son <code>None</code> son ignorados.`;return{c(){s=j("p"),s.innerHTML=o},l(t){s=w(t,"P",{"data-svelte-h":!0}),T(s)!=="svelte-ts28l"&&(s.innerHTML=o)},m(t,r){l(t,s,r)},p:R,d(t){t&&n(s)}}}function va(y){let s,o="Una vez que se haya hecho fine-tuning a tu modelo puedes guardarlo con tu tokenizador usando <code>PreTrainedModel.save_pretrained()</code>:",t,r,m,d,k="Cuando quieras usar el modelo otra vez c√°rgalo con <code>PreTrainedModel.from_pretrained()</code>:",J,Z,x;return r=new U({props:{code:"cHRfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZChwdF9zYXZlX2RpcmVjdG9yeSklMEFwdF9tb2RlbC5zYXZlX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`,wrap:!1}}),Z=new U({props:{code:"cHRfbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)',wrap:!1}}),{c(){s=j("p"),s.innerHTML=o,t=i(),f(r.$$.fragment),m=i(),d=j("p"),d.innerHTML=k,J=i(),f(Z.$$.fragment)},l(u){s=w(u,"P",{"data-svelte-h":!0}),T(s)!=="svelte-n61427"&&(s.innerHTML=o),t=c(u),$(r.$$.fragment,u),m=c(u),d=w(u,"P",{"data-svelte-h":!0}),T(d)!=="svelte-1hxci0c"&&(d.innerHTML=k),J=c(u),$(Z.$$.fragment,u)},m(u,v){l(u,s,v),l(u,t,v),g(r,u,v),l(u,m,v),l(u,d,v),l(u,J,v),g(Z,u,v),x=!0},p:R,i(u){x||(b(r.$$.fragment,u),b(Z.$$.fragment,u),x=!0)},o(u){h(r.$$.fragment,u),h(Z.$$.fragment,u),x=!1},d(u){u&&(n(s),n(t),n(m),n(d),n(J)),M(r,u),M(Z,u)}}}function ka(y){let s,o;return s=new z({props:{$$slots:{default:[va]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function Ja(y){let s,o="Una vez que se haya hecho fine-tuning a tu modelo puedes guardarlo con tu tokenizador usando <code>TFPreTrainedModel.save_pretrained()</code>:",t,r,m,d,k="Cuando quieras usar el modelo otra vez c√°rgalo con <code>TFPreTrainedModel.from_pretrained()</code>:",J,Z,x;return r=new U({props:{code:"dGZfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGdGZfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZCh0Zl9zYXZlX2RpcmVjdG9yeSklMEF0Zl9tb2RlbC5zYXZlX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`,wrap:!1}}),Z=new U({props:{code:"dGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMi4lMkZ0Zl9zYXZlX3ByZXRyYWluZWQlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)',wrap:!1}}),{c(){s=j("p"),s.innerHTML=o,t=i(),f(r.$$.fragment),m=i(),d=j("p"),d.innerHTML=k,J=i(),f(Z.$$.fragment)},l(u){s=w(u,"P",{"data-svelte-h":!0}),T(s)!=="svelte-v1iapp"&&(s.innerHTML=o),t=c(u),$(r.$$.fragment,u),m=c(u),d=w(u,"P",{"data-svelte-h":!0}),T(d)!=="svelte-1wvriwm"&&(d.innerHTML=k),J=c(u),$(Z.$$.fragment,u)},m(u,v){l(u,s,v),l(u,t,v),g(r,u,v),l(u,m,v),l(u,d,v),l(u,J,v),g(Z,u,v),x=!0},p:R,i(u){x||(b(r.$$.fragment,u),b(Z.$$.fragment,u),x=!0)},o(u){h(r.$$.fragment,u),h(Z.$$.fragment,u),x=!1},d(u){u&&(n(s),n(t),n(m),n(d),n(J)),M(r,u),M(Z,u)}}}function Za(y){let s,o;return s=new z({props:{$$slots:{default:[Ja]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function Ua(y){let s,o;return s=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKHRmX3NhdmVfZGlyZWN0b3J5KSUwQXB0X21vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3RvcnklMkMlMjBmcm9tX3RmJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p:R,i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function Ca(y){let s,o;return s=new z({props:{$$slots:{default:[Ua]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function xa(y){let s,o;return s=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3RvcnkpJTBBdGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKHB0X3NhdmVfZGlyZWN0b3J5JTJDJTIwZnJvbV9wdCUzRFRydWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p:R,i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function Wa(y){let s,o;return s=new z({props:{$$slots:{default:[xa]},$$scope:{ctx:y}}}),{c(){f(s.$$.fragment)},l(t){$(s.$$.fragment,t)},m(t,r){g(s,t,r),o=!0},p(t,r){const m={};r&2&&(m.$$scope={dirty:r,ctx:t}),s.$set(m)},i(t){o||(b(s.$$.fragment,t),o=!0)},o(t){h(s.$$.fragment,t),o=!1},d(t){M(s,t)}}}function Ra(y){let s,o,t,r,m,d,k,J,Z,x='¬°Entra en marcha con los ü§ó Transformers! Comienza usando <code>pipeline()</code> para una inferencia veloz, carga un modelo preentrenado y un tokenizador con una <a href="./model_doc/auto">AutoClass</a> para resolver tu tarea de texto, visi√≥n o audio.',u,v,W,H,G,C,V="<code>pipeline()</code> es la forma m√°s f√°cil de usar un modelo preentrenado para una tarea dada.",p,_,q,P,ss="El <code>pipeline()</code> soporta muchas tareas comunes listas para usar:",Pe,S,as="<strong>Texto</strong>:",Se,D,ns="<li>An√°lisis de Sentimiento (Sentiment Analysis, en ingl√©s): clasifica la polaridad de un texto dado.</li> <li>Generaci√≥n de Texto (Text Generation, en ingl√©s): genera texto a partir de un input dado.</li> <li>Reconocimiento de Entidades (Name Entity Recognition o NER, en ingl√©s): etiqueta cada palabra con la entidad que representa (persona, fecha, ubicaci√≥n, etc.).</li> <li>Responder Preguntas (Question answering, en ingl√©s): extrae la respuesta del contexto dado un contexto y una pregunta.</li> <li>Rellenar M√°scara (Fill-mask, en ingl√©s): rellena el espacio faltante dado un texto con palabras enmascaradas.</li> <li>Resumir (Summarization, en ingl√©s): genera un resumen de una secuencia larga de texto o un documento.</li> <li>Traducci√≥n (Translation, en ingl√©s): traduce un texto a otro idioma.</li> <li>Extracci√≥n de Caracter√≠sticas (Feature Extraction, en ingl√©s): crea una representaci√≥n tensorial del texto.</li>",De,K,ls="<strong>Imagen</strong>:",Ke,O,rs="<li>Clasificaci√≥n de Im√°genes (Image Classification, en ingl√©s): clasifica una imagen.</li> <li>Segmentaci√≥n de Im√°genes (Image Segmentation, en ingl√©s): clasifica cada pixel de una imagen.</li> <li>Detecci√≥n de Objetos (Object Detection, en ingl√©s): detecta objetos dentro de una imagen.</li>",Oe,ee,os="<strong>Audio</strong>:",et,te,ps="<li>Clasificaci√≥n de Audios (Audio Classification, en ingl√©s): asigna una etiqueta a un segmento de audio.</li> <li>Reconocimiento de Voz Autom√°tico (Automatic Speech Recognition o ASR, en ingl√©s): transcribe datos de audio a un texto.</li>",tt,F,st,se,at,ae,is="En el siguiente ejemplo, usar√°s el <code>pipeline()</code> para an√°lisis de sentimiento.",nt,ne,cs="Instala las siguientes dependencias si a√∫n no lo has hecho:",lt,X,rt,le,ms="Importa <code>pipeline()</code> y especifica la tarea que deseas completar:",ot,re,pt,oe,us='El pipeline descarga y almacena en cach√© el <a href="https://huggingface.co/pysentimiento/robertuito-sentiment-analysis" rel="nofollow">modelo preentrenado</a> y tokeniza para an√°lisis de sentimiento. Si no hubieramos elegido un modelo el pipeline habr√≠a elegido uno por defecto. Ahora puedes usar <code>clasificador</code> en tu texto objetivo:',it,pe,ct,ie,ds="Para m√°s de un enunciado, entrega una lista al <code>pipeline()</code> que devolver√° una lista de diccionarios:",mt,ce,fs='El <code>pipeline()</code> tambi√©n puede iterar sobre un dataset entero. Comienza instalando la biblioteca <a href="https://huggingface.co/docs/datasets/" rel="nofollow">ü§ó Datasets</a>:',ut,me,dt,ue,$s="Crea un <code>pipeline()</code> con la tarea que deseas resolver y el modelo que quieres usar. Coloca el par√°metro <code>device</code> a <code>0</code> para poner los tensores en un dispositivo CUDA:",ft,de,$t,fe,gs='A continuaci√≥n, carga el dataset (ve ü§ó Datasets <a href="https://huggingface.co/docs/datasets/quickstart.html" rel="nofollow">Quick Start</a> para m√°s detalles) sobre el que quisieras iterar. Por ejemplo, vamos a cargar el dataset <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a>:',gt,$e,bt,ge,bs="Debemos asegurarnos de que la frecuencia de muestreo del conjunto de datos coincide con la frecuencia de muestreo con la que se entren√≥ <code>jonatasgrosman/wav2vec2-large-xlsr-53-spanish</code>.",ht,be,Mt,he,hs=`Los archivos de audio se cargan y remuestrean autom√°ticamente cuando llamamos a la columna <code>&quot;audio&quot;</code>.
Extraigamos las matrices de onda cruda (raw waveform, en ingl√©s) de las primeras 4 muestras y pas√©mosla como una lista al pipeline:`,yt,Me,jt,ye,Ms='Para un dataset m√°s grande, donde los inputs son de mayor tama√±o (como en habla/audio o visi√≥n), querr√°s pasar un generador en lugar de una lista que carga todos los inputs en memoria. Ve la <a href="./main_classes/pipelines">documentaci√≥n del pipeline</a> para m√°s informaci√≥n.',wt,je,Tt,we,ys='El <code>pipeline()</code> puede acomodarse a cualquier modelo del <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a> haciendo m√°s f√°cil adaptar el <code>pipeline()</code> para otros casos de uso. Por ejemplo, si quisieras un modelo capaz de manejar texto en franc√©s, usa los tags en el Model Hub para filtrar entre los modelos apropiados. El resultado mejor filtrado devuelve un <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment" rel="nofollow">modelo BERT</a> multilingual fine-tuned para el an√°lisis de sentimiento. Genial, ¬°vamos a usar este modelo!',_t,Te,vt,L,kt,_e,js="Despu√©s puedes especificar el modelo y el tokenizador en el <code>pipeline()</code>, y aplicar el <code>classifier</code> en tu texto objetivo:",Jt,ve,Zt,ke,ws='Si no pudieras encontrar el modelo para tu caso respectivo de uso necesitar√°s ajustar un modelo preentrenado a tus datos. Mira nuestro <a href="./training">tutorial de fine-tuning</a> para aprender c√≥mo. Finalmente, despu√©s de que has ajustado tu modelo preentrenado, ¬°por favor considera compartirlo (ve el tutorial <a href="./model_sharing">aqu√≠</a>) con la comunidad en el Model Hub para democratizar el NLP! ü§ó',Ut,Je,Ct,Ze,xt,Ue,Ts='Por debajo, las clases <code>AutoModelForSequenceClassification</code> y <code>AutoTokenizer</code> trabajan juntas para dar poder al <code>pipeline()</code>. Una <a href="./model_doc/auto">AutoClass</a> es un atajo que autom√°ticamente recupera la arquitectura de un modelo preentrenado con su nombre o el path. S√≥lo necesitar√°s seleccionar el <code>AutoClass</code> apropiado para tu tarea y tu tokenizador asociado con <code>AutoTokenizer</code>.',Wt,Ce,_s="Regresemos a nuestro ejemplo y veamos c√≥mo puedes usar el <code>AutoClass</code> para reproducir los resultados del <code>pipeline()</code>.",Rt,xe,Gt,We,vs='Un tokenizador es responsable de procesar el texto a un formato que sea entendible para el modelo. Primero, el tokenizador separar√° el texto en palabras llamadas <em>tokens</em>. Hay m√∫ltiples reglas que gobiernan el proceso de tokenizaci√≥n incluyendo el c√≥mo separar una palabra y en qu√© nivel (aprende m√°s sobre tokenizaci√≥n <a href="./tokenizer_summary">aqu√≠</a>). Lo m√°s importante es recordar que necesitar√°s instanciar el tokenizador con el mismo nombre del modelo para asegurar que est√°s usando las mismas reglas de tokenizaci√≥n con las que el modelo fue preentrenado.',Ht,Re,ks="Carga un tokenizador con <code>AutoTokenizer</code>:",Vt,Ge,zt,He,Js="Despu√©s, el tokenizador convierte los tokens a n√∫meros para construir un tensor que servir√° como input para el modelo. Esto es conocido como el <em>vocabulario</em> del modelo.",qt,Ve,Zs="Pasa tu texto al tokenizador:",Ft,ze,Xt,qe,Us="El tokenizador devolver√° un diccionario conteniendo:",Lt,Fe,Cs='<li><a href="./glossary#input-ids">input_ids</a>: representaciones num√©ricas de los tokens.</li> <li><a href=".glossary#attention-mask">atttention_mask</a>: indica cu√°les tokens deben ser atendidos.</li>',It,Xe,xs="Como con el <code>pipeline()</code>, el tokenizador aceptar√° una lista de inputs. Adem√°s, el tokenizador tambi√©n puede rellenar (pad, en ingl√©s) y truncar el texto para devolver un lote (batch, en ingl√©s) de longitud uniforme:",Bt,I,Yt,Le,Ws='Lee el tutorial de <a href="./preprocessing">preprocessing</a> para m√°s detalles acerca de la tokenizaci√≥n.',At,Ie,Nt,B,Et,Y,Qt,Be,Rs='Los modelos son <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow"><code>torch.nn.Module</code></a> o <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow"><code>tf.keras.Model</code></a> est√°ndares as√≠ que podr√°s usarlos en tu training loop usual. Sin embargo, para facilitar las cosas, ü§ó Transformers provee una clase <code>Trainer</code> para PyTorch que a√±ade funcionalidades para entrenamiento distribuido, precici√≥n mixta, y m√°s. Para TensorFlow, puedes usar el m√©todo <code>fit</code> desde <a href="https://keras.io/" rel="nofollow">Keras</a>. Consulta el <a href="./training">tutorial de entrenamiento</a> para m√°s detalles.',Pt,A,St,Ye,Dt,N,Kt,Ae,Gs="Una caracter√≠stica particularmente interesante de ü§ó Transformers es la habilidad de guardar el modelo y cargarlo como un modelo de PyTorch o TensorFlow. El par√°metro <code>from_pt</code> o <code>from_tf</code> puede convertir el modelo de un framework al otro:",Ot,E,es,Qe,ts;return m=new Q({props:{title:"Tour r√°pido",local:"tour-r√°pido",headingTag:"h1"}}),k=new sa({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/quicktour.ipynb"}]}}),v=new Ee({props:{$$slots:{default:[aa]},$$scope:{ctx:y}}}),H=new Q({props:{title:"Pipeline",local:"pipeline",headingTag:"h2"}}),_=new Es({props:{id:"tiZFewofSLM"}}),F=new Ee({props:{$$slots:{default:[na]},$$scope:{ctx:y}}}),se=new Q({props:{title:"Uso del Pipeline",local:"uso-del-pipeline",headingTag:"h3"}}),X=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pa],pytorch:[ra]},$$scope:{ctx:y}}}),re=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc2lmaWNhZG9yJTIwJTNEJTIwcGlwZWxpbmUoJTIyc2VudGltZW50LWFuYWx5c2lzJTIyJTJDJTIwbW9kZWwlM0QlMjJweXNlbnRpbWllbnRvJTJGcm9iZXJ0dWl0by1zZW50aW1lbnQtYW5hbHlzaXMlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>clasificador = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=<span class="hljs-string">&quot;pysentimiento/robertuito-sentiment-analysis&quot;</span>)`,wrap:!1}}),pe=new U({props:{code:"Y2xhc2lmaWNhZG9yKCUyMkVzdGFtb3MlMjBtdXklMjBmZWxpY2VzJTIwZGUlMjBtb3N0cmFydGUlMjBsYSUyMGJpYmxpb3RlY2ElMjBkZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>clasificador(<span class="hljs-string">&quot;Estamos muy felices de mostrarte la biblioteca de ü§ó Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POS&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9320</span>}]`,wrap:!1}}),me=new U({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRz",highlighted:"pip install datasets",wrap:!1}}),de=new U({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwcGlwZWxpbmUlMEElMEFyZWNvbm9jZWRvcl9kZV92b3olMjAlM0QlMjBwaXBlbGluZSglMEElMjAlMjAlMjAlMjAlMjJhdXRvbWF0aWMtc3BlZWNoLXJlY29nbml0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJqb25hdGFzZ3Jvc21hbiUyRndhdjJ2ZWMyLWxhcmdlLXhsc3ItNTMtc3BhbmlzaCUyMiUyQyUyMGRldmljZSUzRDAlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>reconocedor_de_voz = pipeline(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;jonatasgrosman/wav2vec2-large-xlsr-53-spanish&quot;</span>, device=<span class="hljs-number">0</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),$e=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjBuYW1lJTNEJTIyZXMtRVMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;es-ES&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),be=new U({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEcmVjb25vY2Vkb3JfZGVfdm96LmZlYXR1cmVfZXh0cmFjdG9yLnNhbXBsaW5nX3JhdGUpKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=reconocedor_de_voz.feature_extractor.sampling_rate))',wrap:!1}}),Me=new U({props:{code:"cmVzdWx0YWRvJTIwJTNEJTIwcmVjb25vY2Vkb3JfZGVfdm96KGRhdGFzZXQlNUIlM0E0JTVEJTVCJTIyYXVkaW8lMjIlNUQpJTBBcHJpbnQoJTVCZCU1QiUyMnRleHQlMjIlNUQlMjBmb3IlMjBkJTIwaW4lMjByZXN1bHRhZG8lNUQp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>resultado = reconocedor_de_voz(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> resultado])
[<span class="hljs-string">&#x27;ahora buenas eh a ver tengo un problema con vuestra aplicaci√≥n resulta que que quiero hacer una transferencia bancaria a una cuenta conocida pero me da error la aplicaci√≥n a ver que a ver que puede ser&#x27;</span>, <span class="hljs-string">&#x27;la aplicaci√≥n no cargue saldo de mi nueva cuenta&#x27;</span>, <span class="hljs-string">&#x27;hola tengo un problema con la aplicaci√≥n no carga y y tampoco veo que carga el saldo de mi cuenta nueva dice que la aplicaci√≥n est√° siendo reparada y ahora no puedo acceder a mi cuenta no necesito inmediatamente&#x27;</span>, <span class="hljs-string">&#x27;hora buena la aplicaci√≥n no se carga la vida no carga el saldo de mi cuenta nueva dice que la villadenta siendo reparada y oro no puedo hacer a mi cuenta&#x27;</span>]`,wrap:!1}}),je=new Q({props:{title:"Usa otro modelo y otro tokenizador en el pipeline",local:"usa-otro-modelo-y-otro-tokenizador-en-el-pipeline",headingTag:"h3"}}),Te=new U({props:{code:"bW9kZWxfbmFtZSUyMCUzRCUyMCUyMm5scHRvd24lMkZiZXJ0LWJhc2UtbXVsdGlsaW5ndWFsLXVuY2FzZWQtc2VudGltZW50JTIy",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>',wrap:!1}}),L=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ua],pytorch:[ca]},$$scope:{ctx:y}}}),ve=new U({props:{code:"Y2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnNlbnRpbWVudC1hbmFseXNpcyUyMiUyQyUyMG1vZGVsJTNEbW9kZWwlMkMlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIpJTBBY2xhc3NpZmllciglMjJOb3VzJTIwc29tbWVzJTIwdHIlQzMlQThzJTIwaGV1cmV1eCUyMGRlJTIwdm91cyUyMHByJUMzJUE5c2VudGVyJTIwbGElMjBiaWJsaW90aCVDMyVBOHF1ZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes tr√®s heureux de vous pr√©senter la biblioth√®que ü§ó Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`,wrap:!1}}),Je=new Q({props:{title:"AutoClass",local:"autoclass",headingTag:"h2"}}),Ze=new Es({props:{id:"AhChOFRegn4"}}),xe=new Q({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h3"}}),Ge=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEFub21icmVfZGVsX21vZGVsbyUyMCUzRCUyMCUyMm5scHRvd24lMkZiZXJ0LWJhc2UtbXVsdGlsaW5ndWFsLXVuY2FzZWQtc2VudGltZW50JTIyJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQobm9tYnJlX2RlbF9tb2RlbG8p",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>nombre_del_modelo = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(nombre_del_modelo)`,wrap:!1}}),ze=new U({props:{code:"ZW5jb2RpbmclMjAlM0QlMjB0b2tlbml6ZXIoJTIyRXN0YW1vcyUyMG11eSUyMGZlbGljZXMlMjBkZSUyMG1vc3RyYXJ0ZSUyMGxhJTIwYmlibGlvdGVjYSUyMGRlJTIwJUYwJTlGJUE0JTk3JTIwVHJhbnNmb3JtZXJzLiUyMiklMEFwcmludChlbmNvZGluZyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;Estamos muy felices de mostrarte la biblioteca de ü§ó Transformers.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">10602</span>, <span class="hljs-number">14000</span>, <span class="hljs-number">13653</span>, <span class="hljs-number">43353</span>, <span class="hljs-number">10107</span>, <span class="hljs-number">10102</span>, <span class="hljs-number">47201</span>, <span class="hljs-number">10218</span>, <span class="hljs-number">10106</span>, <span class="hljs-number">18283</span>, <span class="hljs-number">10102</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),I=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ga],pytorch:[fa]},$$scope:{ctx:y}}}),Ie=new Q({props:{title:"AutoModel",local:"automodel",headingTag:"h3"}}),B=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[wa],pytorch:[Ma]},$$scope:{ctx:y}}}),Y=new Ee({props:{$$slots:{default:[Ta]},$$scope:{ctx:y}}}),A=new Ee({props:{$$slots:{default:[_a]},$$scope:{ctx:y}}}),Ye=new Q({props:{title:"Guarda un modelo",local:"guarda-un-modelo",headingTag:"h3"}}),N=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Za],pytorch:[ka]},$$scope:{ctx:y}}}),E=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Wa],pytorch:[Ca]},$$scope:{ctx:y}}}),{c(){s=j("meta"),o=i(),t=j("p"),r=i(),f(m.$$.fragment),d=i(),f(k.$$.fragment),J=i(),Z=j("p"),Z.innerHTML=x,u=i(),f(v.$$.fragment),W=i(),f(H.$$.fragment),G=i(),C=j("p"),C.innerHTML=V,p=i(),f(_.$$.fragment),q=i(),P=j("p"),P.innerHTML=ss,Pe=i(),S=j("p"),S.innerHTML=as,Se=i(),D=j("ul"),D.innerHTML=ns,De=i(),K=j("p"),K.innerHTML=ls,Ke=i(),O=j("ul"),O.innerHTML=rs,Oe=i(),ee=j("p"),ee.innerHTML=os,et=i(),te=j("ul"),te.innerHTML=ps,tt=i(),f(F.$$.fragment),st=i(),f(se.$$.fragment),at=i(),ae=j("p"),ae.innerHTML=is,nt=i(),ne=j("p"),ne.textContent=cs,lt=i(),f(X.$$.fragment),rt=i(),le=j("p"),le.innerHTML=ms,ot=i(),f(re.$$.fragment),pt=i(),oe=j("p"),oe.innerHTML=us,it=i(),f(pe.$$.fragment),ct=i(),ie=j("p"),ie.innerHTML=ds,mt=i(),ce=j("p"),ce.innerHTML=fs,ut=i(),f(me.$$.fragment),dt=i(),ue=j("p"),ue.innerHTML=$s,ft=i(),f(de.$$.fragment),$t=i(),fe=j("p"),fe.innerHTML=gs,gt=i(),f($e.$$.fragment),bt=i(),ge=j("p"),ge.innerHTML=bs,ht=i(),f(be.$$.fragment),Mt=i(),he=j("p"),he.innerHTML=hs,yt=i(),f(Me.$$.fragment),jt=i(),ye=j("p"),ye.innerHTML=Ms,wt=i(),f(je.$$.fragment),Tt=i(),we=j("p"),we.innerHTML=ys,_t=i(),f(Te.$$.fragment),vt=i(),f(L.$$.fragment),kt=i(),_e=j("p"),_e.innerHTML=js,Jt=i(),f(ve.$$.fragment),Zt=i(),ke=j("p"),ke.innerHTML=ws,Ut=i(),f(Je.$$.fragment),Ct=i(),f(Ze.$$.fragment),xt=i(),Ue=j("p"),Ue.innerHTML=Ts,Wt=i(),Ce=j("p"),Ce.innerHTML=_s,Rt=i(),f(xe.$$.fragment),Gt=i(),We=j("p"),We.innerHTML=vs,Ht=i(),Re=j("p"),Re.innerHTML=ks,Vt=i(),f(Ge.$$.fragment),zt=i(),He=j("p"),He.innerHTML=Js,qt=i(),Ve=j("p"),Ve.textContent=Zs,Ft=i(),f(ze.$$.fragment),Xt=i(),qe=j("p"),qe.textContent=Us,Lt=i(),Fe=j("ul"),Fe.innerHTML=Cs,It=i(),Xe=j("p"),Xe.innerHTML=xs,Bt=i(),f(I.$$.fragment),Yt=i(),Le=j("p"),Le.innerHTML=Ws,At=i(),f(Ie.$$.fragment),Nt=i(),f(B.$$.fragment),Et=i(),f(Y.$$.fragment),Qt=i(),Be=j("p"),Be.innerHTML=Rs,Pt=i(),f(A.$$.fragment),St=i(),f(Ye.$$.fragment),Dt=i(),f(N.$$.fragment),Kt=i(),Ae=j("p"),Ae.innerHTML=Gs,Ot=i(),f(E.$$.fragment),es=i(),Qe=j("p"),this.h()},l(e){const a=Ks("svelte-u9bgzb",document.head);s=w(a,"META",{name:!0,content:!0}),a.forEach(n),o=c(e),t=w(e,"P",{}),As(t).forEach(n),r=c(e),$(m.$$.fragment,e),d=c(e),$(k.$$.fragment,e),J=c(e),Z=w(e,"P",{"data-svelte-h":!0}),T(Z)!=="svelte-13nw4gz"&&(Z.innerHTML=x),u=c(e),$(v.$$.fragment,e),W=c(e),$(H.$$.fragment,e),G=c(e),C=w(e,"P",{"data-svelte-h":!0}),T(C)!=="svelte-ewfhnr"&&(C.innerHTML=V),p=c(e),$(_.$$.fragment,e),q=c(e),P=w(e,"P",{"data-svelte-h":!0}),T(P)!=="svelte-1jqphav"&&(P.innerHTML=ss),Pe=c(e),S=w(e,"P",{"data-svelte-h":!0}),T(S)!=="svelte-17b5j97"&&(S.innerHTML=as),Se=c(e),D=w(e,"UL",{"data-svelte-h":!0}),T(D)!=="svelte-6ta65g"&&(D.innerHTML=ns),De=c(e),K=w(e,"P",{"data-svelte-h":!0}),T(K)!=="svelte-rb8iw8"&&(K.innerHTML=ls),Ke=c(e),O=w(e,"UL",{"data-svelte-h":!0}),T(O)!=="svelte-1v0wd43"&&(O.innerHTML=rs),Oe=c(e),ee=w(e,"P",{"data-svelte-h":!0}),T(ee)!=="svelte-hdckv1"&&(ee.innerHTML=os),et=c(e),te=w(e,"UL",{"data-svelte-h":!0}),T(te)!=="svelte-1pkh8rq"&&(te.innerHTML=ps),tt=c(e),$(F.$$.fragment,e),st=c(e),$(se.$$.fragment,e),at=c(e),ae=w(e,"P",{"data-svelte-h":!0}),T(ae)!=="svelte-1fv0ej7"&&(ae.innerHTML=is),nt=c(e),ne=w(e,"P",{"data-svelte-h":!0}),T(ne)!=="svelte-oumdq9"&&(ne.textContent=cs),lt=c(e),$(X.$$.fragment,e),rt=c(e),le=w(e,"P",{"data-svelte-h":!0}),T(le)!=="svelte-ssbliq"&&(le.innerHTML=ms),ot=c(e),$(re.$$.fragment,e),pt=c(e),oe=w(e,"P",{"data-svelte-h":!0}),T(oe)!=="svelte-y0jlde"&&(oe.innerHTML=us),it=c(e),$(pe.$$.fragment,e),ct=c(e),ie=w(e,"P",{"data-svelte-h":!0}),T(ie)!=="svelte-ibp4nf"&&(ie.innerHTML=ds),mt=c(e),ce=w(e,"P",{"data-svelte-h":!0}),T(ce)!=="svelte-1kffnl1"&&(ce.innerHTML=fs),ut=c(e),$(me.$$.fragment,e),dt=c(e),ue=w(e,"P",{"data-svelte-h":!0}),T(ue)!=="svelte-b3hx8j"&&(ue.innerHTML=$s),ft=c(e),$(de.$$.fragment,e),$t=c(e),fe=w(e,"P",{"data-svelte-h":!0}),T(fe)!=="svelte-4yp267"&&(fe.innerHTML=gs),gt=c(e),$($e.$$.fragment,e),bt=c(e),ge=w(e,"P",{"data-svelte-h":!0}),T(ge)!=="svelte-atu66e"&&(ge.innerHTML=bs),ht=c(e),$(be.$$.fragment,e),Mt=c(e),he=w(e,"P",{"data-svelte-h":!0}),T(he)!=="svelte-1mkx8ug"&&(he.innerHTML=hs),yt=c(e),$(Me.$$.fragment,e),jt=c(e),ye=w(e,"P",{"data-svelte-h":!0}),T(ye)!=="svelte-9lshw6"&&(ye.innerHTML=Ms),wt=c(e),$(je.$$.fragment,e),Tt=c(e),we=w(e,"P",{"data-svelte-h":!0}),T(we)!=="svelte-zgc2l2"&&(we.innerHTML=ys),_t=c(e),$(Te.$$.fragment,e),vt=c(e),$(L.$$.fragment,e),kt=c(e),_e=w(e,"P",{"data-svelte-h":!0}),T(_e)!=="svelte-1ryc7vk"&&(_e.innerHTML=js),Jt=c(e),$(ve.$$.fragment,e),Zt=c(e),ke=w(e,"P",{"data-svelte-h":!0}),T(ke)!=="svelte-avcnwa"&&(ke.innerHTML=ws),Ut=c(e),$(Je.$$.fragment,e),Ct=c(e),$(Ze.$$.fragment,e),xt=c(e),Ue=w(e,"P",{"data-svelte-h":!0}),T(Ue)!=="svelte-68o3at"&&(Ue.innerHTML=Ts),Wt=c(e),Ce=w(e,"P",{"data-svelte-h":!0}),T(Ce)!=="svelte-16bhkd5"&&(Ce.innerHTML=_s),Rt=c(e),$(xe.$$.fragment,e),Gt=c(e),We=w(e,"P",{"data-svelte-h":!0}),T(We)!=="svelte-i7oto7"&&(We.innerHTML=vs),Ht=c(e),Re=w(e,"P",{"data-svelte-h":!0}),T(Re)!=="svelte-oqza3o"&&(Re.innerHTML=ks),Vt=c(e),$(Ge.$$.fragment,e),zt=c(e),He=w(e,"P",{"data-svelte-h":!0}),T(He)!=="svelte-1cjxkf4"&&(He.innerHTML=Js),qt=c(e),Ve=w(e,"P",{"data-svelte-h":!0}),T(Ve)!=="svelte-1ae5dy5"&&(Ve.textContent=Zs),Ft=c(e),$(ze.$$.fragment,e),Xt=c(e),qe=w(e,"P",{"data-svelte-h":!0}),T(qe)!=="svelte-1el9s0a"&&(qe.textContent=Us),Lt=c(e),Fe=w(e,"UL",{"data-svelte-h":!0}),T(Fe)!=="svelte-19f0evt"&&(Fe.innerHTML=Cs),It=c(e),Xe=w(e,"P",{"data-svelte-h":!0}),T(Xe)!=="svelte-1oclrls"&&(Xe.innerHTML=xs),Bt=c(e),$(I.$$.fragment,e),Yt=c(e),Le=w(e,"P",{"data-svelte-h":!0}),T(Le)!=="svelte-15ybisq"&&(Le.innerHTML=Ws),At=c(e),$(Ie.$$.fragment,e),Nt=c(e),$(B.$$.fragment,e),Et=c(e),$(Y.$$.fragment,e),Qt=c(e),Be=w(e,"P",{"data-svelte-h":!0}),T(Be)!=="svelte-nmhxq5"&&(Be.innerHTML=Rs),Pt=c(e),$(A.$$.fragment,e),St=c(e),$(Ye.$$.fragment,e),Dt=c(e),$(N.$$.fragment,e),Kt=c(e),Ae=w(e,"P",{"data-svelte-h":!0}),T(Ae)!=="svelte-17keh5w"&&(Ae.innerHTML=Gs),Ot=c(e),$(E.$$.fragment,e),es=c(e),Qe=w(e,"P",{}),As(Qe).forEach(n),this.h()},h(){Ns(s,"name","hf:doc:metadata"),Ns(s,"content",Ga)},m(e,a){Os(document.head,s),l(e,o,a),l(e,t,a),l(e,r,a),g(m,e,a),l(e,d,a),g(k,e,a),l(e,J,a),l(e,Z,a),l(e,u,a),g(v,e,a),l(e,W,a),g(H,e,a),l(e,G,a),l(e,C,a),l(e,p,a),g(_,e,a),l(e,q,a),l(e,P,a),l(e,Pe,a),l(e,S,a),l(e,Se,a),l(e,D,a),l(e,De,a),l(e,K,a),l(e,Ke,a),l(e,O,a),l(e,Oe,a),l(e,ee,a),l(e,et,a),l(e,te,a),l(e,tt,a),g(F,e,a),l(e,st,a),g(se,e,a),l(e,at,a),l(e,ae,a),l(e,nt,a),l(e,ne,a),l(e,lt,a),g(X,e,a),l(e,rt,a),l(e,le,a),l(e,ot,a),g(re,e,a),l(e,pt,a),l(e,oe,a),l(e,it,a),g(pe,e,a),l(e,ct,a),l(e,ie,a),l(e,mt,a),l(e,ce,a),l(e,ut,a),g(me,e,a),l(e,dt,a),l(e,ue,a),l(e,ft,a),g(de,e,a),l(e,$t,a),l(e,fe,a),l(e,gt,a),g($e,e,a),l(e,bt,a),l(e,ge,a),l(e,ht,a),g(be,e,a),l(e,Mt,a),l(e,he,a),l(e,yt,a),g(Me,e,a),l(e,jt,a),l(e,ye,a),l(e,wt,a),g(je,e,a),l(e,Tt,a),l(e,we,a),l(e,_t,a),g(Te,e,a),l(e,vt,a),g(L,e,a),l(e,kt,a),l(e,_e,a),l(e,Jt,a),g(ve,e,a),l(e,Zt,a),l(e,ke,a),l(e,Ut,a),g(Je,e,a),l(e,Ct,a),g(Ze,e,a),l(e,xt,a),l(e,Ue,a),l(e,Wt,a),l(e,Ce,a),l(e,Rt,a),g(xe,e,a),l(e,Gt,a),l(e,We,a),l(e,Ht,a),l(e,Re,a),l(e,Vt,a),g(Ge,e,a),l(e,zt,a),l(e,He,a),l(e,qt,a),l(e,Ve,a),l(e,Ft,a),g(ze,e,a),l(e,Xt,a),l(e,qe,a),l(e,Lt,a),l(e,Fe,a),l(e,It,a),l(e,Xe,a),l(e,Bt,a),g(I,e,a),l(e,Yt,a),l(e,Le,a),l(e,At,a),g(Ie,e,a),l(e,Nt,a),g(B,e,a),l(e,Et,a),g(Y,e,a),l(e,Qt,a),l(e,Be,a),l(e,Pt,a),g(A,e,a),l(e,St,a),g(Ye,e,a),l(e,Dt,a),g(N,e,a),l(e,Kt,a),l(e,Ae,a),l(e,Ot,a),g(E,e,a),l(e,es,a),l(e,Qe,a),ts=!0},p(e,[a]){const Hs={};a&2&&(Hs.$$scope={dirty:a,ctx:e}),v.$set(Hs);const Vs={};a&2&&(Vs.$$scope={dirty:a,ctx:e}),F.$set(Vs);const zs={};a&2&&(zs.$$scope={dirty:a,ctx:e}),X.$set(zs);const qs={};a&2&&(qs.$$scope={dirty:a,ctx:e}),L.$set(qs);const Fs={};a&2&&(Fs.$$scope={dirty:a,ctx:e}),I.$set(Fs);const Xs={};a&2&&(Xs.$$scope={dirty:a,ctx:e}),B.$set(Xs);const Ls={};a&2&&(Ls.$$scope={dirty:a,ctx:e}),Y.$set(Ls);const Is={};a&2&&(Is.$$scope={dirty:a,ctx:e}),A.$set(Is);const Bs={};a&2&&(Bs.$$scope={dirty:a,ctx:e}),N.$set(Bs);const Ys={};a&2&&(Ys.$$scope={dirty:a,ctx:e}),E.$set(Ys)},i(e){ts||(b(m.$$.fragment,e),b(k.$$.fragment,e),b(v.$$.fragment,e),b(H.$$.fragment,e),b(_.$$.fragment,e),b(F.$$.fragment,e),b(se.$$.fragment,e),b(X.$$.fragment,e),b(re.$$.fragment,e),b(pe.$$.fragment,e),b(me.$$.fragment,e),b(de.$$.fragment,e),b($e.$$.fragment,e),b(be.$$.fragment,e),b(Me.$$.fragment,e),b(je.$$.fragment,e),b(Te.$$.fragment,e),b(L.$$.fragment,e),b(ve.$$.fragment,e),b(Je.$$.fragment,e),b(Ze.$$.fragment,e),b(xe.$$.fragment,e),b(Ge.$$.fragment,e),b(ze.$$.fragment,e),b(I.$$.fragment,e),b(Ie.$$.fragment,e),b(B.$$.fragment,e),b(Y.$$.fragment,e),b(A.$$.fragment,e),b(Ye.$$.fragment,e),b(N.$$.fragment,e),b(E.$$.fragment,e),ts=!0)},o(e){h(m.$$.fragment,e),h(k.$$.fragment,e),h(v.$$.fragment,e),h(H.$$.fragment,e),h(_.$$.fragment,e),h(F.$$.fragment,e),h(se.$$.fragment,e),h(X.$$.fragment,e),h(re.$$.fragment,e),h(pe.$$.fragment,e),h(me.$$.fragment,e),h(de.$$.fragment,e),h($e.$$.fragment,e),h(be.$$.fragment,e),h(Me.$$.fragment,e),h(je.$$.fragment,e),h(Te.$$.fragment,e),h(L.$$.fragment,e),h(ve.$$.fragment,e),h(Je.$$.fragment,e),h(Ze.$$.fragment,e),h(xe.$$.fragment,e),h(Ge.$$.fragment,e),h(ze.$$.fragment,e),h(I.$$.fragment,e),h(Ie.$$.fragment,e),h(B.$$.fragment,e),h(Y.$$.fragment,e),h(A.$$.fragment,e),h(Ye.$$.fragment,e),h(N.$$.fragment,e),h(E.$$.fragment,e),ts=!1},d(e){e&&(n(o),n(t),n(r),n(d),n(J),n(Z),n(u),n(W),n(G),n(C),n(p),n(q),n(P),n(Pe),n(S),n(Se),n(D),n(De),n(K),n(Ke),n(O),n(Oe),n(ee),n(et),n(te),n(tt),n(st),n(at),n(ae),n(nt),n(ne),n(lt),n(rt),n(le),n(ot),n(pt),n(oe),n(it),n(ct),n(ie),n(mt),n(ce),n(ut),n(dt),n(ue),n(ft),n($t),n(fe),n(gt),n(bt),n(ge),n(ht),n(Mt),n(he),n(yt),n(jt),n(ye),n(wt),n(Tt),n(we),n(_t),n(vt),n(kt),n(_e),n(Jt),n(Zt),n(ke),n(Ut),n(Ct),n(xt),n(Ue),n(Wt),n(Ce),n(Rt),n(Gt),n(We),n(Ht),n(Re),n(Vt),n(zt),n(He),n(qt),n(Ve),n(Ft),n(Xt),n(qe),n(Lt),n(Fe),n(It),n(Xe),n(Bt),n(Yt),n(Le),n(At),n(Nt),n(Et),n(Qt),n(Be),n(Pt),n(St),n(Dt),n(Kt),n(Ae),n(Ot),n(es),n(Qe)),n(s),M(m,e),M(k,e),M(v,e),M(H,e),M(_,e),M(F,e),M(se,e),M(X,e),M(re,e),M(pe,e),M(me,e),M(de,e),M($e,e),M(be,e),M(Me,e),M(je,e),M(Te,e),M(L,e),M(ve,e),M(Je,e),M(Ze,e),M(xe,e),M(Ge,e),M(ze,e),M(I,e),M(Ie,e),M(B,e),M(Y,e),M(A,e),M(Ye,e),M(N,e),M(E,e)}}}const Ga='{"title":"Tour r√°pido","local":"tour-r√°pido","sections":[{"title":"Pipeline","local":"pipeline","sections":[{"title":"Uso del Pipeline","local":"uso-del-pipeline","sections":[],"depth":3},{"title":"Usa otro modelo y otro tokenizador en el pipeline","local":"usa-otro-modelo-y-otro-tokenizador-en-el-pipeline","sections":[],"depth":3}],"depth":2},{"title":"AutoClass","local":"autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":3},{"title":"AutoModel","local":"automodel","sections":[],"depth":3},{"title":"Guarda un modelo","local":"guarda-un-modelo","sections":[],"depth":3}],"depth":2}],"depth":1}';function Ha(y){return Ps(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ya extends Ss{constructor(s){super(),Ds(this,s,Ha,Ra,Qs,{})}}export{Ya as component};
