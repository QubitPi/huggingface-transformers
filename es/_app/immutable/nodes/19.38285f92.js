import{s as Ua,f as Os,n as za,o as Ia}from"../chunks/scheduler.36a0863c.js";import{S as Ca,i as Ga,g as p,s as n,r as L,m as o,H as v,A as Za,h as i,f as e,c as l,j as K,u as S,x as u,n as r,B as w,k as h,y as m,a as t,v as F,d as N,t as Y,w as A}from"../chunks/index.f891bdb2.js";import{C as sa}from"../chunks/CodeBlock.3ec784ea.js";import{D as qa}from"../chunks/DocNotebookDropdown.81c1f0fb.js";import{H as aa}from"../chunks/Heading.3fb90772.js";function Ba(ea){let b,as,O,es,_,ts,j,ns,k,ta='La perplejidad, perplexity en ingl√©s (PPL), es una de las m√©tricas m√°s comunes para evaluar modelos de lenguaje. Antes de sumergirnos, debemos tener en cuenta que esta m√©trica se aplica espec√≠ficamente a modelos de lenguaje cl√°sicos (a veces llamados modelos autorregresivos o causales) y no est√° bien definida para modelos de lenguaje enmascarados como BERT (ver <a href="model_summary">resumen del modelo</a>).',ls,g,Ns,ps,wa='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>‚Ä¶</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X = (x_0, x_1, \\dots, x_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">‚Ä¶</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>',is,ms,ba='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi></mrow><annotation encoding="application/x-tex">X</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span></span></span></span>',os,rs,fa='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>PPL</mtext><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>‚Å°</mo><mrow><mo fence="true">{</mo><mrow><mo>‚àí</mo><mfrac><mn>1</mn><mi>t</mi></mfrac><munderover><mo>‚àë</mo><mi>i</mi><mi>t</mi></munderover><mi>log</mi><mo>‚Å°</mo><msub><mi>p</mi><mi>Œ∏</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">‚à£</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">\\text{PPL}(X) = \\exp \\left\\{ {-\\frac{1}{t}\\sum_i^t \\log p_\\theta (x_i|x_{&lt;i}) } \\right\\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">PPL</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0582em;vertical-align:-1.2777em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mord">‚àí</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7806em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">‚àë</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">Œ∏</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">‚à£</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">}</span></span></span></span></span></span></span>',cs,y,Ys,ds,Ma='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>‚Å°</mo><msub><mi>p</mi><mi>Œ∏</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">‚à£</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\\log p_\\theta (x_i|x_{&lt;i})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">Œ∏</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">‚à£</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>',us,hs,xa='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{&lt;i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span>',gs,ys,U,na='Esto tambi√©n es equivalente a la exponenciaci√≥n de la entrop√≠a cruzada entre los datos y las predicciones del modelo. Para obtener m√°s intuici√≥n sobre la perplejidad y su relaci√≥n con los Bits Por Car√°cter (BPC) y la compresi√≥n de datos, echa un vistazo a esta <a href="https://thegradient.pub/understanding-evaluation-metrics-for-language-models/" rel="nofollow">fant√°stica publicaci√≥n en el blog de ‚ÄúThe Gradient‚Äù</a>.',vs,z,ws,I,la="Si no estuvi√©ramos limitados por el tama√±o del contexto de un modelo, evaluar√≠amos la perplejidad (PPL) del modelo auto regresivamente factorizando una secuencia y condicion√°ndonos en toda la subsecuencia precedente en cada paso, como se muestra a continuaci√≥n.",bs,f,pa,fs,c,As,C,ia="GPT-2",Ds,Ms,Ta='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>Œ∏</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant="normal">‚à£</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\\theta(x_t|x_{&lt;t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">Œ∏</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">‚à£</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>',xs,Ts,Ja='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span>',Js,_s,d,Ks,js,_a='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>',ks,Us,ja='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">‚Äã</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>',zs,Is,ka='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>‚àí</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">‚àí</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>',Cs,Gs,M,ma,Zs,G,oa="Esto es r√°pido de calcular, ya que la perplejidad de cada segmento se puede calcular en un solo pase hacia adelante, pero sirve como una aproximaci√≥n pobre de la perplejidad completamente factorizada y generalmente dar√° como resultado una PPL m√°s alta (peor) porque el modelo tendr√° menos contexto en la mayor√≠a de los pasos de predicci√≥n.",qs,Z,ra="En cambio, la PPL de modelos de longitud fija deber√≠a evaluarse con una estrategia de ventana deslizante. Esto implica deslizar repetidamente la ventana de contexto para que el modelo tenga m√°s contexto al hacer cada predicci√≥n.",Bs,x,ca,Es,q,da=`Esta es una aproximaci√≥n m√°s cercana a la verdadera descomposici√≥n de la probabilidad de la secuencia y generalmente dar√° como resultado una puntuaci√≥n m√°s favorable. La desventaja es que requiere un pase hacia adelante separado para cada token en el corpus. Un buen compromiso pr√°ctico es emplear una ventana deslizante estratificada, moviendo el contexto con pasos m√°s grandes en lugar de deslizarse de 1 token a la vez. Esto permite que la computaci√≥n avance mucho m√°s r√°pido, mientras le da al modelo un contexto amplio para hacer
predicciones en cada paso.`,Ps,B,$s,E,ua="Demostremos este proceso con GPT-2.",Ws,P,Xs,$,ha="Carguemos el conjunto de datos WikiText-2 y evaluemos la perplejidad utilizando algunas estrategias de ventana deslizante diferentes. Dado que este conjunto de datos es peque√±o y solo estamos realizando un pase hacia adelante sobre el conjunto, podemos cargar y codificar todo el conjunto de datos en la memoria.",Rs,W,Vs,X,ga="Con ü§ó Transformers, simplemente podemos pasar los <code>input_ids</code> como las <code>labels</code> a nuestro modelo, y la media negativa del log-likelihood para cada token se devuelve como la p√©rdida. Sin embargo, con nuestro enfoque de ventana deslizante, hay superposici√≥n en los tokens que pasamos al modelo en cada iteraci√≥n. No queremos que el log-likelihood de los tokens que estamos tratando solo como contexto se incluya en nuestra p√©rdida, por lo que podemos establecer estos objetivos en <code>-100</code> para que se ignoren. El siguiente es un ejemplo de c√≥mo podr√≠amos hacer esto con un paso de <code>512</code>. Esto significa que el modelo tendr√° al menos <code>512</code> tokens como contexto al calcular el log-likelihood condicional de cualquier token (siempre que haya <code>512</code> tokens precedentes disponibles para condicionar).",Hs,R,Qs,V,ya=`Ejecuta esto con la longitud de paso igual a la longitud m√°xima de entrada es equivalente a la estrategia sub √≥ptima,
sin ventana deslizante, que discutimos anteriormente. Cuanto menor sea el paso, m√°s contexto tendr√° el modelo para
realizar cada predicci√≥n y, por lo general, mejor ser√° la perplejidad informada.`,Ls,H,va=`Cuando ejecutamos lo anterior con <code>stride = 1024</code>, es decir, sin superposici√≥n, la PPL resultante es <code>19.44</code>, que es
aproximadamente la misma que la <code>19.93</code> informada en el art√≠culo de GPT-2. Al utilizar <code>stride = 512</code> y, por lo tanto,
emplear nuestra estrategia de ventana deslizante, esto disminuye a <code>16.45</code>. Esto no solo es una puntuaci√≥n m√°s favorable, sino que se calcula de una manera m√°s cercana a la verdadera descomposici√≥n autorregresiva de la probabilidad de una secuencia.`,Ss,ss,Fs;return _=new aa({props:{title:"Perplejidad de los modelos de longitud fija",local:"perplejidad-de-los-modelos-de-longitud-fija",headingTag:"h1"}}),j=new qa({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/perplexity.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/perplexity.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/perplexity.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/perplexity.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/pytorch/perplexity.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/es/tensorflow/perplexity.ipynb"}]}}),z=new aa({props:{title:"C√°lculo de PPL con modelos de longitud fija",local:"c√°lculo-de-ppl-con-modelos-de-longitud-fija",headingTag:"h2"}}),B=new aa({props:{title:"Ejemplo: C√°lculo de la perplejidad con GPT-2 en ü§ó Transformers",local:"ejemplo-c√°lculo-de-la-perplejidad-con-gpt-2-en--transformers",headingTag:"h2"}}),P=new sa({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEdQVDJMTUhlYWRNb2RlbCUyQyUyMEdQVDJUb2tlbml6ZXJGYXN0JTBBJTBBZGV2aWNlJTIwJTNEJTIwJTIyY3VkYSUyMiUwQW1vZGVsX2lkJTIwJTNEJTIwJTIyb3BlbmFpLWNvbW11bml0eSUyRmdwdDItbGFyZ2UlMjIlMEFtb2RlbCUyMCUzRCUyMEdQVDJMTUhlYWRNb2RlbC5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpLnRvKGRldmljZSklMEF0b2tlbml6ZXIlMjAlM0QlMjBHUFQyVG9rZW5pemVyRmFzdC5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2LMHeadModel, GPT2TokenizerFast

device = <span class="hljs-string">&quot;cuda&quot;</span>
model_id = <span class="hljs-string">&quot;openai-community/gpt2-large&quot;</span>
model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
tokenizer = GPT2TokenizerFast.from_pretrained(model_id)`,wrap:!1}}),W=new sa({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBdGVzdCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ3aWtpdGV4dCUyMiUyQyUyMCUyMndpa2l0ZXh0LTItcmF3LXYxJTIyJTJDJTIwc3BsaXQlM0QlMjJ0ZXN0JTIyKSUwQWVuY29kaW5ncyUyMCUzRCUyMHRva2VuaXplciglMjIlNUNuJTVDbiUyMi5qb2luKHRlc3QlNUIlMjJ0ZXh0JTIyJTVEKSUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIp",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

test = load_dataset(<span class="hljs-string">&quot;wikitext&quot;</span>, <span class="hljs-string">&quot;wikitext-2-raw-v1&quot;</span>, split=<span class="hljs-string">&quot;test&quot;</span>)
encodings = tokenizer(<span class="hljs-string">&quot;\\n\\n&quot;</span>.join(test[<span class="hljs-string">&quot;text&quot;</span>]), return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),R=new sa({props:{code:"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",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm

max_length = model.config.n_positions
stride = <span class="hljs-number">512</span>
seq_len = encodings.input_ids.size(<span class="hljs-number">1</span>)

nlls = []
prev_end_loc = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> begin_loc <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, seq_len, stride)):
    end_loc = <span class="hljs-built_in">min</span>(begin_loc + max_length, seq_len)
    trg_len = end_loc - prev_end_loc  <span class="hljs-comment"># puede ser diferente del paso en el √∫ltimo bucle</span>
    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)
    target_ids = input_ids.clone()
    target_ids[:, :-trg_len] = -<span class="hljs-number">100</span>

    <span class="hljs-keyword">with</span> torch.no_grad():
        outputs = model(input_ids, labels=target_ids)

        <span class="hljs-comment"># la p√©rdida se calcula utilizando CrossEntropyLoss, que promedia las etiquetas v√°lidas</span>
        <span class="hljs-comment"># N.B. el modelo solo calcula la p√©rdida sobre trg_len - 1 etiquetas, porque desplaza las etiqueta internamente</span>
        <span class="hljs-comment"># a la izquierda por 1.</span>
        neg_log_likelihood = outputs.loss

    nlls.append(neg_log_likelihood)

    prev_end_loc = end_loc
    <span class="hljs-keyword">if</span> end_loc == seq_len:
        <span class="hljs-keyword">break</span>

ppl = torch.exp(torch.stack(nlls).mean())`,wrap:!1}}),{c(){b=p("meta"),as=n(),O=p("p"),es=n(),L(_.$$.fragment),ts=n(),L(j.$$.fragment),ns=n(),k=p("p"),k.innerHTML=ta,ls=n(),g=p("p"),Ns=o("La perplejidad se define como la media negativa exponenciada del log-likelihood de una secuencia. Si tenemos una secuencia tokenizada"),ps=new v(!1),is=o(", entonces la perplejidad de"),ms=new v(!1),os=o(` es,
`),rs=new v(!1),cs=n(),y=p("p"),Ys=o("donde"),ds=new v(!1),us=o(" es el log-likelihood del token i-√©simo condicionado a los tokens precedentes"),hs=new v(!1),gs=o(" seg√∫n nuestro modelo. De manera intuitiva, se puede pensar en esto como una evaluaci√≥n de la capacidad del modelo para predecir de manera uniforme entre el conjunto de tokens especificados en un corpus. Es importante destacar que el procedimiento de tokenizaci√≥n tiene un impacto directo en la perplejidad de un modelo, lo cual siempre debe tenerse en cuenta al comparar diferentes modelos."),ys=n(),U=p("p"),U.innerHTML=na,vs=n(),L(z.$$.fragment),ws=n(),I=p("p"),I.textContent=la,bs=n(),f=p("img"),fs=n(),c=p("p"),As=o("Sin embargo, al trabajar con modelos aproximados, generalmente tenemos una restricci√≥n en la cantidad de tokens que el modelo puede procesar. La versi√≥n m√°s grande de "),C=p("a"),C.textContent=ia,Ds=o(", por ejemplo, tiene una longitud fija de 1024 tokens, por lo que no podemos calcular"),Ms=new v(!1),xs=o(" directamente cuando"),Ts=new v(!1),Js=o(" es mayor que 1024."),_s=n(),d=p("p"),Ks=o("En cambio, la secuencia se divide t√≠picamente en subsecuencias iguales al tama√±o m√°ximo de entrada del modelo. Si el tama√±o m√°ximo de entrada, de un modelo es"),js=new v(!1),ks=o(", entonces aproximamos la probabilidad de un token"),Us=new v(!1),zs=o(" condicion√°ndonos solo en los"),Is=new v(!1),Cs=o(" tokens que lo preceden en lugar de todo el contexto. Al evaluar la perplejidad del modelo en una secuencia, un enfoque tentador pero sub √≥ptimo es dividir la secuencia en fragmentos independientes y sumar los log-likelihood descompuestos de cada segmento de manera independiente."),Gs=n(),M=p("img"),Zs=n(),G=p("p"),G.textContent=oa,qs=n(),Z=p("p"),Z.textContent=ra,Bs=n(),x=p("img"),Es=n(),q=p("p"),q.textContent=da,Ps=n(),L(B.$$.fragment),$s=n(),E=p("p"),E.textContent=ua,Ws=n(),L(P.$$.fragment),Xs=n(),$=p("p"),$.textContent=ha,Rs=n(),L(W.$$.fragment),Vs=n(),X=p("p"),X.innerHTML=ga,Hs=n(),L(R.$$.fragment),Qs=n(),V=p("p"),V.textContent=ya,Ls=n(),H=p("p"),H.innerHTML=va,Ss=n(),ss=p("p"),this.h()},l(s){const a=Za("svelte-u9bgzb",document.head);b=i(a,"META",{name:!0,content:!0}),a.forEach(e),as=l(s),O=i(s,"P",{}),K(O).forEach(e),es=l(s),S(_.$$.fragment,s),ts=l(s),S(j.$$.fragment,s),ns=l(s),k=i(s,"P",{"data-svelte-h":!0}),u(k)!=="svelte-1reha6e"&&(k.innerHTML=ta),ls=l(s),g=i(s,"P",{});var Q=K(g);Ns=r(Q,"La perplejidad se define como la media negativa exponenciada del log-likelihood de una secuencia. Si tenemos una secuencia tokenizada"),ps=w(Q,!1),is=r(Q,", entonces la perplejidad de"),ms=w(Q,!1),os=r(Q,` es,
`),rs=w(Q,!1),Q.forEach(e),cs=l(s),y=i(s,"P",{});var D=K(y);Ys=r(D,"donde"),ds=w(D,!1),us=r(D," es el log-likelihood del token i-√©simo condicionado a los tokens precedentes"),hs=w(D,!1),gs=r(D," seg√∫n nuestro modelo. De manera intuitiva, se puede pensar en esto como una evaluaci√≥n de la capacidad del modelo para predecir de manera uniforme entre el conjunto de tokens especificados en un corpus. Es importante destacar que el procedimiento de tokenizaci√≥n tiene un impacto directo en la perplejidad de un modelo, lo cual siempre debe tenerse en cuenta al comparar diferentes modelos."),D.forEach(e),ys=l(s),U=i(s,"P",{"data-svelte-h":!0}),u(U)!=="svelte-snllqq"&&(U.innerHTML=na),vs=l(s),S(z.$$.fragment,s),ws=l(s),I=i(s,"P",{"data-svelte-h":!0}),u(I)!=="svelte-hq13j"&&(I.textContent=la),bs=l(s),f=i(s,"IMG",{width:!0,alt:!0,src:!0}),fs=l(s),c=i(s,"P",{});var T=K(c);As=r(T,"Sin embargo, al trabajar con modelos aproximados, generalmente tenemos una restricci√≥n en la cantidad de tokens que el modelo puede procesar. La versi√≥n m√°s grande de "),C=i(T,"A",{href:!0,"data-svelte-h":!0}),u(C)!=="svelte-1kdeo4m"&&(C.textContent=ia),Ds=r(T,", por ejemplo, tiene una longitud fija de 1024 tokens, por lo que no podemos calcular"),Ms=w(T,!1),xs=r(T," directamente cuando"),Ts=w(T,!1),Js=r(T," es mayor que 1024."),T.forEach(e),_s=l(s),d=i(s,"P",{});var J=K(d);Ks=r(J,"En cambio, la secuencia se divide t√≠picamente en subsecuencias iguales al tama√±o m√°ximo de entrada del modelo. Si el tama√±o m√°ximo de entrada, de un modelo es"),js=w(J,!1),ks=r(J,", entonces aproximamos la probabilidad de un token"),Us=w(J,!1),zs=r(J," condicion√°ndonos solo en los"),Is=w(J,!1),Cs=r(J," tokens que lo preceden en lugar de todo el contexto. Al evaluar la perplejidad del modelo en una secuencia, un enfoque tentador pero sub √≥ptimo es dividir la secuencia en fragmentos independientes y sumar los log-likelihood descompuestos de cada segmento de manera independiente."),J.forEach(e),Gs=l(s),M=i(s,"IMG",{width:!0,alt:!0,src:!0}),Zs=l(s),G=i(s,"P",{"data-svelte-h":!0}),u(G)!=="svelte-cyw0ih"&&(G.textContent=oa),qs=l(s),Z=i(s,"P",{"data-svelte-h":!0}),u(Z)!=="svelte-g4wjdt"&&(Z.textContent=ra),Bs=l(s),x=i(s,"IMG",{width:!0,alt:!0,src:!0}),Es=l(s),q=i(s,"P",{"data-svelte-h":!0}),u(q)!=="svelte-1mrshih"&&(q.textContent=da),Ps=l(s),S(B.$$.fragment,s),$s=l(s),E=i(s,"P",{"data-svelte-h":!0}),u(E)!=="svelte-1glfcjc"&&(E.textContent=ua),Ws=l(s),S(P.$$.fragment,s),Xs=l(s),$=i(s,"P",{"data-svelte-h":!0}),u($)!=="svelte-nmcyfw"&&($.textContent=ha),Rs=l(s),S(W.$$.fragment,s),Vs=l(s),X=i(s,"P",{"data-svelte-h":!0}),u(X)!=="svelte-l65yd5"&&(X.innerHTML=ga),Hs=l(s),S(R.$$.fragment,s),Qs=l(s),V=i(s,"P",{"data-svelte-h":!0}),u(V)!=="svelte-115s0x8"&&(V.textContent=ya),Ls=l(s),H=i(s,"P",{"data-svelte-h":!0}),u(H)!=="svelte-sun4pd"&&(H.innerHTML=va),Ss=l(s),ss=i(s,"P",{}),K(ss).forEach(e),this.h()},h(){h(b,"name","hf:doc:metadata"),h(b,"content",Ea),ps.a=is,ms.a=os,rs.a=null,ds.a=us,hs.a=gs,h(f,"width","600"),h(f,"alt","Full decomposition of a sequence with unlimited context length"),Os(f.src,pa="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif")||h(f,"src",pa),h(C,"href","model_doc/gpt2"),Ms.a=xs,Ts.a=Js,js.a=ks,Us.a=zs,Is.a=Cs,h(M,"width","600"),h(M,"alt","Suboptimal PPL not taking advantage of full available context"),Os(M.src,ma="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif")||h(M,"src",ma),h(x,"width","600"),h(x,"alt","Sliding window PPL taking advantage of all available context"),Os(x.src,ca="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_sliding.gif")||h(x,"src",ca)},m(s,a){m(document.head,b),t(s,as,a),t(s,O,a),t(s,es,a),F(_,s,a),t(s,ts,a),F(j,s,a),t(s,ns,a),t(s,k,a),t(s,ls,a),t(s,g,a),m(g,Ns),ps.m(wa,g),m(g,is),ms.m(ba,g),m(g,os),rs.m(fa,g),t(s,cs,a),t(s,y,a),m(y,Ys),ds.m(Ma,y),m(y,us),hs.m(xa,y),m(y,gs),t(s,ys,a),t(s,U,a),t(s,vs,a),F(z,s,a),t(s,ws,a),t(s,I,a),t(s,bs,a),t(s,f,a),t(s,fs,a),t(s,c,a),m(c,As),m(c,C),m(c,Ds),Ms.m(Ta,c),m(c,xs),Ts.m(Ja,c),m(c,Js),t(s,_s,a),t(s,d,a),m(d,Ks),js.m(_a,d),m(d,ks),Us.m(ja,d),m(d,zs),Is.m(ka,d),m(d,Cs),t(s,Gs,a),t(s,M,a),t(s,Zs,a),t(s,G,a),t(s,qs,a),t(s,Z,a),t(s,Bs,a),t(s,x,a),t(s,Es,a),t(s,q,a),t(s,Ps,a),F(B,s,a),t(s,$s,a),t(s,E,a),t(s,Ws,a),F(P,s,a),t(s,Xs,a),t(s,$,a),t(s,Rs,a),F(W,s,a),t(s,Vs,a),t(s,X,a),t(s,Hs,a),F(R,s,a),t(s,Qs,a),t(s,V,a),t(s,Ls,a),t(s,H,a),t(s,Ss,a),t(s,ss,a),Fs=!0},p:za,i(s){Fs||(N(_.$$.fragment,s),N(j.$$.fragment,s),N(z.$$.fragment,s),N(B.$$.fragment,s),N(P.$$.fragment,s),N(W.$$.fragment,s),N(R.$$.fragment,s),Fs=!0)},o(s){Y(_.$$.fragment,s),Y(j.$$.fragment,s),Y(z.$$.fragment,s),Y(B.$$.fragment,s),Y(P.$$.fragment,s),Y(W.$$.fragment,s),Y(R.$$.fragment,s),Fs=!1},d(s){s&&(e(as),e(O),e(es),e(ts),e(ns),e(k),e(ls),e(g),e(cs),e(y),e(ys),e(U),e(vs),e(ws),e(I),e(bs),e(f),e(fs),e(c),e(_s),e(d),e(Gs),e(M),e(Zs),e(G),e(qs),e(Z),e(Bs),e(x),e(Es),e(q),e(Ps),e($s),e(E),e(Ws),e(Xs),e($),e(Rs),e(Vs),e(X),e(Hs),e(Qs),e(V),e(Ls),e(H),e(Ss),e(ss)),e(b),A(_,s),A(j,s),A(z,s),A(B,s),A(P,s),A(W,s),A(R,s)}}}const Ea='{"title":"Perplejidad de los modelos de longitud fija","local":"perplejidad-de-los-modelos-de-longitud-fija","sections":[{"title":"C√°lculo de PPL con modelos de longitud fija","local":"c√°lculo-de-ppl-con-modelos-de-longitud-fija","sections":[],"depth":2},{"title":"Ejemplo: C√°lculo de la perplejidad con GPT-2 en ü§ó Transformers","local":"ejemplo-c√°lculo-de-la-perplejidad-con-gpt-2-en--transformers","sections":[],"depth":2}],"depth":1}';function Pa(ea){return Ia(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ha extends Ca{constructor(b){super(),Ga(this,b,Pa,Ba,Ua,{})}}export{Ha as component};
