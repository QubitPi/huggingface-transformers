import{s as se,n as ie,o as le}from"../chunks/scheduler.36a0863c.js";import{S as re,i as de,g as i,s as n,r as W,A as ce,h as l,f as o,c as s,j as X,u as Y,x as r,k as Z,y as ue,a as t,v as ee,d as ae,t as oe,w as te}from"../chunks/index.f891bdb2.js";import{H as ne}from"../chunks/Heading.3fb90772.js";function pe(N){let d,P,C,q,c,w,u,S="ü§ó Transformers es una biblioteca construida para:",L,p,B="<li>Los investigadores y educadores de NLP que busquen usar/estudiar/extender modelos transformers a gran escala</li> <li>Profesionales que quieren optimizar esos modelos y/o ponerlos en producci√≥n</li> <li>Ingenieros que solo quieren descargar un modelo preentrenado y usarlo para resolver una tarea NLP dada.</li>",z,m,K="La biblioteca fue dise√±ada con dos fuertes objetivos en mente:",M,f,D=`<li><p>Que sea tan f√°cil y r√°pida de utilizar como sea posible:</p> <ul><li>Hemos limitado enormemente el n√∫mero de abstracciones que el usuario tiene que aprender. De hecho, no hay casi abstracciones,
solo tres clases est√°ndar necesarias para usar cada modelo: <a href="main_classes/configuration">configuration</a>,
<a href="main_classes/model">models</a> y <a href="main_classes/tokenizer">tokenizer</a>.</li> <li>Todas estas clases pueden ser inicializadas de forma simple y unificada a partir de ejemplos pre-entrenados mediante el uso de un m√©todo
<code>from_pretrained()</code> com√∫n de solicitud que se encargar√° de descargar (si es necesario), almacenar y cargar la solicitud de clase relacionada y datos asociados
(configurations‚Äô hyper-parameters, tokenizers‚Äô vocabulary, and models‚Äô weights) a partir de un control pre-entrenado proporcionado en
<a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a> o de tu propio control guardado.</li> <li>Por encima de esas tres clases est√°ndar, la biblioteca proporciona dos APIs: <code>pipeline()</code> para usar r√°pidamente un modelo (junto a su configuracion y tokenizer asociados)
sobre una tarea dada, y <code>Trainer</code>/<code>Keras.fit</code> para entrenar u optimizar de forma r√°pida un modelo dado.</li> <li>Como consecuencia, esta biblioteca NO es una caja de herramientas modular de bloques individuales para redes neuronales. Si quieres extender/construir sobre la biblioteca,
usa simplemente los m√≥dulos regulares de Python/PyTorch/TensorFlow/Keras y emplea las clases est√°ndar de la biblioteca como punto de partida para reutilizar funcionalidades
tales como abrir/guardar modelo.</li></ul></li> <li><p>Proporciona modelos modernos con rendimientos lo m√°s parecido posible a los modelos originales:</p> <ul><li>Proporcionamos al menos un ejemplo para cada arquitectura que reproduce un resultado proporcionado por los autores de dicha arquitectura.</li> <li>El c√≥digo normalmente es parecido al c√≥digo base original, lo cual significa que alg√∫n c√≥digo Pytorch puede no ser tan
<em>pytorchic</em> como podr√≠a ser por haber sido convertido a c√≥digo TensorFlow, y viceversa.</li></ul></li>`,$,g,O="Unos cuantos objetivos adicionales:",k,b,Q="<li><p>Exponer las caracter√≠sticas internas de los modelos de la forma m√°s coherente posible:</p> <ul><li>Damos acceso, mediante una sola API, a todos los estados ocultos y pesos de atenci√≥n.</li> <li>Tokenizer y el modelo de API base est√°n estandarizados para cambiar f√°cilmente entre modelos.</li></ul></li> <li><p>Incorporar una selecci√≥n subjetiva de herramientas de gran potencial para la optimizaci√≥n/investigaci√≥n de estos modelos:</p> <ul><li>Una forma sencilla/coherente de a√±adir nuevos tokens al vocabulario e incrustraciones (embeddings, en ingl√©s) para optimizaci√≥n.</li> <li>Formas sencillas de camuflar y reducir ‚Äútransformer heads‚Äù.</li></ul></li> <li><p>Cambiar f√°cilmente entre PyTorch y TensorFlow 2.0, permitiendo el entrenamiento usando un marco y la inferencia usando otro.</p></li>",H,v,j,h,R="La biblioteca est√° construida alrededor de tres tipos de clases para cada modelo:",U,y,G=`<li><strong>Model classes</strong> como <code>BertModel</code>, que consisten en m√°s de 30 modelos PyTorch (<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow">torch.nn.Module</a>) o modelos Keras (<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">tf.keras.Model</a>) que funcionan con pesos pre-entrenados proporcionados en la
biblioteca.</li> <li><strong>Configuration classes</strong> como <code>BertConfig</code>, que almacena todos los par√°metros necesarios para construir un modelo.
No siempre tienes que generarla tu. En particular, si estas usando un modelo pre-entrenado sin ninguna modificaci√≥n,
la creaci√≥n del modelo se encargar√° autom√°ticamente de generar la configuraci√≥n (que es parte del modelo).</li> <li><strong>Tokenizer classes</strong> como <code>BertTokenizer</code>, que almacena el vocabulario para cada modelo y proporciona m√©todos para
codificar/decodificar strings en una lista de √≠ndices de ‚Äútoken embeddings‚Äù para ser empleados en un modelo.</li>`,E,_,J="Todas estas clases pueden ser generadas a partir de ejemplos pre-entrenados, y guardados localmente usando dos m√©todos:",F,x,V=`<li><code>from_pretrained()</code> permite generar un modelo/configuraci√≥n/tokenizer a partir de una versi√≥n pre-entrenada proporcionada ya sea por
la propia biblioteca (los modelos compatibles se pueden encontrar en <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>) o
guardados localmente (o en un servidor) por el usuario.</li> <li><code>save_pretrained()</code> permite guardar un modelo/configuraci√≥n/tokenizer localmente, de forma que puede ser empleado de nuevo usando
<code>from_pretrained()</code>.</li>`,A,T,I;return c=new ne({props:{title:"Filosof√≠a",local:"filosof√≠a",headingTag:"h1"}}),v=new ne({props:{title:"Conceptos principales",local:"conceptos-principales",headingTag:"h2"}}),{c(){d=i("meta"),P=n(),C=i("p"),q=n(),W(c.$$.fragment),w=n(),u=i("p"),u.textContent=S,L=n(),p=i("ul"),p.innerHTML=B,z=n(),m=i("p"),m.textContent=K,M=n(),f=i("ul"),f.innerHTML=D,$=n(),g=i("p"),g.textContent=O,k=n(),b=i("ul"),b.innerHTML=Q,H=n(),W(v.$$.fragment),j=n(),h=i("p"),h.textContent=R,U=n(),y=i("ul"),y.innerHTML=G,E=n(),_=i("p"),_.textContent=J,F=n(),x=i("ul"),x.innerHTML=V,A=n(),T=i("p"),this.h()},l(e){const a=ce("svelte-u9bgzb",document.head);d=l(a,"META",{name:!0,content:!0}),a.forEach(o),P=s(e),C=l(e,"P",{}),X(C).forEach(o),q=s(e),Y(c.$$.fragment,e),w=s(e),u=l(e,"P",{"data-svelte-h":!0}),r(u)!=="svelte-1vbdb49"&&(u.textContent=S),L=s(e),p=l(e,"UL",{"data-svelte-h":!0}),r(p)!=="svelte-6xtsel"&&(p.innerHTML=B),z=s(e),m=l(e,"P",{"data-svelte-h":!0}),r(m)!=="svelte-1wtux22"&&(m.textContent=K),M=s(e),f=l(e,"UL",{"data-svelte-h":!0}),r(f)!=="svelte-1euljsf"&&(f.innerHTML=D),$=s(e),g=l(e,"P",{"data-svelte-h":!0}),r(g)!=="svelte-116kkxj"&&(g.textContent=O),k=s(e),b=l(e,"UL",{"data-svelte-h":!0}),r(b)!=="svelte-1stml3v"&&(b.innerHTML=Q),H=s(e),Y(v.$$.fragment,e),j=s(e),h=l(e,"P",{"data-svelte-h":!0}),r(h)!=="svelte-1wizrvd"&&(h.textContent=R),U=s(e),y=l(e,"UL",{"data-svelte-h":!0}),r(y)!=="svelte-1wjca98"&&(y.innerHTML=G),E=s(e),_=l(e,"P",{"data-svelte-h":!0}),r(_)!=="svelte-11kx7ql"&&(_.textContent=J),F=s(e),x=l(e,"UL",{"data-svelte-h":!0}),r(x)!=="svelte-nafgvv"&&(x.innerHTML=V),A=s(e),T=l(e,"P",{}),X(T).forEach(o),this.h()},h(){Z(d,"name","hf:doc:metadata"),Z(d,"content",me)},m(e,a){ue(document.head,d),t(e,P,a),t(e,C,a),t(e,q,a),ee(c,e,a),t(e,w,a),t(e,u,a),t(e,L,a),t(e,p,a),t(e,z,a),t(e,m,a),t(e,M,a),t(e,f,a),t(e,$,a),t(e,g,a),t(e,k,a),t(e,b,a),t(e,H,a),ee(v,e,a),t(e,j,a),t(e,h,a),t(e,U,a),t(e,y,a),t(e,E,a),t(e,_,a),t(e,F,a),t(e,x,a),t(e,A,a),t(e,T,a),I=!0},p:ie,i(e){I||(ae(c.$$.fragment,e),ae(v.$$.fragment,e),I=!0)},o(e){oe(c.$$.fragment,e),oe(v.$$.fragment,e),I=!1},d(e){e&&(o(P),o(C),o(q),o(w),o(u),o(L),o(p),o(z),o(m),o(M),o(f),o($),o(g),o(k),o(b),o(H),o(j),o(h),o(U),o(y),o(E),o(_),o(F),o(x),o(A),o(T)),o(d),te(c,e),te(v,e)}}}const me='{"title":"Filosof√≠a","local":"filosof√≠a","sections":[{"title":"Conceptos principales","local":"conceptos-principales","sections":[],"depth":2}],"depth":1}';function fe(N){return le(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class he extends re{constructor(d){super(),de(this,d,fe,pe,se,{})}}export{he as component};
