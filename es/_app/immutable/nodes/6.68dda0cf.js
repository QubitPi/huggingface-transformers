import{s as z,n as q,o as G}from"../chunks/scheduler.36a0863c.js";import{S as V,i as Q,g as b,s as r,r as j,A as $,h as m,f as a,c as n,j as S,u as R,x as E,k as M,y as H,a as o,v as P,d as D,t as L,w as F}from"../chunks/index.f891bdb2.js";import{H as I}from"../chunks/Heading.3fb90772.js";function U(B){let l,p,f,_,s,w,i,O="Esta p√°gina agrupa los recursos de ü§ó Transformers desarrollados por la comunidad.",T,g,v,c,x='<thead><tr><th align="left">Recurso</th> <th align="left">Descripci√≥n</th> <th align="right">Autor</th></tr></thead> <tbody><tr><td align="left"><a href="https://www.darigovresearch.com/huggingface-transformers-glossary-flashcards" rel="nofollow">Hugging Face Transformers Glossary Flashcards</a></td> <td align="left">Un conjunto de flashcards basadas en el [Glosario de documentos de Transformers] (glosario) que se ha puesto en un formato que se puede aprender/revisar f√°cilmente usando <a href="https://apps.ankiweb.net/" rel="nofollow">Anki</a> una fuente abierta, aplicaci√≥n de multiplataforma dise√±ada espec√≠ficamente para la retenci√≥n de conocimientos a largo plazo. Ve este <a href="https://www.youtube.com/watch?v=Dji_h7PILrw" rel="nofollow">Introductory video on how to use the flashcards</a>.</td> <td align="right"><a href="https://www.darigovresearch.com/" rel="nofollow">Darigov Research</a></td></tr></tbody>',y,d,C,h,N='<thead><tr><th align="left">Cuaderno</th> <th align="left">Descripci√≥n</th> <th align="left">Autor</th> <th align="right"></th></tr></thead> <tbody><tr><td align="left"><a href="https://github.com/AlekseyKorshuk/huggingartists" rel="nofollow">Ajustar un transformador preentrenado para generar letras</a></td> <td align="left">C√≥mo generar letras al estilo de tu artista favorito ajustando un modelo GPT-2</td> <td align="left"><a href="https://github.com/AlekseyKorshuk" rel="nofollow">Aleksey Korshuk</a></td> <td align="right"><a href="https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/snapthat/TF-T5-text-to-text" rel="nofollow">Entrenar T5 en Tensorflow 2</a></td> <td align="left">C√≥mo entrenar a T5 para cualquier tarea usando Tensorflow 2. Este cuaderno demuestra una tarea de preguntas y respuestas implementada en Tensorflow 2 usando SQUAD</td> <td align="left"><a href="https://github.com/HarrisDePerceptron" rel="nofollow">Muhammad Harris</a></td> <td align="right"><a href="https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb" rel="nofollow">Entrenar T5 en TPU</a></td> <td align="left">C√≥mo entrenar a T5 en SQUAD con Transformers y Nlp</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb" rel="nofollow">Ajustar T5 para Clasificaci√≥n y Opci√≥n M√∫ltiple</a></td> <td align="left">C√≥mo ajustar T5 para clasificaci√≥n y tareas de opci√≥n m√∫ltiple usando un formato de texto a texto con PyTorch Lightning</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb" rel="nofollow">Ajustar DialoGPT en nuevos conjuntos de datos e idiomas</a></td> <td align="left">C√≥mo ajustar el modelo DialoGPT en un nuevo conjunto de datos para chatbots conversacionales de di√°logo abierto</td> <td align="left"><a href="https://github.com/ncoop57" rel="nofollow">Nathan Cooper</a></td> <td align="right"><a href="https://colab.research.google.com/github/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb" rel="nofollow">Modelado de secuencias largas con Reformer</a></td> <td align="left">C√≥mo entrenar en secuencias de hasta 500,000 tokens con Reformer</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ohmeow/ohmeow_website/blob/master/_notebooks/2020-05-23-text-generation-with-blurr.ipynb" rel="nofollow">Ajustar BART para resumir</a></td> <td align="left">C√≥mo ajustar BART para resumir con fastai usando blurr</td> <td align="left"><a href="https://ohmeow.com/" rel="nofollow">Wayde Gilliam</a></td> <td align="right"><a href="https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/_notebooks/2020-05-23-text-generation-with-blurr.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb" rel="nofollow">Ajustar un Transformador previamente entrenado en los tweets de cualquier persona</a></td> <td align="left">C√≥mo generar tweets al estilo de tu cuenta de Twitter favorita ajustando un modelo GPT-2</td> <td align="left"><a href="https://github.com/borisdayma" rel="nofollow">Boris Dayma</a></td> <td align="right"><a href="https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb" rel="nofollow">Optimizar ü§ó modelos de Hugging Face con pesos y sesgos</a></td> <td align="left">Un tutorial completo que muestra la integraci√≥n de W&amp;B con Hugging Face</td> <td align="left"><a href="https://github.com/borisdayma" rel="nofollow">Boris Dayma</a></td> <td align="right"><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb" rel="nofollow">Preentrenar Longformer</a></td> <td align="left">C√≥mo construir una versi√≥n ‚Äúlarga‚Äù de modelos preentrenados existentes</td> <td align="left"><a href="https://beltagy.net" rel="nofollow">Iz Beltagy</a></td> <td align="right"><a href="https://colab.research.google.com/github/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb" rel="nofollow">Ajustar Longformer para control de calidad</a></td> <td align="left">C√≥mo ajustar el modelo antiguo para la tarea de control de calidad</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/How_to_evaluate_Longformer_on_TriviaQA_using_NLP.ipynb" rel="nofollow">Evaluar modelo con ü§ónlp</a></td> <td align="left">C√≥mo evaluar longformer en TriviaQA con <code>nlp</code></td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1m7eTGlPmLRgoPkkA7rkhQdZ9ydpmsdLE?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb" rel="nofollow">Ajustar fino de T5 para la extracci√≥n de amplitud de opini√≥n</a></td> <td align="left">C√≥mo ajustar T5 para la extracci√≥n de intervalos de opiniones mediante un formato de texto a texto con PyTorch Lightning</td> <td align="left"><a href="https://github.com/enzoampil" rel="nofollow">Lorenzo Ampil</a></td> <td align="right"><a href="https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb" rel="nofollow">Ajustar fino de DistilBert para la clasificaci√≥n multiclase</a></td> <td align="left">C√≥mo ajustar DistilBert para la clasificaci√≥n multiclase con PyTorch</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb" rel="nofollow">Ajustar BERT para la clasificaci√≥n de etiquetas m√∫ltiples</a></td> <td align="left">C√≥mo ajustar BERT para la clasificaci√≥n de m√∫ltiples etiquetas usando PyTorch</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb" rel="nofollow">Ajustar T5 para resumir</a></td> <td align="left">C√≥mo ajustar T5 para resumir en PyTorch y realizar un seguimiento de los experimentos con WandB</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ELS-RD/transformers-notebook/blob/master/Divide_Hugging_Face_Transformers_training_time_by_2_or_more.ipynb" rel="nofollow">Acelerar el ajuste fino en transformadores con Dynamic Padding/Bucketing</a></td> <td align="left">C√≥mo acelerar el ajuste fino en un factor de 2 usando relleno din√°mico/cubetas</td> <td align="left"><a href="https://github.com/pommedeterresautee" rel="nofollow">Michael Benesty</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1CBfRU1zbfu7-ijiOqAAQUA-RJaxfcJoO?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Reformer_For_Masked_LM.ipynb" rel="nofollow">Preentrenar Reformer para modelado de lenguaje enmascarado</a></td> <td align="left">C√≥mo entrenar un modelo Reformer con capas de autoatenci√≥n bidireccionales</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1tzzh0i8PgDQGV3SMFUGxM7_gGae3K-uW?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/lordtt13/word-embeddings/blob/master/COVID-19%20Research%20Data/COVID-SciBERT.ipynb" rel="nofollow">Ampliar y ajustar Sci-BERT</a></td> <td align="left">C√≥mo aumentar el vocabulario de un modelo SciBERT preentrenado de AllenAI en el conjunto de datos CORD y canalizarlo.</td> <td align="left"><a href="https://github.com/lordtt13" rel="nofollow">Tanmay Thakur</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1rqAR40goxbAfez1xvF3hBJphSCsvXmh8" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/lordtt13/transformers-experiments/blob/master/Custom%20Tasks/fine-tune-blenderbot_small-for-summarization.ipynb" rel="nofollow">Ajustar fino de BlenderBotSmall para res√∫menes usando la API de Entrenador</a></td> <td align="left">C√≥mo ajustar BlenderBotSmall para resumir en un conjunto de datos personalizado, utilizando la API de Entrenador.</td> <td align="left"><a href="https://github.com/lordtt13" rel="nofollow">Tanmay Thakur</a></td> <td align="right"><a href="https://colab.research.google.com/drive/19Wmupuls7mykSGyRN_Qo6lPQhgp56ymq?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb" rel="nofollow">Ajustar Electra e interpreta con gradientes integrados</a></td> <td align="left">C√≥mo ajustar Electra para el an√°lisis de sentimientos e interpretar predicciones con Captum Integrated Gradients</td> <td align="left"><a href="https://elsanns.github.io" rel="nofollow">Eliza Szczechla</a></td> <td align="right"><a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb" rel="nofollow">ajustar un modelo GPT-2 que no est√° en ingl√©s con la clase Trainer</a></td> <td align="left">C√≥mo ajustar un modelo GPT-2 que no est√° en ingl√©s con la clase Trainer</td> <td align="left"><a href="https://www.philschmid.de" rel="nofollow">Philipp Schmid</a></td> <td align="right"><a href="https://colab.research.google.com/github/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb" rel="nofollow">Ajustar un modelo DistilBERT para la tarea de clasificaci√≥n de m√∫ltiples etiquetas</a></td> <td align="left">C√≥mo ajustar un modelo DistilBERT para la tarea de clasificaci√≥n de m√∫ltiples etiquetas</td> <td align="left"><a href="https://github.com/DhavalTaunk08" rel="nofollow">Dhaval Taunk</a></td> <td align="right"><a href="https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb" rel="nofollow">Ajustar ALBERT para la clasificaci√≥n de pares de oraciones</a></td> <td align="left">C√≥mo ajustar un modelo ALBERT u otro modelo basado en BERT para la tarea de clasificaci√≥n de pares de oraciones</td> <td align="left"><a href="https://github.com/NadirEM" rel="nofollow">Nadir El Manouzi</a></td> <td align="right"><a href="https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb" rel="nofollow">Ajustar a Roberta para el an√°lisis de sentimientos</a></td> <td align="left">C√≥mo ajustar un modelo de Roberta para el an√°lisis de sentimientos</td> <td align="left"><a href="https://github.com/DhavalTaunk08" rel="nofollow">Dhaval Taunk</a></td> <td align="right"><a href="https://colab.research.google.com/github/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/flexudy-pipe/qugeev" rel="nofollow">Evaluaci√≥n de modelos de generaci√≥n de preguntas</a></td> <td align="left">¬øQu√© tan precisas son las respuestas a las preguntas generadas por tu modelo de transformador seq2seq?</td> <td align="left"><a href="https://github.com/zolekode" rel="nofollow">Pascal Zoleko</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1bpsSqCQU-iw_5nNoRm_crPq6FRuJthq_?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb" rel="nofollow">Clasificar texto con DistilBERT y Tensorflow</a></td> <td align="left">C√≥mo ajustar DistilBERT para la clasificaci√≥n de texto en TensorFlow</td> <td align="left"><a href="https://github.com/peterbayerle" rel="nofollow">Peter Bayerle</a></td> <td align="right"><a href="https://colab.research.google.com/github/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb" rel="nofollow">Aprovechar BERT para el resumen de codificador y decodificador en CNN/Dailymail</a></td> <td align="left">C√≥mo iniciar en caliente un <em>EncoderDecoderModel</em> con un punto de control <em>google-bert/bert-base-uncased</em> para resumir en CNN/Dailymail</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb" rel="nofollow">Aprovechar RoBERTa para el resumen de codificador-decodificador en BBC XSum</a></td> <td align="left">C√≥mo iniciar en caliente un <em>EncoderDecoderModel</em> compartido con un punto de control <em>FacebookAI/roberta-base</em> para resumir en BBC/XSum</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb" rel="nofollow">Ajustar TAPAS en Sequential Question Answering (SQA)</a></td> <td align="left">C√≥mo ajustar <em>TapasForQuestionAnswering</em> con un punto de control <em>tapas-base</em> en el conjunto de datos del Sequential Question Answering (SQA)</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb" rel="nofollow">Evaluar TAPAS en Table Fact Checking (TabFact)</a></td> <td align="left">C√≥mo evaluar un <em>TapasForSequenceClassification</em> ajustado con un punto de control <em>tapas-base-finetuned-tabfact</em> usando una combinaci√≥n de ü§ó conjuntos de datos y ü§ó bibliotecas de transformadores</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb" rel="nofollow">Ajustar de mBART para traducci√≥n</a></td> <td align="left">C√≥mo ajustar mBART utilizando Seq2SeqTrainer para la traducci√≥n del hindi al ingl√©s</td> <td align="left"><a href="https://github.com/vasudevgupta7" rel="nofollow">Vasudev Gupta</a></td> <td align="right"><a href="https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb" rel="nofollow">Ajustar LayoutLM en FUNSD (a form understanding dataset)</a></td> <td align="left">C√≥mo ajustar <em>LayoutLMForTokenClassification</em> en el conjunto de datos de FUNSD para la extracci√≥n de informaci√≥n de documentos escaneados</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb" rel="nofollow">Ajustar DistilGPT2 y genere texto</a></td> <td align="left">C√≥mo ajustar DistilGPT2 y generar texto</td> <td align="left"><a href="https://github.com/tripathiaakash" rel="nofollow">Aakash Tripathi</a></td> <td align="right"><a href="https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb" rel="nofollow">Ajustar LED en tokens de hasta 8K</a></td> <td align="left">C√≥mo ajustar LED en pubmed para res√∫menes de largo alcance</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb" rel="nofollow">Evaluar LED en Arxiv</a></td> <td align="left">C√≥mo evaluar efectivamente LED en res√∫menes de largo alcance</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb" rel="nofollow">Ajustar fino de LayoutLM en RVL-CDIP (un conjunto de datos de clasificaci√≥n de im√°genes de documentos)</a></td> <td align="left">C√≥mo ajustar <em>LayoutLMForSequenceClassification</em> en el conjunto de datos RVL-CDIP para la clasificaci√≥n de documentos escaneados</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/voidful/huggingface_notebook/blob/main/xlsr_gpt.ipynb" rel="nofollow">Decodificaci√≥n Wav2Vec2 CTC con ajuste GPT2</a></td> <td align="left">C√≥mo decodificar la secuencia CTC con el ajuste del modelo de lenguaje</td> <td align="left"><a href="https://github.com/voidful" rel="nofollow">Eric Lam</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1e_z5jQHYbO2YKEaUgzb1ww1WwiAyydAj?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb" rel="nofollow">Ajustar BART para res√∫menes en dos idiomas con la clase Trainer</a></td> <td align="left">C√≥mo ajustar BART para res√∫menes en dos idiomas con la clase Trainer</td> <td align="left"><a href="https://github.com/elsanns" rel="nofollow">Eliza Szczechla</a></td> <td align="right"><a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb" rel="nofollow">Evaluar Big Bird en Trivia QA</a></td> <td align="left">C√≥mo evaluar BigBird en respuesta a preguntas de documentos largos en Trivia QA</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb" rel="nofollow">Crear subt√≠tulos de video usando Wav2Vec2</a></td> <td align="left">C√≥mo crear subt√≠tulos de YouTube a partir de cualquier v√≠deo transcribiendo el audio con Wav2Vec</td> <td align="left"><a href="https://github.com/Muennighoff" rel="nofollow">Niklas Muennighoff</a></td> <td align="right"><a href="https://colab.research.google.com/github/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb" rel="nofollow">Ajustar el transformador de visi√≥n en CIFAR-10 usando PyTorch Lightning</a></td> <td align="left">C√≥mo ajustar el transformador de visi√≥n (ViT) en CIFAR-10 usando transformadores HuggingFace, conjuntos de datos y PyTorch Lightning</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb" rel="nofollow">Ajustar el Transformador de visi√≥n en CIFAR-10 usando el ü§ó Entrenador</a></td> <td align="left">C√≥mo ajustar el Vision Transformer (ViT) en CIFAR-10 usando HuggingFace Transformers, Datasets y el ü§ó Trainer</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb" rel="nofollow">Evaluar LUKE en Open Entity, un conjunto de datos de tipificaci√≥n de entidades</a></td> <td align="left">C√≥mo evaluar <em>LukeForEntityClassification</em> en el conjunto de datos de entidad abierta</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb" rel="nofollow">Evaluar LUKE en TACRED, un conjunto de datos de extracci√≥n de relaciones</a></td> <td align="left">C√≥mo evaluar <em>LukeForEntityPairClassification</em> en el conjunto de datos TACRED</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb" rel="nofollow">Evaluar LUKE en CoNLL-2003, un punto de referencia importante de NER</a></td> <td align="left">C√≥mo evaluar <em>LukeForEntitySpanClassification</em> en el conjunto de datos CoNLL-2003</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb" rel="nofollow">Evaluar BigBird-Pegasus en el conjunto de datos de PubMed</a></td> <td align="left">C√≥mo evaluar <em>BigBirdPegasusForConditionalGeneration</em> en el conjunto de datos de PubMed</td> <td align="left"><a href="https://github.com/vasudevgupta7" rel="nofollow">Vasudev Gupta</a></td> <td align="right"><a href="https://colab.research.google.com/github/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb" rel="nofollow">Clasificaci√≥n de emociones del habla con Wav2Vec2</a></td> <td align="left">C√≥mo aprovechar un modelo Wav2Vec2 preentrenado para la clasificaci√≥n de emociones en el conjunto de datos MEGA</td> <td align="left"><a href="https://github.com/m3hrdadfi" rel="nofollow">Mehrdad Farahani</a></td> <td align="right"><a href="https://colab.research.google.com/github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb" rel="nofollow">Detectar objetos en una imagen con DETR</a></td> <td align="left">C√≥mo usar un modelo entrenado <em>DetrForObjectDetection</em> para detectar objetos en una imagen y visualizar la atenci√≥n</td> <td align="left"><a href="https://github.com/NielsRogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb" rel="nofollow">Ajustar el DETR en un conjunto de datos de detecci√≥n de objetos personalizados</a></td> <td align="left">C√≥mo ajustar <em>DetrForObjectDetection</em> en un conjunto de datos de detecci√≥n de objetos personalizados</td> <td align="left"><a href="https://github.com/NielsRogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ToluClassics/Notebooks/blob/main/T5_Ner_Finetuning.ipynb" rel="nofollow">Ajustar T5 para el reconocimiento de entidades nombradas</a></td> <td align="left">C√≥mo ajustar <em>T5</em> en una tarea de reconocimiento de entidad nombrada</td> <td align="left"><a href="https://github.com/ToluClassics" rel="nofollow">Ogundepo Odunayo</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr></tbody>',k,u,A;return s=new I({props:{title:"Comunidad",local:"comunidad",headingTag:"h1"}}),g=new I({props:{title:"Los recursos de la comunidad:",local:"los-recursos-de-la-comunidad",headingTag:"h2"}}),d=new I({props:{title:"Los cuadernos de la comunidad:",local:"los-cuadernos-de-la-comunidad",headingTag:"h2"}}),{c(){l=b("meta"),p=r(),f=b("p"),_=r(),j(s.$$.fragment),w=r(),i=b("p"),i.textContent=O,T=r(),j(g.$$.fragment),v=r(),c=b("table"),c.innerHTML=x,y=r(),j(d.$$.fragment),C=r(),h=b("table"),h.innerHTML=N,k=r(),u=b("p"),this.h()},l(t){const e=$("svelte-u9bgzb",document.head);l=m(e,"META",{name:!0,content:!0}),e.forEach(a),p=n(t),f=m(t,"P",{}),S(f).forEach(a),_=n(t),R(s.$$.fragment,t),w=n(t),i=m(t,"P",{"data-svelte-h":!0}),E(i)!=="svelte-g1pyqk"&&(i.textContent=O),T=n(t),R(g.$$.fragment,t),v=n(t),c=m(t,"TABLE",{"data-svelte-h":!0}),E(c)!=="svelte-sxbl1y"&&(c.innerHTML=x),y=n(t),R(d.$$.fragment,t),C=n(t),h=m(t,"TABLE",{"data-svelte-h":!0}),E(h)!=="svelte-rine0h"&&(h.innerHTML=N),k=n(t),u=m(t,"P",{}),S(u).forEach(a),this.h()},h(){M(l,"name","hf:doc:metadata"),M(l,"content",W)},m(t,e){H(document.head,l),o(t,p,e),o(t,f,e),o(t,_,e),P(s,t,e),o(t,w,e),o(t,i,e),o(t,T,e),P(g,t,e),o(t,v,e),o(t,c,e),o(t,y,e),P(d,t,e),o(t,C,e),o(t,h,e),o(t,k,e),o(t,u,e),A=!0},p:q,i(t){A||(D(s.$$.fragment,t),D(g.$$.fragment,t),D(d.$$.fragment,t),A=!0)},o(t){L(s.$$.fragment,t),L(g.$$.fragment,t),L(d.$$.fragment,t),A=!1},d(t){t&&(a(p),a(f),a(_),a(w),a(i),a(T),a(v),a(c),a(y),a(C),a(h),a(k),a(u)),a(l),F(s,t),F(g,t),F(d,t)}}}const W='{"title":"Comunidad","local":"comunidad","sections":[{"title":"Los recursos de la comunidad:","local":"los-recursos-de-la-comunidad","sections":[],"depth":2},{"title":"Los cuadernos de la comunidad:","local":"los-cuadernos-de-la-comunidad","sections":[],"depth":2}],"depth":1}';function K(B){return G(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Z extends V{constructor(l){super(),Q(this,l,K,U,z,{})}}export{Z as component};
