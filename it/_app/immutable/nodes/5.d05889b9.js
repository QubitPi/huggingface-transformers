import{s as Te,o as xe,n as de}from"../chunks/scheduler.36a0863c.js";import{S as Je,i as _e,g as h,s as i,r as y,A as We,h as b,f as s,c as p,j as Ze,u as M,x as Z,k as ze,y as Fe,a as n,v as j,d as k,t as v,w as C}from"../chunks/index.9c13489a.js";import{T as Ge}from"../chunks/Tip.3b06990e.js";import{C as W}from"../chunks/CodeBlock.05d8ec32.js";import{F as Ue,M as we}from"../chunks/Markdown.88297c0b.js";import{H as B}from"../chunks/Heading.7a254a62.js";function Ve(J){let l,m='Ricorda, con architettura ci si riferisce allo scheletro del modello e con checkpoint ai pesi di una determinata architettura. Per esempio, <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a> √® un‚Äôarchitettura, mentre <code>google-bert/bert-base-uncased</code> √® un checkpoint. Modello √® un termine generale che pu√≤ significare sia architettura che checkpoint.';return{c(){l=h("p"),l.innerHTML=m},l(r){l=b(r,"P",{"data-svelte-h":!0}),Z(l)!=="svelte-ymj6p9"&&(l.innerHTML=m)},m(r,o){n(r,l,o)},p:de,d(r){r&&s(l)}}}function He(J){let l,m='Infine, le classi <code>AutoModelFor</code> ti permettono di caricare un modello pre-allenato per un determinato compito (guarda <a href="model_doc/auto">qui</a> per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con <code>AutoModelForSequenceClassification.from_pretrained()</code>:',r,o,u,f,z="Semplicemente utilizza lo stesso checkpoint per caricare un‚Äôarchitettura per un task differente:",T,d,g,$,w='Generalmente, raccomandiamo di utilizzare la classe <code>AutoTokenizer</code> e la classe <code>AutoModelFor</code> per caricare istanze pre-allenate dei modelli. Questo ti assicurer√† di aver caricato la corretta architettura ogni volta. Nel prossimo <a href="preprocessing">tutorial</a>, imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning.',x;return o=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),d=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){l=h("p"),l.innerHTML=m,r=i(),y(o.$$.fragment),u=i(),f=h("p"),f.textContent=z,T=i(),y(d.$$.fragment),g=i(),$=h("p"),$.innerHTML=w},l(t){l=b(t,"P",{"data-svelte-h":!0}),Z(l)!=="svelte-mrmc1k"&&(l.innerHTML=m),r=p(t),M(o.$$.fragment,t),u=p(t),f=b(t,"P",{"data-svelte-h":!0}),Z(f)!=="svelte-1qkx2d7"&&(f.textContent=z),T=p(t),M(d.$$.fragment,t),g=p(t),$=b(t,"P",{"data-svelte-h":!0}),Z($)!=="svelte-fki7m8"&&($.innerHTML=w)},m(t,c){n(t,l,c),n(t,r,c),j(o,t,c),n(t,u,c),n(t,f,c),n(t,T,c),j(d,t,c),n(t,g,c),n(t,$,c),x=!0},p:de,i(t){x||(k(o.$$.fragment,t),k(d.$$.fragment,t),x=!0)},o(t){v(o.$$.fragment,t),v(d.$$.fragment,t),x=!1},d(t){t&&(s(l),s(r),s(u),s(f),s(T),s(g),s($)),C(o,t),C(d,t)}}}function Xe(J){let l,m;return l=new we({props:{$$slots:{default:[He]},$$scope:{ctx:J}}}),{c(){y(l.$$.fragment)},l(r){M(l.$$.fragment,r)},m(r,o){j(l,r,o),m=!0},p(r,o){const u={};o&2&&(u.$$scope={dirty:o,ctx:r}),l.$set(u)},i(r){m||(k(l.$$.fragment,r),m=!0)},o(r){v(l.$$.fragment,r),m=!1},d(r){C(l,r)}}}function Re(J){let l,m='Infine, le classi <code>TFAutoModelFor</code> ti permettono di caricare un modello pre-allenato per un determinato compito (guarda <a href="model_doc/auto">qui</a> per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con <code>TFAutoModelForSequenceClassification.from_pretrained()</code>:',r,o,u,f,z="Semplicemente utilizza lo stesso checkpoint per caricare un‚Äôarchitettura per un task differente:",T,d,g,$,w='Generalmente, raccomandiamo di utilizzare la classe <code>AutoTokenizer</code> e la classe <code>TFAutoModelFor</code> per caricare istanze pre-allenate dei modelli. Questo ti assicurer√† di aver caricato la corretta architettura ogni volta. Nel prossimo <a href="preprocessing">tutorial</a>, imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning.',x;return o=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),d=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){l=h("p"),l.innerHTML=m,r=i(),y(o.$$.fragment),u=i(),f=h("p"),f.textContent=z,T=i(),y(d.$$.fragment),g=i(),$=h("p"),$.innerHTML=w},l(t){l=b(t,"P",{"data-svelte-h":!0}),Z(l)!=="svelte-7mu57g"&&(l.innerHTML=m),r=p(t),M(o.$$.fragment,t),u=p(t),f=b(t,"P",{"data-svelte-h":!0}),Z(f)!=="svelte-1qkx2d7"&&(f.textContent=z),T=p(t),M(d.$$.fragment,t),g=p(t),$=b(t,"P",{"data-svelte-h":!0}),Z($)!=="svelte-xnnzsy"&&($.innerHTML=w)},m(t,c){n(t,l,c),n(t,r,c),j(o,t,c),n(t,u,c),n(t,f,c),n(t,T,c),j(d,t,c),n(t,g,c),n(t,$,c),x=!0},p:de,i(t){x||(k(o.$$.fragment,t),k(d.$$.fragment,t),x=!0)},o(t){v(o.$$.fragment,t),v(d.$$.fragment,t),x=!1},d(t){t&&(s(l),s(r),s(u),s(f),s(T),s(g),s($)),C(o,t),C(d,t)}}}function Ae(J){let l,m;return l=new we({props:{$$slots:{default:[Re]},$$scope:{ctx:J}}}),{c(){y(l.$$.fragment)},l(r){M(l.$$.fragment,r)},m(r,o){j(l,r,o),m=!0},p(r,o){const u={};o&2&&(u.$$scope={dirty:o,ctx:r}),l.$set(u)},i(r){m||(k(l.$$.fragment,r),m=!0)},o(r){v(l.$$.fragment,r),m=!1},d(r){C(l,r)}}}function Ee(J){let l,m,r,o,u,f,z,T="Con cos√¨ tante architetture Transformer differenti, pu√≤ essere sfidante crearne una per il tuo checkpoint. Come parte della filosofia centrale di ü§ó Transformers per rendere la libreria facile, semplice e flessibile da utilizzare, una <code>AutoClass</code> inferisce e carica automaticamente l‚Äôarchitettura corretta da un dato checkpoint. Il metodo <code>from_pretrained</code> ti permette di caricare velocemente un modello pre-allenato per qualsiasi architettura, cos√¨ non devi utilizzare tempo e risorse per allenare un modello da zero. Produrre questo codice agnostico ai checkpoint significa che se il tuo codice funziona per un checkpoint, funzioner√† anche per un altro checkpoint, purch√© sia stato allenato per un compito simile, anche se l‚Äôarchitettura √® differente.",d,g,$,w,x="In questo tutorial, imparerai a:",t,c,$e="<li>Caricare un tokenizer pre-allenato.</li> <li>Caricare un estrattore di caratteristiche (feature extractor, in inglese) pre-allenato.</li> <li>Caricare un processore pre-allenato.</li> <li>Caricare un modello pre-allenato.</li>",S,F,K,G,he="Quasi tutti i compiti di NLP iniziano con un tokenizer. Un tokenizer converte il tuo input in un formato che possa essere elaborato dal modello.",D,U,be="Carica un tokenizer con <code>AutoTokenizer.from_pretrained()</code>:",O,V,ee,H,ge="Poi tokenizza il tuo input come mostrato in seguito:",te,X,ae,R,se,A,ye="Per compiti inerenti a audio e video, un feature extractor processa il segnale audio o l‚Äôimmagine nel formato di input corretto.",le,E,Me="Carica un feature extractor con <code>AutoFeatureExtractor.from_pretrained()</code>:",ne,L,re,N,oe,q,je='Compiti multimodali richiedono un processore che combini i due tipi di strumenti di elaborazione. Per esempio, il modello <a href="model_doc/layoutlmv2">LayoutLMV2</a> richiede un feature extractor per gestire le immagine e un tokenizer per gestire il testo; un processore li combina entrambi.',ie,Y,ke="Carica un processore con <code>AutoProcessor.from_pretrained()</code>:",pe,P,ce,I,me,_,ue,Q,fe;return u=new B({props:{title:"Carica istanze pre-allenate con AutoClass",local:"carica-istanze-pre-allenate-con-autoclass",headingTag:"h1"}}),g=new Ge({props:{$$slots:{default:[Ve]},$$scope:{ctx:J}}}),F=new B({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h2"}}),V=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJGYWNlYm9va0FJJTJGeGxtLXJvYmVydGEtYmFzZSUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;FacebookAI/xlm-roberta-base&quot;</span>)`,wrap:!1}}),X=new W({props:{code:"c2VxdWVuemElMjAlM0QlMjAlMjJJbiUyMHVuJTIwYnVjbyUyMG5lbCUyMHRlcnJlbm8lMjB2aXZldmElMjB1bm8lMjBIb2JiaXQuJTIyJTBBcHJpbnQodG9rZW5pemVyKHNlcXVlbnphKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequenza = <span class="hljs-string">&quot;In un buco nel terreno viveva uno Hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequenza))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">360</span>, <span class="hljs-number">51</span>, <span class="hljs-number">373</span>, <span class="hljs-number">587</span>, <span class="hljs-number">1718</span>, <span class="hljs-number">54644</span>, <span class="hljs-number">22597</span>, <span class="hljs-number">330</span>, <span class="hljs-number">3269</span>, <span class="hljs-number">2291</span>, <span class="hljs-number">22155</span>, <span class="hljs-number">18</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),R=new B({props:{title:"AutoFeatureExtractor",local:"autofeatureextractor",headingTag:"h2"}}),L=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZWhjYWxhYnJlcyUyRndhdjJ2ZWMyLWxnLXhsc3ItZW4tc3BlZWNoLWVtb3Rpb24tcmVjb2duaXRpb24lMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),N=new B({props:{title:"AutoProcessor",local:"autoprocessor",headingTag:"h2"}}),P=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZsYXlvdXRsbXYyLWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`,wrap:!1}}),I=new B({props:{title:"AutoModel",local:"automodel",headingTag:"h2"}}),_=new Ue({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ae],pytorch:[Xe]},$$scope:{ctx:J}}}),{c(){l=h("meta"),m=i(),r=h("p"),o=i(),y(u.$$.fragment),f=i(),z=h("p"),z.innerHTML=T,d=i(),y(g.$$.fragment),$=i(),w=h("p"),w.textContent=x,t=i(),c=h("ul"),c.innerHTML=$e,S=i(),y(F.$$.fragment),K=i(),G=h("p"),G.textContent=he,D=i(),U=h("p"),U.innerHTML=be,O=i(),y(V.$$.fragment),ee=i(),H=h("p"),H.textContent=ge,te=i(),y(X.$$.fragment),ae=i(),y(R.$$.fragment),se=i(),A=h("p"),A.textContent=ye,le=i(),E=h("p"),E.innerHTML=Me,ne=i(),y(L.$$.fragment),re=i(),y(N.$$.fragment),oe=i(),q=h("p"),q.innerHTML=je,ie=i(),Y=h("p"),Y.innerHTML=ke,pe=i(),y(P.$$.fragment),ce=i(),y(I.$$.fragment),me=i(),y(_.$$.fragment),ue=i(),Q=h("p"),this.h()},l(e){const a=We("svelte-u9bgzb",document.head);l=b(a,"META",{name:!0,content:!0}),a.forEach(s),m=p(e),r=b(e,"P",{}),Ze(r).forEach(s),o=p(e),M(u.$$.fragment,e),f=p(e),z=b(e,"P",{"data-svelte-h":!0}),Z(z)!=="svelte-j1c1g2"&&(z.innerHTML=T),d=p(e),M(g.$$.fragment,e),$=p(e),w=b(e,"P",{"data-svelte-h":!0}),Z(w)!=="svelte-lz1oph"&&(w.textContent=x),t=p(e),c=b(e,"UL",{"data-svelte-h":!0}),Z(c)!=="svelte-al227k"&&(c.innerHTML=$e),S=p(e),M(F.$$.fragment,e),K=p(e),G=b(e,"P",{"data-svelte-h":!0}),Z(G)!=="svelte-1m4wodb"&&(G.textContent=he),D=p(e),U=b(e,"P",{"data-svelte-h":!0}),Z(U)!=="svelte-1jqstre"&&(U.innerHTML=be),O=p(e),M(V.$$.fragment,e),ee=p(e),H=b(e,"P",{"data-svelte-h":!0}),Z(H)!=="svelte-nf3ccy"&&(H.textContent=ge),te=p(e),M(X.$$.fragment,e),ae=p(e),M(R.$$.fragment,e),se=p(e),A=b(e,"P",{"data-svelte-h":!0}),Z(A)!=="svelte-upjht"&&(A.textContent=ye),le=p(e),E=b(e,"P",{"data-svelte-h":!0}),Z(E)!=="svelte-1imqvze"&&(E.innerHTML=Me),ne=p(e),M(L.$$.fragment,e),re=p(e),M(N.$$.fragment,e),oe=p(e),q=b(e,"P",{"data-svelte-h":!0}),Z(q)!=="svelte-hgkuwq"&&(q.innerHTML=je),ie=p(e),Y=b(e,"P",{"data-svelte-h":!0}),Z(Y)!=="svelte-1fqg8an"&&(Y.innerHTML=ke),pe=p(e),M(P.$$.fragment,e),ce=p(e),M(I.$$.fragment,e),me=p(e),M(_.$$.fragment,e),ue=p(e),Q=b(e,"P",{}),Ze(Q).forEach(s),this.h()},h(){ze(l,"name","hf:doc:metadata"),ze(l,"content",Le)},m(e,a){Fe(document.head,l),n(e,m,a),n(e,r,a),n(e,o,a),j(u,e,a),n(e,f,a),n(e,z,a),n(e,d,a),j(g,e,a),n(e,$,a),n(e,w,a),n(e,t,a),n(e,c,a),n(e,S,a),j(F,e,a),n(e,K,a),n(e,G,a),n(e,D,a),n(e,U,a),n(e,O,a),j(V,e,a),n(e,ee,a),n(e,H,a),n(e,te,a),j(X,e,a),n(e,ae,a),j(R,e,a),n(e,se,a),n(e,A,a),n(e,le,a),n(e,E,a),n(e,ne,a),j(L,e,a),n(e,re,a),j(N,e,a),n(e,oe,a),n(e,q,a),n(e,ie,a),n(e,Y,a),n(e,pe,a),j(P,e,a),n(e,ce,a),j(I,e,a),n(e,me,a),j(_,e,a),n(e,ue,a),n(e,Q,a),fe=!0},p(e,[a]){const ve={};a&2&&(ve.$$scope={dirty:a,ctx:e}),g.$set(ve);const Ce={};a&2&&(Ce.$$scope={dirty:a,ctx:e}),_.$set(Ce)},i(e){fe||(k(u.$$.fragment,e),k(g.$$.fragment,e),k(F.$$.fragment,e),k(V.$$.fragment,e),k(X.$$.fragment,e),k(R.$$.fragment,e),k(L.$$.fragment,e),k(N.$$.fragment,e),k(P.$$.fragment,e),k(I.$$.fragment,e),k(_.$$.fragment,e),fe=!0)},o(e){v(u.$$.fragment,e),v(g.$$.fragment,e),v(F.$$.fragment,e),v(V.$$.fragment,e),v(X.$$.fragment,e),v(R.$$.fragment,e),v(L.$$.fragment,e),v(N.$$.fragment,e),v(P.$$.fragment,e),v(I.$$.fragment,e),v(_.$$.fragment,e),fe=!1},d(e){e&&(s(m),s(r),s(o),s(f),s(z),s(d),s($),s(w),s(t),s(c),s(S),s(K),s(G),s(D),s(U),s(O),s(ee),s(H),s(te),s(ae),s(se),s(A),s(le),s(E),s(ne),s(re),s(oe),s(q),s(ie),s(Y),s(pe),s(ce),s(me),s(ue),s(Q)),s(l),C(u,e),C(g,e),C(F,e),C(V,e),C(X,e),C(R,e),C(L,e),C(N,e),C(P,e),C(I,e),C(_,e)}}}const Le='{"title":"Carica istanze pre-allenate con AutoClass","local":"carica-istanze-pre-allenate-con-autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":2},{"title":"AutoFeatureExtractor","local":"autofeatureextractor","sections":[],"depth":2},{"title":"AutoProcessor","local":"autoprocessor","sections":[],"depth":2},{"title":"AutoModel","local":"automodel","sections":[],"depth":2}],"depth":1}';function Ne(J){return xe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Se extends Je{constructor(l){super(),_e(this,l,Ne,Ee,Te,{})}}export{Se as component};
