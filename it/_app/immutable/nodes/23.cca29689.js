import{s as lt,o as nt,n as it}from"../chunks/scheduler.36a0863c.js";import{S as at,i as ot,g as o,s as i,r as c,A as rt,h as r,f as l,c as a,j as et,u as d,x as s,k as tt,y as st,a as n,v as m,d as u,t as f,w as M}from"../chunks/index.9c13489a.js";import{T as pt}from"../chunks/Tip.3b06990e.js";import{C as q}from"../chunks/CodeBlock.05d8ec32.js";import{H as O}from"../chunks/Heading.7a254a62.js";function ct(ee){let p,_=`oneccl_bindings_for_pytorch 1.12.0 prebuilt wheel does not work with PyTorch 1.12.1 (it is for PyTorch 1.12.0)
PyTorch 1.12.1 should work with oneccl_bindings_for_pytorch 1.12.100`;return{c(){p=o("p"),p.textContent=_},l(h){p=r(h,"P",{"data-svelte-h":!0}),s(p)!=="svelte-is6c7w"&&(p.textContent=_)},m(h,D){n(h,p,D)},p:it,d(h){h&&l(p)}}}function dt(ee){let p,_,h,D,T,te,U,Xe="Quando l’addestramento su una singola CPU è troppo lento, possiamo usare CPU multiple. Quasta guida si concentra su DDP basato su PyTorch abilitando l’addetramento distribuito su CPU in maniera efficiente.",le,y,ne,b,Re='<a href="https://github.com/oneapi-src/oneCCL" rel="nofollow">Intel® oneCCL</a> (collective communications library) è una libreria per l’addestramento efficiente del deep learning in distribuito e implementa collettivi come allreduce, allgather, alltoall. Per maggiori informazioni su oneCCL, fai riferimento a <a href="https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html" rel="nofollow">oneCCL documentation</a> e <a href="https://spec.oneapi.com/versions/latest/elements/oneCCL/source/index.html" rel="nofollow">oneCCL specification</a>.',ie,w,Be="Il modulo <code>oneccl_bindings_for_pytorch</code> (<code>torch_ccl</code> precedentemente alla versione 1.12)  implementa PyTorch C10D ProcessGroup API e può essere caricato dinamicamente com external ProcessGroup e funziona solo su piattaforma Linux al momento.",ae,g,Ee='Qui trovi informazioni più dettagliate per <a href="https://github.com/intel/torch-ccl" rel="nofollow">oneccl_bind_pt</a>.',oe,x,re,$,Ne="I file wheel sono disponibili per le seguenti versioni di Python:",se,J,Ze='<thead><tr><th align="center">Extension Version</th> <th align="center">Python 3.6</th> <th align="center">Python 3.7</th> <th align="center">Python 3.8</th> <th align="center">Python 3.9</th> <th align="center">Python 3.10</th></tr></thead> <tbody><tr><td align="center">1.13.0</td> <td align="center"></td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td></tr> <tr><td align="center">1.12.100</td> <td align="center"></td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td></tr> <tr><td align="center">1.12.0</td> <td align="center"></td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td></tr> <tr><td align="center">1.11.0</td> <td align="center"></td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td></tr> <tr><td align="center">1.10.0</td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td> <td align="center">√</td> <td align="center"></td></tr></tbody>',pe,v,ce,I,Ge=`dove <code>{pytorch_version}</code> deve essere la tua versione di PyTorch, per l’stanza 1.13.0.
Verifica altri approcci per <a href="https://github.com/intel/torch-ccl" rel="nofollow">oneccl_bind_pt installation</a>.
Le versioni di oneCCL e PyTorch devono combaciare.`,de,C,me,j,ue,z,He="Usa questa implementazione basata su standard MPI per fornire una architettura flessibile, efficiente, scalabile su cluster per Intel®. Questo componente è parte di Intel® oneAPI HPC Toolkit.",fe,L,Qe="oneccl_bindings_for_pytorch è installato insieme al set di strumenti MPI. Necessità di reperire l’ambiente prima di utilizzarlo.",Me,P,Ae="per Intel® oneCCL >= 1.12.0",he,X,Ce,R,Ve="per Intel® oneCCL con versione < 1.12.0",_e,B,Te,E,Ue,N,Se='IPEX fornisce ottimizzazioni delle prestazioni per l’addestramento della CPU sia con Float32 che con BFloat16; puoi fare riferimento a <a href="./perf_train_cpu">single CPU section</a>.',ye,Z,We="Il seguente “Utilizzo in Trainer” prende come esempio mpirun nella libreria Intel® MPI.",be,G,we,H,ke="Per abilitare l’addestramento distribuito multi CPU nel Trainer con il ccl backend, gli utenti devono aggiungere <strong><code>--ddp_backend ccl</code></strong> negli argomenti del comando.",ge,Q,Ye='Vediamo un esempio per il <a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering" rel="nofollow">question-answering example</a>',xe,A,Fe="Il seguente comando abilita due processi sul nodo Xeon, con un processo in esecuzione per ogni socket. Le variabili OMP_NUM_THREADS/CCL_WORKER_COUNT possono essere impostate per una prestazione ottimale.",$e,V,Je,S,De="Il seguente comando abilita l’addestramento per un totale di quattro processi su due Xeon (node0 e node1, prendendo node0 come processo principale), ppn (processes per node) è impostato a 2, on un processo in esecuzione per ogni socket. Le variabili OMP_NUM_THREADS/CCL_WORKER_COUNT possono essere impostate per una prestazione ottimale.",ve,W,qe="In node0, è necessario creare un file di configurazione che contenga gli indirizzi IP di ciascun nodo (per esempio hostfile) e passare il percorso del file di configurazione come parametro.",Ie,k,je,Y,Oe="A questo punto, esegui il seguente comando nel nodo0 e <strong>4DDP</strong> sarà abilitato in node0 e node1 con BF16 auto mixed precision:",ze,F,Le,K,Pe;return T=new O({props:{title:"Addestramento effciente su multiple CPU",local:"addestramento-effciente-su-multiple-cpu",headingTag:"h1"}}),y=new O({props:{title:"Intel® oneCCL Bindings per PyTorch",local:"intel-oneccl-bindings-per-pytorch",headingTag:"h2"}}),x=new O({props:{title:"Intel® oneCCL Bindings per l’installazione PyTorch:",local:"intel-oneccl-bindings-per-linstallazione-pytorch",headingTag:"h3"}}),v=new q({props:{code:"cGlwJTIwaW5zdGFsbCUyMG9uZWNjbF9iaW5kX3B0JTNEJTNEJTdCcHl0b3JjaF92ZXJzaW9uJTdEJTIwLWYlMjBodHRwcyUzQSUyRiUyRmRldmVsb3Blci5pbnRlbC5jb20lMkZpcGV4LXdobC1zdGFibGUtY3B1",highlighted:"pip install oneccl_bind_pt=={pytorch_version} -f https://developer.intel.com/ipex-whl-stable-cpu",wrap:!1}}),C=new pt({props:{warning:!0,$$slots:{default:[ct]},$$scope:{ctx:ee}}}),j=new O({props:{title:"Intel® MPI library",local:"intel-mpi-library",headingTag:"h2"}}),X=new q({props:{code:"b25lY2NsX2JpbmRpbmdzX2Zvcl9weXRvcmNoX3BhdGglM0QlMjQocHl0aG9uJTIwLWMlMjAlMjJmcm9tJTIwb25lY2NsX2JpbmRpbmdzX2Zvcl9weXRvcmNoJTIwaW1wb3J0JTIwY3dkJTNCJTIwcHJpbnQoY3dkKSUyMiklMEFzb3VyY2UlMjAlMjRvbmVjY2xfYmluZGluZ3NfZm9yX3B5dG9yY2hfcGF0aCUyRmVudiUyRnNldHZhcnMuc2g=",highlighted:`oneccl_bindings_for_pytorch_path=$(python -c <span class="hljs-string">&quot;from oneccl_bindings_for_pytorch import cwd; print(cwd)&quot;</span>)
<span class="hljs-built_in">source</span> <span class="hljs-variable">$oneccl_bindings_for_pytorch_path</span>/env/setvars.sh`,wrap:!1}}),B=new q({props:{code:"dG9yY2hfY2NsX3BhdGglM0QlMjQocHl0aG9uJTIwLWMlMjAlMjJpbXBvcnQlMjB0b3JjaCUzQiUyMGltcG9ydCUyMHRvcmNoX2NjbCUzQiUyMGltcG9ydCUyMG9zJTNCJTIwJTIwcHJpbnQob3MucGF0aC5hYnNwYXRoKG9zLnBhdGguZGlybmFtZSh0b3JjaF9jY2wuX19maWxlX18pKSklMjIpJTBBc291cmNlJTIwJTI0dG9yY2hfY2NsX3BhdGglMkZlbnYlMkZzZXR2YXJzLnNo",highlighted:`torch_ccl_path=$(python -c <span class="hljs-string">&quot;import torch; import torch_ccl; import os;  print(os.path.abspath(os.path.dirname(torch_ccl.__file__)))&quot;</span>)
<span class="hljs-built_in">source</span> <span class="hljs-variable">$torch_ccl_path</span>/env/setvars.sh`,wrap:!1}}),E=new O({props:{title:"Installazione IPEX:",local:"installazione-ipex",headingTag:"h4"}}),G=new O({props:{title:"Utilizzo in Trainer",local:"utilizzo-in-trainer",headingTag:"h2"}}),V=new q({props:{code:"JTIwZXhwb3J0JTIwQ0NMX1dPUktFUl9DT1VOVCUzRDElMEElMjBleHBvcnQlMjBNQVNURVJfQUREUiUzRDEyNy4wLjAuMSUwQSUyMG1waXJ1biUyMC1uJTIwMiUyMC1nZW52JTIwT01QX05VTV9USFJFQURTJTNEMjMlMjAlNUMlMEElMjBweXRob24zJTIwcnVuX3FhLnB5JTIwJTVDJTBBJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtYmVydCUyRmJlcnQtbGFyZ2UtdW5jYXNlZCUyMCU1QyUwQSUyMC0tZGF0YXNldF9uYW1lJTIwc3F1YWQlMjAlNUMlMEElMjAtLWRvX3RyYWluJTIwJTVDJTBBJTIwLS1kb19ldmFsJTIwJTVDJTBBJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlMjAxMiUyMCUyMCU1QyUwQSUyMC0tbGVhcm5pbmdfcmF0ZSUyMDNlLTUlMjAlMjAlNUMlMEElMjAtLW51bV90cmFpbl9lcG9jaHMlMjAyJTIwJTIwJTVDJTBBJTIwLS1tYXhfc2VxX2xlbmd0aCUyMDM4NCUyMCU1QyUwQSUyMC0tZG9jX3N0cmlkZSUyMDEyOCUyMCUyMCU1QyUwQSUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRmRlYnVnX3NxdWFkJTJGJTIwJTVDJTBBJTIwLS1ub19jdWRhJTIwJTVDJTBBJTIwLS1kZHBfYmFja2VuZCUyMGNjbCUyMCU1QyUwQSUyMC0tdXNlX2lwZXg=",highlighted:` export CCL_WORKER_COUNT=1
 export MASTER_ADDR=127.0.0.1
 mpirun -n 2 -genv OMP_NUM_THREADS=23 \\
 python3 run_qa.py \\
 --model_name_or_path google-bert/bert-large-uncased \\
 --dataset_name squad \\
 --do_train \\
 --do_eval \\
 --per_device_train_batch_size 12  \\
 --learning_rate 3e-5  \\
 --num_train_epochs 2  \\
 --max_seq_length 384 \\
 --doc_stride 128  \\
 --output_dir /tmp/debug_squad/ \\
 --no_cuda \\
 --ddp_backend ccl \\
 --use_ipex`,wrap:!1}}),k=new q({props:{code:"JTIwY2F0JTIwaG9zdGZpbGUlMEElMjB4eHgueHh4Lnh4eC54eHglMjAlMjNub2RlMCUyMGlwJTBBJTIweHh4Lnh4eC54eHgueHh4JTIwJTIzbm9kZTElMjBpcA==",highlighted:` cat hostfile
 xxx.xxx.xxx.xxx #node0 ip
 xxx.xxx.xxx.xxx #node1 ip`,wrap:!1}}),F=new q({props:{code:"JTIwZXhwb3J0JTIwQ0NMX1dPUktFUl9DT1VOVCUzRDElMEElMjBleHBvcnQlMjBNQVNURVJfQUREUiUzRHh4eC54eHgueHh4Lnh4eCUyMCUyM25vZGUwJTIwaXAlMEElMjBtcGlydW4lMjAtZiUyMGhvc3RmaWxlJTIwLW4lMjA0JTIwLXBwbiUyMDIlMjAlNUMlMEElMjAtZ2VudiUyME9NUF9OVU1fVEhSRUFEUyUzRDIzJTIwJTVDJTBBJTIwcHl0aG9uMyUyMHJ1bl9xYS5weSUyMCU1QyUwQSUyMC0tbW9kZWxfbmFtZV9vcl9wYXRoJTIwZ29vZ2xlLWJlcnQlMkZiZXJ0LWxhcmdlLXVuY2FzZWQlMjAlNUMlMEElMjAtLWRhdGFzZXRfbmFtZSUyMHNxdWFkJTIwJTVDJTBBJTIwLS1kb190cmFpbiUyMCU1QyUwQSUyMC0tZG9fZXZhbCUyMCU1QyUwQSUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTIwMTIlMjAlMjAlNUMlMEElMjAtLWxlYXJuaW5nX3JhdGUlMjAzZS01JTIwJTIwJTVDJTBBJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMiUyMCUyMCU1QyUwQSUyMC0tbWF4X3NlcV9sZW5ndGglMjAzODQlMjAlNUMlMEElMjAtLWRvY19zdHJpZGUlMjAxMjglMjAlMjAlNUMlMEElMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZkZWJ1Z19zcXVhZCUyRiUyMCU1QyUwQSUyMC0tbm9fY3VkYSUyMCU1QyUwQSUyMC0tZGRwX2JhY2tlbmQlMjBjY2wlMjAlNUMlMEElMjAtLXVzZV9pcGV4JTIwJTVDJTBBJTIwLS1iZjE2",highlighted:` export CCL_WORKER_COUNT=1
 export MASTER_ADDR=xxx.xxx.xxx.xxx #node0 ip
 mpirun -f hostfile -n 4 -ppn 2 \\
 -genv OMP_NUM_THREADS=23 \\
 python3 run_qa.py \\
 --model_name_or_path google-bert/bert-large-uncased \\
 --dataset_name squad \\
 --do_train \\
 --do_eval \\
 --per_device_train_batch_size 12  \\
 --learning_rate 3e-5  \\
 --num_train_epochs 2  \\
 --max_seq_length 384 \\
 --doc_stride 128  \\
 --output_dir /tmp/debug_squad/ \\
 --no_cuda \\
 --ddp_backend ccl \\
 --use_ipex \\
 --bf16`,wrap:!1}}),{c(){p=o("meta"),_=i(),h=o("p"),D=i(),c(T.$$.fragment),te=i(),U=o("p"),U.textContent=Xe,le=i(),c(y.$$.fragment),ne=i(),b=o("p"),b.innerHTML=Re,ie=i(),w=o("p"),w.innerHTML=Be,ae=i(),g=o("p"),g.innerHTML=Ee,oe=i(),c(x.$$.fragment),re=i(),$=o("p"),$.textContent=Ne,se=i(),J=o("table"),J.innerHTML=Ze,pe=i(),c(v.$$.fragment),ce=i(),I=o("p"),I.innerHTML=Ge,de=i(),c(C.$$.fragment),me=i(),c(j.$$.fragment),ue=i(),z=o("p"),z.textContent=He,fe=i(),L=o("p"),L.textContent=Qe,Me=i(),P=o("p"),P.textContent=Ae,he=i(),c(X.$$.fragment),Ce=i(),R=o("p"),R.textContent=Ve,_e=i(),c(B.$$.fragment),Te=i(),c(E.$$.fragment),Ue=i(),N=o("p"),N.innerHTML=Se,ye=i(),Z=o("p"),Z.textContent=We,be=i(),c(G.$$.fragment),we=i(),H=o("p"),H.innerHTML=ke,ge=i(),Q=o("p"),Q.innerHTML=Ye,xe=i(),A=o("p"),A.textContent=Fe,$e=i(),c(V.$$.fragment),Je=i(),S=o("p"),S.textContent=De,ve=i(),W=o("p"),W.textContent=qe,Ie=i(),c(k.$$.fragment),je=i(),Y=o("p"),Y.innerHTML=Oe,ze=i(),c(F.$$.fragment),Le=i(),K=o("p"),this.h()},l(e){const t=rt("svelte-u9bgzb",document.head);p=r(t,"META",{name:!0,content:!0}),t.forEach(l),_=a(e),h=r(e,"P",{}),et(h).forEach(l),D=a(e),d(T.$$.fragment,e),te=a(e),U=r(e,"P",{"data-svelte-h":!0}),s(U)!=="svelte-1kfu2az"&&(U.textContent=Xe),le=a(e),d(y.$$.fragment,e),ne=a(e),b=r(e,"P",{"data-svelte-h":!0}),s(b)!=="svelte-1lu0lvx"&&(b.innerHTML=Re),ie=a(e),w=r(e,"P",{"data-svelte-h":!0}),s(w)!=="svelte-ctw5mc"&&(w.innerHTML=Be),ae=a(e),g=r(e,"P",{"data-svelte-h":!0}),s(g)!=="svelte-12jdnef"&&(g.innerHTML=Ee),oe=a(e),d(x.$$.fragment,e),re=a(e),$=r(e,"P",{"data-svelte-h":!0}),s($)!=="svelte-awoh7n"&&($.textContent=Ne),se=a(e),J=r(e,"TABLE",{"data-svelte-h":!0}),s(J)!=="svelte-1yk106u"&&(J.innerHTML=Ze),pe=a(e),d(v.$$.fragment,e),ce=a(e),I=r(e,"P",{"data-svelte-h":!0}),s(I)!=="svelte-xq4hi3"&&(I.innerHTML=Ge),de=a(e),d(C.$$.fragment,e),me=a(e),d(j.$$.fragment,e),ue=a(e),z=r(e,"P",{"data-svelte-h":!0}),s(z)!=="svelte-1v3lzwy"&&(z.textContent=He),fe=a(e),L=r(e,"P",{"data-svelte-h":!0}),s(L)!=="svelte-7y5acl"&&(L.textContent=Qe),Me=a(e),P=r(e,"P",{"data-svelte-h":!0}),s(P)!=="svelte-37i02y"&&(P.textContent=Ae),he=a(e),d(X.$$.fragment,e),Ce=a(e),R=r(e,"P",{"data-svelte-h":!0}),s(R)!=="svelte-2y4a8e"&&(R.textContent=Ve),_e=a(e),d(B.$$.fragment,e),Te=a(e),d(E.$$.fragment,e),Ue=a(e),N=r(e,"P",{"data-svelte-h":!0}),s(N)!=="svelte-ucejiq"&&(N.innerHTML=Se),ye=a(e),Z=r(e,"P",{"data-svelte-h":!0}),s(Z)!=="svelte-1j4jwwj"&&(Z.textContent=We),be=a(e),d(G.$$.fragment,e),we=a(e),H=r(e,"P",{"data-svelte-h":!0}),s(H)!=="svelte-c1ynuc"&&(H.innerHTML=ke),ge=a(e),Q=r(e,"P",{"data-svelte-h":!0}),s(Q)!=="svelte-15bz7m"&&(Q.innerHTML=Ye),xe=a(e),A=r(e,"P",{"data-svelte-h":!0}),s(A)!=="svelte-1aptuua"&&(A.textContent=Fe),$e=a(e),d(V.$$.fragment,e),Je=a(e),S=r(e,"P",{"data-svelte-h":!0}),s(S)!=="svelte-8wv2la"&&(S.textContent=De),ve=a(e),W=r(e,"P",{"data-svelte-h":!0}),s(W)!=="svelte-1m5a0mz"&&(W.textContent=qe),Ie=a(e),d(k.$$.fragment,e),je=a(e),Y=r(e,"P",{"data-svelte-h":!0}),s(Y)!=="svelte-lx9bti"&&(Y.innerHTML=Oe),ze=a(e),d(F.$$.fragment,e),Le=a(e),K=r(e,"P",{}),et(K).forEach(l),this.h()},h(){tt(p,"name","hf:doc:metadata"),tt(p,"content",mt)},m(e,t){st(document.head,p),n(e,_,t),n(e,h,t),n(e,D,t),m(T,e,t),n(e,te,t),n(e,U,t),n(e,le,t),m(y,e,t),n(e,ne,t),n(e,b,t),n(e,ie,t),n(e,w,t),n(e,ae,t),n(e,g,t),n(e,oe,t),m(x,e,t),n(e,re,t),n(e,$,t),n(e,se,t),n(e,J,t),n(e,pe,t),m(v,e,t),n(e,ce,t),n(e,I,t),n(e,de,t),m(C,e,t),n(e,me,t),m(j,e,t),n(e,ue,t),n(e,z,t),n(e,fe,t),n(e,L,t),n(e,Me,t),n(e,P,t),n(e,he,t),m(X,e,t),n(e,Ce,t),n(e,R,t),n(e,_e,t),m(B,e,t),n(e,Te,t),m(E,e,t),n(e,Ue,t),n(e,N,t),n(e,ye,t),n(e,Z,t),n(e,be,t),m(G,e,t),n(e,we,t),n(e,H,t),n(e,ge,t),n(e,Q,t),n(e,xe,t),n(e,A,t),n(e,$e,t),m(V,e,t),n(e,Je,t),n(e,S,t),n(e,ve,t),n(e,W,t),n(e,Ie,t),m(k,e,t),n(e,je,t),n(e,Y,t),n(e,ze,t),m(F,e,t),n(e,Le,t),n(e,K,t),Pe=!0},p(e,[t]){const Ke={};t&2&&(Ke.$$scope={dirty:t,ctx:e}),C.$set(Ke)},i(e){Pe||(u(T.$$.fragment,e),u(y.$$.fragment,e),u(x.$$.fragment,e),u(v.$$.fragment,e),u(C.$$.fragment,e),u(j.$$.fragment,e),u(X.$$.fragment,e),u(B.$$.fragment,e),u(E.$$.fragment,e),u(G.$$.fragment,e),u(V.$$.fragment,e),u(k.$$.fragment,e),u(F.$$.fragment,e),Pe=!0)},o(e){f(T.$$.fragment,e),f(y.$$.fragment,e),f(x.$$.fragment,e),f(v.$$.fragment,e),f(C.$$.fragment,e),f(j.$$.fragment,e),f(X.$$.fragment,e),f(B.$$.fragment,e),f(E.$$.fragment,e),f(G.$$.fragment,e),f(V.$$.fragment,e),f(k.$$.fragment,e),f(F.$$.fragment,e),Pe=!1},d(e){e&&(l(_),l(h),l(D),l(te),l(U),l(le),l(ne),l(b),l(ie),l(w),l(ae),l(g),l(oe),l(re),l($),l(se),l(J),l(pe),l(ce),l(I),l(de),l(me),l(ue),l(z),l(fe),l(L),l(Me),l(P),l(he),l(Ce),l(R),l(_e),l(Te),l(Ue),l(N),l(ye),l(Z),l(be),l(we),l(H),l(ge),l(Q),l(xe),l(A),l($e),l(Je),l(S),l(ve),l(W),l(Ie),l(je),l(Y),l(ze),l(Le),l(K)),l(p),M(T,e),M(y,e),M(x,e),M(v,e),M(C,e),M(j,e),M(X,e),M(B,e),M(E,e),M(G,e),M(V,e),M(k,e),M(F,e)}}}const mt='{"title":"Addestramento effciente su multiple CPU","local":"addestramento-effciente-su-multiple-cpu","sections":[{"title":"Intel® oneCCL Bindings per PyTorch","local":"intel-oneccl-bindings-per-pytorch","sections":[{"title":"Intel® oneCCL Bindings per l’installazione PyTorch:","local":"intel-oneccl-bindings-per-linstallazione-pytorch","sections":[],"depth":3}],"depth":2},{"title":"Intel® MPI library","local":"intel-mpi-library","sections":[{"title":"Installazione IPEX:","local":"installazione-ipex","sections":[],"depth":4}],"depth":2},{"title":"Utilizzo in Trainer","local":"utilizzo-in-trainer","sections":[],"depth":2}],"depth":1}';function ut(ee){return nt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Tt extends at{constructor(p){super(),ot(this,p,ut,dt,lt,{})}}export{Tt as component};
