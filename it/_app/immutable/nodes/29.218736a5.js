import{s as Pl,o as Dl,n as G}from"../chunks/scheduler.36a0863c.js";import{S as Kl,i as Ol,g as w,s as p,r as d,A as es,h as j,f as a,c as m,j as Sl,u as $,x as T,k as Ql,y as ts,a as n,v as g,d as b,t as h,w as M}from"../chunks/index.9c13489a.js";import{T as Qe}from"../chunks/Tip.3b06990e.js";import{Y as El}from"../chunks/Youtube.347c76e5.js";import{C as J}from"../chunks/CodeBlock.05d8ec32.js";import{D as ls}from"../chunks/DocNotebookDropdown.653c9eec.js";import{F as Se,M as x}from"../chunks/Markdown.88297c0b.js";import{H as Q}from"../chunks/Heading.7a254a62.js";function ss(y){let l,o=`Tutti gli esempi di codice presenti in questa documentazione hanno un pulsante in alto a sinistra che permette di selezionare tra PyTorch e TensorFlow. Se
questo non è presente, ci si aspetta che il codice funzioni per entrambi i backend senza alcun cambiamento.`;return{c(){l=w("p"),l.textContent=o},l(t){l=j(t,"P",{"data-svelte-h":!0}),T(l)!=="svelte-8wrg7y"&&(l.textContent=o)},m(t,i){n(t,l,i)},p:G,d(t){t&&a(l)}}}function as(y){let l,o='Per maggiori dettagli legati alla <code>pipeline()</code> e ai compiti ad essa associati, fai riferimento alla documentazione <a href="./main_classes/pipelines">qui</a>.';return{c(){l=w("p"),l.innerHTML=o},l(t){l=j(t,"P",{"data-svelte-h":!0}),T(l)!=="svelte-1x9csbh"&&(l.innerHTML=o)},m(t,i){n(t,l,i)},p:G,d(t){t&&a(l)}}}function ns(y){let l,o;return l=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRvcmNo",highlighted:"pip install torch",wrap:!1}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p:G,i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function is(y){let l,o;return l=new x({props:{$$slots:{default:[ns]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function os(y){let l,o;return l=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRlbnNvcmZsb3c=",highlighted:"pip install tensorflow",wrap:!1}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p:G,i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function rs(y){let l,o;return l=new x({props:{$$slots:{default:[os]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function ps(y){let l,o="Usa <code>AutoModelForSequenceClassification</code> e <code>AutoTokenizer</code> per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una <code>AutoClass</code> in seguito):",t,i,c;return i=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){l=w("p"),l.innerHTML=o,t=p(),d(i.$$.fragment)},l(f){l=j(f,"P",{"data-svelte-h":!0}),T(l)!=="svelte-64igrm"&&(l.innerHTML=o),t=m(f),$(i.$$.fragment,f)},m(f,k){n(f,l,k),n(f,t,k),g(i,f,k),c=!0},p:G,i(f){c||(b(i.$$.fragment,f),c=!0)},o(f){h(i.$$.fragment,f),c=!1},d(f){f&&(a(l),a(t)),M(i,f)}}}function ms(y){let l,o;return l=new x({props:{$$slots:{default:[ps]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function cs(y){let l,o="Usa <code>TFAutoModelForSequenceClassification</code> e <code>AutoTokenizer</code> per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una <code>TFAutoClass</code> in seguito):",t,i,c;return i=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQobW9kZWxfbmFtZSklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){l=w("p"),l.innerHTML=o,t=p(),d(i.$$.fragment)},l(f){l=j(f,"P",{"data-svelte-h":!0}),T(l)!=="svelte-1ihjf5u"&&(l.innerHTML=o),t=m(f),$(i.$$.fragment,f)},m(f,k){n(f,l,k),n(f,t,k),g(i,f,k),c=!0},p:G,i(f){c||(b(i.$$.fragment,f),c=!0)},o(f){h(i.$$.fragment,f),c=!1},d(f){f&&(a(l),a(t)),M(i,f)}}}function us(y){let l,o;return l=new x({props:{$$slots:{default:[cs]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function fs(y){let l,o;return l=new J({props:{code:"cHRfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyU2lhbW8lMjBtb2x0byUyMGZlbGljaSUyMGRpJTIwbW9zdHJhcnRpJTIwbGElMjBsaWJyZXJpYSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIlMkMlMjAlMjJTcGVyaWFtbyUyMHRlJTIwbm9uJTIwbGElMjBvZGllcmFpLiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria 🤗 Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p:G,i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function ds(y){let l,o;return l=new x({props:{$$slots:{default:[fs]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function $s(y){let l,o;return l=new J({props:{code:"dGZfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyU2lhbW8lMjBtb2x0byUyMGZlbGljaSUyMGRpJTIwbW9zdHJhcnRpJTIwbGElMjBsaWJyZXJpYSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIlMkMlMjAlMjJTcGVyaWFtbyUyMHRlJTIwbm9uJTIwbGElMjBvZGllcmFpLiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria 🤗 Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p:G,i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function gs(y){let l,o;return l=new x({props:{$$slots:{default:[$s]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function bs(y){let l,o='Guarda il <a href="./task_summary">task summary</a> per sapere quale classe di <code>AutoModel</code> utilizzare per quale compito.';return{c(){l=w("p"),l.innerHTML=o},l(t){l=j(t,"P",{"data-svelte-h":!0}),T(l)!=="svelte-11t4fw3"&&(l.innerHTML=o)},m(t,i){n(t,l,i)},p:G,d(t){t&&a(l)}}}function hs(y){let l,o="🤗 Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un <code>AutoModel</code> come caricheresti un <code>AutoTokenizer</code>. L’unica differenza è selezionare l’<code>AutoModel</code> corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica <code>AutoModelForSequenceClassification</code>:",t,i,c,f,k,z,U="Ora puoi passare il tuo lotto di input pre-processati direttamente al modello. Devi solo spacchettare il dizionario aggiungendo <code>**</code>:",C,u,_,R,H="Il modello produrrà le attivazioni finali nell’attributo <code>logits</code>. Applica la funzione softmax a <code>logits</code> per ottenere le probabilità:",W,Z,V;return i=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEFwdF9tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),f=new Qe({props:{$$slots:{default:[bs]},$$scope:{ctx:y}}}),u=new J({props:{code:"cHRfb3V0cHV0cyUyMCUzRCUyMHB0X21vZGVsKCoqcHRfYmF0Y2gp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)',wrap:!1}}),Z=new J({props:{code:"ZnJvbSUyMHRvcmNoJTIwaW1wb3J0JTIwbm4lMEElMEFwdF9wcmVkaWN0aW9ucyUyMCUzRCUyMG5uLmZ1bmN0aW9uYWwuc29mdG1heChwdF9vdXRwdXRzLmxvZ2l0cyUyQyUyMGRpbSUzRC0xKSUwQXByaW50KHB0X3ByZWRpY3Rpb25zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0041</span>, <span class="hljs-number">0.0037</span>, <span class="hljs-number">0.0203</span>, <span class="hljs-number">0.2005</span>, <span class="hljs-number">0.7713</span>],
        [<span class="hljs-number">0.3766</span>, <span class="hljs-number">0.3292</span>, <span class="hljs-number">0.1832</span>, <span class="hljs-number">0.0558</span>, <span class="hljs-number">0.0552</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`,wrap:!1}}),{c(){l=w("p"),l.innerHTML=o,t=p(),d(i.$$.fragment),c=p(),d(f.$$.fragment),k=p(),z=w("p"),z.innerHTML=U,C=p(),d(u.$$.fragment),_=p(),R=w("p"),R.innerHTML=H,W=p(),d(Z.$$.fragment)},l(r){l=j(r,"P",{"data-svelte-h":!0}),T(l)!=="svelte-1fgrwgv"&&(l.innerHTML=o),t=m(r),$(i.$$.fragment,r),c=m(r),$(f.$$.fragment,r),k=m(r),z=j(r,"P",{"data-svelte-h":!0}),T(z)!=="svelte-17kjm32"&&(z.innerHTML=U),C=m(r),$(u.$$.fragment,r),_=m(r),R=j(r,"P",{"data-svelte-h":!0}),T(R)!=="svelte-1g2h8eb"&&(R.innerHTML=H),W=m(r),$(Z.$$.fragment,r)},m(r,v){n(r,l,v),n(r,t,v),g(i,r,v),n(r,c,v),g(f,r,v),n(r,k,v),n(r,z,v),n(r,C,v),g(u,r,v),n(r,_,v),n(r,R,v),n(r,W,v),g(Z,r,v),V=!0},p(r,v){const F={};v&2&&(F.$$scope={dirty:v,ctx:r}),f.$set(F)},i(r){V||(b(i.$$.fragment,r),b(f.$$.fragment,r),b(u.$$.fragment,r),b(Z.$$.fragment,r),V=!0)},o(r){h(i.$$.fragment,r),h(f.$$.fragment,r),h(u.$$.fragment,r),h(Z.$$.fragment,r),V=!1},d(r){r&&(a(l),a(t),a(c),a(k),a(z),a(C),a(_),a(R),a(W)),M(i,r),M(f,r),M(u,r),M(Z,r)}}}function Ms(y){let l,o;return l=new x({props:{$$slots:{default:[hs]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function ys(y){let l,o='Guarda il <a href="./task_summary">task summary</a> per sapere quale classe di <code>AutoModel</code> utilizzare per quale compito.';return{c(){l=w("p"),l.innerHTML=o},l(t){l=j(t,"P",{"data-svelte-h":!0}),T(l)!=="svelte-11t4fw3"&&(l.innerHTML=o)},m(t,i){n(t,l,i)},p:G,d(t){t&&a(l)}}}function ws(y){let l,o="🤗 Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un <code>TFAutoModel</code> come caricheresti un <code>AutoTokenizer</code>. L’unica differenza è selezionare il <code>TFAutoModel</code> corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica <code>TFAutoModelForSequenceClassification</code>:",t,i,c,f,k,z,U="Ora puoi passare il tuo lotto di input pre-processati direttamente al modello passando le chiavi del dizionario al tensore:",C,u,_,R,H="Il modello produrrà le attivazioni finali nell’attributo <code>logits</code>. Applica la funzione softmax a <code>logits</code> per ottenere le probabilità:",W,Z,V;return i=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW5vbWVfZGVsX21vZGVsbG8lMjAlM0QlMjAlMjJubHB0b3duJTJGYmVydC1iYXNlLW11bHRpbGluZ3VhbC11bmNhc2VkLXNlbnRpbWVudCUyMiUwQXRmX21vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChub21lX2RlbF9tb2RlbGxvKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(nome_del_modello)`,wrap:!1}}),f=new Qe({props:{$$slots:{default:[ys]},$$scope:{ctx:y}}}),u=new J({props:{code:"dGZfb3V0cHV0cyUyMCUzRCUyMHRmX21vZGVsKHRmX2JhdGNoKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)',wrap:!1}}),Z=new J({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9wcmVkaWN0aW9ucyUyMCUzRCUyMHRmLm5uLnNvZnRtYXgodGZfb3V0cHV0cy5sb2dpdHMlMkMlMjBheGlzJTNELTEpJTBBdGZfcHJlZGljdGlvbnM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`,wrap:!1}}),{c(){l=w("p"),l.innerHTML=o,t=p(),d(i.$$.fragment),c=p(),d(f.$$.fragment),k=p(),z=w("p"),z.textContent=U,C=p(),d(u.$$.fragment),_=p(),R=w("p"),R.innerHTML=H,W=p(),d(Z.$$.fragment)},l(r){l=j(r,"P",{"data-svelte-h":!0}),T(l)!=="svelte-12ss547"&&(l.innerHTML=o),t=m(r),$(i.$$.fragment,r),c=m(r),$(f.$$.fragment,r),k=m(r),z=j(r,"P",{"data-svelte-h":!0}),T(z)!=="svelte-1pbq5oa"&&(z.textContent=U),C=m(r),$(u.$$.fragment,r),_=m(r),R=j(r,"P",{"data-svelte-h":!0}),T(R)!=="svelte-1g2h8eb"&&(R.innerHTML=H),W=m(r),$(Z.$$.fragment,r)},m(r,v){n(r,l,v),n(r,t,v),g(i,r,v),n(r,c,v),g(f,r,v),n(r,k,v),n(r,z,v),n(r,C,v),g(u,r,v),n(r,_,v),n(r,R,v),n(r,W,v),g(Z,r,v),V=!0},p(r,v){const F={};v&2&&(F.$$scope={dirty:v,ctx:r}),f.$set(F)},i(r){V||(b(i.$$.fragment,r),b(f.$$.fragment,r),b(u.$$.fragment,r),b(Z.$$.fragment,r),V=!0)},o(r){h(i.$$.fragment,r),h(f.$$.fragment,r),h(u.$$.fragment,r),h(Z.$$.fragment,r),V=!1},d(r){r&&(a(l),a(t),a(c),a(k),a(z),a(C),a(_),a(R),a(W)),M(i,r),M(f,r),M(u,r),M(Z,r)}}}function js(y){let l,o;return l=new x({props:{$$slots:{default:[ws]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function Ts(y){let l,o=`Tutti i modelli di 🤗 Transformers (PyTorch e TensorFlow) restituiscono i tensori <em>prima</em> della funzione finale
di attivazione (come la softmax) perché la funzione di attivazione finale viene spesso unita a quella di perdita.`;return{c(){l=w("p"),l.innerHTML=o},l(t){l=j(t,"P",{"data-svelte-h":!0}),T(l)!=="svelte-7wdla3"&&(l.innerHTML=o)},m(t,i){n(t,l,i)},p:G,d(t){t&&a(l)}}}function vs(y){let l,o=`Gli output del modello di 🤗 Transformers sono delle dataclasses speciali in modo che i loro attributi vengano auto-completati all’interno di un IDE.
Gli output del modello si comportano anche come una tupla o un dizionario (ad esempio, puoi indicizzare con un intero, una slice o una stringa) nel qual caso gli attributi che sono <code>None</code> vengono ignorati.`;return{c(){l=w("p"),l.innerHTML=o},l(t){l=j(t,"P",{"data-svelte-h":!0}),T(l)!=="svelte-fglpz9"&&(l.innerHTML=o)},m(t,i){n(t,l,i)},p:G,d(t){t&&a(l)}}}function _s(y){let l,o="Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando <code>PreTrainedModel.save_pretrained()</code>:",t,i,c,f,k="Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con <code>PreTrainedModel.from_pretrained()</code>:",z,U,C;return i=new J({props:{code:"cHRfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZChwdF9zYXZlX2RpcmVjdG9yeSklMEFwdF9tb2RlbC5zYXZlX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`,wrap:!1}}),U=new J({props:{code:"cHRfbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)',wrap:!1}}),{c(){l=w("p"),l.innerHTML=o,t=p(),d(i.$$.fragment),c=p(),f=w("p"),f.innerHTML=k,z=p(),d(U.$$.fragment)},l(u){l=j(u,"P",{"data-svelte-h":!0}),T(l)!=="svelte-112corq"&&(l.innerHTML=o),t=m(u),$(i.$$.fragment,u),c=m(u),f=j(u,"P",{"data-svelte-h":!0}),T(f)!=="svelte-fshbgg"&&(f.innerHTML=k),z=m(u),$(U.$$.fragment,u)},m(u,_){n(u,l,_),n(u,t,_),g(i,u,_),n(u,c,_),n(u,f,_),n(u,z,_),g(U,u,_),C=!0},p:G,i(u){C||(b(i.$$.fragment,u),b(U.$$.fragment,u),C=!0)},o(u){h(i.$$.fragment,u),h(U.$$.fragment,u),C=!1},d(u){u&&(a(l),a(t),a(c),a(f),a(z)),M(i,u),M(U,u)}}}function ks(y){let l,o;return l=new x({props:{$$slots:{default:[_s]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function zs(y){let l,o="Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando <code>TFPreTrainedModel.save_pretrained()</code>:",t,i,c,f,k="Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con <code>TFPreTrainedModel.from_pretrained()</code>:",z,U,C;return i=new J({props:{code:"dGZfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGdGZfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZCh0Zl9zYXZlX2RpcmVjdG9yeSklMEF0Zl9tb2RlbC5zYXZlX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`,wrap:!1}}),U=new J({props:{code:"dGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMi4lMkZ0Zl9zYXZlX3ByZXRyYWluZWQlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)',wrap:!1}}),{c(){l=w("p"),l.innerHTML=o,t=p(),d(i.$$.fragment),c=p(),f=w("p"),f.innerHTML=k,z=p(),d(U.$$.fragment)},l(u){l=j(u,"P",{"data-svelte-h":!0}),T(l)!=="svelte-5qobr8"&&(l.innerHTML=o),t=m(u),$(i.$$.fragment,u),c=m(u),f=j(u,"P",{"data-svelte-h":!0}),T(f)!=="svelte-15tj3au"&&(f.innerHTML=k),z=m(u),$(U.$$.fragment,u)},m(u,_){n(u,l,_),n(u,t,_),g(i,u,_),n(u,c,_),n(u,f,_),n(u,z,_),g(U,u,_),C=!0},p:G,i(u){C||(b(i.$$.fragment,u),b(U.$$.fragment,u),C=!0)},o(u){h(i.$$.fragment,u),h(U.$$.fragment,u),C=!1},d(u){u&&(a(l),a(t),a(c),a(f),a(z)),M(i,u),M(U,u)}}}function Js(y){let l,o;return l=new x({props:{$$slots:{default:[zs]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function Us(y){let l,o;return l=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKHRmX3NhdmVfZGlyZWN0b3J5KSUwQXB0X21vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3RvcnklMkMlMjBmcm9tX3RmJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p:G,i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function Zs(y){let l,o;return l=new x({props:{$$slots:{default:[Us]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function Cs(y){let l,o;return l=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3RvcnkpJTBBdGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKHB0X3NhdmVfZGlyZWN0b3J5JTJDJTIwZnJvbV9wdCUzRFRydWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p:G,i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function Rs(y){let l,o;return l=new x({props:{$$slots:{default:[Cs]},$$scope:{ctx:y}}}),{c(){d(l.$$.fragment)},l(t){$(l.$$.fragment,t)},m(t,i){g(l,t,i),o=!0},p(t,i){const c={};i&2&&(c.$$scope={dirty:i,ctx:t}),l.$set(c)},i(t){o||(b(l.$$.fragment,t),o=!0)},o(t){h(l.$$.fragment,t),o=!1},d(t){M(l,t)}}}function Gs(y){let l,o,t,i,c,f,k,z,U,C='Entra in azione con 🤗 Transformers! Inizia utilizzando <code>pipeline()</code> per un’inferenza veloce, carica un modello pre-allenato e un tokenizer con una <a href="./model_doc/auto">AutoClass</a> per risolvere i tuoi compiti legati a testo, immagini o audio.',u,_,R,H,W,Z,V="<code>pipeline()</code> è il modo più semplice per utilizzare un modello pre-allenato per un dato compito.",r,v,F,E,al="La <code>pipeline()</code> supporta molti compiti comuni:",Pe,P,nl="<strong>Testo</strong>:",De,D,il="<li>Analisi del Sentimento (Sentiment Analysis, in inglese): classifica la polarità di un testo dato.</li> <li>Generazione del Testo (Text Generation, in inglese): genera del testo a partire da un dato input.</li> <li>Riconoscimento di Entità (Name Entity Recognition o NER, in inglese): etichetta ogni parola con l’entità che questa rappresenta (persona, data, luogo, ecc.).</li> <li>Rispondere a Domande (Question answering, in inglese): estrae la risposta da un contesto, dato del contesto e una domanda.</li> <li>Riempimento di Maschere (Fill-mask, in inglese): riempie gli spazi mancanti in un testo che ha parole mascherate.</li> <li>Riassumere (Summarization, in inglese): genera una sintesi di una lunga sequenza di testo o di un documento.</li> <li>Traduzione (Translation, in inglese): traduce un testo in un’altra lingua.</li> <li>Estrazione di Caratteristiche (Feature Extraction, in inglese): crea un tensore che rappresenta un testo.</li>",Ke,K,ol="<strong>Immagini</strong>:",Oe,O,rl="<li>Classificazione di Immagini (Image Classification, in inglese): classifica un’immagine.</li> <li>Segmentazione di Immagini (Image Segmentation, in inglese): classifica ogni pixel di un’immagine.</li> <li>Rilevazione di Oggetti (Object Detection, in inglese): rileva oggetti all’interno di un’immagine.</li>",et,ee,pl="<strong>Audio</strong>:",tt,te,ml="<li>Classificazione di Audio (Audio Classification, in inglese): assegna un’etichetta ad un segmento di audio dato.</li> <li>Riconoscimento Vocale Automatico (Automatic Speech Recognition o ASR, in inglese): trascrive il contenuto di un audio dato in un testo.</li>",lt,I,st,le,at,se,cl="Nel seguente esempio, utilizzerai la <code>pipeline()</code> per l’analisi del sentimento.",nt,ae,ul="Installa le seguenti dipendenze se non lo hai già fatto:",it,X,ot,ne,fl="Importa <code>pipeline()</code> e specifica il compito che vuoi completare:",rt,ie,pt,oe,dl='La pipeline scarica e salva il <a href="https://huggingface.co/MilaNLProc/feel-it-italian-sentiment" rel="nofollow">modello pre-allenato</a> e il tokenizer per l’analisi del sentimento. Se non avessimo scelto un modello, la pipeline ne avrebbe scelto uno di default. Ora puoi utilizzare il <code>classifier</code> sul tuo testo obiettivo:',mt,re,ct,pe,$l="Per più di una frase, passa una lista di frasi alla <code>pipeline()</code> la quale restituirà una lista di dizionari:",ut,me,ft,ce,gl='La <code>pipeline()</code> può anche iterare su un dataset intero. Inizia installando la libreria <a href="https://huggingface.co/docs/datasets/" rel="nofollow">🤗 Datasets</a>:',dt,ue,$t,fe,bl="Crea una <code>pipeline()</code> con il compito che vuoi risolvere e con il modello che vuoi utilizzare.",gt,de,bt,$e,hl='Poi, carica un dataset (vedi 🤗 Datasets <a href="https://huggingface.co/docs/datasets/quickstart" rel="nofollow">Quick Start</a> per maggiori dettagli) sul quale vuoi iterare. Per esempio, carichiamo il dataset <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a>:',ht,ge,Mt,be,Ml="Dobbiamo assicurarci che la frequenza di campionamento del set di dati corrisponda alla frequenza di campionamento con cui è stato addestrato <code>radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram</code>.",yt,he,wt,Me,yl=`I file audio vengono caricati automaticamente e ri-campionati quando chiamiamo la colonna “audio”.
Estraiamo i vettori delle forme d’onda grezze delle prime 4 osservazioni e passiamoli come lista alla pipeline:`,jt,ye,Tt,we,wl='Per un dataset più grande dove gli input sono di dimensione maggiore (come nel parlato/audio o nella visione), dovrai passare un generatore al posto di una lista che carica tutti gli input in memoria. Guarda la <a href="./main_classes/pipelines">documentazione della pipeline</a> per maggiori informazioni.',vt,je,_t,Te,jl='La <code>pipeline()</code> può ospitare qualsiasi modello del <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>, rendendo semplice l’adattamento della <code>pipeline()</code> per altri casi d’uso. Per esempio, se si vuole un modello capace di trattare testo in francese, usa i tag presenti nel Model Hub in modo da filtrare per ottenere un modello appropriato. Il miglior risultato filtrato restituisce un modello multi-lingua <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment" rel="nofollow">BERT model</a> fine-tuned per l’analisi del sentimento. Ottimo, utilizziamo questo modello!',kt,ve,zt,L,Jt,_e,Tl="Poi puoi specificare il modello e il tokenizer nella <code>pipeline()</code>, e applicare il <code>classifier</code> sul tuo testo obiettivo:",Ut,ke,Zt,ze,vl='Se non riesci a trovare un modello per il tuo caso d’uso, dovrai fare fine-tuning di un modello pre-allenato sui tuoi dati. Dai un’occhiata al nostro tutorial <a href="./training">fine-tuning tutorial</a> per imparare come. Infine, dopo che hai completato il fine-tuning del tuo modello pre-allenato, considera per favore di condividerlo (vedi il tutorial <a href="./model_sharing">qui</a>) con la comunità sul Model Hub per democratizzare l’NLP! 🤗',Ct,Je,Rt,Ue,Gt,Ze,_l='Al suo interno, le classi <code>AutoModelForSequenceClassification</code> e <code>AutoTokenizer</code> lavorano assieme per dare potere alla <code>pipeline()</code>. Una <a href="./model_doc/auto">AutoClass</a> è una scorciatoia che automaticamente recupera l’architettura di un modello pre-allenato a partire dal suo nome o path. Hai solo bisogno di selezionare la <code>AutoClass</code> appropriata per il tuo compito e il suo tokenizer associato con <code>AutoTokenizer</code>.',Wt,Ce,kl="Ritorniamo al nostro esempio e vediamo come puoi utilizzare la <code>AutoClass</code> per replicare i risultati della <code>pipeline()</code>.",Ht,Re,Vt,Ge,zl='Un tokenizer è responsabile dell’elaborazione del testo in modo da trasformarlo in un formato comprensibile dal modello. Per prima cosa, il tokenizer dividerà il testo in parole chiamate <em>token</em>. Ci sono diverse regole che governano il processo di tokenizzazione, tra cui come dividere una parola e a quale livello (impara di più sulla tokenizzazione <a href="./tokenizer_summary">qui</a>). La cosa più importante da ricordare comunque è che hai bisogno di inizializzare il tokenizer con lo stesso nome del modello in modo da assicurarti che stai utilizzando le stesse regole di tokenizzazione con cui il modello è stato pre-allenato.',xt,We,Jl="Carica un tokenizer con <code>AutoTokenizer</code>:",Ft,He,It,Ve,Ul="Dopodiché, il tokenizer converte i token in numeri in modo da costruire un tensore come input del modello. Questo è conosciuto come il <em>vocabolario</em> del modello.",Xt,xe,Zl="Passa il tuo testo al tokenizer:",Lt,Fe,qt,Ie,Cl="Il tokenizer restituirà un dizionario contenente:",Bt,Xe,Rl='<li><a href="./glossary#input-ids">input_ids</a>: rappresentazioni numeriche dei tuoi token.</li> <li><a href=".glossary#attention-mask">attention_mask</a>: indica quali token devono essere presi in considerazione.</li>',Nt,Le,Gl="Come con la <code>pipeline()</code>, il tokenizer accetterà una lista di input. In più, il tokenizer può anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:",Yt,q,At,qe,Wl='Leggi il tutorial sul <a href="./preprocessing">preprocessing</a> per maggiori dettagli sulla tokenizzazione.',St,Be,Qt,B,Et,N,Pt,Ne,Hl='I modelli sono <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow"><code>torch.nn.Module</code></a> o <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow"><code>tf.keras.Model</code></a> standard così puoi utilizzarli all’interno del tuo training loop usuale. Tuttavia, per rendere le cose più semplici, 🤗 Transformers fornisce una classe <code>Trainer</code> per PyTorch che aggiunge delle funzionalità per l’allenamento distribuito, precisione mista, e altro ancora. Per TensorFlow, puoi utilizzare il metodo <code>fit</code> di <a href="https://keras.io/" rel="nofollow">Keras</a>. Fai riferimento al <a href="./training">tutorial per il training</a> per maggiori dettagli.',Dt,Y,Kt,Ye,Ot,A,el,Ae,Vl="Una caratteristica particolarmente interessante di 🤗 Transformers è la sua abilità di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri <code>from_pt</code> o <code>from_tf</code> possono convertire un modello da un framework all’altro:",tl,S,ll,Ee,sl;return c=new Q({props:{title:"Quick tour",local:"quick-tour",headingTag:"h1"}}),k=new ls({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/it/tensorflow/quicktour.ipynb"}]}}),_=new Qe({props:{$$slots:{default:[ss]},$$scope:{ctx:y}}}),H=new Q({props:{title:"Pipeline",local:"pipeline",headingTag:"h2"}}),v=new El({props:{id:"tiZFewofSLM"}}),I=new Qe({props:{$$slots:{default:[as]},$$scope:{ctx:y}}}),le=new Q({props:{title:"Utilizzo della Pipeline",local:"utilizzo-della-pipeline",headingTag:"h3"}}),X=new Se({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[rs],pytorch:[is]},$$scope:{ctx:y}}}),ie=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmljYXRvcmUlMjAlM0QlMjBwaXBlbGluZSglMjJzZW50aW1lbnQtYW5hbHlzaXMlMjIlMkMlMjBtb2RlbCUzRCUyMk1pbGFOTFByb2MlMkZmZWVsLWl0LWl0YWxpYW4tc2VudGltZW50JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=<span class="hljs-string">&quot;MilaNLProc/feel-it-italian-sentiment&quot;</span>)`,wrap:!1}}),re=new J({props:{code:"Y2xhc3NpZmljYXRvcmUoJTIyU2lhbW8lMjBtb2x0byUyMGZlbGljaSUyMGRpJTIwbW9zdHJhcnRpJTIwbGElMjBsaWJyZXJpYSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classificatore(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria 🤗 Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;positive&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9997</span>}]`,wrap:!1}}),me=new J({props:{code:"cmlzdWx0YXRpJTIwJTNEJTIwY2xhc3NpZmljYXRvcmUoJTBBJTIwJTIwJTIwJTIwJTVCJTIyU2lhbW8lMjBtb2x0byUyMGZlbGljaSUyMGRpJTIwbW9zdHJhcnRpJTIwbGElMjBsaWJyZXJpYSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIlMkMlMjAlMjJTcGVyaWFtbyUyMHRlJTIwbm9uJTIwbGElMjBvZGllcmFpLiUyMiU1RCUwQSklMEFmb3IlMjByaXN1bHRhdG8lMjBpbiUyMHJpc3VsdGF0aSUzQSUwQSUyMCUyMCUyMCUyMHByaW50KGYlMjJldGljaGV0dGElM0ElMjAlN0JyaXN1bHRhdG8lNUInbGFiZWwnJTVEJTdEJTJDJTIwY29uJTIwcHVudGVnZ2lvJTNBJTIwJTdCcm91bmQocmlzdWx0YXRvJTVCJ3Njb3JlJyU1RCUyQyUyMDQpJTdEJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultati = classificatore(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria 🤗 Transformers.&quot;</span>, <span class="hljs-string">&quot;Speriamo te non la odierai.&quot;</span>]
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> risultato <span class="hljs-keyword">in</span> risultati:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;etichetta: <span class="hljs-subst">{risultato[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, con punteggio: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(risultato[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
etichetta: positive, con punteggio: <span class="hljs-number">0.9998</span>
etichetta: negative, con punteggio: <span class="hljs-number">0.9998</span>`,wrap:!1}}),ue=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRzJTIw",highlighted:"pip install datasets ",wrap:!1}}),de=new J({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwcGlwZWxpbmUlMEElMEFyaWNvbm9zY2l0b3JlX3ZvY2FsZSUyMCUzRCUyMHBpcGVsaW5lKCUwQSUyMCUyMCUyMCUyMCUyMmF1dG9tYXRpYy1zcGVlY2gtcmVjb2duaXRpb24lMjIlMkMlMjBtb2RlbCUzRCUyMnJhZGlvZ3JvdXAtY3JpdHMlMkZ3YXYydmVjMi14bHMtci0xYi1pdGFsaWFuLWRvYzRsbS01Z3JhbSUyMiUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>riconoscitore_vocale = pipeline(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;radiogroup-crits/wav2vec2-xls-r-1b-italian-doc4lm-5gram&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),ge=new J({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjBuYW1lJTNEJTIyaXQtSVQlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;it-IT&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),he=new J({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEcmljb25vc2NpdG9yZV92b2NhbGUuZmVhdHVyZV9leHRyYWN0b3Iuc2FtcGxpbmdfcmF0ZSkp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=riconoscitore_vocale.feature_extractor.sampling_rate))',wrap:!1}}),ye=new J({props:{code:"cmlzdWx0YXRvJTIwJTNEJTIwcmljb25vc2NpdG9yZV92b2NhbGUoZGF0YXNldCU1QiUzQTQlNUQlNUIlMjJhdWRpbyUyMiU1RCklMEFwcmludCglNUJkJTVCJTIydGV4dCUyMiU1RCUyMGZvciUyMGQlMjBpbiUyMHJpc3VsdGF0byU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>risultato = riconoscitore_vocale(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> risultato])
[<span class="hljs-string">&#x27;dovrei caricare dei soldi sul mio conto corrente&#x27;</span>, <span class="hljs-string">&#x27;buongiorno e senza vorrei depositare denaro sul mio conto corrente come devo fare per cortesia&#x27;</span>, <span class="hljs-string">&#x27;sì salve vorrei depositare del denaro sul mio conto&#x27;</span>, <span class="hljs-string">&#x27;e buon pomeriggio vorrei depositare dei soldi sul mio conto bancario volleo sapere come posso fare se e posso farlo online ed un altro conto o andandoo tramite bancomut&#x27;</span>]`,wrap:!1}}),je=new Q({props:{title:"Utilizzare un altro modello e tokenizer nella pipeline",local:"utilizzare-un-altro-modello-e-tokenizer-nella-pipeline",headingTag:"h3"}}),ve=new J({props:{code:"bW9kZWxfbmFtZSUyMCUzRCUyMCUyMm5scHRvd24lMkZiZXJ0LWJhc2UtbXVsdGlsaW5ndWFsLXVuY2FzZWQtc2VudGltZW50JTIy",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>',wrap:!1}}),L=new Se({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[us],pytorch:[ms]},$$scope:{ctx:y}}}),ke=new J({props:{code:"Y2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnNlbnRpbWVudC1hbmFseXNpcyUyMiUyQyUyMG1vZGVsJTNEbW9kZWwlMkMlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIpJTBBY2xhc3NpZmllciglMjJOb3VzJTIwc29tbWVzJTIwdHIlQzMlQThzJTIwaGV1cmV1eCUyMGRlJTIwdm91cyUyMHByJUMzJUE5c2VudGVyJTIwbGElMjBiaWJsaW90aCVDMyVBOHF1ZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`,wrap:!1}}),Je=new Q({props:{title:"AutoClass",local:"autoclass",headingTag:"h2"}}),Ue=new El({props:{id:"AhChOFRegn4"}}),Re=new Q({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h3"}}),He=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEFub21lX2RlbF9tb2RlbGxvJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChub21lX2RlbF9tb2RlbGxvKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>nome_del_modello = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(nome_del_modello)`,wrap:!1}}),Fe=new J({props:{code:"ZW5jb2RpbmclMjAlM0QlMjB0b2tlbml6ZXIoJTIyU2lhbW8lMjBtb2x0byUyMGZlbGljaSUyMGRpJTIwbW9zdHJhcnRpJTIwbGElMjBsaWJyZXJpYSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIpJTBBcHJpbnQoZW5jb2Rpbmcp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;Siamo molto felici di mostrarti la libreria 🤗 Transformers.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">56821</span>, <span class="hljs-number">10132</span>, <span class="hljs-number">14407</span>, <span class="hljs-number">13019</span>, <span class="hljs-number">13007</span>, <span class="hljs-number">10120</span>, <span class="hljs-number">47201</span>, <span class="hljs-number">10330</span>, <span class="hljs-number">10106</span>, <span class="hljs-number">91686</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
<span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
<span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),q=new Se({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[gs],pytorch:[ds]},$$scope:{ctx:y}}}),Be=new Q({props:{title:"AutoModel",local:"automodel",headingTag:"h3"}}),B=new Se({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[js],pytorch:[Ms]},$$scope:{ctx:y}}}),N=new Qe({props:{$$slots:{default:[Ts]},$$scope:{ctx:y}}}),Y=new Qe({props:{$$slots:{default:[vs]},$$scope:{ctx:y}}}),Ye=new Q({props:{title:"Salva un modello",local:"salva-un-modello",headingTag:"h3"}}),A=new Se({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Js],pytorch:[ks]},$$scope:{ctx:y}}}),S=new Se({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Rs],pytorch:[Zs]},$$scope:{ctx:y}}}),{c(){l=w("meta"),o=p(),t=w("p"),i=p(),d(c.$$.fragment),f=p(),d(k.$$.fragment),z=p(),U=w("p"),U.innerHTML=C,u=p(),d(_.$$.fragment),R=p(),d(H.$$.fragment),W=p(),Z=w("p"),Z.innerHTML=V,r=p(),d(v.$$.fragment),F=p(),E=w("p"),E.innerHTML=al,Pe=p(),P=w("p"),P.innerHTML=nl,De=p(),D=w("ul"),D.innerHTML=il,Ke=p(),K=w("p"),K.innerHTML=ol,Oe=p(),O=w("ul"),O.innerHTML=rl,et=p(),ee=w("p"),ee.innerHTML=pl,tt=p(),te=w("ul"),te.innerHTML=ml,lt=p(),d(I.$$.fragment),st=p(),d(le.$$.fragment),at=p(),se=w("p"),se.innerHTML=cl,nt=p(),ae=w("p"),ae.textContent=ul,it=p(),d(X.$$.fragment),ot=p(),ne=w("p"),ne.innerHTML=fl,rt=p(),d(ie.$$.fragment),pt=p(),oe=w("p"),oe.innerHTML=dl,mt=p(),d(re.$$.fragment),ct=p(),pe=w("p"),pe.innerHTML=$l,ut=p(),d(me.$$.fragment),ft=p(),ce=w("p"),ce.innerHTML=gl,dt=p(),d(ue.$$.fragment),$t=p(),fe=w("p"),fe.innerHTML=bl,gt=p(),d(de.$$.fragment),bt=p(),$e=w("p"),$e.innerHTML=hl,ht=p(),d(ge.$$.fragment),Mt=p(),be=w("p"),be.innerHTML=Ml,yt=p(),d(he.$$.fragment),wt=p(),Me=w("p"),Me.textContent=yl,jt=p(),d(ye.$$.fragment),Tt=p(),we=w("p"),we.innerHTML=wl,vt=p(),d(je.$$.fragment),_t=p(),Te=w("p"),Te.innerHTML=jl,kt=p(),d(ve.$$.fragment),zt=p(),d(L.$$.fragment),Jt=p(),_e=w("p"),_e.innerHTML=Tl,Ut=p(),d(ke.$$.fragment),Zt=p(),ze=w("p"),ze.innerHTML=vl,Ct=p(),d(Je.$$.fragment),Rt=p(),d(Ue.$$.fragment),Gt=p(),Ze=w("p"),Ze.innerHTML=_l,Wt=p(),Ce=w("p"),Ce.innerHTML=kl,Ht=p(),d(Re.$$.fragment),Vt=p(),Ge=w("p"),Ge.innerHTML=zl,xt=p(),We=w("p"),We.innerHTML=Jl,Ft=p(),d(He.$$.fragment),It=p(),Ve=w("p"),Ve.innerHTML=Ul,Xt=p(),xe=w("p"),xe.textContent=Zl,Lt=p(),d(Fe.$$.fragment),qt=p(),Ie=w("p"),Ie.textContent=Cl,Bt=p(),Xe=w("ul"),Xe.innerHTML=Rl,Nt=p(),Le=w("p"),Le.innerHTML=Gl,Yt=p(),d(q.$$.fragment),At=p(),qe=w("p"),qe.innerHTML=Wl,St=p(),d(Be.$$.fragment),Qt=p(),d(B.$$.fragment),Et=p(),d(N.$$.fragment),Pt=p(),Ne=w("p"),Ne.innerHTML=Hl,Dt=p(),d(Y.$$.fragment),Kt=p(),d(Ye.$$.fragment),Ot=p(),d(A.$$.fragment),el=p(),Ae=w("p"),Ae.innerHTML=Vl,tl=p(),d(S.$$.fragment),ll=p(),Ee=w("p"),this.h()},l(e){const s=es("svelte-u9bgzb",document.head);l=j(s,"META",{name:!0,content:!0}),s.forEach(a),o=m(e),t=j(e,"P",{}),Sl(t).forEach(a),i=m(e),$(c.$$.fragment,e),f=m(e),$(k.$$.fragment,e),z=m(e),U=j(e,"P",{"data-svelte-h":!0}),T(U)!=="svelte-1elpc0g"&&(U.innerHTML=C),u=m(e),$(_.$$.fragment,e),R=m(e),$(H.$$.fragment,e),W=m(e),Z=j(e,"P",{"data-svelte-h":!0}),T(Z)!=="svelte-1ytt2no"&&(Z.innerHTML=V),r=m(e),$(v.$$.fragment,e),F=m(e),E=j(e,"P",{"data-svelte-h":!0}),T(E)!=="svelte-mdjmm2"&&(E.innerHTML=al),Pe=m(e),P=j(e,"P",{"data-svelte-h":!0}),T(P)!=="svelte-worh5i"&&(P.innerHTML=nl),De=m(e),D=j(e,"UL",{"data-svelte-h":!0}),T(D)!=="svelte-1e7qzwz"&&(D.innerHTML=il),Ke=m(e),K=j(e,"P",{"data-svelte-h":!0}),T(K)!=="svelte-1p3xnk0"&&(K.innerHTML=ol),Oe=m(e),O=j(e,"UL",{"data-svelte-h":!0}),T(O)!=="svelte-1r93uab"&&(O.innerHTML=rl),et=m(e),ee=j(e,"P",{"data-svelte-h":!0}),T(ee)!=="svelte-hdckv1"&&(ee.innerHTML=pl),tt=m(e),te=j(e,"UL",{"data-svelte-h":!0}),T(te)!=="svelte-o2s2lz"&&(te.innerHTML=ml),lt=m(e),$(I.$$.fragment,e),st=m(e),$(le.$$.fragment,e),at=m(e),se=j(e,"P",{"data-svelte-h":!0}),T(se)!=="svelte-1yvy2ke"&&(se.innerHTML=cl),nt=m(e),ae=j(e,"P",{"data-svelte-h":!0}),T(ae)!=="svelte-jq5tv3"&&(ae.textContent=ul),it=m(e),$(X.$$.fragment,e),ot=m(e),ne=j(e,"P",{"data-svelte-h":!0}),T(ne)!=="svelte-1ck58lr"&&(ne.innerHTML=fl),rt=m(e),$(ie.$$.fragment,e),pt=m(e),oe=j(e,"P",{"data-svelte-h":!0}),T(oe)!=="svelte-mfkosw"&&(oe.innerHTML=dl),mt=m(e),$(re.$$.fragment,e),ct=m(e),pe=j(e,"P",{"data-svelte-h":!0}),T(pe)!=="svelte-21vcsp"&&(pe.innerHTML=$l),ut=m(e),$(me.$$.fragment,e),ft=m(e),ce=j(e,"P",{"data-svelte-h":!0}),T(ce)!=="svelte-ms5dby"&&(ce.innerHTML=gl),dt=m(e),$(ue.$$.fragment,e),$t=m(e),fe=j(e,"P",{"data-svelte-h":!0}),T(fe)!=="svelte-wg1lhp"&&(fe.innerHTML=bl),gt=m(e),$(de.$$.fragment,e),bt=m(e),$e=j(e,"P",{"data-svelte-h":!0}),T($e)!=="svelte-e3a2xs"&&($e.innerHTML=hl),ht=m(e),$(ge.$$.fragment,e),Mt=m(e),be=j(e,"P",{"data-svelte-h":!0}),T(be)!=="svelte-11fvfrb"&&(be.innerHTML=Ml),yt=m(e),$(he.$$.fragment,e),wt=m(e),Me=j(e,"P",{"data-svelte-h":!0}),T(Me)!=="svelte-aq6297"&&(Me.textContent=yl),jt=m(e),$(ye.$$.fragment,e),Tt=m(e),we=j(e,"P",{"data-svelte-h":!0}),T(we)!=="svelte-4qw8v7"&&(we.innerHTML=wl),vt=m(e),$(je.$$.fragment,e),_t=m(e),Te=j(e,"P",{"data-svelte-h":!0}),T(Te)!=="svelte-1f97bcn"&&(Te.innerHTML=jl),kt=m(e),$(ve.$$.fragment,e),zt=m(e),$(L.$$.fragment,e),Jt=m(e),_e=j(e,"P",{"data-svelte-h":!0}),T(_e)!=="svelte-gseo06"&&(_e.innerHTML=Tl),Ut=m(e),$(ke.$$.fragment,e),Zt=m(e),ze=j(e,"P",{"data-svelte-h":!0}),T(ze)!=="svelte-slx3it"&&(ze.innerHTML=vl),Ct=m(e),$(Je.$$.fragment,e),Rt=m(e),$(Ue.$$.fragment,e),Gt=m(e),Ze=j(e,"P",{"data-svelte-h":!0}),T(Ze)!=="svelte-x634fr"&&(Ze.innerHTML=_l),Wt=m(e),Ce=j(e,"P",{"data-svelte-h":!0}),T(Ce)!=="svelte-gs7f79"&&(Ce.innerHTML=kl),Ht=m(e),$(Re.$$.fragment,e),Vt=m(e),Ge=j(e,"P",{"data-svelte-h":!0}),T(Ge)!=="svelte-1bqnhye"&&(Ge.innerHTML=zl),xt=m(e),We=j(e,"P",{"data-svelte-h":!0}),T(We)!=="svelte-182cse"&&(We.innerHTML=Jl),Ft=m(e),$(He.$$.fragment,e),It=m(e),Ve=j(e,"P",{"data-svelte-h":!0}),T(Ve)!=="svelte-moayds"&&(Ve.innerHTML=Ul),Xt=m(e),xe=j(e,"P",{"data-svelte-h":!0}),T(xe)!=="svelte-zrjuqi"&&(xe.textContent=Zl),Lt=m(e),$(Fe.$$.fragment,e),qt=m(e),Ie=j(e,"P",{"data-svelte-h":!0}),T(Ie)!=="svelte-mgopot"&&(Ie.textContent=Cl),Bt=m(e),Xe=j(e,"UL",{"data-svelte-h":!0}),T(Xe)!=="svelte-5gvcz"&&(Xe.innerHTML=Rl),Nt=m(e),Le=j(e,"P",{"data-svelte-h":!0}),T(Le)!=="svelte-1gzve8v"&&(Le.innerHTML=Gl),Yt=m(e),$(q.$$.fragment,e),At=m(e),qe=j(e,"P",{"data-svelte-h":!0}),T(qe)!=="svelte-1a2gmgw"&&(qe.innerHTML=Wl),St=m(e),$(Be.$$.fragment,e),Qt=m(e),$(B.$$.fragment,e),Et=m(e),$(N.$$.fragment,e),Pt=m(e),Ne=j(e,"P",{"data-svelte-h":!0}),T(Ne)!=="svelte-lxcxy3"&&(Ne.innerHTML=Hl),Dt=m(e),$(Y.$$.fragment,e),Kt=m(e),$(Ye.$$.fragment,e),Ot=m(e),$(A.$$.fragment,e),el=m(e),Ae=j(e,"P",{"data-svelte-h":!0}),T(Ae)!=="svelte-1ld3j5t"&&(Ae.innerHTML=Vl),tl=m(e),$(S.$$.fragment,e),ll=m(e),Ee=j(e,"P",{}),Sl(Ee).forEach(a),this.h()},h(){Ql(l,"name","hf:doc:metadata"),Ql(l,"content",Ws)},m(e,s){ts(document.head,l),n(e,o,s),n(e,t,s),n(e,i,s),g(c,e,s),n(e,f,s),g(k,e,s),n(e,z,s),n(e,U,s),n(e,u,s),g(_,e,s),n(e,R,s),g(H,e,s),n(e,W,s),n(e,Z,s),n(e,r,s),g(v,e,s),n(e,F,s),n(e,E,s),n(e,Pe,s),n(e,P,s),n(e,De,s),n(e,D,s),n(e,Ke,s),n(e,K,s),n(e,Oe,s),n(e,O,s),n(e,et,s),n(e,ee,s),n(e,tt,s),n(e,te,s),n(e,lt,s),g(I,e,s),n(e,st,s),g(le,e,s),n(e,at,s),n(e,se,s),n(e,nt,s),n(e,ae,s),n(e,it,s),g(X,e,s),n(e,ot,s),n(e,ne,s),n(e,rt,s),g(ie,e,s),n(e,pt,s),n(e,oe,s),n(e,mt,s),g(re,e,s),n(e,ct,s),n(e,pe,s),n(e,ut,s),g(me,e,s),n(e,ft,s),n(e,ce,s),n(e,dt,s),g(ue,e,s),n(e,$t,s),n(e,fe,s),n(e,gt,s),g(de,e,s),n(e,bt,s),n(e,$e,s),n(e,ht,s),g(ge,e,s),n(e,Mt,s),n(e,be,s),n(e,yt,s),g(he,e,s),n(e,wt,s),n(e,Me,s),n(e,jt,s),g(ye,e,s),n(e,Tt,s),n(e,we,s),n(e,vt,s),g(je,e,s),n(e,_t,s),n(e,Te,s),n(e,kt,s),g(ve,e,s),n(e,zt,s),g(L,e,s),n(e,Jt,s),n(e,_e,s),n(e,Ut,s),g(ke,e,s),n(e,Zt,s),n(e,ze,s),n(e,Ct,s),g(Je,e,s),n(e,Rt,s),g(Ue,e,s),n(e,Gt,s),n(e,Ze,s),n(e,Wt,s),n(e,Ce,s),n(e,Ht,s),g(Re,e,s),n(e,Vt,s),n(e,Ge,s),n(e,xt,s),n(e,We,s),n(e,Ft,s),g(He,e,s),n(e,It,s),n(e,Ve,s),n(e,Xt,s),n(e,xe,s),n(e,Lt,s),g(Fe,e,s),n(e,qt,s),n(e,Ie,s),n(e,Bt,s),n(e,Xe,s),n(e,Nt,s),n(e,Le,s),n(e,Yt,s),g(q,e,s),n(e,At,s),n(e,qe,s),n(e,St,s),g(Be,e,s),n(e,Qt,s),g(B,e,s),n(e,Et,s),g(N,e,s),n(e,Pt,s),n(e,Ne,s),n(e,Dt,s),g(Y,e,s),n(e,Kt,s),g(Ye,e,s),n(e,Ot,s),g(A,e,s),n(e,el,s),n(e,Ae,s),n(e,tl,s),g(S,e,s),n(e,ll,s),n(e,Ee,s),sl=!0},p(e,[s]){const xl={};s&2&&(xl.$$scope={dirty:s,ctx:e}),_.$set(xl);const Fl={};s&2&&(Fl.$$scope={dirty:s,ctx:e}),I.$set(Fl);const Il={};s&2&&(Il.$$scope={dirty:s,ctx:e}),X.$set(Il);const Xl={};s&2&&(Xl.$$scope={dirty:s,ctx:e}),L.$set(Xl);const Ll={};s&2&&(Ll.$$scope={dirty:s,ctx:e}),q.$set(Ll);const ql={};s&2&&(ql.$$scope={dirty:s,ctx:e}),B.$set(ql);const Bl={};s&2&&(Bl.$$scope={dirty:s,ctx:e}),N.$set(Bl);const Nl={};s&2&&(Nl.$$scope={dirty:s,ctx:e}),Y.$set(Nl);const Yl={};s&2&&(Yl.$$scope={dirty:s,ctx:e}),A.$set(Yl);const Al={};s&2&&(Al.$$scope={dirty:s,ctx:e}),S.$set(Al)},i(e){sl||(b(c.$$.fragment,e),b(k.$$.fragment,e),b(_.$$.fragment,e),b(H.$$.fragment,e),b(v.$$.fragment,e),b(I.$$.fragment,e),b(le.$$.fragment,e),b(X.$$.fragment,e),b(ie.$$.fragment,e),b(re.$$.fragment,e),b(me.$$.fragment,e),b(ue.$$.fragment,e),b(de.$$.fragment,e),b(ge.$$.fragment,e),b(he.$$.fragment,e),b(ye.$$.fragment,e),b(je.$$.fragment,e),b(ve.$$.fragment,e),b(L.$$.fragment,e),b(ke.$$.fragment,e),b(Je.$$.fragment,e),b(Ue.$$.fragment,e),b(Re.$$.fragment,e),b(He.$$.fragment,e),b(Fe.$$.fragment,e),b(q.$$.fragment,e),b(Be.$$.fragment,e),b(B.$$.fragment,e),b(N.$$.fragment,e),b(Y.$$.fragment,e),b(Ye.$$.fragment,e),b(A.$$.fragment,e),b(S.$$.fragment,e),sl=!0)},o(e){h(c.$$.fragment,e),h(k.$$.fragment,e),h(_.$$.fragment,e),h(H.$$.fragment,e),h(v.$$.fragment,e),h(I.$$.fragment,e),h(le.$$.fragment,e),h(X.$$.fragment,e),h(ie.$$.fragment,e),h(re.$$.fragment,e),h(me.$$.fragment,e),h(ue.$$.fragment,e),h(de.$$.fragment,e),h(ge.$$.fragment,e),h(he.$$.fragment,e),h(ye.$$.fragment,e),h(je.$$.fragment,e),h(ve.$$.fragment,e),h(L.$$.fragment,e),h(ke.$$.fragment,e),h(Je.$$.fragment,e),h(Ue.$$.fragment,e),h(Re.$$.fragment,e),h(He.$$.fragment,e),h(Fe.$$.fragment,e),h(q.$$.fragment,e),h(Be.$$.fragment,e),h(B.$$.fragment,e),h(N.$$.fragment,e),h(Y.$$.fragment,e),h(Ye.$$.fragment,e),h(A.$$.fragment,e),h(S.$$.fragment,e),sl=!1},d(e){e&&(a(o),a(t),a(i),a(f),a(z),a(U),a(u),a(R),a(W),a(Z),a(r),a(F),a(E),a(Pe),a(P),a(De),a(D),a(Ke),a(K),a(Oe),a(O),a(et),a(ee),a(tt),a(te),a(lt),a(st),a(at),a(se),a(nt),a(ae),a(it),a(ot),a(ne),a(rt),a(pt),a(oe),a(mt),a(ct),a(pe),a(ut),a(ft),a(ce),a(dt),a($t),a(fe),a(gt),a(bt),a($e),a(ht),a(Mt),a(be),a(yt),a(wt),a(Me),a(jt),a(Tt),a(we),a(vt),a(_t),a(Te),a(kt),a(zt),a(Jt),a(_e),a(Ut),a(Zt),a(ze),a(Ct),a(Rt),a(Gt),a(Ze),a(Wt),a(Ce),a(Ht),a(Vt),a(Ge),a(xt),a(We),a(Ft),a(It),a(Ve),a(Xt),a(xe),a(Lt),a(qt),a(Ie),a(Bt),a(Xe),a(Nt),a(Le),a(Yt),a(At),a(qe),a(St),a(Qt),a(Et),a(Pt),a(Ne),a(Dt),a(Kt),a(Ot),a(el),a(Ae),a(tl),a(ll),a(Ee)),a(l),M(c,e),M(k,e),M(_,e),M(H,e),M(v,e),M(I,e),M(le,e),M(X,e),M(ie,e),M(re,e),M(me,e),M(ue,e),M(de,e),M(ge,e),M(he,e),M(ye,e),M(je,e),M(ve,e),M(L,e),M(ke,e),M(Je,e),M(Ue,e),M(Re,e),M(He,e),M(Fe,e),M(q,e),M(Be,e),M(B,e),M(N,e),M(Y,e),M(Ye,e),M(A,e),M(S,e)}}}const Ws='{"title":"Quick tour","local":"quick-tour","sections":[{"title":"Pipeline","local":"pipeline","sections":[{"title":"Utilizzo della Pipeline","local":"utilizzo-della-pipeline","sections":[],"depth":3},{"title":"Utilizzare un altro modello e tokenizer nella pipeline","local":"utilizzare-un-altro-modello-e-tokenizer-nella-pipeline","sections":[],"depth":3}],"depth":2},{"title":"AutoClass","local":"autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":3},{"title":"AutoModel","local":"automodel","sections":[],"depth":3},{"title":"Salva un modello","local":"salva-un-modello","sections":[],"depth":3}],"depth":2}],"depth":1}';function Hs(y){return Dl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ns extends Kl{constructor(l){super(),Ol(this,l,Hs,Gs,Pl,{})}}export{Ns as component};
