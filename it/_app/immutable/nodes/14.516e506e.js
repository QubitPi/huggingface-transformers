import{s as Ai,n as Si,o as Qi}from"../chunks/scheduler.36a0863c.js";import{S as qi,i as Ki,g as a,s as o,r as d,A as Di,h as s,f as l,c as n,j as Ni,u as p,x as r,k as Pi,y as Oi,a as i,v as m,d as c,t as u,w as M}from"../chunks/index.9c13489a.js";import{C as f}from"../chunks/CodeBlock.05d8ec32.js";import{H as b}from"../chunks/Heading.7a254a62.js";function eo(Vl){let T,tt,Oe,lt,y,it,v,ot,J,Rl=`Un paio di modifiche sono state introdotte nel passaggio dalla versione 3 alla versione 4. Di seguito Ã¨ riportato un riepilogo delle
modifiche previste:`,nt,z,at,_,Xl="I tokenizer python e rust hanno allâ€™incirca le stesse API, ma i tokenizer rust hanno un set di funzionalitÃ  piÃ¹ completo.",st,w,El="CiÃ² introduce due modifiche sostanziali:",rt,g,Fl="<li>La gestione dei token in overflow tra i tokenizer Python e Rust Ã¨ diversa.</li> <li>I tokenizers di rust non accettano numeri interi nei metodi di codifica.</li>",dt,$,pt,h,Yl='<li>Le pipeline ora contengono funzionalitÃ  aggiuntive pronte allâ€™uso. Vedi la <a href="main_classes/pipelines#transformers.TokenClassificationPipeline">pipeline di classificazione dei token con il flag <code>grouped_entities</code></a>.</li> <li>Gli auto-tokenizer ora restituiscono tokenizer rust. Per ottenere invece i tokenizer python, lâ€™utente deve usare il flag <code>use_fast</code> impostandolo <code>False</code>:</li>',mt,j,Nl="Nella versione <code>v3.x</code>:",ct,U,ut,Z,Pl="per ottenere lo stesso nella versione <code>v4.x</code>:",Mt,B,bt,x,ft,k,Al="Il requisito sulla dipendenza SentencePiece Ã¨ stato rimosso da <code>setup.py</code>. Ãˆ stato fatto per avere un canale su anaconda cloud senza basarsi su <code>conda-forge</code>. CiÃ² significa che i tokenizer che dipendono dalla libreria SentencePiece non saranno disponibili con unâ€™installazione standard di <code>transformers</code>.",Tt,W,Sl="CiÃ² include le versioni <strong>lente</strong> di:",yt,C,Ql="<li><code>XLNetTokenizer</code></li> <li><code>AlbertTokenizer</code></li> <li><code>CamembertTokenizer</code></li> <li><code>MBartTokenizer</code></li> <li><code>PegasusTokenizer</code></li> <li><code>T5Tokenizer</code></li> <li><code>ReformerTokenizer</code></li> <li><code>XLMRobertaTokenizer</code></li>",vt,H,Jt,I,ql="Per ottenere lo stesso comportamento della versione <code>v3.x</code>, devi installare anche <code>sentencepiece</code>:",zt,G,Kl="Nella versione <code>v3.x</code>:",_t,L,wt,V,Dl="per ottenere lo stesso nella versione <code>v4.x</code>:",gt,R,$t,X,Ol="o",ht,E,jt,F,Ut,Y,ei="Con lâ€™aggiunta di nuovi modelli, il numero di file nella cartella <code>src/transformers</code> continua a crescere e diventa piÃ¹ difficile navigare e capire. Abbiamo fatto la scelta di inserire ogni modello e i file che lo accompagnano nelle proprie sottocartelle.",Zt,N,ti="Si tratta di una modifica sostanziale in quanto lâ€™importazione di layer intermedi utilizzando direttamente il modulo di un modello deve essere eseguita tramite un percorso diverso.",Bt,P,xt,A,li="Per ottenere lo stesso comportamento della versione <code>v3.x</code>, devi aggiornare il percorso utilizzato per accedere ai layer.",kt,S,ii="Nella versione <code>v3.x</code>:",Wt,Q,Ct,q,oi="per ottenere lo stesso nella versione <code>v4.x</code>:",Ht,K,It,D,Gt,O,ni='Lâ€™<a href="main_classes/output">argomento <code>return_dict</code></a> abilita la restituzione di oggetti python dict-like contenenti gli output del modello, invece delle tuple standard. Questo oggetto Ã¨ self-documented poichÃ© le chiavi possono essere utilizzate per recuperare valori, comportandosi anche come una tupla e gli utenti possono recuperare oggetti per indexing o slicing.',Lt,ee,ai="Questa Ã¨ una modifica sostanziale poichÃ© la tupla non puÃ² essere decompressa: <code>value0, value1 = outputs</code> non funzionerÃ .",Vt,te,Rt,le,si="Per ottenere lo stesso comportamento della versione <code>v3.x</code>, specifica lâ€™argomento <code>return_dict</code> come <code>False</code>, sia nella configurazione del modello che nel passaggio successivo.",Xt,ie,ri="Nella versione <code>v3.x</code>:",Et,oe,Ft,ne,di="per ottenere lo stesso nella versione <code>v4.x</code>:",Yt,ae,Nt,se,pi="o",Pt,re,At,de,St,pe,mi='Gli attributi sono stati rimossi se deprecati da almeno un mese. Lâ€™elenco completo degli attributi obsoleti Ã¨ disponibile in <a href="https://github.com/huggingface/transformers/pull/8604" rel="nofollow">#8604</a>.',Qt,me,ci="Ecco un elenco di questi attributi/metodi/argomenti e quali dovrebbero essere le loro sostituzioni:",qt,ce,ui="In diversi modelli, le etichette diventano coerenti con gli altri modelli:",Kt,ue,Mi="<li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>AlbertForMaskedLM</code> e <code>AlbertForPreTraining</code>.</li> <li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>BertForMaskedLM</code> e <code>BertForPreTraining</code>.</li> <li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>DistilBertForMaskedLM</code>.</li> <li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>ElectraForMaskedLM</code>.</li> <li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>LongformerForMaskedLM</code>.</li> <li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>MobileBertForMaskedLM</code>.</li> <li><code>masked_lm_labels</code> diventa <code>labels</code> in <code>RobertaForMaskedLM</code>.</li> <li><code>lm_labels</code> diventa <code>labels</code> in <code>BartForConditionalGeneration</code>.</li> <li><code>lm_labels</code> diventa <code>labels</code> in <code>GPT2DoubleHeadsModel</code>.</li> <li><code>lm_labels</code> diventa <code>labels</code> in <code>OpenAIGPTDoubleHeadsModel</code>.</li> <li><code>lm_labels</code> diventa <code>labels</code> in <code>T5ForConditionalGeneration</code>.</li>",Dt,Me,bi="In diversi modelli, il meccanismo di memorizzazione nella cache diventa coerente con gli altri:",Ot,be,fi="<li><code>decoder_cached_states</code> diventa <code>past_key_values</code> in tutti i modelli BART-like, FSMT e T5.</li> <li><code>decoder_past_key_values</code> diventa <code>past_key_values</code> in tutti i modelli BART-like, FSMT e T5.</li> <li><code>past</code> diventa <code>past_key_values</code> in tutti i modelli CTRL.</li> <li><code>past</code> diventa <code>past_key_values</code> in tutti i modelli GPT-2.</li>",el,fe,Ti="Per quanto riguarda le classi tokenizer:",tl,Te,yi="<li>Lâ€™attributo tokenizer <code>max_len</code> diventa <code>model_max_length</code>.</li> <li>Lâ€™attributo tokenizer <code>return_lengths</code> diventa <code>return_length</code>.</li> <li>Lâ€™argomento di codifica del tokenizer <code>is_pretokenized</code> diventa <code>is_split_into_words</code>.</li>",ll,ye,vi="Per quanto riguarda la classe <code>Trainer</code>:",il,ve,Ji="<li>Lâ€™argomento <code>tb_writer</code> di <code>Trainer</code> Ã¨ stato rimosso in favore della funzione richiamabile <code>TensorBoardCallback(tb_writer=...)</code>.</li> <li>Lâ€™argomento <code>prediction_loss_only</code> di <code>Trainer</code> Ã¨ stato rimosso in favore dellâ€™argomento di classe <code>args.prediction_loss_only</code>.</li> <li>Lâ€™attributo <code>data_collator</code> di <code>Trainer</code> sarÃ  richiamabile.</li> <li>Il metodo <code>_log</code> di <code>Trainer</code> Ã¨ deprecato a favore di <code>log</code>.</li> <li>Il metodo <code>_training_step</code> di <code>Trainer</code> Ã¨ deprecato a favore di <code>training_step</code>.</li> <li>Il metodo <code>_prediction_loop</code> di <code>Trainer</code> Ã¨ deprecato a favore di <code>prediction_loop</code>.</li> <li>Il metodo <code>is_local_master</code> di <code>Trainer</code> Ã¨ deprecato a favore di <code>is_local_process_zero</code>.</li> <li>Il metodo <code>is_world_master</code> di <code>Trainer</code> Ã¨ deprecato a favore di <code>is_world_process_zero</code>.</li>",ol,Je,zi="Per quanto riguarda la classe <code>TrainingArguments</code>:",nl,ze,_i="<li>Lâ€™argomento <code>evaluate_during_training</code> di <code>TrainingArguments</code> Ã¨ deprecato a favore di <code>evaluation_strategy</code>.</li>",al,_e,wi="Per quanto riguarda il modello Transfo-XL:",sl,we,gi="<li>Lâ€™attributo di configurazione <code>tie_weight</code> di Transfo-XL diventa <code>tie_words_embeddings</code>.</li> <li>Il metodo di modellazione <code>reset_length</code> di Transfo-XL diventa <code>reset_memory_length</code>.</li>",rl,ge,$i="Per quanto riguarda le pipeline:",dl,$e,hi="<li>Lâ€™argomento <code>topk</code> di <code>FillMaskPipeline</code> diventa <code>top_k</code>.</li>",pl,he,ml,je,ji="Ecco un breve riepilogo di ciÃ² a cui prestare attenzione durante il passaggio da <code>pytorch-transformers</code> a ðŸ¤— Transformers.",cl,Ue,ul,Ze,Ui="Per usare Torchscript (vedi #1010, #1204 e #1195) lâ€™ordine specifico delle <strong>parole chiave di input</strong> di alcuni modelli (<code>attention_mask</code>, <code>token_type_ids</code>â€¦) Ã¨ stato modificato.",Ml,Be,Zi="Se inizializzavi i modelli usando parole chiave per gli argomenti, ad esempio <code>model(inputs_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)</code>, questo non dovrebbe causare alcun cambiamento.",bl,xe,Bi="Se inizializzavi i modelli con input posizionali per gli argomenti, ad esempio <code>model(inputs_ids, attention_mask, token_type_ids)</code>, potrebbe essere necessario ricontrollare lâ€™ordine esatto degli argomenti di input.",fl,ke,Tl,We,xi="Ecco un breve riepilogo di ciÃ² a cui prestare attenzione durante la migrazione da <code>pytorch-pretrained-bert</code> a ðŸ¤— Transformers",yl,Ce,vl,He,ki="La principale modifica di rilievo durante la migrazione da <code>pytorch-pretrained-bert</code> a ðŸ¤— Transformers Ã¨ che il metodo dei modelli di previsione dÃ  sempre una <code>tupla</code> con vari elementi a seconda del modello e dei parametri di configurazione.",Jl,Ie,Wi='Il contenuto esatto delle tuple per ciascun modello Ã¨ mostrato in dettaglio nelle docstring dei modelli e nella <a href="https://huggingface.co/transformers/" rel="nofollow">documentazione</a>.',zl,Ge,Ci="In quasi tutti i casi, andrÃ  bene prendendo il primo elemento dellâ€™output come quello che avresti precedentemente utilizzato in <code>pytorch-pretrained-bert</code>.",_l,Le,Hi=`Ecco un esempio di conversione da <code>pytorch-pretrained-bert</code>
a ðŸ¤— Transformers per un modello di classificazione <code>BertForSequenceClassification</code>:`,wl,Ve,gl,Re,$l,Xe,Ii="Modifica sostanziale nel metodo <code>from_pretrained()</code>:",hl,Ee,Gi="<li><p>I modelli sono ora impostati in modalitÃ  di valutazione in maniera predefinita quando usi il metodo <code>from_pretrained()</code>. Per addestrarli non dimenticare di riportarli in modalitÃ  di addestramento (<code>model.train()</code>) per attivare i moduli di dropout.</p></li> <li><p>Gli argomenti aggiuntivi <code>*inputs</code> e <code>**kwargs</code> forniti al metodo <code>from_pretrained()</code> venivano passati direttamente al metodo <code>__init__()</code> della classe sottostante del modello. Ora sono usati per aggiornare prima lâ€™attributo di configurazione del modello, che puÃ² non funzionare con le classi del modello derivate costruite basandosi sui precedenti esempi di <code>BertForSequenceClassification</code>. PiÃ¹ precisamente, gli argomenti posizionali <code>*inputs</code> forniti a <code>from_pretrained()</code> vengono inoltrati direttamente al metodo <code>__init__()</code>  del modello mentre gli argomenti keyword <code>**kwargs</code> (i) che corrispondono agli attributi della classe di configurazione, vengono utilizzati per aggiornare tali attributi (ii) che non corrispondono ad alcun attributo della classe di configurazione, vengono inoltrati al metodo <code>__init__()</code>.</p></li>",jl,Fe,Li="Inoltre, sebbene non si tratti di una modifica sostanziale, i metodi di serializzazione sono stati standardizzati e probabilmente dovresti passare al nuovo metodo <code>save_pretrained(save_directory)</code> se prima usavi qualsiasi altro metodo di serializzazione.",Ul,Ye,Vi="Ecco un esempio:",Zl,Ne,Bl,Pe,xl,Ae,Ri="I due ottimizzatori precedenti inclusi, <code>BertAdam</code> e <code>OpenAIAdam</code>, sono stati sostituiti da un singolo <code>AdamW</code> che presenta alcune differenze:",kl,Se,Xi="<li>implementa solo la correzione del weights decay,</li> <li>lo scheduling ora Ã¨ esterno (vedi sotto),</li> <li>anche il gradient clipping ora Ã¨ esterno (vedi sotto).</li>",Wl,Qe,Ei="Il nuovo ottimizzatore <code>AdamW</code> corrisponde alle API di <code>Adam</code> di PyTorch e ti consente di utilizzare metodi PyTorch o apex per lo scheduling e il clipping.",Cl,qe,Fi='Lo scheduling Ã¨ ora standard <a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate" rel="nofollow">PyTorch learning rate schedulers</a> e non fanno piÃ¹ parte dellâ€™ottimizzatore.',Hl,Ke,Yi="Ecco un esempio di linear warmup e decay con <code>BertAdam</code> e con <code>AdamW</code>:",Il,De,Gl,et,Ll;return y=new b({props:{title:"Migrazione da pacchetti precedenti",local:"migrazione-da-pacchetti-precedenti",headingTag:"h1"}}),v=new b({props:{title:"Migrazione da transformers v3.x a v4.x",local:"migrazione-da-transformers-v3x-a-v4x",headingTag:"h2"}}),z=new b({props:{title:"1. AutoTokenizer e pipeline ora utilizzano tokenizer veloci (rust) per impostazione predefinita.",local:"1-autotokenizer-e-pipeline-ora-utilizzano-tokenizer-veloci-rust-per-impostazione-predefinita",headingTag:"h4"}}),$=new b({props:{title:"Come ottenere lo stesso comportamento di v3.x in v4.x",local:"come-ottenere-lo-stesso-comportamento-di-v3x-in-v4x",headingTag:"h5"}}),U=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS1jYXNlZCUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)`,wrap:!1}}),B=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS1jYXNlZCUyMiUyQyUyMHVzZV9mYXN0JTNERmFsc2Up",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>, use_fast=<span class="hljs-literal">False</span>)`,wrap:!1}}),x=new b({props:{title:"2. SentencePiece Ã¨ stato rimosso dalle dipendenze richieste",local:"2-sentencepiece-Ã¨-stato-rimosso-dalle-dipendenze-richieste",headingTag:"h4"}}),H=new b({props:{title:"Come ottenere lo stesso comportamento della v3.x nella v4.x",local:"come-ottenere-lo-stesso-comportamento-della-v3x-nella-v4x",headingTag:"h5"}}),L=new f({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycw==",highlighted:"pip install transformers",wrap:!1}}),R=new f({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyU1QnNlbnRlbmNlcGllY2UlNUQ=",highlighted:"pip install transformers[sentencepiece]",wrap:!1}}),E=new f({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMHN0ZW50ZW5jZXBpZWNl",highlighted:"pip install transformers stentencepiece",wrap:!1}}),F=new b({props:{title:"3. Lâ€™architettura delle repo Ã¨ stato aggiornata in modo che ogni modello abbia la propria cartella",local:"3-larchitettura-delle-repo-Ã¨-stato-aggiornata-in-modo-che-ogni-modello-abbia-la-propria-cartella",headingTag:"h4"}}),P=new b({props:{title:"Come ottenere lo stesso comportamento della v3.x nella v4.x",local:"come-ottenere-lo-stesso-comportamento-della-v3x-nella-v4x",headingTag:"h5"}}),Q=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbGluZ19iZXJ0JTIwaW1wb3J0JTIwQmVydExheWVy",highlighted:"from transformers.modeling_bert import BertLayer",wrap:!1}}),K=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbHMuYmVydC5tb2RlbGluZ19iZXJ0JTIwaW1wb3J0JTIwQmVydExheWVy",highlighted:"from transformers.models.bert.modeling_bert import BertLayer",wrap:!1}}),D=new b({props:{title:"4. Impostare lâ€™argomento return_dict su True per impostazione predefinita",local:"4-impostare-largomento-returndict-su-true-per-impostazione-predefinita",headingTag:"h4"}}),te=new b({props:{title:"Come ottenere lo stesso comportamento della v3.x nella v4.x",local:"come-ottenere-lo-stesso-comportamento-della-v3x-nella-v4x",headingTag:"h5"}}),oe=new f({props:{code:"bW9kZWwlMjAlM0QlMjBCZXJ0TW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLWNhc2VkJTIyKSUwQW91dHB1dHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cyk=",highlighted:`model = BertModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)
outputs = model(**inputs)`,wrap:!1}}),ae=new f({props:{code:"bW9kZWwlMjAlM0QlMjBCZXJ0TW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLWNhc2VkJTIyKSUwQW91dHB1dHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cyUyQyUyMHJldHVybl9kaWN0JTNERmFsc2Up",highlighted:`model = BertModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)
outputs = model(**inputs, return_dict=False)`,wrap:!1}}),re=new f({props:{code:"bW9kZWwlMjAlM0QlMjBCZXJ0TW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLWNhc2VkJTIyJTJDJTIwcmV0dXJuX2RpY3QlM0RGYWxzZSklMEFvdXRwdXRzJTIwJTNEJTIwbW9kZWwoKippbnB1dHMp",highlighted:`model = BertModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>, return_dict=False)
outputs = model(**inputs)`,wrap:!1}}),de=new b({props:{title:"5. Rimozione di alcuni attributi deprecati",local:"5-rimozione-di-alcuni-attributi-deprecati",headingTag:"h4"}}),he=new b({props:{title:"Passaggio da pytorch-transformers a ðŸ¤— Transformers",local:"passaggio-da-pytorch-transformers-a--transformers",headingTag:"h2"}}),Ue=new b({props:{title:"Lâ€™ordine posizionale di alcune parole chiave di input dei modelli ( attention_mask , token_type_ids â€¦) Ã¨ cambiato",local:"lordine-posizionale-di-alcune-parole-chiave-di-input-dei-modelli--attentionmask--tokentypeids--Ã¨-cambiato",headingTag:"h3"}}),ke=new b({props:{title:"Migrazione da pytorch-pretrained-bert",local:"migrazione-da-pytorch-pretrained-bert",headingTag:"h2"}}),Ce=new b({props:{title:"I modelli restituiscono sempre tuple",local:"i-modelli-restituiscono-sempre-tuple",headingTag:"h3"}}),Ve=new f({props:{code:"JTIzJTIwQ2FyaWNoaWFtbyUyMGlsJTIwbm9zdHJvJTIwbW9kZWxsbyUwQW1vZGVsJTIwJTNEJTIwQmVydEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBJTBBJTIzJTIwU2UlMjB1c2F2aSUyMHF1ZXN0YSUyMHJpZ2ElMjBpbiUyMHB5dG9yY2gtcHJldHJhaW5lZC1iZXJ0JTIwJTNBJTBBbG9zcyUyMCUzRCUyMG1vZGVsKGlucHV0X2lkcyUyQyUyMGxhYmVscyUzRGxhYmVscyklMEElMEElMjMlMjBPcmElMjB1c2ElMjBxdWVzdGElMjByaWdhJTIwaW4lMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBwZXIlMjBlc3RyYXJyZSUyMGxhJTIwcGVyZGl0YSUyMGRhbGxhJTIwdHVwbGElMjBkaSUyMG91dHB1dCUzQSUwQW91dHB1dHMlMjAlM0QlMjBtb2RlbChpbnB1dF9pZHMlMkMlMjBsYWJlbHMlM0RsYWJlbHMpJTBBbG9zcyUyMCUzRCUyMG91dHB1dHMlNUIwJTVEJTBBJTBBJTIzJTIwSW4lMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBwdW9pJTIwYW5jaGUlMjBhdmVyZSUyMGFjY2Vzc28lMjBhaSUyMGxvZ2l0JTNBJTBBbG9zcyUyQyUyMGxvZ2l0cyUyMCUzRCUyMG91dHB1dHMlNUIlM0EyJTVEJTBBJTBBJTIzJTIwRWQlMjBhbmNoZSUyMGFnbGklMjBhdHRlbnRpb24lMjB3ZWlnaHQlMjBzZSUyMGNvbmZpZ3VyaSUyMGlsJTIwbW9kZWxsbyUyMHBlciUyMHJlc3RpdHVpcmxpJTIwKGUlMjBhbmNoZSUyMGFsdHJpJTIwb3V0cHV0JTJDJTIwdmVkaSUyMGxlJTIwZG9jc3RyaW5nJTIwZSUyMGxhJTIwZG9jdW1lbnRhemlvbmUpJTBBbW9kZWwlMjAlM0QlMjBCZXJ0Rm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyJTIwZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtdW5jYXNlZCUyMiUyQyUyMG91dHB1dF9hdHRlbnRpb25zJTNEVHJ1ZSklMEFvdXRwdXRzJTIwJTNEJTIwbW9kZWwoaW5wdXRfaWRzJTJDJTIwbGFiZWxzJTNEbGFiZWxzKSUwQWxvc3MlMkMlMjBsb2dpdHMlMkMlMjBhdHRlbnRpb25zJTIwJTNEJTIwb3V0cHV0cw==",highlighted:`<span class="hljs-comment"># Carichiamo il nostro modello</span>
model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)

<span class="hljs-comment"># Se usavi questa riga in pytorch-pretrained-bert :</span>
loss = model(input_ids, labels=labels)

<span class="hljs-comment"># Ora usa questa riga in ðŸ¤— Transformers per estrarre la perdita dalla tupla di output:</span>
outputs = model(input_ids, labels=labels)
loss = outputs[<span class="hljs-number">0</span>]

<span class="hljs-comment"># In ðŸ¤— Transformers puoi anche avere accesso ai logit:</span>
loss, logits = outputs[:<span class="hljs-number">2</span>]

<span class="hljs-comment"># Ed anche agli attention weight se configuri il modello per restituirli (e anche altri output, vedi le docstring e la documentazione)</span>
model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot; google-bert/bert-base-uncased&quot;</span>, output_attentions=<span class="hljs-literal">True</span>)
outputs = model(input_ids, labels=labels)
loss, logits, attentions = outputs`,wrap:!1}}),Re=new b({props:{title:"Serializzazione",local:"serializzazione",headingTag:"h3"}}),Ne=new f({props:{code:"JTIzJTIzJTIzJTIwQ2FyaWNoaWFtbyUyMHVuJTIwbW9kZWxsbyUyMGUlMjB1biUyMHRva2VuaXplciUwQW1vZGVsJTIwJTNEJTIwQmVydEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLXVuY2FzZWQlMjIpJTBBdG9rZW5pemVyJTIwJTNEJTIwQmVydFRva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtdW5jYXNlZCUyMiklMEElMEElMjMlMjMlMjMlMjBGYWNjaWFtbyUyMGZhcmUlMjBhbGN1bmUlMjBjb3NlJTIwYWwlMjBub3N0cm8lMjBtb2RlbGxvJTIwZSUyMHRva2VuaXplciUwQSUyMyUyMEVzJTNBJTIwYWdnaXVuZ2lhbW8lMjBudW92aSUyMHRva2VuJTIwYWwlMjB2b2NhYm9sYXJpbyUyMGUlMjBhZ2xpJTIwZW1iZW5kaW5nJTIwZGVsJTIwbm9zdHJvJTIwbW9kZWxsbyUwQXRva2VuaXplci5hZGRfdG9rZW5zKCU1QiUyMiU1QlNQRUNJQUxfVE9LRU5fMSU1RCUyMiUyQyUyMCUyMiU1QlNQRUNJQUxfVE9LRU5fMiU1RCUyMiU1RCklMEFtb2RlbC5yZXNpemVfdG9rZW5fZW1iZWRkaW5ncyhsZW4odG9rZW5pemVyKSklMEElMjMlMjBBbGxlbmlhbW8lMjBpbCUyMG5vc3RybyUyMG1vZGVsbG8lMEF0cmFpbihtb2RlbCklMEElMEElMjMlMjMlMjMlMjBPcmElMjBzYWx2aWFtbyUyMGlsJTIwbm9zdHJvJTIwbW9kZWxsbyUyMGUlMjBpbCUyMHRva2VuaXplciUyMGluJTIwdW5hJTIwY2FydGVsbGElMEFtb2RlbC5zYXZlX3ByZXRyYWluZWQoJTIyLiUyRm15X3NhdmVkX21vZGVsX2RpcmVjdG9yeSUyRiUyMiklMEF0b2tlbml6ZXIuc2F2ZV9wcmV0cmFpbmVkKCUyMi4lMkZteV9zYXZlZF9tb2RlbF9kaXJlY3RvcnklMkYlMjIpJTBBJTBBJTIzJTIzJTIzJTIwUmljYXJpY2hpYW1vJTIwaWwlMjBtb2RlbGxvJTIwZSUyMGlsJTIwdG9rZW5pemVyJTBBbW9kZWwlMjAlM0QlMjBCZXJ0Rm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyLiUyRm15X3NhdmVkX21vZGVsX2RpcmVjdG9yeSUyRiUyMiklMEF0b2tlbml6ZXIlMjAlM0QlMjBCZXJ0VG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjIuJTJGbXlfc2F2ZWRfbW9kZWxfZGlyZWN0b3J5JTJGJTIyKQ==",highlighted:`<span class="hljs-comment">### Carichiamo un modello e un tokenizer</span>
model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)
tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)

<span class="hljs-comment">### Facciamo fare alcune cose al nostro modello e tokenizer</span>
<span class="hljs-comment"># Es: aggiungiamo nuovi token al vocabolario e agli embending del nostro modello</span>
tokenizer.add_tokens([<span class="hljs-string">&quot;[SPECIAL_TOKEN_1]&quot;</span>, <span class="hljs-string">&quot;[SPECIAL_TOKEN_2]&quot;</span>])
model.resize_token_embeddings(<span class="hljs-built_in">len</span>(tokenizer))
<span class="hljs-comment"># Alleniamo il nostro modello</span>
train(model)

<span class="hljs-comment">### Ora salviamo il nostro modello e il tokenizer in una cartella</span>
model.save_pretrained(<span class="hljs-string">&quot;./my_saved_model_directory/&quot;</span>)
tokenizer.save_pretrained(<span class="hljs-string">&quot;./my_saved_model_directory/&quot;</span>)

<span class="hljs-comment">### Ricarichiamo il modello e il tokenizer</span>
model = BertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./my_saved_model_directory/&quot;</span>)
tokenizer = BertTokenizer.from_pretrained(<span class="hljs-string">&quot;./my_saved_model_directory/&quot;</span>)`,wrap:!1}}),Pe=new b({props:{title:"Ottimizzatori: BertAdam e OpenAIAdam ora sono AdamW, lo scheduling Ã¨ quello standard PyTorch",local:"ottimizzatori-bertadam-e-openaiadam-ora-sono-adamw-lo-scheduling-Ã¨-quello-standard-pytorch",headingTag:"h3"}}),De=new f({props:{code:"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",highlighted:`<span class="hljs-comment"># Parametri:</span>
lr = <span class="hljs-number">1e-3</span>
max_grad_norm = <span class="hljs-number">1.0</span>
num_training_steps = <span class="hljs-number">1000</span>
num_warmup_steps = <span class="hljs-number">100</span>
warmup_proportion = <span class="hljs-built_in">float</span>( num_warmup_steps) / <span class="hljs-built_in">float</span>(num_training_steps) <span class="hljs-comment"># 0.1</span>

<span class="hljs-comment">### In precedenza l&#x27;ottimizzatore BertAdam veniva istanziato in questo modo:</span>
optimizer = BertAdam(
   model.parameters(),
   lr=lr,
   schedule=<span class="hljs-string">&quot;warmup_linear&quot;</span>,
   warmup=warmup_proportion,
   num_training_steps=num_training_steps,
)
<span class="hljs-comment">### e usato in questo modo:</span>
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_data:
   loss = model(batch)
   loss.backward()
   optimizer.step()

<span class="hljs-comment">### In ðŸ¤— Transformers, ottimizzatore e schedule sono divisi e usati in questo modo:</span>
optimizer = AdamW(
   model.parameters(), lr=lr, correct_bias=<span class="hljs-literal">False</span>
) <span class="hljs-comment"># Per riprodurre il comportamento specifico di BertAdam impostare correct_bias=False</span>
scheduler = get_linear_schedule_with_warmup(
   optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps
) <span class="hljs-comment"># PyTorch scheduler</span>
<span class="hljs-comment">### e va usato cosÃ¬:</span>
<span class="hljs-keyword">for</span> batch <span class="hljs-keyword">in</span> train_data:
   loss = model(batch)
   loss.backward()
   torch.nn.utils.clip_grad_norm_(
   model.parameters(), max_grad_norm
   ) <span class="hljs-comment"># Gradient clipping non Ã¨ piÃ¹ in AdamW (quindi puoi usare amp senza problemi)</span>
   optimizer.step()
   scheduler.step()`,wrap:!1}}),{c(){T=a("meta"),tt=o(),Oe=a("p"),lt=o(),d(y.$$.fragment),it=o(),d(v.$$.fragment),ot=o(),J=a("p"),J.textContent=Rl,nt=o(),d(z.$$.fragment),at=o(),_=a("p"),_.textContent=Xl,st=o(),w=a("p"),w.textContent=El,rt=o(),g=a("ul"),g.innerHTML=Fl,dt=o(),d($.$$.fragment),pt=o(),h=a("ul"),h.innerHTML=Yl,mt=o(),j=a("p"),j.innerHTML=Nl,ct=o(),d(U.$$.fragment),ut=o(),Z=a("p"),Z.innerHTML=Pl,Mt=o(),d(B.$$.fragment),bt=o(),d(x.$$.fragment),ft=o(),k=a("p"),k.innerHTML=Al,Tt=o(),W=a("p"),W.innerHTML=Sl,yt=o(),C=a("ul"),C.innerHTML=Ql,vt=o(),d(H.$$.fragment),Jt=o(),I=a("p"),I.innerHTML=ql,zt=o(),G=a("p"),G.innerHTML=Kl,_t=o(),d(L.$$.fragment),wt=o(),V=a("p"),V.innerHTML=Dl,gt=o(),d(R.$$.fragment),$t=o(),X=a("p"),X.textContent=Ol,ht=o(),d(E.$$.fragment),jt=o(),d(F.$$.fragment),Ut=o(),Y=a("p"),Y.innerHTML=ei,Zt=o(),N=a("p"),N.textContent=ti,Bt=o(),d(P.$$.fragment),xt=o(),A=a("p"),A.innerHTML=li,kt=o(),S=a("p"),S.innerHTML=ii,Wt=o(),d(Q.$$.fragment),Ct=o(),q=a("p"),q.innerHTML=oi,Ht=o(),d(K.$$.fragment),It=o(),d(D.$$.fragment),Gt=o(),O=a("p"),O.innerHTML=ni,Lt=o(),ee=a("p"),ee.innerHTML=ai,Vt=o(),d(te.$$.fragment),Rt=o(),le=a("p"),le.innerHTML=si,Xt=o(),ie=a("p"),ie.innerHTML=ri,Et=o(),d(oe.$$.fragment),Ft=o(),ne=a("p"),ne.innerHTML=di,Yt=o(),d(ae.$$.fragment),Nt=o(),se=a("p"),se.textContent=pi,Pt=o(),d(re.$$.fragment),At=o(),d(de.$$.fragment),St=o(),pe=a("p"),pe.innerHTML=mi,Qt=o(),me=a("p"),me.textContent=ci,qt=o(),ce=a("p"),ce.textContent=ui,Kt=o(),ue=a("ul"),ue.innerHTML=Mi,Dt=o(),Me=a("p"),Me.textContent=bi,Ot=o(),be=a("ul"),be.innerHTML=fi,el=o(),fe=a("p"),fe.textContent=Ti,tl=o(),Te=a("ul"),Te.innerHTML=yi,ll=o(),ye=a("p"),ye.innerHTML=vi,il=o(),ve=a("ul"),ve.innerHTML=Ji,ol=o(),Je=a("p"),Je.innerHTML=zi,nl=o(),ze=a("ul"),ze.innerHTML=_i,al=o(),_e=a("p"),_e.textContent=wi,sl=o(),we=a("ul"),we.innerHTML=gi,rl=o(),ge=a("p"),ge.textContent=$i,dl=o(),$e=a("ul"),$e.innerHTML=hi,pl=o(),d(he.$$.fragment),ml=o(),je=a("p"),je.innerHTML=ji,cl=o(),d(Ue.$$.fragment),ul=o(),Ze=a("p"),Ze.innerHTML=Ui,Ml=o(),Be=a("p"),Be.innerHTML=Zi,bl=o(),xe=a("p"),xe.innerHTML=Bi,fl=o(),d(ke.$$.fragment),Tl=o(),We=a("p"),We.innerHTML=xi,yl=o(),d(Ce.$$.fragment),vl=o(),He=a("p"),He.innerHTML=ki,Jl=o(),Ie=a("p"),Ie.innerHTML=Wi,zl=o(),Ge=a("p"),Ge.innerHTML=Ci,_l=o(),Le=a("p"),Le.innerHTML=Hi,wl=o(),d(Ve.$$.fragment),gl=o(),d(Re.$$.fragment),$l=o(),Xe=a("p"),Xe.innerHTML=Ii,hl=o(),Ee=a("ol"),Ee.innerHTML=Gi,jl=o(),Fe=a("p"),Fe.innerHTML=Li,Ul=o(),Ye=a("p"),Ye.textContent=Vi,Zl=o(),d(Ne.$$.fragment),Bl=o(),d(Pe.$$.fragment),xl=o(),Ae=a("p"),Ae.innerHTML=Ri,kl=o(),Se=a("ul"),Se.innerHTML=Xi,Wl=o(),Qe=a("p"),Qe.innerHTML=Ei,Cl=o(),qe=a("p"),qe.innerHTML=Fi,Hl=o(),Ke=a("p"),Ke.innerHTML=Yi,Il=o(),d(De.$$.fragment),Gl=o(),et=a("p"),this.h()},l(e){const t=Di("svelte-u9bgzb",document.head);T=s(t,"META",{name:!0,content:!0}),t.forEach(l),tt=n(e),Oe=s(e,"P",{}),Ni(Oe).forEach(l),lt=n(e),p(y.$$.fragment,e),it=n(e),p(v.$$.fragment,e),ot=n(e),J=s(e,"P",{"data-svelte-h":!0}),r(J)!=="svelte-668hq5"&&(J.textContent=Rl),nt=n(e),p(z.$$.fragment,e),at=n(e),_=s(e,"P",{"data-svelte-h":!0}),r(_)!=="svelte-gf1el4"&&(_.textContent=Xl),st=n(e),w=s(e,"P",{"data-svelte-h":!0}),r(w)!=="svelte-1m5uxey"&&(w.textContent=El),rt=n(e),g=s(e,"UL",{"data-svelte-h":!0}),r(g)!=="svelte-57nl0c"&&(g.innerHTML=Fl),dt=n(e),p($.$$.fragment,e),pt=n(e),h=s(e,"UL",{"data-svelte-h":!0}),r(h)!=="svelte-1jqlgbo"&&(h.innerHTML=Yl),mt=n(e),j=s(e,"P",{"data-svelte-h":!0}),r(j)!=="svelte-s7f1fx"&&(j.innerHTML=Nl),ct=n(e),p(U.$$.fragment,e),ut=n(e),Z=s(e,"P",{"data-svelte-h":!0}),r(Z)!=="svelte-1ggfn91"&&(Z.innerHTML=Pl),Mt=n(e),p(B.$$.fragment,e),bt=n(e),p(x.$$.fragment,e),ft=n(e),k=s(e,"P",{"data-svelte-h":!0}),r(k)!=="svelte-1yqxt38"&&(k.innerHTML=Al),Tt=n(e),W=s(e,"P",{"data-svelte-h":!0}),r(W)!=="svelte-7vgiw8"&&(W.innerHTML=Sl),yt=n(e),C=s(e,"UL",{"data-svelte-h":!0}),r(C)!=="svelte-gqa7ea"&&(C.innerHTML=Ql),vt=n(e),p(H.$$.fragment,e),Jt=n(e),I=s(e,"P",{"data-svelte-h":!0}),r(I)!=="svelte-e0qch8"&&(I.innerHTML=ql),zt=n(e),G=s(e,"P",{"data-svelte-h":!0}),r(G)!=="svelte-s7f1fx"&&(G.innerHTML=Kl),_t=n(e),p(L.$$.fragment,e),wt=n(e),V=s(e,"P",{"data-svelte-h":!0}),r(V)!=="svelte-1ggfn91"&&(V.innerHTML=Dl),gt=n(e),p(R.$$.fragment,e),$t=n(e),X=s(e,"P",{"data-svelte-h":!0}),r(X)!=="svelte-1cem39h"&&(X.textContent=Ol),ht=n(e),p(E.$$.fragment,e),jt=n(e),p(F.$$.fragment,e),Ut=n(e),Y=s(e,"P",{"data-svelte-h":!0}),r(Y)!=="svelte-1d9aumn"&&(Y.innerHTML=ei),Zt=n(e),N=s(e,"P",{"data-svelte-h":!0}),r(N)!=="svelte-z35xty"&&(N.textContent=ti),Bt=n(e),p(P.$$.fragment,e),xt=n(e),A=s(e,"P",{"data-svelte-h":!0}),r(A)!=="svelte-1syye96"&&(A.innerHTML=li),kt=n(e),S=s(e,"P",{"data-svelte-h":!0}),r(S)!=="svelte-s7f1fx"&&(S.innerHTML=ii),Wt=n(e),p(Q.$$.fragment,e),Ct=n(e),q=s(e,"P",{"data-svelte-h":!0}),r(q)!=="svelte-1ggfn91"&&(q.innerHTML=oi),Ht=n(e),p(K.$$.fragment,e),It=n(e),p(D.$$.fragment,e),Gt=n(e),O=s(e,"P",{"data-svelte-h":!0}),r(O)!=="svelte-15fnb1f"&&(O.innerHTML=ni),Lt=n(e),ee=s(e,"P",{"data-svelte-h":!0}),r(ee)!=="svelte-6z85oe"&&(ee.innerHTML=ai),Vt=n(e),p(te.$$.fragment,e),Rt=n(e),le=s(e,"P",{"data-svelte-h":!0}),r(le)!=="svelte-1bl6pbd"&&(le.innerHTML=si),Xt=n(e),ie=s(e,"P",{"data-svelte-h":!0}),r(ie)!=="svelte-s7f1fx"&&(ie.innerHTML=ri),Et=n(e),p(oe.$$.fragment,e),Ft=n(e),ne=s(e,"P",{"data-svelte-h":!0}),r(ne)!=="svelte-1ggfn91"&&(ne.innerHTML=di),Yt=n(e),p(ae.$$.fragment,e),Nt=n(e),se=s(e,"P",{"data-svelte-h":!0}),r(se)!=="svelte-1cem39h"&&(se.textContent=pi),Pt=n(e),p(re.$$.fragment,e),At=n(e),p(de.$$.fragment,e),St=n(e),pe=s(e,"P",{"data-svelte-h":!0}),r(pe)!=="svelte-1jgy8li"&&(pe.innerHTML=mi),Qt=n(e),me=s(e,"P",{"data-svelte-h":!0}),r(me)!=="svelte-1jjvwm4"&&(me.textContent=ci),qt=n(e),ce=s(e,"P",{"data-svelte-h":!0}),r(ce)!=="svelte-ykanzw"&&(ce.textContent=ui),Kt=n(e),ue=s(e,"UL",{"data-svelte-h":!0}),r(ue)!=="svelte-19g3nxw"&&(ue.innerHTML=Mi),Dt=n(e),Me=s(e,"P",{"data-svelte-h":!0}),r(Me)!=="svelte-ja413z"&&(Me.textContent=bi),Ot=n(e),be=s(e,"UL",{"data-svelte-h":!0}),r(be)!=="svelte-1wt3yrf"&&(be.innerHTML=fi),el=n(e),fe=s(e,"P",{"data-svelte-h":!0}),r(fe)!=="svelte-1hgabrv"&&(fe.textContent=Ti),tl=n(e),Te=s(e,"UL",{"data-svelte-h":!0}),r(Te)!=="svelte-31xrbn"&&(Te.innerHTML=yi),ll=n(e),ye=s(e,"P",{"data-svelte-h":!0}),r(ye)!=="svelte-170kx12"&&(ye.innerHTML=vi),il=n(e),ve=s(e,"UL",{"data-svelte-h":!0}),r(ve)!=="svelte-1d9dzd2"&&(ve.innerHTML=Ji),ol=n(e),Je=s(e,"P",{"data-svelte-h":!0}),r(Je)!=="svelte-uuss7p"&&(Je.innerHTML=zi),nl=n(e),ze=s(e,"UL",{"data-svelte-h":!0}),r(ze)!=="svelte-10nscti"&&(ze.innerHTML=_i),al=n(e),_e=s(e,"P",{"data-svelte-h":!0}),r(_e)!=="svelte-13a2h9b"&&(_e.textContent=wi),sl=n(e),we=s(e,"UL",{"data-svelte-h":!0}),r(we)!=="svelte-g6j8ra"&&(we.innerHTML=gi),rl=n(e),ge=s(e,"P",{"data-svelte-h":!0}),r(ge)!=="svelte-1k2o8s3"&&(ge.textContent=$i),dl=n(e),$e=s(e,"UL",{"data-svelte-h":!0}),r($e)!=="svelte-8otb07"&&($e.innerHTML=hi),pl=n(e),p(he.$$.fragment,e),ml=n(e),je=s(e,"P",{"data-svelte-h":!0}),r(je)!=="svelte-l36xrj"&&(je.innerHTML=ji),cl=n(e),p(Ue.$$.fragment,e),ul=n(e),Ze=s(e,"P",{"data-svelte-h":!0}),r(Ze)!=="svelte-seplpo"&&(Ze.innerHTML=Ui),Ml=n(e),Be=s(e,"P",{"data-svelte-h":!0}),r(Be)!=="svelte-1ro2lsk"&&(Be.innerHTML=Zi),bl=n(e),xe=s(e,"P",{"data-svelte-h":!0}),r(xe)!=="svelte-1plbv18"&&(xe.innerHTML=Bi),fl=n(e),p(ke.$$.fragment,e),Tl=n(e),We=s(e,"P",{"data-svelte-h":!0}),r(We)!=="svelte-q2e62a"&&(We.innerHTML=xi),yl=n(e),p(Ce.$$.fragment,e),vl=n(e),He=s(e,"P",{"data-svelte-h":!0}),r(He)!=="svelte-4cf5r"&&(He.innerHTML=ki),Jl=n(e),Ie=s(e,"P",{"data-svelte-h":!0}),r(Ie)!=="svelte-bgxvfx"&&(Ie.innerHTML=Wi),zl=n(e),Ge=s(e,"P",{"data-svelte-h":!0}),r(Ge)!=="svelte-1jfesn2"&&(Ge.innerHTML=Ci),_l=n(e),Le=s(e,"P",{"data-svelte-h":!0}),r(Le)!=="svelte-83adx7"&&(Le.innerHTML=Hi),wl=n(e),p(Ve.$$.fragment,e),gl=n(e),p(Re.$$.fragment,e),$l=n(e),Xe=s(e,"P",{"data-svelte-h":!0}),r(Xe)!=="svelte-1d5f1v"&&(Xe.innerHTML=Ii),hl=n(e),Ee=s(e,"OL",{"data-svelte-h":!0}),r(Ee)!=="svelte-5qzntw"&&(Ee.innerHTML=Gi),jl=n(e),Fe=s(e,"P",{"data-svelte-h":!0}),r(Fe)!=="svelte-1pjusnp"&&(Fe.innerHTML=Li),Ul=n(e),Ye=s(e,"P",{"data-svelte-h":!0}),r(Ye)!=="svelte-1nimzcx"&&(Ye.textContent=Vi),Zl=n(e),p(Ne.$$.fragment,e),Bl=n(e),p(Pe.$$.fragment,e),xl=n(e),Ae=s(e,"P",{"data-svelte-h":!0}),r(Ae)!=="svelte-2o9zch"&&(Ae.innerHTML=Ri),kl=n(e),Se=s(e,"UL",{"data-svelte-h":!0}),r(Se)!=="svelte-15b1x1u"&&(Se.innerHTML=Xi),Wl=n(e),Qe=s(e,"P",{"data-svelte-h":!0}),r(Qe)!=="svelte-5iz2eq"&&(Qe.innerHTML=Ei),Cl=n(e),qe=s(e,"P",{"data-svelte-h":!0}),r(qe)!=="svelte-18bzze7"&&(qe.innerHTML=Fi),Hl=n(e),Ke=s(e,"P",{"data-svelte-h":!0}),r(Ke)!=="svelte-hz6tan"&&(Ke.innerHTML=Yi),Il=n(e),p(De.$$.fragment,e),Gl=n(e),et=s(e,"P",{}),Ni(et).forEach(l),this.h()},h(){Pi(T,"name","hf:doc:metadata"),Pi(T,"content",to)},m(e,t){Oi(document.head,T),i(e,tt,t),i(e,Oe,t),i(e,lt,t),m(y,e,t),i(e,it,t),m(v,e,t),i(e,ot,t),i(e,J,t),i(e,nt,t),m(z,e,t),i(e,at,t),i(e,_,t),i(e,st,t),i(e,w,t),i(e,rt,t),i(e,g,t),i(e,dt,t),m($,e,t),i(e,pt,t),i(e,h,t),i(e,mt,t),i(e,j,t),i(e,ct,t),m(U,e,t),i(e,ut,t),i(e,Z,t),i(e,Mt,t),m(B,e,t),i(e,bt,t),m(x,e,t),i(e,ft,t),i(e,k,t),i(e,Tt,t),i(e,W,t),i(e,yt,t),i(e,C,t),i(e,vt,t),m(H,e,t),i(e,Jt,t),i(e,I,t),i(e,zt,t),i(e,G,t),i(e,_t,t),m(L,e,t),i(e,wt,t),i(e,V,t),i(e,gt,t),m(R,e,t),i(e,$t,t),i(e,X,t),i(e,ht,t),m(E,e,t),i(e,jt,t),m(F,e,t),i(e,Ut,t),i(e,Y,t),i(e,Zt,t),i(e,N,t),i(e,Bt,t),m(P,e,t),i(e,xt,t),i(e,A,t),i(e,kt,t),i(e,S,t),i(e,Wt,t),m(Q,e,t),i(e,Ct,t),i(e,q,t),i(e,Ht,t),m(K,e,t),i(e,It,t),m(D,e,t),i(e,Gt,t),i(e,O,t),i(e,Lt,t),i(e,ee,t),i(e,Vt,t),m(te,e,t),i(e,Rt,t),i(e,le,t),i(e,Xt,t),i(e,ie,t),i(e,Et,t),m(oe,e,t),i(e,Ft,t),i(e,ne,t),i(e,Yt,t),m(ae,e,t),i(e,Nt,t),i(e,se,t),i(e,Pt,t),m(re,e,t),i(e,At,t),m(de,e,t),i(e,St,t),i(e,pe,t),i(e,Qt,t),i(e,me,t),i(e,qt,t),i(e,ce,t),i(e,Kt,t),i(e,ue,t),i(e,Dt,t),i(e,Me,t),i(e,Ot,t),i(e,be,t),i(e,el,t),i(e,fe,t),i(e,tl,t),i(e,Te,t),i(e,ll,t),i(e,ye,t),i(e,il,t),i(e,ve,t),i(e,ol,t),i(e,Je,t),i(e,nl,t),i(e,ze,t),i(e,al,t),i(e,_e,t),i(e,sl,t),i(e,we,t),i(e,rl,t),i(e,ge,t),i(e,dl,t),i(e,$e,t),i(e,pl,t),m(he,e,t),i(e,ml,t),i(e,je,t),i(e,cl,t),m(Ue,e,t),i(e,ul,t),i(e,Ze,t),i(e,Ml,t),i(e,Be,t),i(e,bl,t),i(e,xe,t),i(e,fl,t),m(ke,e,t),i(e,Tl,t),i(e,We,t),i(e,yl,t),m(Ce,e,t),i(e,vl,t),i(e,He,t),i(e,Jl,t),i(e,Ie,t),i(e,zl,t),i(e,Ge,t),i(e,_l,t),i(e,Le,t),i(e,wl,t),m(Ve,e,t),i(e,gl,t),m(Re,e,t),i(e,$l,t),i(e,Xe,t),i(e,hl,t),i(e,Ee,t),i(e,jl,t),i(e,Fe,t),i(e,Ul,t),i(e,Ye,t),i(e,Zl,t),m(Ne,e,t),i(e,Bl,t),m(Pe,e,t),i(e,xl,t),i(e,Ae,t),i(e,kl,t),i(e,Se,t),i(e,Wl,t),i(e,Qe,t),i(e,Cl,t),i(e,qe,t),i(e,Hl,t),i(e,Ke,t),i(e,Il,t),m(De,e,t),i(e,Gl,t),i(e,et,t),Ll=!0},p:Si,i(e){Ll||(c(y.$$.fragment,e),c(v.$$.fragment,e),c(z.$$.fragment,e),c($.$$.fragment,e),c(U.$$.fragment,e),c(B.$$.fragment,e),c(x.$$.fragment,e),c(H.$$.fragment,e),c(L.$$.fragment,e),c(R.$$.fragment,e),c(E.$$.fragment,e),c(F.$$.fragment,e),c(P.$$.fragment,e),c(Q.$$.fragment,e),c(K.$$.fragment,e),c(D.$$.fragment,e),c(te.$$.fragment,e),c(oe.$$.fragment,e),c(ae.$$.fragment,e),c(re.$$.fragment,e),c(de.$$.fragment,e),c(he.$$.fragment,e),c(Ue.$$.fragment,e),c(ke.$$.fragment,e),c(Ce.$$.fragment,e),c(Ve.$$.fragment,e),c(Re.$$.fragment,e),c(Ne.$$.fragment,e),c(Pe.$$.fragment,e),c(De.$$.fragment,e),Ll=!0)},o(e){u(y.$$.fragment,e),u(v.$$.fragment,e),u(z.$$.fragment,e),u($.$$.fragment,e),u(U.$$.fragment,e),u(B.$$.fragment,e),u(x.$$.fragment,e),u(H.$$.fragment,e),u(L.$$.fragment,e),u(R.$$.fragment,e),u(E.$$.fragment,e),u(F.$$.fragment,e),u(P.$$.fragment,e),u(Q.$$.fragment,e),u(K.$$.fragment,e),u(D.$$.fragment,e),u(te.$$.fragment,e),u(oe.$$.fragment,e),u(ae.$$.fragment,e),u(re.$$.fragment,e),u(de.$$.fragment,e),u(he.$$.fragment,e),u(Ue.$$.fragment,e),u(ke.$$.fragment,e),u(Ce.$$.fragment,e),u(Ve.$$.fragment,e),u(Re.$$.fragment,e),u(Ne.$$.fragment,e),u(Pe.$$.fragment,e),u(De.$$.fragment,e),Ll=!1},d(e){e&&(l(tt),l(Oe),l(lt),l(it),l(ot),l(J),l(nt),l(at),l(_),l(st),l(w),l(rt),l(g),l(dt),l(pt),l(h),l(mt),l(j),l(ct),l(ut),l(Z),l(Mt),l(bt),l(ft),l(k),l(Tt),l(W),l(yt),l(C),l(vt),l(Jt),l(I),l(zt),l(G),l(_t),l(wt),l(V),l(gt),l($t),l(X),l(ht),l(jt),l(Ut),l(Y),l(Zt),l(N),l(Bt),l(xt),l(A),l(kt),l(S),l(Wt),l(Ct),l(q),l(Ht),l(It),l(Gt),l(O),l(Lt),l(ee),l(Vt),l(Rt),l(le),l(Xt),l(ie),l(Et),l(Ft),l(ne),l(Yt),l(Nt),l(se),l(Pt),l(At),l(St),l(pe),l(Qt),l(me),l(qt),l(ce),l(Kt),l(ue),l(Dt),l(Me),l(Ot),l(be),l(el),l(fe),l(tl),l(Te),l(ll),l(ye),l(il),l(ve),l(ol),l(Je),l(nl),l(ze),l(al),l(_e),l(sl),l(we),l(rl),l(ge),l(dl),l($e),l(pl),l(ml),l(je),l(cl),l(ul),l(Ze),l(Ml),l(Be),l(bl),l(xe),l(fl),l(Tl),l(We),l(yl),l(vl),l(He),l(Jl),l(Ie),l(zl),l(Ge),l(_l),l(Le),l(wl),l(gl),l($l),l(Xe),l(hl),l(Ee),l(jl),l(Fe),l(Ul),l(Ye),l(Zl),l(Bl),l(xl),l(Ae),l(kl),l(Se),l(Wl),l(Qe),l(Cl),l(qe),l(Hl),l(Ke),l(Il),l(Gl),l(et)),l(T),M(y,e),M(v,e),M(z,e),M($,e),M(U,e),M(B,e),M(x,e),M(H,e),M(L,e),M(R,e),M(E,e),M(F,e),M(P,e),M(Q,e),M(K,e),M(D,e),M(te,e),M(oe,e),M(ae,e),M(re,e),M(de,e),M(he,e),M(Ue,e),M(ke,e),M(Ce,e),M(Ve,e),M(Re,e),M(Ne,e),M(Pe,e),M(De,e)}}}const to='{"title":"Migrazione da pacchetti precedenti","local":"migrazione-da-pacchetti-precedenti","sections":[{"title":"Migrazione da transformers v3.x a v4.x","local":"migrazione-da-transformers-v3x-a-v4x","sections":[{"title":"1. AutoTokenizer e pipeline ora utilizzano tokenizer veloci (rust) per impostazione predefinita.","local":"1-autotokenizer-e-pipeline-ora-utilizzano-tokenizer-veloci-rust-per-impostazione-predefinita","sections":[{"title":"Come ottenere lo stesso comportamento di v3.x in v4.x","local":"come-ottenere-lo-stesso-comportamento-di-v3x-in-v4x","sections":[],"depth":5}],"depth":4},{"title":"2. SentencePiece Ã¨ stato rimosso dalle dipendenze richieste","local":"2-sentencepiece-Ã¨-stato-rimosso-dalle-dipendenze-richieste","sections":[{"title":"Come ottenere lo stesso comportamento della v3.x nella v4.x","local":"come-ottenere-lo-stesso-comportamento-della-v3x-nella-v4x","sections":[],"depth":5}],"depth":4},{"title":"3. Lâ€™architettura delle repo Ã¨ stato aggiornata in modo che ogni modello abbia la propria cartella","local":"3-larchitettura-delle-repo-Ã¨-stato-aggiornata-in-modo-che-ogni-modello-abbia-la-propria-cartella","sections":[{"title":"Come ottenere lo stesso comportamento della v3.x nella v4.x","local":"come-ottenere-lo-stesso-comportamento-della-v3x-nella-v4x","sections":[],"depth":5}],"depth":4},{"title":"4. Impostare lâ€™argomento return_dict su True per impostazione predefinita","local":"4-impostare-largomento-returndict-su-true-per-impostazione-predefinita","sections":[{"title":"Come ottenere lo stesso comportamento della v3.x nella v4.x","local":"come-ottenere-lo-stesso-comportamento-della-v3x-nella-v4x","sections":[],"depth":5}],"depth":4},{"title":"5. Rimozione di alcuni attributi deprecati","local":"5-rimozione-di-alcuni-attributi-deprecati","sections":[],"depth":4}],"depth":2},{"title":"Passaggio da pytorch-transformers a ðŸ¤— Transformers","local":"passaggio-da-pytorch-transformers-a--transformers","sections":[{"title":"Lâ€™ordine posizionale di alcune parole chiave di input dei modelli ( attention_mask , token_type_ids â€¦) Ã¨ cambiato","local":"lordine-posizionale-di-alcune-parole-chiave-di-input-dei-modelli--attentionmask--tokentypeids--Ã¨-cambiato","sections":[],"depth":3}],"depth":2},{"title":"Migrazione da pytorch-pretrained-bert","local":"migrazione-da-pytorch-pretrained-bert","sections":[{"title":"I modelli restituiscono sempre tuple","local":"i-modelli-restituiscono-sempre-tuple","sections":[],"depth":3},{"title":"Serializzazione","local":"serializzazione","sections":[],"depth":3},{"title":"Ottimizzatori: BertAdam e OpenAIAdam ora sono AdamW, lo scheduling Ã¨ quello standard PyTorch","local":"ottimizzatori-bertadam-e-openaiadam-ora-sono-adamw-lo-scheduling-Ã¨-quello-standard-pytorch","sections":[],"depth":3}],"depth":2}],"depth":1}';function lo(Vl){return Qi(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class so extends qi{constructor(T){super(),Ki(this,T,lo,eo,Ai,{})}}export{so as component};
