<meta charset="utf-8" /><meta name="hf:doc:metadata" content="{&quot;title&quot;:&quot;Community&quot;,&quot;local&quot;:&quot;community&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Community resources:&quot;,&quot;local&quot;:&quot;community-resources&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Community notebooks:&quot;,&quot;local&quot;:&quot;community-notebooks&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}">
		<link href="/docs/transformers/main/ja/_app/immutable/assets/0.e3b0c442.css" rel="modulepreload">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/entry/start.e4e638ff.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/scheduler.9bc65507.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/singletons.1a8126ff.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/index.3b203c72.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/paths.b54ca2a4.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/entry/app.9eb58bd7.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/index.707bf1b6.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/nodes/0.aec38eb9.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/each.e59479a4.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/nodes/11.3aa6c461.js">
		<link rel="modulepreload" href="/docs/transformers/main/ja/_app/immutable/chunks/Heading.342b1fa6.js"><!-- HEAD_svelte-u9bgzb_START --><meta name="hf:doc:metadata" content="{&quot;title&quot;:&quot;Community&quot;,&quot;local&quot;:&quot;community&quot;,&quot;sections&quot;:[{&quot;title&quot;:&quot;Community resources:&quot;,&quot;local&quot;:&quot;community-resources&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2},{&quot;title&quot;:&quot;Community notebooks:&quot;,&quot;local&quot;:&quot;community-notebooks&quot;,&quot;sections&quot;:[],&quot;depth&quot;:2}],&quot;depth&quot;:1}"><!-- HEAD_svelte-u9bgzb_END -->      <p></p>   <h1 class="relative group"><a id="community" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#community"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Community</span></h1> <p data-svelte-h="svelte-e3qqtl">このページは、コミュニティによって開発された🤗 Transformersに関するリソースをまとめたものです。</p>  <h2 class="relative group"><a id="community-resources" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#community-resources"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Community resources:</span></h2> <table data-svelte-h="svelte-upaqh4"><thead><tr><th align="left">リソース</th> <th align="left">説明</th> <th align="right">作者</th></tr></thead> <tbody><tr><td align="left"><a href="https://www.darigovresearch.com/huggingface-transformers-glossary-flashcards" rel="nofollow">Hugging Face Transformers Glossary Flashcards</a></td> <td align="left"><a href="glossary">Transformers Docs Glossary</a>に基づいたフラッシュカードセットです。このセットは、長期の知識定着を特に考慮して設計されたオープンソースのクロスプラットフォームアプリである<a href="https://apps.ankiweb.net/" rel="nofollow">Anki</a>を使用して簡単に学習/復習できる形式になっています。<a href="https://www.youtube.com/watch?v=Dji_h7PILrw" rel="nofollow">フラッシュカードの使用方法に関する紹介ビデオはこちら</a>をご覧ください。</td> <td align="right"><a href="https://www.darigovresearch.com/" rel="nofollow">Darigov Research</a></td></tr></tbody></table>  <h2 class="relative group"><a id="community-notebooks" class="header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full" href="#community-notebooks"><span><svg class="" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" width="1em" height="1em" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 256"><path d="M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z" fill="currentColor"></path></svg></span></a> <span>Community notebooks:</span></h2> <table data-svelte-h="svelte-iccxtl"><thead><tr><th align="left">ノートブック</th> <th align="left">説明</th> <th align="left">著者</th> <th align="right"></th></tr></thead> <tbody><tr><td align="left"><a href="https://github.com/AlekseyKorshuk/huggingartists" rel="nofollow">事前学習済みのTransformerを微調整して歌詞を生成</a></td> <td align="left">GPT-2モデルを微調整してお気に入りのアーティストのスタイルで歌詞を生成する方法</td> <td align="left"><a href="https://github.com/AlekseyKorshuk" rel="nofollow">Aleksey Korshuk</a></td> <td align="right"><a href="https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/snapthat/TF-T5-text-to-text" rel="nofollow">Tensorflow 2でT5をトレーニング</a></td> <td align="left">Tensorflow 2を使用して任意のタスクに対してT5をトレーニングする方法。このノートブックはTensorflow 2を使用してSQUADで実装された質問と回答タスクを示しています。</td> <td align="left"><a href="https://github.com/HarrisDePerceptron" rel="nofollow">Muhammad Harris</a></td> <td align="right"><a href="https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb" rel="nofollow">TPUでT5をトレーニング</a></td> <td align="left">TransformersとNlpを使用してSQUADでT5をトレーニングする方法</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb" rel="nofollow">分類と多肢選択のためにT5を微調整</a></td> <td align="left">PyTorch Lightningを使用してテキスト対テキスト形式でT5を分類と多肢選択タスクに微調整する方法</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb" rel="nofollow">新しいデータセットと言語でDialoGPTを微調整</a></td> <td align="left">DialoGPTモデルを新しいデータセットでオープンダイアログ会話用の微調整する方法</td> <td align="left"><a href="https://github.com/ncoop57" rel="nofollow">Nathan Cooper</a></td> <td align="right"><a href="https://colab.research.google.com/github/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb" rel="nofollow">Reformerを使用した長いシーケンスモデリング</a></td> <td align="left">Reformerを使用して500,000トークンまでのシーケンスをトレーニングする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb" rel="nofollow">要約のためにBARTを微調整</a></td> <td align="left">Blurrを使用して要約のためにBARTを微調整する方法</td> <td align="left"><a href="https://ohmeow.com/" rel="nofollow">Wayde Gilliam</a></td> <td align="right"><a href="https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb" rel="nofollow">事前学習済みのTransformerを微調整して誰かのツイートを生成</a></td> <td align="left">GPT-2モデルを微調整してお気に入りのTwitterアカウントのスタイルでツイートを生成する方法</td> <td align="left"><a href="https://github.com/borisdayma" rel="nofollow">Boris Dayma</a></td> <td align="right"><a href="https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb" rel="nofollow">🤗 Hugging FaceモデルをWeights &amp; Biasesで最適化</a></td> <td align="left">Hugging FaceとWeights &amp; Biasesの統合を示す完全なチュートリアル</td> <td align="left"><a href="https://github.com/borisdayma" rel="nofollow">Boris Dayma</a></td> <td align="right"><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb" rel="nofollow">Longformerの事前学習</a></td> <td align="left">既存の事前学習済みモデルの「長い」バージョンを構築する方法</td> <td align="left"><a href="https://beltagy.net" rel="nofollow">Iz Beltagy</a></td> <td align="right"><a href="https://colab.research.google.com/github/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb" rel="nofollow">QAタスクのためにLongformerを微調整</a></td> <td align="left">QAタスクのためにLongformerモデルを微調整する方法</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/How_to_evaluate_Longformer_on_TriviaQA_using_NLP.ipynb" rel="nofollow">🤗nlpを使用したモデルの評価</a></td> <td align="left"><code>nlp</code>を使用してTriviaQAでLongformerを評価する方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1m7eTGlPmLRgoPkkA7rkhQdZ9ydpmsdLE?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb" rel="nofollow">感情スパン抽出のためにT5を微調整</a></td> <td align="left">PyTorch Lightningを使用して感情スパン抽出のためにT5を微調整する方法</td> <td align="left"><a href="https://github.com/enzoampil" rel="nofollow">Lorenzo Ampil</a></td> <td align="right"><a href="https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb" rel="nofollow">DistilBertをマルチクラス分類にファインチューニング</a></td> <td align="left">PyTorchを使用してDistilBertをマルチクラス分類にファインチューニングする方法</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb" rel="nofollow">BERTをマルチラベル分類にファインチューニング</a></td> <td align="left">PyTorchを使用してBERTをマルチラベル分類にファインチューニングする方法</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb" rel="nofollow">T5を要約にファインチューニング</a></td> <td align="left">PyTorchを使用してT5を要約にファインチューニングし、WandBで実験をトラッキングする方法</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/ELS-RD/transformers-notebook/blob/master/Divide_Hugging_Face_Transformers_training_time_by_2_or_more.ipynb" rel="nofollow">ダイナミックパディング/バケッティングを使用してTransformersのファインチューニングを高速化</a></td> <td align="left">ダイナミックパディング/バケッティングを使用してファインチューニングを2倍高速化する方法</td> <td align="left"><a href="https://github.com/pommedeterresautee" rel="nofollow">Michael Benesty</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1CBfRU1zbfu7-ijiOqAAQUA-RJaxfcJoO?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Reformer_For_Masked_LM.ipynb" rel="nofollow">マスク言語モデリングのためのReformerの事前学習</a></td> <td align="left">双方向セルフアテンションレイヤーを備えたReformerモデルのトレーニング方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1tzzh0i8PgDQGV3SMFUGxM7_gGae3K-uW?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/lordtt13/word-embeddings/blob/master/COVID-19%20Research%20Data/COVID-SciBERT.ipynb" rel="nofollow">Sci-BERTを拡張してファインチューニング</a></td> <td align="left">AllenAIのCORDデータセットで事前学習済みのSciBERTモデルの語彙を拡張し、パイプライン化する方法</td> <td align="left"><a href="https://github.com/lordtt13" rel="nofollow">Tanmay Thakur</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1rqAR40goxbAfez1xvF3hBJphSCsvXmh8" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/lordtt13/transformers-experiments/blob/master/Custom%20Tasks/fine-tune-blenderbot_small-for-summarization.ipynb" rel="nofollow">Trainer APIを使用してBlenderBotSmallを要約のためにファインチューニング</a></td> <td align="left">カスタムデータセットでBlenderBotSmallを要約のためにファインチューニングする方法、Trainer APIを使用</td> <td align="left"><a href="https://github.com/lordtt13" rel="nofollow">Tanmay Thakur</a></td> <td align="right"><a href="https://colab.research.google.com/drive/19Wmupuls7mykSGyRN_Qo6lPQhgp56ymq?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb" rel="nofollow">ElectraをファインチューニングしてCaptum Integrated Gradientsで解釈</a></td> <td align="left">Electraを感情分析のためにファインチューニングし、Captum Integrated Gradientsで予測を解釈する方法</td> <td align="left"><a href="https://elsanns.github.io" rel="nofollow">Eliza Szczechla</a></td> <td align="right"><a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb" rel="nofollow">Trainerクラスを使用して非英語のGPT-2モデルをファインチューニング</a></td> <td align="left">Trainerクラスを使用して非英語のGPT-2モデルをファインチューニングする方法</td> <td align="left"><a href="https://www.philschmid.de" rel="nofollow">Philipp Schmid</a></td> <td align="right"><a href="https://colab.research.google.com/github/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb" rel="nofollow">DistilBERTモデルをマルチラベル分類タスクのためにファインチューニング</a></td> <td align="left">DistilBERTモデルをマルチラベル分類タスクのためにファインチューニングする方法</td> <td align="left"><a href="https://github.com/DhavalTaunk08" rel="nofollow">Dhaval Taunk</a></td> <td align="right"><a href="https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb" rel="nofollow">ALBERTを文ペア分類タスクのためにファインチューニング</a></td> <td align="left">ALBERTモデルまたは他のBERTベースのモデルを文ペア分類タスクのためにファインチューニングする方法</td> <td align="left"><a href="https://github.com/NadirEM" rel="nofollow">Nadir El Manouzi</a></td> <td align="right"><a href="https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb" rel="nofollow">RoBERTaを感情分析のためにファインチューニング</a></td> <td align="left">RoBERTaモデルを感情分析のためにファインチューニングする方法</td> <td align="left"><a href="https://github.com/DhavalTaunk08" rel="nofollow">Dhaval Taunk</a></td> <td align="right"><a href="https://colab.research.google.com/github/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/flexudy-pipe/qugeev" rel="nofollow">質問生成モデルの評価</a></td> <td align="left">seq2seqトランスフォーマーモデルによって生成された質問の回答の正確さを評価する方法</td> <td align="left"><a href="https://github.com/zolekode" rel="nofollow">Pascal Zoleko</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1bpsSqCQU-iw_5nNoRm_crPq6FRuJthq_?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb" rel="nofollow">DistilBERTとTensorflowを使用してテキストを分類</a></td> <td align="left">TensorFlowでテキスト分類のためにDistilBERTをファインチューニングする方法</td> <td align="left"><a href="https://github.com/peterbayerle" rel="nofollow">Peter Bayerle</a></td> <td align="right"><a href="https://colab.research.google.com/github/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb" rel="nofollow">CNN/Dailymailでのエンコーダーデコーダー要約にBERTを活用</a></td> <td align="left"><em>google-bert/bert-base-uncased</em> チェックポイントを使用してCNN/Dailymailの要約のために <em>EncoderDecoderModel</em> をウォームスタートする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb" rel="nofollow">BBC XSumでのエンコーダーデコーダー要約にRoBERTaを活用</a></td> <td align="left"><em>FacebookAI/roberta-base</em> チェックポイントを使用してBBC/XSumの要約のための共有 <em>EncoderDecoderModel</em> をウォームスタートする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb" rel="nofollow">TAPASをシーケンシャル質問応答（SQA）でファインチューニング</a></td> <td align="left">シーケンシャル質問応答（SQA）データセットで <em>tapas-base</em> チェックポイントを使用して <em>TapasForQuestionAnswering</em> をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb" rel="nofollow">TabFactでTAPASを評価</a></td> <td align="left"><em>tapas-base-finetuned-tabfact</em> チェックポイントを使用してファインチューニングされた <em>TapasForSequenceClassification</em> を評価する方法、🤗 datasets と 🤗 transformers ライブラリを組み合わせて使用</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb" rel="nofollow">翻訳のためのmBARTをファインチューニング</a></td> <td align="left">Seq2SeqTrainerを使用してHindiからEnglishへの翻訳のためにmBARTをファインチューニングする方法</td> <td align="left"><a href="https://github.com/vasudevgupta7" rel="nofollow">Vasudev Gupta</a></td> <td align="right"><a href="https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb" rel="nofollow">FUNSD（フォーム理解データセット）でLayoutLMをファインチューニング</a></td> <td align="left">スキャンされたドキュメントからの情報抽出のためにFUNSDデータセットで <em>LayoutLMForTokenClassification</em> をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb" rel="nofollow">DistilGPT2のファインチューニングとテキスト生成</a></td> <td align="left">DistilGPT2のファインチューニングとテキスト生成方法</td> <td align="left"><a href="https://github.com/tripathiaakash" rel="nofollow">Aakash Tripathi</a></td> <td align="right"><a href="https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb" rel="nofollow">最大8KトークンでのLEDのファインチューニング</a></td> <td align="left">ロングレンジ要約のためのpubmedでLEDをファインチューニングする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb" rel="nofollow">ArxivでのLEDの評価</a></td> <td align="left">ロングレンジ要約のためのLEDの効果的な評価方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb" rel="nofollow">RVL-CDIP（文書画像分類データセット）でのLayoutLMのファインチューニング</a></td> <td align="left">スキャンされた文書の分類のためのRVL-CDIPデータセットで<em>LayoutLMForSequenceClassification</em>をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/voidful/huggingface_notebook/blob/main/xlsr_gpt.ipynb" rel="nofollow">Wav2Vec2 CTCデコーディングとGPT2の調整</a></td> <td align="left">言語モデルの調整を伴うCTCシーケンスのデコーディング方法</td> <td align="left"><a href="https://github.com/voidful" rel="nofollow">Eric Lam</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1e_z5jQHYbO2YKEaUgzb1ww1WwiAyydAj?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb" rel="nofollow">Trainerクラスを使用した2言語の要約用にBARTをファインチューニング</a></td> <td align="left">トレーナークラスを使用して2つの言語での要約用にBARTをファインチューニングする方法</td> <td align="left"><a href="https://github.com/elsanns" rel="nofollow">Eliza Szczechla</a></td> <td align="right"><a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb" rel="nofollow">PubMedデータセットでBigBirdの評価</a></td> <td align="left">Trivia QAの長いドキュメント質問応答でBigBirdの評価方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb" rel="nofollow">Wav2Vec2を使用してビデオの字幕を作成する</a></td> <td align="left">Wav2Vecでオーディオを転記して任意のビデオからYouTubeの字幕を作成する方法</td> <td align="left"><a href="https://github.com/Muennighoff" rel="nofollow">Niklas Muennighoff</a></td> <td align="right"><a href="https://colab.research.google.com/github/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb" rel="nofollow">PyTorch Lightningを使用したCIFAR-10でのVision Transformerのファインチューニング</a></td> <td align="left">HuggingFace Transformers、Datasets、およびPyTorch Lightningを使用してCIFAR-10でVision Transformer（ViT）をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb" rel="nofollow">🤗 Trainerを使用したCIFAR-10でのVision Transformerのファインチューニング</a></td> <td align="left">HuggingFace Transformers、Datasets、および🤗 Trainerを使用してCIFAR-10でVision Transformer（ViT）をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb" rel="nofollow">Open Entity、エンティティタイピングデータセットでLUKEの評価</a></td> <td align="left">Open Entityデータセットで<em>LukeForEntityClassification</em>の評価方法</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb" rel="nofollow">TACRED、関係抽出データセットでLUKEの評価</a></td> <td align="left">TACREDデータセットで<em>LukeForEntityPairClassification</em>の評価方法</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb" rel="nofollow">CoNLL-2003、重要なNERベンチマークでLUKEの評価</a></td> <td align="left">CoNLL-2003データセットで<em>LukeForEntitySpanClassification</em>の評価方法</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb" rel="nofollow">PubMedデータセットでBigBird-Pegasusの評価</a></td> <td align="left">PubMedデータセットで<em>BigBirdPegasusForConditionalGeneration</em>の評価方法</td> <td align="left"><a href="https://github.com/vasudevgupta7" rel="nofollow">Vasudev Gupta</a></td> <td align="right"><a href="https://colab.research.google.com/github/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb" rel="nofollow">Wav2Vec2を使用したスピーチエモーション分類</a></td> <td align="left">MEGAデータセットでの感情分類のための事前学習済みWav2Vec2モデルの利用方法</td> <td align="left"><a href="https://github.com/m3hrdadfi" rel="nofollow">Mehrdad Farahani</a></td> <td align="right"><a href="https://colab.research.google.com/github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb" rel="nofollow">DETRを使用して画像内のオブジェクトを検出する</a></td> <td align="left">トレーニング済み<em>DetrForObjectDetection</em>モデルを使用して画像内のオブジェクトを検出し、注意を可視化する方法</td> <td align="left"><a href="https://github.com/NielsRogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb" rel="nofollow">カスタムオブジェクト検出データセットでDETRをファインチューニングする</a></td> <td align="left">カスタムオブジェクト検出データセットで<em>DetrForObjectDetection</em>をファインチューニングする方法</td> <td align="left"><a href="https://github.com/NielsRogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr> <tr><td align="left"><a href="https://github.com/ToluClassics/Notebooks/blob/main/T5_Ner_Finetuning.ipynb" rel="nofollow">Named Entity RecognitionのためにT5をファインチューニング</a></td> <td align="left">Named Entity RecognitionタスクでT5をファインチューニングする方法</td> <td align="left"><a href="https://github.com/ToluClassics" rel="nofollow">Ogundepo Odunayo</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"></a></td></tr></tbody></table>  <p></p> 
			
			<script>
				{
					__sveltekit_l6ewbf = {
						assets: "/docs/transformers/main/ja",
						base: "/docs/transformers/main/ja",
						env: {}
					};

					const element = document.currentScript.parentElement;

					const data = [null,null];

					Promise.all([
						import("/docs/transformers/main/ja/_app/immutable/entry/start.e4e638ff.js"),
						import("/docs/transformers/main/ja/_app/immutable/entry/app.9eb58bd7.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 11],
							data,
							form: null,
							error: null
						});
					});
				}
			</script>
		
