import{s as Ja,f as Ds,n as Ua,o as ja}from"../chunks/scheduler.9bc65507.js";import{S as ka,i as Ca,g as p,s as n,r as L,m as r,H as T,A as za,h as m,f as t,c as e,j as K,u as N,x as c,n as o,B as _,k as y,y as i,a as l,v as A,d as Y,t as S,w as F}from"../chunks/index.707bf1b6.js";import{C as Ks}from"../chunks/CodeBlock.54a9f38d.js";import{D as Ga}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{H as Os}from"../chunks/Heading.342b1fa6.js";function Ia(sa){let u,ts,O,ls,J,ns,U,es,j,aa='パープレキシティ（PPL）は言語モデルの評価に最も一般的な指標の1つです。深入りする前に、この指標は特に古典的な言語モデル（時にはオートレグレッシブまたは因果言語モデルとも呼ばれる）に適用され、BERTなどのマスクされた言語モデルには適していないことに注意すべきです（モデルの概要を参照してください<a href="model_summary">モデルの概要</a>）。',ps,M,Ns,ms,Ma='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>X</mi><mo>=</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">X = (x_0, x_1, \\dots, x_t)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>',is,rs,wa='<span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>PPL</mtext><mo stretchy="false">(</mo><mi>X</mi><mo stretchy="false">)</mo><mo>=</mo><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">{</mo><mrow><mo>−</mo><mfrac><mn>1</mn><mi>t</mi></mfrac><munderover><mo>∑</mo><mi>i</mi><mi>t</mi></munderover><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub><mo stretchy="false">)</mo></mrow><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">\\text{PPL}(X) = \\exp \\left\\{ {-\\frac{1}{t}\\sum_i^t \\log p_\\theta (x_i|x_{&lt;i}) } \\right\\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord">PPL</span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07847em;">X</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.0582em;vertical-align:-1.2777em;"></span><span class="mop">exp</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.7806em;"><span style="top:-1.8723em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size4">}</span></span></span></span></span></span></span>',cs,d,As,q,ta="\\theta (x_i|x",Ys,os,ba='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">x_{&lt;i}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6079em;vertical-align:-0.1774em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span></span></span></span>',hs,gs,k,la='これはまた、データとモデルの予測との間の交差エントロピーの指数化と同等です。パープレキシティおよびビット・パー・キャラクター（BPC）とデータ圧縮との関係についての詳細な情報については、この<a href="https://thegradient.pub/understanding-evaluation-metrics-for-language-models/" rel="nofollow">素晴らしい The Gradient のブログ記事</a>を参照してください。',ys,C,ds,z,na="モデルのコンテキストサイズに制約がない場合、モデルのパープレキシティを評価するためには、シーケンスを自己回帰的に因子分解し、各ステップで前のサブシーケンスに条件を付けることで計算します。以下に示すように。",us,w,ea,Ms,h,Ss,G,pa="GPT-2",Fs,ws,fa='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em;"></span><span class="mord mathnormal">t</span></span></span></span>',bs,fs,va='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_\\theta(x_t|x_{&lt;t})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mrel mtight">&lt;</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.1774em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>',vs,xs,g,qs,Ts,xa='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span></span></span></span>',_s,Js,Ta='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>t</mi></msub></mrow><annotation encoding="application/x-tex">x_t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>',Us,js,_a='<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span>',ks,Cs,b,ma,zs,I,ia="これは各セグメントのパープレキシティが1回のフォワードパスで計算できるため、計算が迅速ですが、通常、モデルはほとんどの予測ステップでコンテキストが少ないため、完全に因子分解されたパープレキシティの悪い近似となり、通常、より高い（悪い）PPLを返します。",Gs,Z,ra="代わりに、固定長モデルのPPLはスライディングウィンドウ戦略を用いて評価するべきです。これには、モデルが各予測ステップでより多くのコンテキストを持つように、コンテキストウィンドウを繰り返しスライドさせるという方法が含まれます。",Is,f,ca,Zs,B,oa="これはシーケンスの確率のより正確な分解に近いものであり、通常はより有利なスコアを生成します。欠点は、コーパス内の各トークンに対して別個の前方パスが必要です。実用的な妥協案は、1トークンずつスライドする代わりに、より大きなストライドでコンテキストを移動するストライド型のスライディングウィンドウを使用することです。これにより、計算がはるかに高速に進行できる一方で、モデルには各ステップで予測を行うための大きなコンテキストが提供されます。",Bs,W,Ws,$,ha="GPT-2を使用してこのプロセスをデモンストレーションしてみましょう。",$s,E,Es,P,ga="WikiText-2データセットを読み込み、異なるスライディングウィンドウ戦略を使用してパープレキシティを評価します。このデータセットは小規模で、セット全体に対して単一のフォワードパスを実行するだけなので、データセット全体をメモリに読み込んでエンコードするだけで十分です。",Ps,X,Xs,R,ya="🤗 Transformersを使用すると、単純に<code>input_ids</code>をモデルの<code>labels</code>として渡すことで、各トークンの平均負の対数尤度が損失として返されます。しかし、スライディングウィンドウのアプローチでは、各イテレーションでモデルに渡すトークンにオーバーラップがあります。私たちは、コンテキストとして扱っているトークンの対数尤度を損失に含めたくありません。そのため、これらの対象を <code>-100</code> に設定して無視されるようにします。以下は、ストライドを <code>512</code> とした場合の例です。これにより、モデルは任意のトークンの条件付けの尤度を計算する際に、少なくともコンテキストとして 512 トークンを持つことになります（512 個の前のトークンが利用可能である場合）。",Rs,H,Hs,V,da="ストライド長が最大入力長と同じ場合、上述の最適でないスライディングウィンドウ戦略と同等です。ストライドが小さいほど、モデルは各予測を行う際により多くのコンテキストを持つため、通常、報告される困難度（perplexity）が向上します。",Vs,Q,ua="上記のコードを <code>stride = 1024</code> で実行すると、オーバーラップがない状態で、結果の困難度（perplexity）は <code>19.44</code> になります。これは GPT-2 の論文に報告された <code>19.93</code> とほぼ同等です。一方、<code>stride = 512</code> を使用し、このようにストライディングウィンドウ戦略を採用すると、困難度（perplexity）が <code>16.45</code> に向上します。これはより好意的なスコアだけでなく、シーケンスの尤度の真の自己回帰分解により近い方法で計算されています。",Qs,ss,Ls;return J=new Os({props:{title:"Perplexity of fixed-length models",local:"perplexity-of-fixed-length-models",headingTag:"h1"}}),U=new Ga({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/perplexity.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/perplexity.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/perplexity.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/perplexity.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/perplexity.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/perplexity.ipynb"}]}}),C=new Os({props:{title:"Calculating PPL with fixed-length models",local:"calculating-ppl-with-fixed-length-models",headingTag:"h2"}}),W=new Os({props:{title:"Example: Calculating perplexity with GPT-2 in 🤗 Transformers",local:"example-calculating-perplexity-with-gpt-2-in--transformers",headingTag:"h2"}}),E=new Ks({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEdQVDJMTUhlYWRNb2RlbCUyQyUyMEdQVDJUb2tlbml6ZXJGYXN0JTBBJTBBZGV2aWNlJTIwJTNEJTIwJTIyY3VkYSUyMiUwQW1vZGVsX2lkJTIwJTNEJTIwJTIyb3BlbmFpLWNvbW11bml0eSUyRmdwdDItbGFyZ2UlMjIlMEFtb2RlbCUyMCUzRCUyMEdQVDJMTUhlYWRNb2RlbC5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpLnRvKGRldmljZSklMEF0b2tlbml6ZXIlMjAlM0QlMjBHUFQyVG9rZW5pemVyRmFzdC5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> GPT2LMHeadModel, GPT2TokenizerFast

device = <span class="hljs-string">&quot;cuda&quot;</span>
model_id = <span class="hljs-string">&quot;openai-community/gpt2-large&quot;</span>
model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
tokenizer = GPT2TokenizerFast.from_pretrained(model_id)`,wrap:!1}}),X=new Ks({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBdGVzdCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ3aWtpdGV4dCUyMiUyQyUyMCUyMndpa2l0ZXh0LTItcmF3LXYxJTIyJTJDJTIwc3BsaXQlM0QlMjJ0ZXN0JTIyKSUwQWVuY29kaW5ncyUyMCUzRCUyMHRva2VuaXplciglMjIlNUNuJTVDbiUyMi5qb2luKHRlc3QlNUIlMjJ0ZXh0JTIyJTVEKSUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIp",highlighted:`<span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

test = load_dataset(<span class="hljs-string">&quot;wikitext&quot;</span>, <span class="hljs-string">&quot;wikitext-2-raw-v1&quot;</span>, split=<span class="hljs-string">&quot;test&quot;</span>)
encodings = tokenizer(<span class="hljs-string">&quot;\\n\\n&quot;</span>.join(test[<span class="hljs-string">&quot;text&quot;</span>]), return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),H=new Ks({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHFkbSUyMGltcG9ydCUyMHRxZG0lMEElMEFtYXhfbGVuZ3RoJTIwJTNEJTIwbW9kZWwuY29uZmlnLm5fcG9zaXRpb25zJTBBc3RyaWRlJTIwJTNEJTIwNTEyJTBBc2VxX2xlbiUyMCUzRCUyMGVuY29kaW5ncy5pbnB1dF9pZHMuc2l6ZSgxKSUwQSUwQW5sbHMlMjAlM0QlMjAlNUIlNUQlMEFwcmV2X2VuZF9sb2MlMjAlM0QlMjAwJTBBZm9yJTIwYmVnaW5fbG9jJTIwaW4lMjB0cWRtKHJhbmdlKDAlMkMlMjBzZXFfbGVuJTJDJTIwc3RyaWRlKSklM0ElMEElMjAlMjAlMjAlMjBlbmRfbG9jJTIwJTNEJTIwbWluKGJlZ2luX2xvYyUyMCUyQiUyMG1heF9sZW5ndGglMkMlMjBzZXFfbGVuKSUwQSUyMCUyMCUyMCUyMHRyZ19sZW4lMjAlM0QlMjBlbmRfbG9jJTIwLSUyMHByZXZfZW5kX2xvYyUyMCUyMCUyMyUyMG1heSUyMGJlJTIwZGlmZmVyZW50JTIwZnJvbSUyMHN0cmlkZSUyMG9uJTIwbGFzdCUyMGxvb3AlMEElMjAlMjAlMjAlMjBpbnB1dF9pZHMlMjAlM0QlMjBlbmNvZGluZ3MuaW5wdXRfaWRzJTVCJTNBJTJDJTIwYmVnaW5fbG9jJTNBZW5kX2xvYyU1RC50byhkZXZpY2UpJTBBJTIwJTIwJTIwJTIwdGFyZ2V0X2lkcyUyMCUzRCUyMGlucHV0X2lkcy5jbG9uZSgpJTBBJTIwJTIwJTIwJTIwdGFyZ2V0X2lkcyU1QiUzQSUyQyUyMCUzQS10cmdfbGVuJTVEJTIwJTNEJTIwLTEwMCUwQSUwQSUyMCUyMCUyMCUyMHdpdGglMjB0b3JjaC5ub19ncmFkKCklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBvdXRwdXRzJTIwJTNEJTIwbW9kZWwoaW5wdXRfaWRzJTJDJTIwbGFiZWxzJTNEdGFyZ2V0X2lkcyklMEElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjMlMjBsb3NzJTIwaXMlMjBjYWxjdWxhdGVkJTIwdXNpbmclMjBDcm9zc0VudHJvcHlMb3NzJTIwd2hpY2glMjBhdmVyYWdlcyUyMG92ZXIlMjB2YWxpZCUyMGxhYmVscyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMyUyME4uQi4lMjB0aGUlMjBtb2RlbCUyMG9ubHklMjBjYWxjdWxhdGVzJTIwbG9zcyUyMG92ZXIlMjB0cmdfbGVuJTIwLSUyMDElMjBsYWJlbHMlMkMlMjBiZWNhdXNlJTIwaXQlMjBpbnRlcm5hbGx5JTIwc2hpZnRzJTIwdGhlJTIwbGFiZWxzJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIzJTIwdG8lMjB0aGUlMjBsZWZ0JTIwYnklMjAxLiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG5lZ19sb2dfbGlrZWxpaG9vZCUyMCUzRCUyMG91dHB1dHMubG9zcyUwQSUwQSUyMCUyMCUyMCUyMG5sbHMuYXBwZW5kKG5lZ19sb2dfbGlrZWxpaG9vZCklMEElMEElMjAlMjAlMjAlMjBwcmV2X2VuZF9sb2MlMjAlM0QlMjBlbmRfbG9jJTBBJTIwJTIwJTIwJTIwaWYlMjBlbmRfbG9jJTIwJTNEJTNEJTIwc2VxX2xlbiUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGJyZWFrJTBBJTBBcHBsJTIwJTNEJTIwdG9yY2guZXhwKHRvcmNoLnN0YWNrKG5sbHMpLm1lYW4oKSk=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm

max_length = model.config.n_positions
stride = <span class="hljs-number">512</span>
seq_len = encodings.input_ids.size(<span class="hljs-number">1</span>)

nlls = []
prev_end_loc = <span class="hljs-number">0</span>
<span class="hljs-keyword">for</span> begin_loc <span class="hljs-keyword">in</span> tqdm(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, seq_len, stride)):
    end_loc = <span class="hljs-built_in">min</span>(begin_loc + max_length, seq_len)
    trg_len = end_loc - prev_end_loc  <span class="hljs-comment"># may be different from stride on last loop</span>
    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)
    target_ids = input_ids.clone()
    target_ids[:, :-trg_len] = -<span class="hljs-number">100</span>

    <span class="hljs-keyword">with</span> torch.no_grad():
        outputs = model(input_ids, labels=target_ids)

        <span class="hljs-comment"># loss is calculated using CrossEntropyLoss which averages over valid labels</span>
        <span class="hljs-comment"># N.B. the model only calculates loss over trg_len - 1 labels, because it internally shifts the labels</span>
        <span class="hljs-comment"># to the left by 1.</span>
        neg_log_likelihood = outputs.loss

    nlls.append(neg_log_likelihood)

    prev_end_loc = end_loc
    <span class="hljs-keyword">if</span> end_loc == seq_len:
        <span class="hljs-keyword">break</span>

ppl = torch.exp(torch.stack(nlls).mean())`,wrap:!1}}),{c(){u=p("meta"),ts=n(),O=p("p"),ls=n(),L(J.$$.fragment),ns=n(),L(U.$$.fragment),es=n(),j=p("p"),j.innerHTML=aa,ps=n(),M=p("p"),Ns=r("パープレキシティは、シーケンスの指数平均負の対数尤度として定義されます。トークン化されたシーケンス"),ms=new T(!1),is=r(` がある場合、\\(X\\) のパープレキシティは次のように表されます。
`),rs=new T(!1),cs=n(),d=p("p"),As=r("ここで、\\(\\log p"),q=p("em"),q.textContent=ta,Ys=r("{<i})\\) はモデルによる前のトークン"),os=new T(!1),hs=r(" に対する第iトークンの対数尤度です。直感的には、これはモデルがコーパス内の指定されたトークンの集合に対して一様に予測する能力の評価と考えることができます。重要なのは、これによってトークン化手法がモデルのパープレキシティに直接影響を与えるため、異なるモデルを比較する際には常に考慮すべきであるということです。"),gs=n(),k=p("p"),k.innerHTML=la,ys=n(),L(C.$$.fragment),ds=n(),z=p("p"),z.textContent=na,us=n(),w=p("img"),Ms=n(),h=p("p"),Ss=r("しかし、通常、近似モデルを使用する場合、モデルが処理できるトークン数に制約があります。例えば、最大の"),G=p("a"),G.textContent=pa,Fs=r("のバージョンは1024トークンの固定長を持っているため、1024よりも大きい"),ws=new T(!1),bs=r(" に対して"),fs=new T(!1),vs=r(" を直接計算することはできません。"),xs=n(),g=p("p"),qs=r("代わりに、通常、シーケンスはモデルの最大入力サイズに等しいサブシーケンスに分割されます。モデルの最大入力サイズが"),Ts=new T(!1),_s=r(" の場合、トークン"),Js=new T(!1),Us=r(" の尤度を近似するには、完全なコンテキストではなく、それを先行する"),js=new T(!1),ks=r(" トークンにのみ条件を付けることがあります。シーケンスのモデルのパープレキシティを評価する際、誘惑的ですが非効率な方法は、シーケンスを分割し、各セグメントの分解対数尤度を独立に合算することです。"),Cs=n(),b=p("img"),zs=n(),I=p("p"),I.textContent=ia,Gs=n(),Z=p("p"),Z.textContent=ra,Is=n(),f=p("img"),Zs=n(),B=p("p"),B.textContent=oa,Bs=n(),L(W.$$.fragment),Ws=n(),$=p("p"),$.textContent=ha,$s=n(),L(E.$$.fragment),Es=n(),P=p("p"),P.textContent=ga,Ps=n(),L(X.$$.fragment),Xs=n(),R=p("p"),R.innerHTML=ya,Rs=n(),L(H.$$.fragment),Hs=n(),V=p("p"),V.textContent=da,Vs=n(),Q=p("p"),Q.innerHTML=ua,Qs=n(),ss=p("p"),this.h()},l(s){const a=za("svelte-u9bgzb",document.head);u=m(a,"META",{name:!0,content:!0}),a.forEach(t),ts=e(s),O=m(s,"P",{}),K(O).forEach(t),ls=e(s),N(J.$$.fragment,s),ns=e(s),N(U.$$.fragment,s),es=e(s),j=m(s,"P",{"data-svelte-h":!0}),c(j)!=="svelte-1svt3i0"&&(j.innerHTML=aa),ps=e(s),M=m(s,"P",{});var as=K(M);Ns=o(as,"パープレキシティは、シーケンスの指数平均負の対数尤度として定義されます。トークン化されたシーケンス"),ms=_(as,!1),is=o(as,` がある場合、\\(X\\) のパープレキシティは次のように表されます。
`),rs=_(as,!1),as.forEach(t),cs=e(s),d=m(s,"P",{});var D=K(d);As=o(D,"ここで、\\(\\log p"),q=m(D,"EM",{"data-svelte-h":!0}),c(q)!=="svelte-u5ex0m"&&(q.textContent=ta),Ys=o(D,"{<i})\\) はモデルによる前のトークン"),os=_(D,!1),hs=o(D," に対する第iトークンの対数尤度です。直感的には、これはモデルがコーパス内の指定されたトークンの集合に対して一様に予測する能力の評価と考えることができます。重要なのは、これによってトークン化手法がモデルのパープレキシティに直接影響を与えるため、異なるモデルを比較する際には常に考慮すべきであるということです。"),D.forEach(t),gs=e(s),k=m(s,"P",{"data-svelte-h":!0}),c(k)!=="svelte-1kscyw8"&&(k.innerHTML=la),ys=e(s),N(C.$$.fragment,s),ds=e(s),z=m(s,"P",{"data-svelte-h":!0}),c(z)!=="svelte-vg3xo8"&&(z.textContent=na),us=e(s),w=m(s,"IMG",{width:!0,alt:!0,src:!0}),Ms=e(s),h=m(s,"P",{});var v=K(h);Ss=o(v,"しかし、通常、近似モデルを使用する場合、モデルが処理できるトークン数に制約があります。例えば、最大の"),G=m(v,"A",{href:!0,"data-svelte-h":!0}),c(G)!=="svelte-12zunfo"&&(G.textContent=pa),Fs=o(v,"のバージョンは1024トークンの固定長を持っているため、1024よりも大きい"),ws=_(v,!1),bs=o(v," に対して"),fs=_(v,!1),vs=o(v," を直接計算することはできません。"),v.forEach(t),xs=e(s),g=m(s,"P",{});var x=K(g);qs=o(x,"代わりに、通常、シーケンスはモデルの最大入力サイズに等しいサブシーケンスに分割されます。モデルの最大入力サイズが"),Ts=_(x,!1),_s=o(x," の場合、トークン"),Js=_(x,!1),Us=o(x," の尤度を近似するには、完全なコンテキストではなく、それを先行する"),js=_(x,!1),ks=o(x," トークンにのみ条件を付けることがあります。シーケンスのモデルのパープレキシティを評価する際、誘惑的ですが非効率な方法は、シーケンスを分割し、各セグメントの分解対数尤度を独立に合算することです。"),x.forEach(t),Cs=e(s),b=m(s,"IMG",{width:!0,alt:!0,src:!0}),zs=e(s),I=m(s,"P",{"data-svelte-h":!0}),c(I)!=="svelte-qz3f35"&&(I.textContent=ia),Gs=e(s),Z=m(s,"P",{"data-svelte-h":!0}),c(Z)!=="svelte-16pocdr"&&(Z.textContent=ra),Is=e(s),f=m(s,"IMG",{width:!0,alt:!0,src:!0}),Zs=e(s),B=m(s,"P",{"data-svelte-h":!0}),c(B)!=="svelte-1x5apy7"&&(B.textContent=oa),Bs=e(s),N(W.$$.fragment,s),Ws=e(s),$=m(s,"P",{"data-svelte-h":!0}),c($)!=="svelte-ozwe3j"&&($.textContent=ha),$s=e(s),N(E.$$.fragment,s),Es=e(s),P=m(s,"P",{"data-svelte-h":!0}),c(P)!=="svelte-1v3mz4u"&&(P.textContent=ga),Ps=e(s),N(X.$$.fragment,s),Xs=e(s),R=m(s,"P",{"data-svelte-h":!0}),c(R)!=="svelte-kazetg"&&(R.innerHTML=ya),Rs=e(s),N(H.$$.fragment,s),Hs=e(s),V=m(s,"P",{"data-svelte-h":!0}),c(V)!=="svelte-1h0iwce"&&(V.textContent=da),Vs=e(s),Q=m(s,"P",{"data-svelte-h":!0}),c(Q)!=="svelte-1ct5dbc"&&(Q.innerHTML=ua),Qs=e(s),ss=m(s,"P",{}),K(ss).forEach(t),this.h()},h(){y(u,"name","hf:doc:metadata"),y(u,"content",Za),ms.a=is,rs.a=null,os.a=hs,y(w,"width","600"),y(w,"alt","完全なコンテキスト長のシーケンスの分解"),Ds(w.src,ea="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif")||y(w,"src",ea),y(G,"href","model_doc/gpt2"),ws.a=bs,fs.a=vs,Ts.a=_s,Js.a=Us,js.a=ks,y(b,"width","600"),y(b,"alt","利用可能な完全なコンテキストを活用しない非最適なPPL"),Ds(b.src,ma="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif")||y(b,"src",ma),y(f,"width","600"),y(f,"alt","Sliding window PPL taking advantage of all available context"),Ds(f.src,ca="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_sliding.gif")||y(f,"src",ca)},m(s,a){i(document.head,u),l(s,ts,a),l(s,O,a),l(s,ls,a),A(J,s,a),l(s,ns,a),A(U,s,a),l(s,es,a),l(s,j,a),l(s,ps,a),l(s,M,a),i(M,Ns),ms.m(Ma,M),i(M,is),rs.m(wa,M),l(s,cs,a),l(s,d,a),i(d,As),i(d,q),i(d,Ys),os.m(ba,d),i(d,hs),l(s,gs,a),l(s,k,a),l(s,ys,a),A(C,s,a),l(s,ds,a),l(s,z,a),l(s,us,a),l(s,w,a),l(s,Ms,a),l(s,h,a),i(h,Ss),i(h,G),i(h,Fs),ws.m(fa,h),i(h,bs),fs.m(va,h),i(h,vs),l(s,xs,a),l(s,g,a),i(g,qs),Ts.m(xa,g),i(g,_s),Js.m(Ta,g),i(g,Us),js.m(_a,g),i(g,ks),l(s,Cs,a),l(s,b,a),l(s,zs,a),l(s,I,a),l(s,Gs,a),l(s,Z,a),l(s,Is,a),l(s,f,a),l(s,Zs,a),l(s,B,a),l(s,Bs,a),A(W,s,a),l(s,Ws,a),l(s,$,a),l(s,$s,a),A(E,s,a),l(s,Es,a),l(s,P,a),l(s,Ps,a),A(X,s,a),l(s,Xs,a),l(s,R,a),l(s,Rs,a),A(H,s,a),l(s,Hs,a),l(s,V,a),l(s,Vs,a),l(s,Q,a),l(s,Qs,a),l(s,ss,a),Ls=!0},p:Ua,i(s){Ls||(Y(J.$$.fragment,s),Y(U.$$.fragment,s),Y(C.$$.fragment,s),Y(W.$$.fragment,s),Y(E.$$.fragment,s),Y(X.$$.fragment,s),Y(H.$$.fragment,s),Ls=!0)},o(s){S(J.$$.fragment,s),S(U.$$.fragment,s),S(C.$$.fragment,s),S(W.$$.fragment,s),S(E.$$.fragment,s),S(X.$$.fragment,s),S(H.$$.fragment,s),Ls=!1},d(s){s&&(t(ts),t(O),t(ls),t(ns),t(es),t(j),t(ps),t(M),t(cs),t(d),t(gs),t(k),t(ys),t(ds),t(z),t(us),t(w),t(Ms),t(h),t(xs),t(g),t(Cs),t(b),t(zs),t(I),t(Gs),t(Z),t(Is),t(f),t(Zs),t(B),t(Bs),t(Ws),t($),t($s),t(Es),t(P),t(Ps),t(Xs),t(R),t(Rs),t(Hs),t(V),t(Vs),t(Q),t(Qs),t(ss)),t(u),F(J,s),F(U,s),F(C,s),F(W,s),F(E,s),F(X,s),F(H,s)}}}const Za='{"title":"Perplexity of fixed-length models","local":"perplexity-of-fixed-length-models","sections":[{"title":"Calculating PPL with fixed-length models","local":"calculating-ppl-with-fixed-length-models","sections":[],"depth":2},{"title":"Example: Calculating perplexity with GPT-2 in 🤗 Transformers","local":"example-calculating-perplexity-with-gpt-2-in--transformers","sections":[],"depth":2}],"depth":1}';function Ba(sa){return ja(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ra extends ka{constructor(u){super(),Ca(this,u,Ba,Ia,Ja,{})}}export{Ra as component};
