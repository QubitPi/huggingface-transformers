import{s as Gt,o as Lt,n as Xt}from"../chunks/scheduler.9bc65507.js";import{S as Vt,i as Qt,g as p,s,r as m,A as It,h as o,f as l,c as n,j as Et,u as d,x as r,k as ce,y as Nt,a,v as f,d as b,t as M,w as u}from"../chunks/index.707bf1b6.js";import{T as Ht}from"../chunks/Tip.c2ecdbf4.js";import{C as y}from"../chunks/CodeBlock.54a9f38d.js";import{D as Pt}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{H as _}from"../chunks/Heading.342b1fa6.js";function zt(Me){let i,$="PEFTアダプターを<code>AutoModelFor</code>クラスまたは基本モデルクラス（<code>OPTForCausalLM</code>または<code>LlamaForCausalLM</code>など）で読み込むことができます。";return{c(){i=p("p"),i.innerHTML=$},l(c){i=o(c,"P",{"data-svelte-h":!0}),r(i)!=="svelte-1n21l1q"&&(i.innerHTML=$)},m(c,T){a(c,i,T)},p:Xt,d(c){c&&l(i)}}}function Yt(Me){let i,$='<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>を使用したモデルの微調整に慣れていない場合は、<a href="training">事前トレーニング済みモデルの微調整</a>チュートリアルをご覧ください。';return{c(){i=p("p"),i.innerHTML=$},l(c){i=o(c,"P",{"data-svelte-h":!0}),r(i)!=="svelte-x674ad"&&(i.innerHTML=$)},m(c,T){a(c,i,T)},p:Xt,d(c){c&&l(i)}}}function qt(Me){let i,$,c,T,Z,ye,k,$e,U,dt='<a href="https://huggingface.co/blog/peft" rel="nofollow">Parameter-Efficient Fine Tuning (PEFT)</a> メソッドは、事前学習済みモデルのパラメータをファインチューニング中に凍結し、その上にわずかな訓練可能なパラメータ（アダプター）を追加するアプローチです。アダプターは、タスク固有の情報を学習するために訓練されます。このアプローチは、メモリ使用量が少なく、完全にファインチューニングされたモデルと比較して計算リソースを低く抑えつつ、同等の結果を生成することが示されています。',Te,j,ft="PEFTで訓練されたアダプターは通常、完全なモデルのサイズよりも1桁小さく、共有、保存、読み込むのが便利です。",he,h,bt='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/PEFT-hub-screenshot.png"/> <figcaption class="text-center">Hubに格納されているOPTForCausalLMモデルのアダプター重みは、モデルの全体サイズの約6MBで、モデル重みの全サイズは約700MBです。</figcaption>',we,F,Mt='🤗 PEFTライブラリについて詳しく知りたい場合は、<a href="https://huggingface.co/docs/peft/index" rel="nofollow">ドキュメンテーション</a>をご覧ください。',ge,v,Je,W,ut="🤗 PEFTをインストールして始めましょう：",Ce,B,_e,R,ct="新機能を試してみたい場合、ソースからライブラリをインストールすることに興味があるかもしれません：",Ze,x,ke,E,Ue,H,yt="🤗 Transformersは、いくつかのPEFT（Parameter Efficient Fine-Tuning）メソッドをネイティブにサポートしており、ローカルまたはHubに格納されたアダプターウェイトを簡単に読み込んで実行またはトレーニングできます。以下のメソッドがサポートされています：",je,X,$t='<li><a href="https://huggingface.co/docs/peft/conceptual_guides/lora" rel="nofollow">Low Rank Adapters</a></li> <li><a href="https://huggingface.co/docs/peft/conceptual_guides/ia3" rel="nofollow">IA3</a></li> <li><a href="https://arxiv.org/abs/2303.10512" rel="nofollow">AdaLoRA</a></li>',Fe,G,Tt='他のPEFTメソッドを使用したい場合、プロンプト学習やプロンプト調整などについて詳しく知りたい場合、または🤗 PEFTライブラリ全般については、<a href="https://huggingface.co/docs/peft/index" rel="nofollow">ドキュメンテーション</a>を参照してください。',ve,L,We,V,ht="🤗 TransformersからPEFTアダプターモデルを読み込んで使用するには、Hubリポジトリまたはローカルディレクトリに <code>adapter_config.json</code> ファイルとアダプターウェイトが含まれていることを確認してください。次に、<code>AutoModelFor</code> クラスを使用してPEFTアダプターモデルを読み込むことができます。たとえば、因果言語モデリング用のPEFTアダプターモデルを読み込むには：",Be,Q,wt='<li>PEFTモデルのIDを指定します。</li> <li>それを<a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoModelForCausalLM">AutoModelForCausalLM</a> クラスに渡します。</li>',Re,I,xe,w,Ee,N,gt="また、<code>load_adapter</code>メソッドを呼び出すことで、PEFTアダプターを読み込むこともできます：",He,P,Xe,z,Ge,Y,Jt='<code>bitsandbytes</code> 統合は、8ビットおよび4ビットの精度データ型をサポートしており、大規模なモデルを読み込む際にメモリを節約するのに役立ちます（詳細については <code>bitsandbytes</code> 統合の<a href="./quantization#bitsandbytes-integration">ガイド</a>を参照してください）。<a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> に <code>load_in_8bit</code> または <code>load_in_4bit</code> パラメータを追加し、<code>device_map=&quot;auto&quot;</code> を設定してモデルを効果的にハードウェアに分散配置できます：',Le,q,Ve,A,Qe,S,Ct="既存のアダプターを持つモデルに新しいアダプターを追加するために <code>~peft.PeftModel.add_adapter</code> を使用できます。ただし、新しいアダプターは現在のアダプターと同じタイプである限り、これを行うことができます。たとえば、モデルに既存の LoRA アダプターがアタッチされている場合：",Ie,K,Ne,D,_t="新しいアダプタを追加するには:",Pe,O,ze,ee,Zt="<code>~peft.PeftModel.set_adapter</code> を使用して、どのアダプターを使用するかを設定できます：",Ye,te,qe,le,Ae,ae,kt="モデルにアダプターを追加したら、アダプターモジュールを有効または無効にすることができます。アダプターモジュールを有効にするには、次の手順を実行します：",Se,se,Ke,ne,Ut="アダプターモジュールを無効にするには：",De,pe,Oe,oe,et,ie,jt='PEFTアダプターは<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>クラスでサポートされており、特定のユースケースに対してアダプターをトレーニングすることができます。数行のコードを追加するだけで済みます。たとえば、LoRAアダプターをトレーニングする場合:',tt,g,lt,re,Ft="<li>タスクタイプとハイパーパラメータに対するアダプターの構成を定義します（ハイパーパラメータの詳細については<code>~peft.LoraConfig</code>を参照してください）。</li>",at,me,st,J,vt="<li>モデルにアダプターを追加する。</li>",nt,de,pt,C,Wt='<li>これで、モデルを <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> に渡すことができます！</li>',ot,fe,it,be,Bt="保存するトレーニング済みアダプタとそれを読み込むための手順：",rt,ue,mt;return Z=new _({props:{title:"Load adapters with 🤗 PEFT",local:"load-adapters-with--peft",headingTag:"h1"}}),k=new Pt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/peft.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/peft.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/peft.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/peft.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/peft.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/peft.ipynb"}]}}),v=new _({props:{title:"Setup",local:"setup",headingTag:"h2"}}),B=new y({props:{code:"cGlwJTIwaW5zdGFsbCUyMHBlZnQ=",highlighted:"pip install peft",wrap:!1}}),x=new y({props:{code:"cGlwJTIwaW5zdGFsbCUyMGdpdCUyQmh0dHBzJTNBJTJGJTJGZ2l0aHViLmNvbSUyRmh1Z2dpbmdmYWNlJTJGcGVmdC5naXQ=",highlighted:"pip install git+https://github.com/huggingface/peft.git",wrap:!1}}),E=new _({props:{title:"Supported PEFT models",local:"supported-peft-models",headingTag:"h2"}}),L=new _({props:{title:"Load a PEFT adapter",local:"load-a-peft-adapter",headingTag:"h2"}}),I=new y({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQXBlZnRfbW9kZWxfaWQlMjAlM0QlMjAlMjJ5YmVsa2FkYSUyRm9wdC0zNTBtLWxvcmElMjIlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChwZWZ0X21vZGVsX2lkKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

peft_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>
model = AutoModelForCausalLM.from_pretrained(peft_model_id)`,wrap:!1}}),w=new Ht({props:{$$slots:{default:[zt]},$$scope:{ctx:Me}}}),P=new y({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQW1vZGVsX2lkJTIwJTNEJTIwJTIyZmFjZWJvb2slMkZvcHQtMzUwbSUyMiUwQXBlZnRfbW9kZWxfaWQlMjAlM0QlMjAlMjJ5YmVsa2FkYSUyRm9wdC0zNTBtLWxvcmElMjIlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChtb2RlbF9pZCklMEFtb2RlbC5sb2FkX2FkYXB0ZXIocGVmdF9tb2RlbF9pZCk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

model_id = <span class="hljs-string">&quot;facebook/opt-350m&quot;</span>
peft_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>

model = AutoModelForCausalLM.from_pretrained(model_id)
model.load_adapter(peft_model_id)`,wrap:!1}}),z=new _({props:{title:"Load in 8bit or 4bit",local:"load-in-8bit-or-4bit",headingTag:"h2"}}),q=new y({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQXBlZnRfbW9kZWxfaWQlMjAlM0QlMjAlMjJ5YmVsa2FkYSUyRm9wdC0zNTBtLWxvcmElMjIlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChwZWZ0X21vZGVsX2lkJTJDJTIwZGV2aWNlX21hcCUzRCUyMmF1dG8lMjIlMkMlMjBsb2FkX2luXzhiaXQlM0RUcnVlKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

peft_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>
model = AutoModelForCausalLM.from_pretrained(peft_model_id, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>)`,wrap:!1}}),A=new _({props:{title:"Add a new adapter",local:"add-a-new-adapter",headingTag:"h2"}}),K=new y({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwT1BURm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTBBZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBQZWZ0Q29uZmlnJTBBJTBBbW9kZWxfaWQlMjAlM0QlMjAlMjJmYWNlYm9vayUyRm9wdC0zNTBtJTIyJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpJTBBJTBBbG9yYV9jb25maWclMjAlM0QlMjBMb3JhQ29uZmlnKCUwQSUyMCUyMCUyMCUyMHRhcmdldF9tb2R1bGVzJTNEJTVCJTIycV9wcm9qJTIyJTJDJTIwJTIya19wcm9qJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwaW5pdF9sb3JhX3dlaWdodHMlM0RGYWxzZSUwQSklMEElMEFtb2RlbC5hZGRfYWRhcHRlcihsb3JhX2NvbmZpZyUyQyUyMGFkYXB0ZXJfbmFtZSUzRCUyMmFkYXB0ZXJfMSUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer
<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftConfig

model_id = <span class="hljs-string">&quot;facebook/opt-350m&quot;</span>
model = AutoModelForCausalLM.from_pretrained(model_id)

lora_config = LoraConfig(
    target_modules=[<span class="hljs-string">&quot;q_proj&quot;</span>, <span class="hljs-string">&quot;k_proj&quot;</span>],
    init_lora_weights=<span class="hljs-literal">False</span>
)

model.add_adapter(lora_config, adapter_name=<span class="hljs-string">&quot;adapter_1&quot;</span>)`,wrap:!1}}),O=new y({props:{code:"JTIzJTIwYXR0YWNoJTIwbmV3JTIwYWRhcHRlciUyMHdpdGglMjBzYW1lJTIwY29uZmlnJTBBbW9kZWwuYWRkX2FkYXB0ZXIobG9yYV9jb25maWclMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJhZGFwdGVyXzIlMjIp",highlighted:`<span class="hljs-comment"># attach new adapter with same config</span>
model.add_adapter(lora_config, adapter_name=<span class="hljs-string">&quot;adapter_2&quot;</span>)`,wrap:!1}}),te=new y({props:{code:"JTIzJTIwdXNlJTIwYWRhcHRlcl8xJTBBbW9kZWwuc2V0X2FkYXB0ZXIoJTIyYWRhcHRlcl8xJTIyKSUwQW91dHB1dCUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqaW5wdXRzKSUwQXByaW50KHRva2VuaXplci5kZWNvZGUob3V0cHV0X2Rpc2FibGVkJTVCMCU1RCUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSklMEElMEElMjMlMjB1c2UlMjBhZGFwdGVyXzIlMEFtb2RlbC5zZXRfYWRhcHRlciglMjJhZGFwdGVyXzIlMjIpJTBBb3V0cHV0X2VuYWJsZWQlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKmlucHV0cyklMEFwcmludCh0b2tlbml6ZXIuZGVjb2RlKG91dHB1dF9lbmFibGVkJTVCMCU1RCUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSk=",highlighted:`<span class="hljs-comment"># use adapter_1</span>
model.set_adapter(<span class="hljs-string">&quot;adapter_1&quot;</span>)
output = model.generate(**inputs)
<span class="hljs-built_in">print</span>(tokenizer.decode(output_disabled[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))

<span class="hljs-comment"># use adapter_2</span>
model.set_adapter(<span class="hljs-string">&quot;adapter_2&quot;</span>)
output_enabled = model.generate(**inputs)
<span class="hljs-built_in">print</span>(tokenizer.decode(output_enabled[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))`,wrap:!1}}),le=new _({props:{title:"Enable and disable adapters",local:"enable-and-disable-adapters",headingTag:"h2"}}),se=new y({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwT1BURm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTBBZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBQZWZ0Q29uZmlnJTBBJTBBbW9kZWxfaWQlMjAlM0QlMjAlMjJmYWNlYm9vayUyRm9wdC0zNTBtJTIyJTBBYWRhcHRlcl9tb2RlbF9pZCUyMCUzRCUyMCUyMnliZWxrYWRhJTJGb3B0LTM1MG0tbG9yYSUyMiUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2lkKSUwQXRleHQlMjAlM0QlMjAlMjJIZWxsbyUyMiUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcih0ZXh0JTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChtb2RlbF9pZCklMEFwZWZ0X2NvbmZpZyUyMCUzRCUyMFBlZnRDb25maWcuZnJvbV9wcmV0cmFpbmVkKGFkYXB0ZXJfbW9kZWxfaWQpJTBBJTBBJTIzJTIwdG8lMjBpbml0aWF0ZSUyMHdpdGglMjByYW5kb20lMjB3ZWlnaHRzJTBBcGVmdF9jb25maWcuaW5pdF9sb3JhX3dlaWdodHMlMjAlM0QlMjBGYWxzZSUwQSUwQW1vZGVsLmFkZF9hZGFwdGVyKHBlZnRfY29uZmlnKSUwQW1vZGVsLmVuYWJsZV9hZGFwdGVycygpJTBBb3V0cHV0JTIwJTNEJTIwbW9kZWwuZ2VuZXJhdGUoKippbnB1dHMp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer
<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftConfig

model_id = <span class="hljs-string">&quot;facebook/opt-350m&quot;</span>
adapter_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_id)
text = <span class="hljs-string">&quot;Hello&quot;</span>
inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

model = AutoModelForCausalLM.from_pretrained(model_id)
peft_config = PeftConfig.from_pretrained(adapter_model_id)

<span class="hljs-comment"># to initiate with random weights</span>
peft_config.init_lora_weights = <span class="hljs-literal">False</span>

model.add_adapter(peft_config)
model.enable_adapters()
output = model.generate(**inputs)`,wrap:!1}}),pe=new y({props:{code:"bW9kZWwuZGlzYWJsZV9hZGFwdGVycygpJTBBb3V0cHV0JTIwJTNEJTIwbW9kZWwuZ2VuZXJhdGUoKippbnB1dHMp",highlighted:`model.disable_adapters()
output = model.generate(**inputs)`,wrap:!1}}),oe=new _({props:{title:"Train a PEFT adapter",local:"train-a-peft-adapter",headingTag:"h2"}}),g=new Ht({props:{$$slots:{default:[Yt]},$$scope:{ctx:Me}}}),me=new y({props:{code:"ZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBMb3JhQ29uZmlnJTBBJTBBcGVmdF9jb25maWclMjAlM0QlMjBMb3JhQ29uZmlnKCUwQSUyMCUyMCUyMCUyMGxvcmFfYWxwaGElM0QxNiUyQyUwQSUyMCUyMCUyMCUyMGxvcmFfZHJvcG91dCUzRDAuMSUyQyUwQSUyMCUyMCUyMCUyMHIlM0Q2NCUyQyUwQSUyMCUyMCUyMCUyMGJpYXMlM0QlMjJub25lJTIyJTJDJTBBJTIwJTIwJTIwJTIwdGFza190eXBlJTNEJTIyQ0FVU0FMX0xNJTIyJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig

peft_config = LoraConfig(
    lora_alpha=<span class="hljs-number">16</span>,
    lora_dropout=<span class="hljs-number">0.1</span>,
    r=<span class="hljs-number">64</span>,
    bias=<span class="hljs-string">&quot;none&quot;</span>,
    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span>,
)`,wrap:!1}}),de=new y({props:{code:"bW9kZWwuYWRkX2FkYXB0ZXIocGVmdF9jb25maWcp",highlighted:"model.add_adapter(peft_config)",wrap:!1}}),fe=new y({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIobW9kZWwlM0Rtb2RlbCUyQyUyMC4uLiklMEF0cmFpbmVyLnRyYWluKCk=",highlighted:`trainer = Trainer(model=model, ...)
trainer.train()`,wrap:!1}}),{c(){i=p("meta"),$=s(),c=p("p"),T=s(),m(Z.$$.fragment),ye=s(),m(k.$$.fragment),$e=s(),U=p("p"),U.innerHTML=dt,Te=s(),j=p("p"),j.textContent=ft,he=s(),h=p("div"),h.innerHTML=bt,we=s(),F=p("p"),F.innerHTML=Mt,ge=s(),m(v.$$.fragment),Je=s(),W=p("p"),W.textContent=ut,Ce=s(),m(B.$$.fragment),_e=s(),R=p("p"),R.textContent=ct,Ze=s(),m(x.$$.fragment),ke=s(),m(E.$$.fragment),Ue=s(),H=p("p"),H.textContent=yt,je=s(),X=p("ul"),X.innerHTML=$t,Fe=s(),G=p("p"),G.innerHTML=Tt,ve=s(),m(L.$$.fragment),We=s(),V=p("p"),V.innerHTML=ht,Be=s(),Q=p("ol"),Q.innerHTML=wt,Re=s(),m(I.$$.fragment),xe=s(),m(w.$$.fragment),Ee=s(),N=p("p"),N.innerHTML=gt,He=s(),m(P.$$.fragment),Xe=s(),m(z.$$.fragment),Ge=s(),Y=p("p"),Y.innerHTML=Jt,Le=s(),m(q.$$.fragment),Ve=s(),m(A.$$.fragment),Qe=s(),S=p("p"),S.innerHTML=Ct,Ie=s(),m(K.$$.fragment),Ne=s(),D=p("p"),D.textContent=_t,Pe=s(),m(O.$$.fragment),ze=s(),ee=p("p"),ee.innerHTML=Zt,Ye=s(),m(te.$$.fragment),qe=s(),m(le.$$.fragment),Ae=s(),ae=p("p"),ae.textContent=kt,Se=s(),m(se.$$.fragment),Ke=s(),ne=p("p"),ne.textContent=Ut,De=s(),m(pe.$$.fragment),Oe=s(),m(oe.$$.fragment),et=s(),ie=p("p"),ie.innerHTML=jt,tt=s(),m(g.$$.fragment),lt=s(),re=p("ol"),re.innerHTML=Ft,at=s(),m(me.$$.fragment),st=s(),J=p("ol"),J.innerHTML=vt,nt=s(),m(de.$$.fragment),pt=s(),C=p("ol"),C.innerHTML=Wt,ot=s(),m(fe.$$.fragment),it=s(),be=p("p"),be.textContent=Bt,rt=s(),ue=p("p"),this.h()},l(e){const t=It("svelte-u9bgzb",document.head);i=o(t,"META",{name:!0,content:!0}),t.forEach(l),$=n(e),c=o(e,"P",{}),Et(c).forEach(l),T=n(e),d(Z.$$.fragment,e),ye=n(e),d(k.$$.fragment,e),$e=n(e),U=o(e,"P",{"data-svelte-h":!0}),r(U)!=="svelte-5gn15j"&&(U.innerHTML=dt),Te=n(e),j=o(e,"P",{"data-svelte-h":!0}),r(j)!=="svelte-w1i7an"&&(j.textContent=ft),he=n(e),h=o(e,"DIV",{class:!0,"data-svelte-h":!0}),r(h)!=="svelte-1fuskl2"&&(h.innerHTML=bt),we=n(e),F=o(e,"P",{"data-svelte-h":!0}),r(F)!=="svelte-17ytuwu"&&(F.innerHTML=Mt),ge=n(e),d(v.$$.fragment,e),Je=n(e),W=o(e,"P",{"data-svelte-h":!0}),r(W)!=="svelte-o72cq6"&&(W.textContent=ut),Ce=n(e),d(B.$$.fragment,e),_e=n(e),R=o(e,"P",{"data-svelte-h":!0}),r(R)!=="svelte-13qklsb"&&(R.textContent=ct),Ze=n(e),d(x.$$.fragment,e),ke=n(e),d(E.$$.fragment,e),Ue=n(e),H=o(e,"P",{"data-svelte-h":!0}),r(H)!=="svelte-1u7vx0t"&&(H.textContent=yt),je=n(e),X=o(e,"UL",{"data-svelte-h":!0}),r(X)!=="svelte-1ulyaf4"&&(X.innerHTML=$t),Fe=n(e),G=o(e,"P",{"data-svelte-h":!0}),r(G)!=="svelte-ez8kei"&&(G.innerHTML=Tt),ve=n(e),d(L.$$.fragment,e),We=n(e),V=o(e,"P",{"data-svelte-h":!0}),r(V)!=="svelte-1sgrl5r"&&(V.innerHTML=ht),Be=n(e),Q=o(e,"OL",{"data-svelte-h":!0}),r(Q)!=="svelte-xqfpxn"&&(Q.innerHTML=wt),Re=n(e),d(I.$$.fragment,e),xe=n(e),d(w.$$.fragment,e),Ee=n(e),N=o(e,"P",{"data-svelte-h":!0}),r(N)!=="svelte-1yiz7ih"&&(N.innerHTML=gt),He=n(e),d(P.$$.fragment,e),Xe=n(e),d(z.$$.fragment,e),Ge=n(e),Y=o(e,"P",{"data-svelte-h":!0}),r(Y)!=="svelte-1nrcesk"&&(Y.innerHTML=Jt),Le=n(e),d(q.$$.fragment,e),Ve=n(e),d(A.$$.fragment,e),Qe=n(e),S=o(e,"P",{"data-svelte-h":!0}),r(S)!=="svelte-1rl7ayd"&&(S.innerHTML=Ct),Ie=n(e),d(K.$$.fragment,e),Ne=n(e),D=o(e,"P",{"data-svelte-h":!0}),r(D)!=="svelte-uxkarq"&&(D.textContent=_t),Pe=n(e),d(O.$$.fragment,e),ze=n(e),ee=o(e,"P",{"data-svelte-h":!0}),r(ee)!=="svelte-sbepkg"&&(ee.innerHTML=Zt),Ye=n(e),d(te.$$.fragment,e),qe=n(e),d(le.$$.fragment,e),Ae=n(e),ae=o(e,"P",{"data-svelte-h":!0}),r(ae)!=="svelte-17y8rb4"&&(ae.textContent=kt),Se=n(e),d(se.$$.fragment,e),Ke=n(e),ne=o(e,"P",{"data-svelte-h":!0}),r(ne)!=="svelte-n3dw5b"&&(ne.textContent=Ut),De=n(e),d(pe.$$.fragment,e),Oe=n(e),d(oe.$$.fragment,e),et=n(e),ie=o(e,"P",{"data-svelte-h":!0}),r(ie)!=="svelte-1h3qr37"&&(ie.innerHTML=jt),tt=n(e),d(g.$$.fragment,e),lt=n(e),re=o(e,"OL",{"data-svelte-h":!0}),r(re)!=="svelte-1u22mfv"&&(re.innerHTML=Ft),at=n(e),d(me.$$.fragment,e),st=n(e),J=o(e,"OL",{start:!0,"data-svelte-h":!0}),r(J)!=="svelte-y6k54s"&&(J.innerHTML=vt),nt=n(e),d(de.$$.fragment,e),pt=n(e),C=o(e,"OL",{start:!0,"data-svelte-h":!0}),r(C)!=="svelte-1rilrtg"&&(C.innerHTML=Wt),ot=n(e),d(fe.$$.fragment,e),it=n(e),be=o(e,"P",{"data-svelte-h":!0}),r(be)!=="svelte-16hz5kg"&&(be.textContent=Bt),rt=n(e),ue=o(e,"P",{}),Et(ue).forEach(l),this.h()},h(){ce(i,"name","hf:doc:metadata"),ce(i,"content",At),ce(h,"class","flex flex-col justify-center"),ce(J,"start","2"),ce(C,"start","3")},m(e,t){Nt(document.head,i),a(e,$,t),a(e,c,t),a(e,T,t),f(Z,e,t),a(e,ye,t),f(k,e,t),a(e,$e,t),a(e,U,t),a(e,Te,t),a(e,j,t),a(e,he,t),a(e,h,t),a(e,we,t),a(e,F,t),a(e,ge,t),f(v,e,t),a(e,Je,t),a(e,W,t),a(e,Ce,t),f(B,e,t),a(e,_e,t),a(e,R,t),a(e,Ze,t),f(x,e,t),a(e,ke,t),f(E,e,t),a(e,Ue,t),a(e,H,t),a(e,je,t),a(e,X,t),a(e,Fe,t),a(e,G,t),a(e,ve,t),f(L,e,t),a(e,We,t),a(e,V,t),a(e,Be,t),a(e,Q,t),a(e,Re,t),f(I,e,t),a(e,xe,t),f(w,e,t),a(e,Ee,t),a(e,N,t),a(e,He,t),f(P,e,t),a(e,Xe,t),f(z,e,t),a(e,Ge,t),a(e,Y,t),a(e,Le,t),f(q,e,t),a(e,Ve,t),f(A,e,t),a(e,Qe,t),a(e,S,t),a(e,Ie,t),f(K,e,t),a(e,Ne,t),a(e,D,t),a(e,Pe,t),f(O,e,t),a(e,ze,t),a(e,ee,t),a(e,Ye,t),f(te,e,t),a(e,qe,t),f(le,e,t),a(e,Ae,t),a(e,ae,t),a(e,Se,t),f(se,e,t),a(e,Ke,t),a(e,ne,t),a(e,De,t),f(pe,e,t),a(e,Oe,t),f(oe,e,t),a(e,et,t),a(e,ie,t),a(e,tt,t),f(g,e,t),a(e,lt,t),a(e,re,t),a(e,at,t),f(me,e,t),a(e,st,t),a(e,J,t),a(e,nt,t),f(de,e,t),a(e,pt,t),a(e,C,t),a(e,ot,t),f(fe,e,t),a(e,it,t),a(e,be,t),a(e,rt,t),a(e,ue,t),mt=!0},p(e,[t]){const Rt={};t&2&&(Rt.$$scope={dirty:t,ctx:e}),w.$set(Rt);const xt={};t&2&&(xt.$$scope={dirty:t,ctx:e}),g.$set(xt)},i(e){mt||(b(Z.$$.fragment,e),b(k.$$.fragment,e),b(v.$$.fragment,e),b(B.$$.fragment,e),b(x.$$.fragment,e),b(E.$$.fragment,e),b(L.$$.fragment,e),b(I.$$.fragment,e),b(w.$$.fragment,e),b(P.$$.fragment,e),b(z.$$.fragment,e),b(q.$$.fragment,e),b(A.$$.fragment,e),b(K.$$.fragment,e),b(O.$$.fragment,e),b(te.$$.fragment,e),b(le.$$.fragment,e),b(se.$$.fragment,e),b(pe.$$.fragment,e),b(oe.$$.fragment,e),b(g.$$.fragment,e),b(me.$$.fragment,e),b(de.$$.fragment,e),b(fe.$$.fragment,e),mt=!0)},o(e){M(Z.$$.fragment,e),M(k.$$.fragment,e),M(v.$$.fragment,e),M(B.$$.fragment,e),M(x.$$.fragment,e),M(E.$$.fragment,e),M(L.$$.fragment,e),M(I.$$.fragment,e),M(w.$$.fragment,e),M(P.$$.fragment,e),M(z.$$.fragment,e),M(q.$$.fragment,e),M(A.$$.fragment,e),M(K.$$.fragment,e),M(O.$$.fragment,e),M(te.$$.fragment,e),M(le.$$.fragment,e),M(se.$$.fragment,e),M(pe.$$.fragment,e),M(oe.$$.fragment,e),M(g.$$.fragment,e),M(me.$$.fragment,e),M(de.$$.fragment,e),M(fe.$$.fragment,e),mt=!1},d(e){e&&(l($),l(c),l(T),l(ye),l($e),l(U),l(Te),l(j),l(he),l(h),l(we),l(F),l(ge),l(Je),l(W),l(Ce),l(_e),l(R),l(Ze),l(ke),l(Ue),l(H),l(je),l(X),l(Fe),l(G),l(ve),l(We),l(V),l(Be),l(Q),l(Re),l(xe),l(Ee),l(N),l(He),l(Xe),l(Ge),l(Y),l(Le),l(Ve),l(Qe),l(S),l(Ie),l(Ne),l(D),l(Pe),l(ze),l(ee),l(Ye),l(qe),l(Ae),l(ae),l(Se),l(Ke),l(ne),l(De),l(Oe),l(et),l(ie),l(tt),l(lt),l(re),l(at),l(st),l(J),l(nt),l(pt),l(C),l(ot),l(it),l(be),l(rt),l(ue)),l(i),u(Z,e),u(k,e),u(v,e),u(B,e),u(x,e),u(E,e),u(L,e),u(I,e),u(w,e),u(P,e),u(z,e),u(q,e),u(A,e),u(K,e),u(O,e),u(te,e),u(le,e),u(se,e),u(pe,e),u(oe,e),u(g,e),u(me,e),u(de,e),u(fe,e)}}}const At='{"title":"Load adapters with 🤗 PEFT","local":"load-adapters-with--peft","sections":[{"title":"Setup","local":"setup","sections":[],"depth":2},{"title":"Supported PEFT models","local":"supported-peft-models","sections":[],"depth":2},{"title":"Load a PEFT adapter","local":"load-a-peft-adapter","sections":[],"depth":2},{"title":"Load in 8bit or 4bit","local":"load-in-8bit-or-4bit","sections":[],"depth":2},{"title":"Add a new adapter","local":"add-a-new-adapter","sections":[],"depth":2},{"title":"Enable and disable adapters","local":"enable-and-disable-adapters","sections":[],"depth":2},{"title":"Train a PEFT adapter","local":"train-a-peft-adapter","sections":[],"depth":2}],"depth":1}';function St(Me){return Lt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class al extends Vt{constructor(i){super(),Qt(this,i,St,qt,Gt,{})}}export{al as component};
