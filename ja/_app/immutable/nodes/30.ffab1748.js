import{s as St,o as At,n as Pt}from"../chunks/scheduler.9bc65507.js";import{S as Kt,i as Dt,g as i,s as a,r as o,A as Ot,h as p,f as l,c as n,j as Yt,u as m,x as r,k as ft,y as el,a as s,v as g,d as c,t as u,w as d}from"../chunks/index.707bf1b6.js";import{T as tl}from"../chunks/Tip.c2ecdbf4.js";import{C as T}from"../chunks/CodeBlock.54a9f38d.js";import{D as ll}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{H as h}from"../chunks/Heading.342b1fa6.js";function sl(ye){let M,J='åŸºæœ¬çš„ãªLLMã®ä½¿ç”¨ã«èˆˆå‘³ãŒã‚ã‚‹å ´åˆã€é«˜ãƒ¬ãƒ™ãƒ«ã® <a href="pipeline_tutorial"><code>Pipeline</code></a> ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒè‰¯ã„å‡ºç™ºç‚¹ã§ã™ã€‚ãŸã ã—ã€LLMã¯ã—ã°ã—ã°é‡å­åŒ–ã‚„ãƒˆãƒ¼ã‚¯ãƒ³é¸æŠã‚¹ãƒ†ãƒƒãƒ—ã®ç´°ã‹ã„åˆ¶å¾¡ãªã©ã®é«˜åº¦ãªæ©Ÿèƒ½ãŒå¿…è¦ã§ã‚ã‚Šã€ã“ã‚Œã¯ <a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a> ã‚’ä»‹ã—ã¦æœ€è‰¯ã«è¡Œã‚ã‚Œã¾ã™ã€‚LLMã¨ã®è‡ªå·±å›å¸°ç”Ÿæˆã¯ãƒªã‚½ãƒ¼ã‚¹ãŒå¤šãå¿…è¦ã§ã‚ã‚Šã€é©åˆ‡ãªã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã®ãŸã‚ã«GPUã§å®Ÿè¡Œã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚';return{c(){M=i("p"),M.innerHTML=J},l(f){M=p(f,"P",{"data-svelte-h":!0}),r(M)!=="svelte-1sday44"&&(M.innerHTML=J)},m(f,fe){s(f,M,fe)},p:Pt,d(f){f&&l(M)}}}function al(ye){let M,J,f,fe,w,be,U,je,_,ht="LLMã€ã¾ãŸã¯Large Language Modelsï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆã®éµã¨ãªã‚‹è¦ç´ ã§ã™ã€‚è¦ã™ã‚‹ã«ã€ã“ã‚Œã‚‰ã¯å¤§è¦æ¨¡ãªäº‹å‰è¨“ç·´æ¸ˆã¿ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒ«ã§ã€ä¸ãˆã‚‰ã‚ŒãŸå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦æ¬¡ã®å˜èªï¼ˆã¾ãŸã¯ã€ã‚ˆã‚Šæ­£ç¢ºã«ã¯ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã‚’äºˆæ¸¬ã™ã‚‹ã‚ˆã†ã«è¨“ç·´ã•ã‚Œã¦ã„ã¾ã™ã€‚ãƒˆãƒ¼ã‚¯ãƒ³ã‚’1ã¤ãšã¤äºˆæ¸¬ã™ã‚‹ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã‚’å‘¼ã³å‡ºã™ã ã‘ã§ã¯æ–°ã—ã„æ–‡ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã«ä½•ã‹ã‚ˆã‚Šç²¾å·§ãªã“ã¨ã‚’ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚è‡ªå·±å›å¸°ç”Ÿæˆã‚’è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",Te,Z,yt='è‡ªå·±å›å¸°ç”Ÿæˆã¯ã€æ¨è«–æ™‚ã®æ‰‹ç¶šãã§ã€ã„ãã¤ã‹ã®åˆæœŸå…¥åŠ›ã‚’ä¸ãˆãŸçŠ¶æ…‹ã§ã€ãƒ¢ãƒ‡ãƒ«ã‚’åå¾©çš„ã«å‘¼ã³å‡ºã™æ‰‹æ³•ã§ã™ã€‚ğŸ¤— Transformersã§ã¯ã€ã“ã‚Œã¯<a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a>ãƒ¡ã‚½ãƒƒãƒ‰ã«ã‚ˆã£ã¦å‡¦ç†ã•ã‚Œã€ã“ã‚Œã¯ç”Ÿæˆèƒ½åŠ›ã‚’æŒã¤ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§åˆ©ç”¨å¯èƒ½ã§ã™ã€‚',Je,$,bt="ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§ã¯ã€ä»¥ä¸‹ã®ã“ã¨ã‚’ç¤ºã—ã¾ã™ï¼š",we,k,jt="<li>LLMã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•</li> <li>ä¸€èˆ¬çš„ãªè½ã¨ã—ç©´ã‚’å›é¿ã™ã‚‹æ–¹æ³•</li> <li>LLMã‚’æœ€å¤§é™ã«æ´»ç”¨ã™ã‚‹ãŸã‚ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—</li>",Ue,G,Tt="å§‹ã‚ã‚‹å‰ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼š",_e,v,Ze,C,$e,I,Jt='<a href="tasks/language_modeling">å› æœè¨€èªãƒ¢ãƒ‡ãƒªãƒ³ã‚°</a>ã®ãŸã‚ã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸè¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’å…¥åŠ›ã¨ã—ã¦å—ã‘å–ã‚Šã€æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ç¢ºç‡åˆ†å¸ƒã‚’è¿”ã—ã¾ã™ã€‚',ke,y,wt='<video style="max-width: 90%; margin: auto;" autoplay="" loop="" muted="" playsinline="" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_1_1080p.mov"></video> <figcaption>&quot;Forward pass of an LLM&quot;</figcaption>',Ge,W,Ut="LLMï¼ˆLanguage Modelï¼‰ã«ã‚ˆã‚‹è‡ªå·±å›å¸°ç”Ÿæˆã®é‡è¦ãªå´é¢ã®1ã¤ã¯ã€ã“ã®ç¢ºç‡åˆ†å¸ƒã‹ã‚‰æ¬¡ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠã™ã‚‹æ–¹æ³•ã§ã™ã€‚ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®ãƒˆãƒ¼ã‚¯ãƒ³ãŒå¾—ã‚‰ã‚Œã‚‹é™ã‚Šã€ä½•ã§ã‚‚å¯èƒ½ã§ã™ã€‚ã“ã‚Œã¯ã€ç¢ºç‡åˆ†å¸ƒã‹ã‚‰æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠã™ã‚‹ã ã‘ã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ–¹æ³•ã‹ã‚‰ã€çµæœã®åˆ†å¸ƒã‹ã‚‰ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹å‰ã«æ•°ã€…ã®å¤‰æ›ã‚’é©ç”¨ã™ã‚‹ã»ã©è¤‡é›‘ãªæ–¹æ³•ã¾ã§ã€ã‚ã‚‰ã‚†ã‚‹æ–¹æ³•ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚",ve,b,_t='<video style="max-width: 90%; margin: auto;" autoplay="" loop="" muted="" playsinline="" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/assisted-generation/gif_2_1080p.mov"></video> <figcaption>&quot;Autoregressive generation iteratively selects the next token from a probability distribution to generate text&quot;</figcaption>',Ce,x,Zt="ä¸Šè¨˜ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ã€ã‚ã‚‹åœæ­¢æ¡ä»¶ãŒæº€ãŸã•ã‚Œã‚‹ã¾ã§åå¾©çš„ã«ç¹°ã‚Šè¿”ã•ã‚Œã¾ã™ã€‚ç†æƒ³çš„ã«ã¯ã€åœæ­¢æ¡ä»¶ã¯ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦æŒ‡ç¤ºã•ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã¯çµ‚äº†ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆ<code>EOS</code>ï¼‰ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å‡ºåŠ›ã™ã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å­¦ç¿’ã™ã¹ãã§ã™ã€‚ã“ã‚ŒãŒãã†ã§ãªã„å ´åˆã€ç”Ÿæˆã¯ã‚ã‚‰ã‹ã˜ã‚å®šç¾©ã•ã‚ŒãŸæœ€å¤§é•·ã«é”ã—ãŸã¨ãã«åœæ­¢ã—ã¾ã™ã€‚",Ie,L,$t='ãƒˆãƒ¼ã‚¯ãƒ³é¸æŠã‚¹ãƒ†ãƒƒãƒ—ã¨åœæ­¢æ¡ä»¶ã‚’é©åˆ‡ã«è¨­å®šã™ã‚‹ã“ã¨ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒã‚¿ã‚¹ã‚¯ã§æœŸå¾…ã©ãŠã‚Šã«æŒ¯ã‚‹èˆã†ãŸã‚ã«é‡è¦ã§ã™ã€‚ãã‚ŒãŒã€å„ãƒ¢ãƒ‡ãƒ«ã«é–¢é€£ä»˜ã‘ã‚‰ã‚ŒãŸ <a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationConfig">GenerationConfig</a> ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ç†ç”±ã§ã‚ã‚Šã€ã“ã‚Œã«ã¯å„ªã‚ŒãŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–ãŒå«ã¾ã‚Œã€ãƒ¢ãƒ‡ãƒ«ã¨ä¸€ç·’ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚',We,V,kt="ã‚³ãƒ¼ãƒ‰ã«ã¤ã„ã¦è©±ã—ã¾ã—ã‚‡ã†ï¼",xe,j,Le,X,Gt="ã¾ãšã€ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚",Ve,R,Xe,z,vt="<code>from_pretrained</code> å‘¼ã³å‡ºã—ã§2ã¤ã®ãƒ•ãƒ©ã‚°ãŒã‚ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š",Re,B,Ct='<li><code>device_map</code> ã¯ãƒ¢ãƒ‡ãƒ«ã‚’ã‚ãªãŸã®GPUã«ç§»å‹•ã•ã›ã¾ã™</li> <li><code>load_in_4bit</code> ã¯<a href="main_classes/quantization">4ãƒ“ãƒƒãƒˆã®å‹•çš„é‡å­åŒ–</a>ã‚’é©ç”¨ã—ã¦ãƒªã‚½ãƒ¼ã‚¹è¦ä»¶ã‚’å¤§å¹…ã«å‰Šæ¸›ã—ã¾ã™</li>',ze,H,It="ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã™ã‚‹ä»–ã®æ–¹æ³•ã‚‚ã‚ã‚Šã¾ã™ãŒã€ã“ã‚Œã¯LLMã‚’å§‹ã‚ã‚‹ãŸã‚ã®è‰¯ã„åŸºæº–ã§ã™ã€‚",Be,F,Wt='æ¬¡ã«ã€<a href="tokenizer_summary">ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶</a>ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚’å‰å‡¦ç†ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚',He,q,Fe,Q,xt='<code>model_inputs</code> å¤‰æ•°ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã¨ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ã‚’ä¿æŒã—ã¦ã„ã¾ã™ã€‚ <a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a> ã¯ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒã‚¹ã‚¯ãŒæ¸¡ã•ã‚Œã¦ã„ãªã„å ´åˆã§ã‚‚ã€æœ€å–„ã®åŠªåŠ›ã‚’ã—ã¦ãã‚Œã‚’æ¨æ¸¬ã—ã‚ˆã†ã¨ã—ã¾ã™ãŒã€ã§ãã‚‹é™ã‚Šæ¸¡ã™ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚æœ€é©ãªçµæœã‚’å¾—ã‚‹ãŸã‚ã§ã™ã€‚',qe,E,Lt='æœ€å¾Œã«ã€<a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³ã‚’å–å¾—ã—ã€ãã‚Œã‚’è¡¨ç¤ºã™ã‚‹å‰ã«ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚',Qe,N,Ee,Y,Vt="ã“ã‚Œã§å®Œäº†ã§ã™ï¼ã‚ãšã‹ãªã‚³ãƒ¼ãƒ‰è¡Œæ•°ã§ã€LLMï¼ˆLarge Language Modelï¼‰ã®ãƒ‘ãƒ¯ãƒ¼ã‚’æ´»ç”¨ã§ãã¾ã™ã€‚",Ne,S,Ye,A,Xt='<a href="generation_strategies">ç”Ÿæˆæˆ¦ç•¥</a>ã¯ãŸãã•ã‚“ã‚ã‚Šã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å€¤ãŒã‚ãªãŸã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«é©ã—ã¦ã„ãªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚å‡ºåŠ›ãŒæœŸå¾…é€šã‚Šã§ãªã„å ´åˆã€æœ€ã‚‚ä¸€èˆ¬çš„ãªè½ã¨ã—ç©´ã¨ãã®å›é¿æ–¹æ³•ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸã€‚',Se,P,Ae,K,Pe,D,Rt='<a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationConfig">GenerationConfig</a> ãƒ•ã‚¡ã‚¤ãƒ«ã§æŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€<code>generate</code> ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€å¤§ã§ 20 ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§è¿”ã—ã¾ã™ã€‚æˆ‘ã€…ã¯ <code>generate</code> ã‚³ãƒ¼ãƒ«ã§ <code>max_new_tokens</code> ã‚’æ‰‹å‹•ã§è¨­å®šã™ã‚‹ã“ã¨ã‚’å¼·ããŠå‹§ã‚ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€è¿”ã•ã‚Œã‚‹æ–°ã—ã„ãƒˆãƒ¼ã‚¯ãƒ³ã®æœ€å¤§æ•°ã‚’åˆ¶å¾¡ã§ãã¾ã™ã€‚LLMï¼ˆæ­£ç¢ºã«ã¯ã€<a href="https://huggingface.co/learn/nlp-course/chapter1/6?fw=pt" rel="nofollow">ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å°‚ç”¨ãƒ¢ãƒ‡ãƒ«</a>ï¼‰ã‚‚å‡ºåŠ›ã®ä¸€éƒ¨ã¨ã—ã¦å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿”ã™ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚',Ke,O,De,ee,Oe,te,zt='ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€ <a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationConfig">GenerationConfig</a> ãƒ•ã‚¡ã‚¤ãƒ«ã§æŒ‡å®šã•ã‚Œã¦ã„ãªã„é™ã‚Šã€<code>generate</code> ã¯å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æœ€ã‚‚å¯èƒ½æ€§ã®é«˜ã„ãƒˆãƒ¼ã‚¯ãƒ³ã‚’é¸æŠã—ã¾ã™ï¼ˆè²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ï¼‰ã€‚ã‚¿ã‚¹ã‚¯ã«å¿œã˜ã¦ã€ã“ã‚Œã¯æœ›ã¾ã—ããªã„ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚„ã‚¨ãƒƒã‚»ã‚¤ã®ã‚ˆã†ãªå‰µé€ çš„ãªã‚¿ã‚¹ã‚¯ã§ã¯ã€ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãŒæœ‰ç›Šã§ã™ã€‚ä¸€æ–¹ã€éŸ³å£°ã®è»¢å†™ã‚„ç¿»è¨³ã®ã‚ˆã†ãªå…¥åŠ›ã«åŸºã¥ãã‚¿ã‚¹ã‚¯ã§ã¯ã€è²ªæ¬²ãƒ‡ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒæœ‰ç›Šã§ã™ã€‚<code>do_sample=True</code> ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã§ãã¾ã™ã€‚ã“ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ã®è©³ç´°ã¯ã€ã“ã®<a href="https://huggingface.co/blog/how-to-generate" rel="nofollow">ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆ</a>ã§å­¦ã¶ã“ã¨ãŒã§ãã¾ã™ã€‚',et,le,tt,se,lt,ae,Bt='LLMï¼ˆLarge Language Modelsï¼‰ã¯<a href="https://huggingface.co/learn/nlp-course/chapter1/6?fw=pt" rel="nofollow">ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å°‚ç”¨</a>ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚ã‚Šã€å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç¹°ã‚Šè¿”ã—å‡¦ç†ã™ã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚å…¥åŠ›ãŒåŒã˜é•·ã•ã§ãªã„å ´åˆã€ãã‚Œã‚‰ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚LLMã¯ãƒ‘ãƒƒãƒ‰ãƒˆãƒ¼ã‚¯ãƒ³ã‹ã‚‰ã®ç¶šãã‚’å­¦ç¿’ã—ã¦ã„ãªã„ãŸã‚ã€å…¥åŠ›ã¯å·¦ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€ç”Ÿæˆã«å¯¾ã—ã¦æ³¨ç›®ãƒã‚¹ã‚¯ã‚’æ¸¡ã—å¿˜ã‚Œãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ï¼',st,ne,at,ie,nt,pe,Ht="ã‚ªãƒ¼ãƒˆãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ–ç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹ã¯æ¯”è¼ƒçš„ç°¡å˜ã§ã™ãŒã€LLMã‚’æœ€å¤§é™ã«æ´»ç”¨ã™ã‚‹ã“ã¨ã¯å¤šãã®è¦ç´ ãŒçµ¡ã‚€ãŸã‚ã€æŒ‘æˆ¦çš„ãªè©¦ã¿ã¨ãªã‚Šã¾ã™ã€‚LLMã®ä½¿ç”¨ã¨ç†è§£ã‚’ã•ã‚‰ã«æ·±ã‚ã‚‹ãŸã‚ã®æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã«ã¤ã„ã¦ã¯ä»¥ä¸‹ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’ã”è¦§ãã ã•ã„ã€‚",it,re,pt,oe,Ft='<li><a href="generation_strategies">ã‚¬ã‚¤ãƒ‰</a>ï¼šç•°ãªã‚‹ç”Ÿæˆæ–¹æ³•ã‚’åˆ¶å¾¡ã™ã‚‹æ–¹æ³•ã€ç”Ÿæˆæ§‹æˆãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®šæ–¹æ³•ã€å‡ºåŠ›ã®ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–¹æ³•ã«ã¤ã„ã¦ã®ã‚¬ã‚¤ãƒ‰;</li> <li><a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationConfig">GenerationConfig</a>ã€<a href="/docs/transformers/main/ja/main_classes/text_generation#transformers.GenerationMixin.generate">generate()</a>ã€ãŠã‚ˆã³<a href="internal/generation_utils">ç”Ÿæˆé–¢é€£ã‚¯ãƒ©ã‚¹</a>ã«é–¢ã™ã‚‹APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã€‚</li>',rt,me,ot,ge,qt='<li><a href="https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard" rel="nofollow">Open LLM ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>ï¼šã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å“è³ªã«ç„¦ç‚¹ã‚’å½“ã¦ãŸãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰;</li> <li><a href="https://huggingface.co/spaces/optimum/llm-perf-leaderboard" rel="nofollow">Open LLM-Perf ãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰</a>ï¼šLLMã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã«ç„¦ç‚¹ã‚’å½“ã¦ãŸãƒªãƒ¼ãƒ€ãƒ¼ãƒœãƒ¼ãƒ‰ã€‚</li>',mt,ce,gt,ue,Qt='<li><a href="main_classes/quantization">ã‚¬ã‚¤ãƒ‰</a>ï¼šãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ã‚¯ã‚ªãƒ³ã‚¿ã‚¤ã‚ºã«é–¢ã™ã‚‹ã‚¬ã‚¤ãƒ‰ã€‚ã“ã‚Œã«ã‚ˆã‚Šãƒ¡ãƒ¢ãƒªè¦ä»¶ã‚’åŠ‡çš„ã«å‰Šæ¸›ã™ã‚‹æ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚</li>',ct,de,ut,Me,Et='<li><a href="https://github.com/huggingface/text-generation-inference" rel="nofollow"><code>text-generation-inference</code></a>ï¼šLLMç”¨ã®æœ¬ç•ªå‘ã‘ã‚µãƒ¼ãƒãƒ¼;</li> <li><a href="https://github.com/huggingface/optimum" rel="nofollow"><code>optimum</code></a>ï¼šç‰¹å®šã®ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ãƒ‡ãƒã‚¤ã‚¹å‘ã‘ã«æœ€é©åŒ–ã•ã‚ŒãŸğŸ¤— Transformersã®æ‹¡å¼µã€‚</li>',dt,he,Mt;return w=new h({props:{title:"Generation with LLMs",local:"generation-with-llms",headingTag:"h1"}}),U=new ll({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/llm_tutorial.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/llm_tutorial.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/llm_tutorial.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/llm_tutorial.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/llm_tutorial.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/llm_tutorial.ipynb"}]}}),v=new T({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGJpdHNhbmRieXRlcyUzRSUzRDAuMzkuMCUyMC1x",highlighted:"pip install transformers bitsandbytes&gt;=0.39.0 -q",wrap:!1}}),C=new h({props:{title:"Generate text",local:"generate-text",headingTag:"h2"}}),j=new tl({props:{$$slots:{default:[sl]},$$scope:{ctx:ye}}}),R=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyb3BlbmxtLXJlc2VhcmNoJTJGb3Blbl9sbGFtYV83YiUyMiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyJTJDJTIwbG9hZF9pbl80Yml0JTNEVHJ1ZSUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;openlm-research/open_llama_7b&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_4bit=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),q=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJvcGVubG0tcmVzZWFyY2glMkZvcGVuX2xsYW1hXzdiJTIyKSUwQW1vZGVsX2lucHV0cyUyMCUzRCUyMHRva2VuaXplciglNUIlMjJBJTIwbGlzdCUyMG9mJTIwY29sb3JzJTNBJTIwcmVkJTJDJTIwYmx1ZSUyMiU1RCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpLnRvKCUyMmN1ZGElMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;openlm-research/open_llama_7b&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model_inputs = tokenizer([<span class="hljs-string">&quot;A list of colors: red, blue&quot;</span>], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)`,wrap:!1}}),N=new T({props:{code:"Z2VuZXJhdGVkX2lkcyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqbW9kZWxfaW5wdXRzKSUwQXRva2VuaXplci5iYXRjaF9kZWNvZGUoZ2VuZXJhdGVkX2lkcyUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;A list of colors: red, blue, green, yellow, black, white, and brown&#x27;</span>`,wrap:!1}}),S=new h({props:{title:"Common pitfalls",local:"common-pitfalls",headingTag:"h2"}}),P=new T({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKCUyMm9wZW5sbS1yZXNlYXJjaCUyRm9wZW5fbGxhbWFfN2IlMjIpJTBBdG9rZW5pemVyLnBhZF90b2tlbiUyMCUzRCUyMHRva2VuaXplci5lb3NfdG9rZW4lMjAlMjAlMjMlMjBMbGFtYSUyMGhhcyUyMG5vJTIwcGFkJTIwdG9rZW4lMjBieSUyMGRlZmF1bHQlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJvcGVubG0tcmVzZWFyY2glMkZvcGVuX2xsYW1hXzdiJTIyJTJDJTIwZGV2aWNlX21hcCUzRCUyMmF1dG8lMjIlMkMlMjBsb2FkX2luXzRiaXQlM0RUcnVlJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;openlm-research/open_llama_7b&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.pad_token = tokenizer.eos_token  <span class="hljs-comment"># Llama has no pad token by default</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;openlm-research/open_llama_7b&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_4bit=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),K=new h({props:{title:"Generated output is too short/long",local:"generated-output-is-too-shortlong",headingTag:"h3"}}),O=new T({props:{code:"bW9kZWxfaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKCU1QiUyMkElMjBzZXF1ZW5jZSUyMG9mJTIwbnVtYmVycyUzQSUyMDElMkMlMjAyJTIyJTVEJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMikudG8oJTIyY3VkYSUyMiklMEElMEElMjMlMjBCeSUyMGRlZmF1bHQlMkMlMjB0aGUlMjBvdXRwdXQlMjB3aWxsJTIwY29udGFpbiUyMHVwJTIwdG8lMjAyMCUyMHRva2VucyUwQWdlbmVyYXRlZF9pZHMlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKm1vZGVsX2lucHV0cyklMEF0b2tlbml6ZXIuYmF0Y2hfZGVjb2RlKGdlbmVyYXRlZF9pZHMlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSklNUIwJTVEJTBBJTBBJTIzJTIwU2V0dGluZyUyMCU2MG1heF9uZXdfdG9rZW5zJTYwJTIwYWxsb3dzJTIweW91JTIwdG8lMjBjb250cm9sJTIwdGhlJTIwbWF4aW11bSUyMGxlbmd0aCUwQWdlbmVyYXRlZF9pZHMlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKm1vZGVsX2lucHV0cyUyQyUyMG1heF9uZXdfdG9rZW5zJTNENTApJTBBdG9rZW5pemVyLmJhdGNoX2RlY29kZShnZW5lcmF0ZWRfaWRzJTJDJTIwc2tpcF9zcGVjaWFsX3Rva2VucyUzRFRydWUpJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model_inputs = tokenizer([<span class="hljs-string">&quot;A sequence of numbers: 1, 2&quot;</span>], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># By default, the output will contain up to 20 tokens</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;A sequence of numbers: 1, 2, 3, 4, 5&#x27;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Setting \`max_new_tokens\` allows you to control the maximum length</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs, max_new_tokens=<span class="hljs-number">50</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;A sequence of numbers: 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,&#x27;</span>`,wrap:!1}}),ee=new h({props:{title:"Incorrect generation mode",local:"incorrect-generation-mode",headingTag:"h3"}}),le=new T({props:{code:"JTIzJTIwU2V0JTIwc2VlZCUyMG9yJTIwcmVwcm9kdWNpYmlsaXR5JTIwLS0lMjB5b3UlMjBkb24ndCUyMG5lZWQlMjB0aGlzJTIwdW5sZXNzJTIweW91JTIwd2FudCUyMGZ1bGwlMjByZXByb2R1Y2liaWxpdHklMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwc2V0X3NlZWQlMEFzZXRfc2VlZCgwKSUwQSUwQW1vZGVsX2lucHV0cyUyMCUzRCUyMHRva2VuaXplciglNUIlMjJJJTIwYW0lMjBhJTIwY2F0LiUyMiU1RCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpLnRvKCUyMmN1ZGElMjIpJTBBJTBBJTIzJTIwTExNJTIwJTJCJTIwZ3JlZWR5JTIwZGVjb2RpbmclMjAlM0QlMjByZXBldGl0aXZlJTJDJTIwYm9yaW5nJTIwb3V0cHV0JTBBZ2VuZXJhdGVkX2lkcyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqbW9kZWxfaW5wdXRzKSUwQXRva2VuaXplci5iYXRjaF9kZWNvZGUoZ2VuZXJhdGVkX2lkcyUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSU1QjAlNUQlMEElMEElMjMlMjBXaXRoJTIwc2FtcGxpbmclMkMlMjB0aGUlMjBvdXRwdXQlMjBiZWNvbWVzJTIwbW9yZSUyMGNyZWF0aXZlISUwQWdlbmVyYXRlZF9pZHMlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKm1vZGVsX2lucHV0cyUyQyUyMGRvX3NhbXBsZSUzRFRydWUpJTBBdG9rZW5pemVyLmJhdGNoX2RlY29kZShnZW5lcmF0ZWRfaWRzJTJDJTIwc2tpcF9zcGVjaWFsX3Rva2VucyUzRFRydWUpJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Set seed or reproducibility -- you don&#x27;t need this unless you want full reproducibility</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> set_seed
<span class="hljs-meta">&gt;&gt;&gt; </span>set_seed(<span class="hljs-number">0</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>model_inputs = tokenizer([<span class="hljs-string">&quot;I am a cat.&quot;</span>], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># LLM + greedy decoding = repetitive, boring output</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;I am a cat. I am a cat. I am a cat. I am a cat&#x27;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With sampling, the output becomes more creative!</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs, do_sample=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;I am a cat.\\nI just need to be. I am always.\\nEvery time&#x27;</span>`,wrap:!1}}),se=new h({props:{title:"Wrong padding side",local:"wrong-padding-side",headingTag:"h3"}}),ne=new T({props:{code:"JTIzJTIwVGhlJTIwdG9rZW5pemVyJTIwaW5pdGlhbGl6ZWQlMjBhYm92ZSUyMGhhcyUyMHJpZ2h0LXBhZGRpbmclMjBhY3RpdmUlMjBieSUyMGRlZmF1bHQlM0ElMjB0aGUlMjAxc3QlMjBzZXF1ZW5jZSUyQyUwQSUyMyUyMHdoaWNoJTIwaXMlMjBzaG9ydGVyJTJDJTIwaGFzJTIwcGFkZGluZyUyMG9uJTIwdGhlJTIwcmlnaHQlMjBzaWRlLiUyMEdlbmVyYXRpb24lMjBmYWlscy4lMEFtb2RlbF9pbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyMSUyQyUyMDIlMkMlMjAzJTIyJTJDJTIwJTIyQSUyQyUyMEIlMkMlMjBDJTJDJTIwRCUyQyUyMEUlMjIlNUQlMkMlMjBwYWRkaW5nJTNEVHJ1ZSUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIlMEEpLnRvKCUyMmN1ZGElMjIpJTBBZ2VuZXJhdGVkX2lkcyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqbW9kZWxfaW5wdXRzKSUwQXRva2VuaXplci5iYXRjaF9kZWNvZGUoZ2VuZXJhdGVkX2lkcyU1QjAlNUQlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSklNUIwJTVEJTBBJTBBJTIzJTIwV2l0aCUyMGxlZnQtcGFkZGluZyUyQyUyMGl0JTIwd29ya3MlMjBhcyUyMGV4cGVjdGVkISUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKCUyMm9wZW5sbS1yZXNlYXJjaCUyRm9wZW5fbGxhbWFfN2IlMjIlMkMlMjBwYWRkaW5nX3NpZGUlM0QlMjJsZWZ0JTIyKSUwQXRva2VuaXplci5wYWRfdG9rZW4lMjAlM0QlMjB0b2tlbml6ZXIuZW9zX3Rva2VuJTIwJTIwJTIzJTIwTGxhbWElMjBoYXMlMjBubyUyMHBhZCUyMHRva2VuJTIwYnklMjBkZWZhdWx0JTBBbW9kZWxfaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKCUwQSUyMCUyMCUyMCUyMCU1QiUyMjElMkMlMjAyJTJDJTIwMyUyMiUyQyUyMCUyMkElMkMlMjBCJTJDJTIwQyUyQyUyMEQlMkMlMjBFJTIyJTVEJTJDJTIwcGFkZGluZyUzRFRydWUlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyJTBBKS50byglMjJjdWRhJTIyKSUwQWdlbmVyYXRlZF9pZHMlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKm1vZGVsX2lucHV0cyklMEF0b2tlbml6ZXIuYmF0Y2hfZGVjb2RlKGdlbmVyYXRlZF9pZHMlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSklNUIwJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># The tokenizer initialized above has right-padding active by default: the 1st sequence,</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># which is shorter, has padding on the right side. Generation fails.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model_inputs = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;1, 2, 3&quot;</span>, <span class="hljs-string">&quot;A, B, C, D, E&quot;</span>], padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">... </span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;&#x27;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># With left-padding, it works as expected!</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;openlm-research/open_llama_7b&quot;</span>, padding_side=<span class="hljs-string">&quot;left&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.pad_token = tokenizer.eos_token  <span class="hljs-comment"># Llama has no pad token by default</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model_inputs = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;1, 2, 3&quot;</span>, <span class="hljs-string">&quot;A, B, C, D, E&quot;</span>], padding=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>
<span class="hljs-meta">... </span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>generated_ids = model.generate(**model_inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-string">&#x27;1, 2, 3, 4, 5, 6,&#x27;</span>`,wrap:!1}}),ie=new h({props:{title:"Further resources",local:"further-resources",headingTag:"h2"}}),re=new h({props:{title:"Advanced generate usage",local:"advanced-generate-usage",headingTag:"h3"}}),me=new h({props:{title:"LLM leaderboards",local:"llm-leaderboards",headingTag:"h3"}}),ce=new h({props:{title:"Latency and throughput",local:"latency-and-throughput",headingTag:"h3"}}),de=new h({props:{title:"Related libraries",local:"related-libraries",headingTag:"h3"}}),{c(){M=i("meta"),J=a(),f=i("p"),fe=a(),o(w.$$.fragment),be=a(),o(U.$$.fragment),je=a(),_=i("p"),_.textContent=ht,Te=a(),Z=i("p"),Z.innerHTML=yt,Je=a(),$=i("p"),$.textContent=bt,we=a(),k=i("ul"),k.innerHTML=jt,Ue=a(),G=i("p"),G.textContent=Tt,_e=a(),o(v.$$.fragment),Ze=a(),o(C.$$.fragment),$e=a(),I=i("p"),I.innerHTML=Jt,ke=a(),y=i("figure"),y.innerHTML=wt,Ge=a(),W=i("p"),W.textContent=Ut,ve=a(),b=i("figure"),b.innerHTML=_t,Ce=a(),x=i("p"),x.innerHTML=Zt,Ie=a(),L=i("p"),L.innerHTML=$t,We=a(),V=i("p"),V.textContent=kt,xe=a(),o(j.$$.fragment),Le=a(),X=i("p"),X.textContent=Gt,Ve=a(),o(R.$$.fragment),Xe=a(),z=i("p"),z.innerHTML=vt,Re=a(),B=i("ul"),B.innerHTML=Ct,ze=a(),H=i("p"),H.textContent=It,Be=a(),F=i("p"),F.innerHTML=Wt,He=a(),o(q.$$.fragment),Fe=a(),Q=i("p"),Q.innerHTML=xt,qe=a(),E=i("p"),E.innerHTML=Lt,Qe=a(),o(N.$$.fragment),Ee=a(),Y=i("p"),Y.textContent=Vt,Ne=a(),o(S.$$.fragment),Ye=a(),A=i("p"),A.innerHTML=Xt,Se=a(),o(P.$$.fragment),Ae=a(),o(K.$$.fragment),Pe=a(),D=i("p"),D.innerHTML=Rt,Ke=a(),o(O.$$.fragment),De=a(),o(ee.$$.fragment),Oe=a(),te=i("p"),te.innerHTML=zt,et=a(),o(le.$$.fragment),tt=a(),o(se.$$.fragment),lt=a(),ae=i("p"),ae.innerHTML=Bt,st=a(),o(ne.$$.fragment),at=a(),o(ie.$$.fragment),nt=a(),pe=i("p"),pe.textContent=Ht,it=a(),o(re.$$.fragment),pt=a(),oe=i("ol"),oe.innerHTML=Ft,rt=a(),o(me.$$.fragment),ot=a(),ge=i("ol"),ge.innerHTML=qt,mt=a(),o(ce.$$.fragment),gt=a(),ue=i("ol"),ue.innerHTML=Qt,ct=a(),o(de.$$.fragment),ut=a(),Me=i("ol"),Me.innerHTML=Et,dt=a(),he=i("p"),this.h()},l(e){const t=Ot("svelte-u9bgzb",document.head);M=p(t,"META",{name:!0,content:!0}),t.forEach(l),J=n(e),f=p(e,"P",{}),Yt(f).forEach(l),fe=n(e),m(w.$$.fragment,e),be=n(e),m(U.$$.fragment,e),je=n(e),_=p(e,"P",{"data-svelte-h":!0}),r(_)!=="svelte-1p8oyus"&&(_.textContent=ht),Te=n(e),Z=p(e,"P",{"data-svelte-h":!0}),r(Z)!=="svelte-18326uo"&&(Z.innerHTML=yt),Je=n(e),$=p(e,"P",{"data-svelte-h":!0}),r($)!=="svelte-10d5jzs"&&($.textContent=bt),we=n(e),k=p(e,"UL",{"data-svelte-h":!0}),r(k)!=="svelte-114gruu"&&(k.innerHTML=jt),Ue=n(e),G=p(e,"P",{"data-svelte-h":!0}),r(G)!=="svelte-5jpx9c"&&(G.textContent=Tt),_e=n(e),m(v.$$.fragment,e),Ze=n(e),m(C.$$.fragment,e),$e=n(e),I=p(e,"P",{"data-svelte-h":!0}),r(I)!=="svelte-1kvqgos"&&(I.innerHTML=Jt),ke=n(e),y=p(e,"FIGURE",{class:!0,"data-svelte-h":!0}),r(y)!=="svelte-hjgddv"&&(y.innerHTML=wt),Ge=n(e),W=p(e,"P",{"data-svelte-h":!0}),r(W)!=="svelte-1vvn9v3"&&(W.textContent=Ut),ve=n(e),b=p(e,"FIGURE",{class:!0,"data-svelte-h":!0}),r(b)!=="svelte-1uqc9hk"&&(b.innerHTML=_t),Ce=n(e),x=p(e,"P",{"data-svelte-h":!0}),r(x)!=="svelte-1q7bq18"&&(x.innerHTML=Zt),Ie=n(e),L=p(e,"P",{"data-svelte-h":!0}),r(L)!=="svelte-1xlt8wi"&&(L.innerHTML=$t),We=n(e),V=p(e,"P",{"data-svelte-h":!0}),r(V)!=="svelte-1gzvd9k"&&(V.textContent=kt),xe=n(e),m(j.$$.fragment,e),Le=n(e),X=p(e,"P",{"data-svelte-h":!0}),r(X)!=="svelte-1mik2gq"&&(X.textContent=Gt),Ve=n(e),m(R.$$.fragment,e),Xe=n(e),z=p(e,"P",{"data-svelte-h":!0}),r(z)!=="svelte-dj98s8"&&(z.innerHTML=vt),Re=n(e),B=p(e,"UL",{"data-svelte-h":!0}),r(B)!=="svelte-k3ww82"&&(B.innerHTML=Ct),ze=n(e),H=p(e,"P",{"data-svelte-h":!0}),r(H)!=="svelte-1ved9f1"&&(H.textContent=It),Be=n(e),F=p(e,"P",{"data-svelte-h":!0}),r(F)!=="svelte-1vkr8y3"&&(F.innerHTML=Wt),He=n(e),m(q.$$.fragment,e),Fe=n(e),Q=p(e,"P",{"data-svelte-h":!0}),r(Q)!=="svelte-1ri477u"&&(Q.innerHTML=xt),qe=n(e),E=p(e,"P",{"data-svelte-h":!0}),r(E)!=="svelte-voqumo"&&(E.innerHTML=Lt),Qe=n(e),m(N.$$.fragment,e),Ee=n(e),Y=p(e,"P",{"data-svelte-h":!0}),r(Y)!=="svelte-1fgh7wz"&&(Y.textContent=Vt),Ne=n(e),m(S.$$.fragment,e),Ye=n(e),A=p(e,"P",{"data-svelte-h":!0}),r(A)!=="svelte-k0wny5"&&(A.innerHTML=Xt),Se=n(e),m(P.$$.fragment,e),Ae=n(e),m(K.$$.fragment,e),Pe=n(e),D=p(e,"P",{"data-svelte-h":!0}),r(D)!=="svelte-80musy"&&(D.innerHTML=Rt),Ke=n(e),m(O.$$.fragment,e),De=n(e),m(ee.$$.fragment,e),Oe=n(e),te=p(e,"P",{"data-svelte-h":!0}),r(te)!=="svelte-gscn2d"&&(te.innerHTML=zt),et=n(e),m(le.$$.fragment,e),tt=n(e),m(se.$$.fragment,e),lt=n(e),ae=p(e,"P",{"data-svelte-h":!0}),r(ae)!=="svelte-fd0pc8"&&(ae.innerHTML=Bt),st=n(e),m(ne.$$.fragment,e),at=n(e),m(ie.$$.fragment,e),nt=n(e),pe=p(e,"P",{"data-svelte-h":!0}),r(pe)!=="svelte-1d601do"&&(pe.textContent=Ht),it=n(e),m(re.$$.fragment,e),pt=n(e),oe=p(e,"OL",{"data-svelte-h":!0}),r(oe)!=="svelte-142agms"&&(oe.innerHTML=Ft),rt=n(e),m(me.$$.fragment,e),ot=n(e),ge=p(e,"OL",{"data-svelte-h":!0}),r(ge)!=="svelte-1mag1j5"&&(ge.innerHTML=qt),mt=n(e),m(ce.$$.fragment,e),gt=n(e),ue=p(e,"OL",{"data-svelte-h":!0}),r(ue)!=="svelte-1d7xcac"&&(ue.innerHTML=Qt),ct=n(e),m(de.$$.fragment,e),ut=n(e),Me=p(e,"OL",{"data-svelte-h":!0}),r(Me)!=="svelte-1v1y2ns"&&(Me.innerHTML=Et),dt=n(e),he=p(e,"P",{}),Yt(he).forEach(l),this.h()},h(){ft(M,"name","hf:doc:metadata"),ft(M,"content",nl),ft(y,"class","image table text-center m-0 w-full"),ft(b,"class","image table text-center m-0 w-full")},m(e,t){el(document.head,M),s(e,J,t),s(e,f,t),s(e,fe,t),g(w,e,t),s(e,be,t),g(U,e,t),s(e,je,t),s(e,_,t),s(e,Te,t),s(e,Z,t),s(e,Je,t),s(e,$,t),s(e,we,t),s(e,k,t),s(e,Ue,t),s(e,G,t),s(e,_e,t),g(v,e,t),s(e,Ze,t),g(C,e,t),s(e,$e,t),s(e,I,t),s(e,ke,t),s(e,y,t),s(e,Ge,t),s(e,W,t),s(e,ve,t),s(e,b,t),s(e,Ce,t),s(e,x,t),s(e,Ie,t),s(e,L,t),s(e,We,t),s(e,V,t),s(e,xe,t),g(j,e,t),s(e,Le,t),s(e,X,t),s(e,Ve,t),g(R,e,t),s(e,Xe,t),s(e,z,t),s(e,Re,t),s(e,B,t),s(e,ze,t),s(e,H,t),s(e,Be,t),s(e,F,t),s(e,He,t),g(q,e,t),s(e,Fe,t),s(e,Q,t),s(e,qe,t),s(e,E,t),s(e,Qe,t),g(N,e,t),s(e,Ee,t),s(e,Y,t),s(e,Ne,t),g(S,e,t),s(e,Ye,t),s(e,A,t),s(e,Se,t),g(P,e,t),s(e,Ae,t),g(K,e,t),s(e,Pe,t),s(e,D,t),s(e,Ke,t),g(O,e,t),s(e,De,t),g(ee,e,t),s(e,Oe,t),s(e,te,t),s(e,et,t),g(le,e,t),s(e,tt,t),g(se,e,t),s(e,lt,t),s(e,ae,t),s(e,st,t),g(ne,e,t),s(e,at,t),g(ie,e,t),s(e,nt,t),s(e,pe,t),s(e,it,t),g(re,e,t),s(e,pt,t),s(e,oe,t),s(e,rt,t),g(me,e,t),s(e,ot,t),s(e,ge,t),s(e,mt,t),g(ce,e,t),s(e,gt,t),s(e,ue,t),s(e,ct,t),g(de,e,t),s(e,ut,t),s(e,Me,t),s(e,dt,t),s(e,he,t),Mt=!0},p(e,[t]){const Nt={};t&2&&(Nt.$$scope={dirty:t,ctx:e}),j.$set(Nt)},i(e){Mt||(c(w.$$.fragment,e),c(U.$$.fragment,e),c(v.$$.fragment,e),c(C.$$.fragment,e),c(j.$$.fragment,e),c(R.$$.fragment,e),c(q.$$.fragment,e),c(N.$$.fragment,e),c(S.$$.fragment,e),c(P.$$.fragment,e),c(K.$$.fragment,e),c(O.$$.fragment,e),c(ee.$$.fragment,e),c(le.$$.fragment,e),c(se.$$.fragment,e),c(ne.$$.fragment,e),c(ie.$$.fragment,e),c(re.$$.fragment,e),c(me.$$.fragment,e),c(ce.$$.fragment,e),c(de.$$.fragment,e),Mt=!0)},o(e){u(w.$$.fragment,e),u(U.$$.fragment,e),u(v.$$.fragment,e),u(C.$$.fragment,e),u(j.$$.fragment,e),u(R.$$.fragment,e),u(q.$$.fragment,e),u(N.$$.fragment,e),u(S.$$.fragment,e),u(P.$$.fragment,e),u(K.$$.fragment,e),u(O.$$.fragment,e),u(ee.$$.fragment,e),u(le.$$.fragment,e),u(se.$$.fragment,e),u(ne.$$.fragment,e),u(ie.$$.fragment,e),u(re.$$.fragment,e),u(me.$$.fragment,e),u(ce.$$.fragment,e),u(de.$$.fragment,e),Mt=!1},d(e){e&&(l(J),l(f),l(fe),l(be),l(je),l(_),l(Te),l(Z),l(Je),l($),l(we),l(k),l(Ue),l(G),l(_e),l(Ze),l($e),l(I),l(ke),l(y),l(Ge),l(W),l(ve),l(b),l(Ce),l(x),l(Ie),l(L),l(We),l(V),l(xe),l(Le),l(X),l(Ve),l(Xe),l(z),l(Re),l(B),l(ze),l(H),l(Be),l(F),l(He),l(Fe),l(Q),l(qe),l(E),l(Qe),l(Ee),l(Y),l(Ne),l(Ye),l(A),l(Se),l(Ae),l(Pe),l(D),l(Ke),l(De),l(Oe),l(te),l(et),l(tt),l(lt),l(ae),l(st),l(at),l(nt),l(pe),l(it),l(pt),l(oe),l(rt),l(ot),l(ge),l(mt),l(gt),l(ue),l(ct),l(ut),l(Me),l(dt),l(he)),l(M),d(w,e),d(U,e),d(v,e),d(C,e),d(j,e),d(R,e),d(q,e),d(N,e),d(S,e),d(P,e),d(K,e),d(O,e),d(ee,e),d(le,e),d(se,e),d(ne,e),d(ie,e),d(re,e),d(me,e),d(ce,e),d(de,e)}}}const nl='{"title":"Generation with LLMs","local":"generation-with-llms","sections":[{"title":"Generate text","local":"generate-text","sections":[],"depth":2},{"title":"Common pitfalls","local":"common-pitfalls","sections":[{"title":"Generated output is too short/long","local":"generated-output-is-too-shortlong","sections":[],"depth":3},{"title":"Incorrect generation mode","local":"incorrect-generation-mode","sections":[],"depth":3},{"title":"Wrong padding side","local":"wrong-padding-side","sections":[],"depth":3}],"depth":2},{"title":"Further resources","local":"further-resources","sections":[{"title":"Advanced generate usage","local":"advanced-generate-usage","sections":[],"depth":3},{"title":"LLM leaderboards","local":"llm-leaderboards","sections":[],"depth":3},{"title":"Latency and throughput","local":"latency-and-throughput","sections":[],"depth":3},{"title":"Related libraries","local":"related-libraries","sections":[],"depth":3}],"depth":2}],"depth":1}';function il(ye){return At(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ul extends Kt{constructor(M){super(),Dt(this,M,il,al,St,{})}}export{ul as component};
