import{s as V,n as z,o as q}from"../chunks/scheduler.9bc65507.js";import{S as $,i as Q,g as f,s as r,r as P,A as j,h as m,f as a,c as i,j as O,u as E,x as A,k as G,y as H,a as e,v as D,d as L,t as F,w as B}from"../chunks/index.707bf1b6.js";import{H as N}from"../chunks/Heading.342b1fa6.js";function U(S){let l,u,d,_,s,T,n,I="このページは、コミュニティによって開発された🤗 Transformersに関するリソースをまとめたものです。",w,g,y,h,M='<thead><tr><th align="left">リソース</th> <th align="left">説明</th> <th align="right">作者</th></tr></thead> <tbody><tr><td align="left"><a href="https://www.darigovresearch.com/huggingface-transformers-glossary-flashcards" rel="nofollow">Hugging Face Transformers Glossary Flashcards</a></td> <td align="left"><a href="glossary">Transformers Docs Glossary</a>に基づいたフラッシュカードセットです。このセットは、長期の知識定着を特に考慮して設計されたオープンソースのクロスプラットフォームアプリである<a href="https://apps.ankiweb.net/" rel="nofollow">Anki</a>を使用して簡単に学習/復習できる形式になっています。<a href="https://www.youtube.com/watch?v=Dji_h7PILrw" rel="nofollow">フラッシュカードの使用方法に関する紹介ビデオはこちら</a>をご覧ください。</td> <td align="right"><a href="https://www.darigovresearch.com/" rel="nofollow">Darigov Research</a></td></tr></tbody>',v,b,k,c,x='<thead><tr><th align="left">ノートブック</th> <th align="left">説明</th> <th align="left">著者</th> <th align="right"></th></tr></thead> <tbody><tr><td align="left"><a href="https://github.com/AlekseyKorshuk/huggingartists" rel="nofollow">事前学習済みのTransformerを微調整して歌詞を生成</a></td> <td align="left">GPT-2モデルを微調整してお気に入りのアーティストのスタイルで歌詞を生成する方法</td> <td align="left"><a href="https://github.com/AlekseyKorshuk" rel="nofollow">Aleksey Korshuk</a></td> <td align="right"><a href="https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/snapthat/TF-T5-text-to-text" rel="nofollow">Tensorflow 2でT5をトレーニング</a></td> <td align="left">Tensorflow 2を使用して任意のタスクに対してT5をトレーニングする方法。このノートブックはTensorflow 2を使用してSQUADで実装された質問と回答タスクを示しています。</td> <td align="left"><a href="https://github.com/HarrisDePerceptron" rel="nofollow">Muhammad Harris</a></td> <td align="right"><a href="https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb" rel="nofollow">TPUでT5をトレーニング</a></td> <td align="left">TransformersとNlpを使用してSQUADでT5をトレーニングする方法</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb" rel="nofollow">分類と多肢選択のためにT5を微調整</a></td> <td align="left">PyTorch Lightningを使用してテキスト対テキスト形式でT5を分類と多肢選択タスクに微調整する方法</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb" rel="nofollow">新しいデータセットと言語でDialoGPTを微調整</a></td> <td align="left">DialoGPTモデルを新しいデータセットでオープンダイアログ会話用の微調整する方法</td> <td align="left"><a href="https://github.com/ncoop57" rel="nofollow">Nathan Cooper</a></td> <td align="right"><a href="https://colab.research.google.com/github/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb" rel="nofollow">Reformerを使用した長いシーケンスモデリング</a></td> <td align="left">Reformerを使用して500,000トークンまでのシーケンスをトレーニングする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb" rel="nofollow">要約のためにBARTを微調整</a></td> <td align="left">Blurrを使用して要約のためにBARTを微調整する方法</td> <td align="left"><a href="https://ohmeow.com/" rel="nofollow">Wayde Gilliam</a></td> <td align="right"><a href="https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb" rel="nofollow">事前学習済みのTransformerを微調整して誰かのツイートを生成</a></td> <td align="left">GPT-2モデルを微調整してお気に入りのTwitterアカウントのスタイルでツイートを生成する方法</td> <td align="left"><a href="https://github.com/borisdayma" rel="nofollow">Boris Dayma</a></td> <td align="right"><a href="https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb" rel="nofollow">🤗 Hugging FaceモデルをWeights &amp; Biasesで最適化</a></td> <td align="left">Hugging FaceとWeights &amp; Biasesの統合を示す完全なチュートリアル</td> <td align="left"><a href="https://github.com/borisdayma" rel="nofollow">Boris Dayma</a></td> <td align="right"><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb" rel="nofollow">Longformerの事前学習</a></td> <td align="left">既存の事前学習済みモデルの「長い」バージョンを構築する方法</td> <td align="left"><a href="https://beltagy.net" rel="nofollow">Iz Beltagy</a></td> <td align="right"><a href="https://colab.research.google.com/github/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb" rel="nofollow">QAタスクのためにLongformerを微調整</a></td> <td align="left">QAタスクのためにLongformerモデルを微調整する方法</td> <td align="left"><a href="https://github.com/patil-suraj" rel="nofollow">Suraj Patil</a></td> <td align="right"><a href="https://colab.research.google.com/github/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/How_to_evaluate_Longformer_on_TriviaQA_using_NLP.ipynb" rel="nofollow">🤗nlpを使用したモデルの評価</a></td> <td align="left"><code>nlp</code>を使用してTriviaQAでLongformerを評価する方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1m7eTGlPmLRgoPkkA7rkhQdZ9ydpmsdLE?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb" rel="nofollow">感情スパン抽出のためにT5を微調整</a></td> <td align="left">PyTorch Lightningを使用して感情スパン抽出のためにT5を微調整する方法</td> <td align="left"><a href="https://github.com/enzoampil" rel="nofollow">Lorenzo Ampil</a></td> <td align="right"><a href="https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb" rel="nofollow">DistilBertをマルチクラス分類にファインチューニング</a></td> <td align="left">PyTorchを使用してDistilBertをマルチクラス分類にファインチューニングする方法</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb" rel="nofollow">BERTをマルチラベル分類にファインチューニング</a></td> <td align="left">PyTorchを使用してBERTをマルチラベル分類にファインチューニングする方法</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb" rel="nofollow">T5を要約にファインチューニング</a></td> <td align="left">PyTorchを使用してT5を要約にファインチューニングし、WandBで実験をトラッキングする方法</td> <td align="left"><a href="https://github.com/abhimishra91" rel="nofollow">Abhishek Kumar Mishra</a></td> <td align="right"><a href="https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ELS-RD/transformers-notebook/blob/master/Divide_Hugging_Face_Transformers_training_time_by_2_or_more.ipynb" rel="nofollow">ダイナミックパディング/バケッティングを使用してTransformersのファインチューニングを高速化</a></td> <td align="left">ダイナミックパディング/バケッティングを使用してファインチューニングを2倍高速化する方法</td> <td align="left"><a href="https://github.com/pommedeterresautee" rel="nofollow">Michael Benesty</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1CBfRU1zbfu7-ijiOqAAQUA-RJaxfcJoO?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Reformer_For_Masked_LM.ipynb" rel="nofollow">マスク言語モデリングのためのReformerの事前学習</a></td> <td align="left">双方向セルフアテンションレイヤーを備えたReformerモデルのトレーニング方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1tzzh0i8PgDQGV3SMFUGxM7_gGae3K-uW?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/lordtt13/word-embeddings/blob/master/COVID-19%20Research%20Data/COVID-SciBERT.ipynb" rel="nofollow">Sci-BERTを拡張してファインチューニング</a></td> <td align="left">AllenAIのCORDデータセットで事前学習済みのSciBERTモデルの語彙を拡張し、パイプライン化する方法</td> <td align="left"><a href="https://github.com/lordtt13" rel="nofollow">Tanmay Thakur</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1rqAR40goxbAfez1xvF3hBJphSCsvXmh8" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/lordtt13/transformers-experiments/blob/master/Custom%20Tasks/fine-tune-blenderbot_small-for-summarization.ipynb" rel="nofollow">Trainer APIを使用してBlenderBotSmallを要約のためにファインチューニング</a></td> <td align="left">カスタムデータセットでBlenderBotSmallを要約のためにファインチューニングする方法、Trainer APIを使用</td> <td align="left"><a href="https://github.com/lordtt13" rel="nofollow">Tanmay Thakur</a></td> <td align="right"><a href="https://colab.research.google.com/drive/19Wmupuls7mykSGyRN_Qo6lPQhgp56ymq?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb" rel="nofollow">ElectraをファインチューニングしてCaptum Integrated Gradientsで解釈</a></td> <td align="left">Electraを感情分析のためにファインチューニングし、Captum Integrated Gradientsで予測を解釈する方法</td> <td align="left"><a href="https://elsanns.github.io" rel="nofollow">Eliza Szczechla</a></td> <td align="right"><a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb" rel="nofollow">Trainerクラスを使用して非英語のGPT-2モデルをファインチューニング</a></td> <td align="left">Trainerクラスを使用して非英語のGPT-2モデルをファインチューニングする方法</td> <td align="left"><a href="https://www.philschmid.de" rel="nofollow">Philipp Schmid</a></td> <td align="right"><a href="https://colab.research.google.com/github/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb" rel="nofollow">DistilBERTモデルをマルチラベル分類タスクのためにファインチューニング</a></td> <td align="left">DistilBERTモデルをマルチラベル分類タスクのためにファインチューニングする方法</td> <td align="left"><a href="https://github.com/DhavalTaunk08" rel="nofollow">Dhaval Taunk</a></td> <td align="right"><a href="https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb" rel="nofollow">ALBERTを文ペア分類タスクのためにファインチューニング</a></td> <td align="left">ALBERTモデルまたは他のBERTベースのモデルを文ペア分類タスクのためにファインチューニングする方法</td> <td align="left"><a href="https://github.com/NadirEM" rel="nofollow">Nadir El Manouzi</a></td> <td align="right"><a href="https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb" rel="nofollow">RoBERTaを感情分析のためにファインチューニング</a></td> <td align="left">RoBERTaモデルを感情分析のためにファインチューニングする方法</td> <td align="left"><a href="https://github.com/DhavalTaunk08" rel="nofollow">Dhaval Taunk</a></td> <td align="right"><a href="https://colab.research.google.com/github/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/flexudy-pipe/qugeev" rel="nofollow">質問生成モデルの評価</a></td> <td align="left">seq2seqトランスフォーマーモデルによって生成された質問の回答の正確さを評価する方法</td> <td align="left"><a href="https://github.com/zolekode" rel="nofollow">Pascal Zoleko</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1bpsSqCQU-iw_5nNoRm_crPq6FRuJthq_?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb" rel="nofollow">DistilBERTとTensorflowを使用してテキストを分類</a></td> <td align="left">TensorFlowでテキスト分類のためにDistilBERTをファインチューニングする方法</td> <td align="left"><a href="https://github.com/peterbayerle" rel="nofollow">Peter Bayerle</a></td> <td align="right"><a href="https://colab.research.google.com/github/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb" rel="nofollow">CNN/Dailymailでのエンコーダーデコーダー要約にBERTを活用</a></td> <td align="left"><em>google-bert/bert-base-uncased</em> チェックポイントを使用してCNN/Dailymailの要約のために <em>EncoderDecoderModel</em> をウォームスタートする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb" rel="nofollow">BBC XSumでのエンコーダーデコーダー要約にRoBERTaを活用</a></td> <td align="left"><em>FacebookAI/roberta-base</em> チェックポイントを使用してBBC/XSumの要約のための共有 <em>EncoderDecoderModel</em> をウォームスタートする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb" rel="nofollow">TAPASをシーケンシャル質問応答（SQA）でファインチューニング</a></td> <td align="left">シーケンシャル質問応答（SQA）データセットで <em>tapas-base</em> チェックポイントを使用して <em>TapasForQuestionAnswering</em> をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb" rel="nofollow">TabFactでTAPASを評価</a></td> <td align="left"><em>tapas-base-finetuned-tabfact</em> チェックポイントを使用してファインチューニングされた <em>TapasForSequenceClassification</em> を評価する方法、🤗 datasets と 🤗 transformers ライブラリを組み合わせて使用</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb" rel="nofollow">翻訳のためのmBARTをファインチューニング</a></td> <td align="left">Seq2SeqTrainerを使用してHindiからEnglishへの翻訳のためにmBARTをファインチューニングする方法</td> <td align="left"><a href="https://github.com/vasudevgupta7" rel="nofollow">Vasudev Gupta</a></td> <td align="right"><a href="https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb" rel="nofollow">FUNSD（フォーム理解データセット）でLayoutLMをファインチューニング</a></td> <td align="left">スキャンされたドキュメントからの情報抽出のためにFUNSDデータセットで <em>LayoutLMForTokenClassification</em> をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a></td></tr> <tr><td align="left"><a href="https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb" rel="nofollow">DistilGPT2のファインチューニングとテキスト生成</a></td> <td align="left">DistilGPT2のファインチューニングとテキスト生成方法</td> <td align="left"><a href="https://github.com/tripathiaakash" rel="nofollow">Aakash Tripathi</a></td> <td align="right"><a href="https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb" rel="nofollow">最大8KトークンでのLEDのファインチューニング</a></td> <td align="left">ロングレンジ要約のためのpubmedでLEDをファインチューニングする方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb" rel="nofollow">ArxivでのLEDの評価</a></td> <td align="left">ロングレンジ要約のためのLEDの効果的な評価方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb" rel="nofollow">RVL-CDIP（文書画像分類データセット）でのLayoutLMのファインチューニング</a></td> <td align="left">スキャンされた文書の分類のためのRVL-CDIPデータセットで<em>LayoutLMForSequenceClassification</em>をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/voidful/huggingface_notebook/blob/main/xlsr_gpt.ipynb" rel="nofollow">Wav2Vec2 CTCデコーディングとGPT2の調整</a></td> <td align="left">言語モデルの調整を伴うCTCシーケンスのデコーディング方法</td> <td align="left"><a href="https://github.com/voidful" rel="nofollow">Eric Lam</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1e_z5jQHYbO2YKEaUgzb1ww1WwiAyydAj?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb" rel="nofollow">Trainerクラスを使用した2言語の要約用にBARTをファインチューニング</a></td> <td align="left">トレーナークラスを使用して2つの言語での要約用にBARTをファインチューニングする方法</td> <td align="left"><a href="https://github.com/elsanns" rel="nofollow">Eliza Szczechla</a></td> <td align="right"><a href="https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb" rel="nofollow">PubMedデータセットでBigBirdの評価</a></td> <td align="left">Trivia QAの長いドキュメント質問応答でBigBirdの評価方法</td> <td align="left"><a href="https://github.com/patrickvonplaten" rel="nofollow">Patrick von Platen</a></td> <td align="right"><a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb" rel="nofollow">Wav2Vec2を使用してビデオの字幕を作成する</a></td> <td align="left">Wav2Vecでオーディオを転記して任意のビデオからYouTubeの字幕を作成する方法</td> <td align="left"><a href="https://github.com/Muennighoff" rel="nofollow">Niklas Muennighoff</a></td> <td align="right"><a href="https://colab.research.google.com/github/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb" rel="nofollow">PyTorch Lightningを使用したCIFAR-10でのVision Transformerのファインチューニング</a></td> <td align="left">HuggingFace Transformers、Datasets、およびPyTorch Lightningを使用してCIFAR-10でVision Transformer（ViT）をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb" rel="nofollow">🤗 Trainerを使用したCIFAR-10でのVision Transformerのファインチューニング</a></td> <td align="left">HuggingFace Transformers、Datasets、および🤗 Trainerを使用してCIFAR-10でVision Transformer（ViT）をファインチューニングする方法</td> <td align="left"><a href="https://github.com/nielsrogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb" rel="nofollow">Open Entity、エンティティタイピングデータセットでLUKEの評価</a></td> <td align="left">Open Entityデータセットで<em>LukeForEntityClassification</em>の評価方法</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb" rel="nofollow">TACRED、関係抽出データセットでLUKEの評価</a></td> <td align="left">TACREDデータセットで<em>LukeForEntityPairClassification</em>の評価方法</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb" rel="nofollow">CoNLL-2003、重要なNERベンチマークでLUKEの評価</a></td> <td align="left">CoNLL-2003データセットで<em>LukeForEntitySpanClassification</em>の評価方法</td> <td align="left"><a href="https://github.com/ikuyamada" rel="nofollow">Ikuya Yamada</a></td> <td align="right"><a href="https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb" rel="nofollow">PubMedデータセットでBigBird-Pegasusの評価</a></td> <td align="left">PubMedデータセットで<em>BigBirdPegasusForConditionalGeneration</em>の評価方法</td> <td align="left"><a href="https://github.com/vasudevgupta7" rel="nofollow">Vasudev Gupta</a></td> <td align="right"><a href="https://colab.research.google.com/github/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb" rel="nofollow">Wav2Vec2を使用したスピーチエモーション分類</a></td> <td align="left">MEGAデータセットでの感情分類のための事前学習済みWav2Vec2モデルの利用方法</td> <td align="left"><a href="https://github.com/m3hrdadfi" rel="nofollow">Mehrdad Farahani</a></td> <td align="right"><a href="https://colab.research.google.com/github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb" rel="nofollow">DETRを使用して画像内のオブジェクトを検出する</a></td> <td align="left">トレーニング済み<em>DetrForObjectDetection</em>モデルを使用して画像内のオブジェクトを検出し、注意を可視化する方法</td> <td align="left"><a href="https://github.com/NielsRogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb" rel="nofollow">カスタムオブジェクト検出データセットでDETRをファインチューニングする</a></td> <td align="left">カスタムオブジェクト検出データセットで<em>DetrForObjectDetection</em>をファインチューニングする方法</td> <td align="left"><a href="https://github.com/NielsRogge" rel="nofollow">Niels Rogge</a></td> <td align="right"><a href="https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr> <tr><td align="left"><a href="https://github.com/ToluClassics/Notebooks/blob/main/T5_Ner_Finetuning.ipynb" rel="nofollow">Named Entity RecognitionのためにT5をファインチューニング</a></td> <td align="left">Named Entity RecognitionタスクでT5をファインチューニングする方法</td> <td align="left"><a href="https://github.com/ToluClassics" rel="nofollow">Ogundepo Odunayo</a></td> <td align="right"><a href="https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Colabで開く"/></a></td></tr></tbody>',C,p,R;return s=new N({props:{title:"Community",local:"community",headingTag:"h1"}}),g=new N({props:{title:"Community resources:",local:"community-resources",headingTag:"h2"}}),b=new N({props:{title:"Community notebooks:",local:"community-notebooks",headingTag:"h2"}}),{c(){l=f("meta"),u=r(),d=f("p"),_=r(),P(s.$$.fragment),T=r(),n=f("p"),n.textContent=I,w=r(),P(g.$$.fragment),y=r(),h=f("table"),h.innerHTML=M,v=r(),P(b.$$.fragment),k=r(),c=f("table"),c.innerHTML=x,C=r(),p=f("p"),this.h()},l(t){const o=j("svelte-u9bgzb",document.head);l=m(o,"META",{name:!0,content:!0}),o.forEach(a),u=i(t),d=m(t,"P",{}),O(d).forEach(a),_=i(t),E(s.$$.fragment,t),T=i(t),n=m(t,"P",{"data-svelte-h":!0}),A(n)!=="svelte-e3qqtl"&&(n.textContent=I),w=i(t),E(g.$$.fragment,t),y=i(t),h=m(t,"TABLE",{"data-svelte-h":!0}),A(h)!=="svelte-upaqh4"&&(h.innerHTML=M),v=i(t),E(b.$$.fragment,t),k=i(t),c=m(t,"TABLE",{"data-svelte-h":!0}),A(c)!=="svelte-iccxtl"&&(c.innerHTML=x),C=i(t),p=m(t,"P",{}),O(p).forEach(a),this.h()},h(){G(l,"name","hf:doc:metadata"),G(l,"content",W)},m(t,o){H(document.head,l),e(t,u,o),e(t,d,o),e(t,_,o),D(s,t,o),e(t,T,o),e(t,n,o),e(t,w,o),D(g,t,o),e(t,y,o),e(t,h,o),e(t,v,o),D(b,t,o),e(t,k,o),e(t,c,o),e(t,C,o),e(t,p,o),R=!0},p:z,i(t){R||(L(s.$$.fragment,t),L(g.$$.fragment,t),L(b.$$.fragment,t),R=!0)},o(t){F(s.$$.fragment,t),F(g.$$.fragment,t),F(b.$$.fragment,t),R=!1},d(t){t&&(a(u),a(d),a(_),a(T),a(n),a(w),a(y),a(h),a(v),a(k),a(c),a(C),a(p)),a(l),B(s,t),B(g,t),B(b,t)}}}const W='{"title":"Community","local":"community","sections":[{"title":"Community resources:","local":"community-resources","sections":[],"depth":2},{"title":"Community notebooks:","local":"community-notebooks","sections":[],"depth":2}],"depth":1}';function K(S){return q(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Z extends ${constructor(l){super(),Q(this,l,K,U,V,{})}}export{Z as component};
