import{s as gt,o as kt,n as Ye}from"../chunks/scheduler.9bc65507.js";import{S as ht,i as $t,g as l,s as a,r as g,A as vt,h as p,f as n,c as o,j as I,u as k,x as _,k as q,y as t,a as m,v as h,d as $,t as v,w as b}from"../chunks/index.707bf1b6.js";import{T as bt}from"../chunks/Tip.c2ecdbf4.js";import{D as V}from"../chunks/Docstring.17db21ae.js";import{C as ut}from"../chunks/CodeBlock.54a9f38d.js";import{E as ft}from"../chunks/ExampleCodeBlock.4f515aa9.js";import{H as Ie}from"../chunks/Heading.342b1fa6.js";function xt(D){let i,w=`CPM のアーキテクチャは、トークン化方法を除いて GPT-2 と同じです。詳細については、<a href="openai-community/gpt2">GPT-2 ドキュメント</a> を参照してください。
API リファレンス情報。`;return{c(){i=l("p"),i.innerHTML=w},l(d){i=p(d,"P",{"data-svelte-h":!0}),_(i)!=="svelte-hrrftm"&&(i.innerHTML=w)},m(d,c){m(d,i,c)},p:Ye,d(d){d&&n(i)}}}function Ct(D){let i,w="sequence pair mask has the following format:",d,c,f;return c=new ut({props:{code:"MCUyMDAlMjAwJTIwMCUyMDAlMjAwJTIwMCUyMDAlMjAwJTIwMCUyMDAlMjAxJTIwMSUyMDElMjAxJTIwMSUyMDElMjAxJTIwMSUyMDElMEElN0MlMjBmaXJzdCUyMHNlcXVlbmNlJTIwJTIwJTIwJTIwJTdDJTIwc2Vjb25kJTIwc2VxdWVuY2UlMjAlN0M=",highlighted:`0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1 1
| first sequence    | second sequence |`,wrap:!1}}),{c(){i=l("p"),i.textContent=w,d=a(),g(c.$$.fragment)},l(r){i=p(r,"P",{"data-svelte-h":!0}),_(i)!=="svelte-16klr56"&&(i.textContent=w),d=o(r),k(c.$$.fragment,r)},m(r,x){m(r,i,x),m(r,d,x),h(c,r,x),f=!0},p:Ye,i(r){f||($(c.$$.fragment,r),f=!0)},o(r){v(c.$$.fragment,r),f=!1},d(r){r&&(n(i),n(d)),b(c,r)}}}function wt(D){let i,w="sequence pair mask has the following format:",d,c,f;return c=new ut({props:{code:"MCUyMDAlMjAwJTIwMCUyMDAlMjAwJTIwMCUyMDAlMjAwJTIwMCUyMDAlMjAxJTIwMSUyMDElMjAxJTIwMSUyMDElMjAxJTIwMSUyMDElMEElN0MlMjBmaXJzdCUyMHNlcXVlbmNlJTIwJTIwJTIwJTIwJTdDJTIwc2Vjb25kJTIwc2VxdWVuY2UlMjAlN0M=",highlighted:`0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 0 </span>0<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1<span class="hljs-number"> 1 </span>1 1
| first sequence    | second sequence |`,wrap:!1}}),{c(){i=l("p"),i.textContent=w,d=a(),g(c.$$.fragment)},l(r){i=p(r,"P",{"data-svelte-h":!0}),_(i)!=="svelte-16klr56"&&(i.textContent=w),d=o(r),k(c.$$.fragment,r)},m(r,x){m(r,i,x),m(r,d,x),h(c,r,x),f=!0},p:Ye,i(r){f||($(c.$$.fragment,r),f=!0)},o(r){v(c.$$.fragment,r),f=!1},d(r){r&&(n(i),n(d)),b(c,r)}}}function Tt(D){let i,w,d,c,f,r,x,he,G,Re=`CPM モデルは、Zhengyan Zhang、Xu Han、Hao Zhou、Pei Ke、Yuxian Gu によって <a href="https://arxiv.org/abs/2012.00413" rel="nofollow">CPM: A Large-scale Generative Chinese Pre-trained Language Model</a> で提案されました。葉徳明、秦裕佳、
Yusheng Su、Haozhe Ji、Jian Guan、Fanchao Qi、Xiaozi Wang、Yanan Zheng、Guoyang Zeng、Huanqi Cao、Shengqi Chen、
Daixuan Li、Zhenbo Sun、Zhiyuan Liu、Minlie Huang、Wentao Han、Jie Tang、Juanzi Li、Xiaoyan Zhu、Maosong Sun。`,$e,O,Ke="論文の要約は次のとおりです。",ve,S,et=`<em>事前トレーニングされた言語モデル (PLM) は、さまざまな下流の NLP タスクに有益であることが証明されています。最近ではGPT-3、
1,750億個のパラメータと570GBの学習データを備え、数回の撮影（1枚でも）の容量で大きな注目を集めました
ゼロショット）学習。ただし、GPT-3 を適用して中国語の NLP タスクに対処することは依然として困難です。
GPT-3 の言語は主に英語であり、パラメーターは公開されていません。この技術レポートでは、
大規模な中国語トレーニング データに対する生成的事前トレーニングを備えた中国語事前トレーニング済み言語モデル (CPM)。最高に
私たちの知識の限りでは、26 億のパラメータと 100GB の中国語トレーニング データを備えた CPM は、事前トレーニングされた中国語としては最大のものです。
言語モデルは、会話、エッセイの作成、
クローゼテストと言語理解。広範な実験により、CPM が多くの環境で優れたパフォーマンスを達成できることが実証されています。
少数ショット (ゼロショットでも) 学習の設定での NLP タスク。</em>`,be,X,tt=`このモデルは <a href="https://huggingface.co/canwenxu" rel="nofollow">canwenxu</a> によって提供されました。オリジナルの実装が見つかります
ここ: <a href="https://github.com/TsinghuaAI/CPM-Generate" rel="nofollow">https://github.com/TsinghuaAI/CPM-Generate</a>`,xe,j,Ce,B,we,u,Q,qe,ae,nt="Runs pre-tokenization with Jieba segmentation tool. It is used in CPM models.",ze,y,Z,De,oe,st=`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An XLNet sequence has the following format:`,je,re,at="<li>single sequence: <code>X &lt;sep&gt; &lt;cls&gt;</code></li> <li>pair of sequences: <code>A &lt;sep&gt; B &lt;sep&gt; &lt;cls&gt;</code></li>",Ae,A,W,Je,ie,ot="Converts a sequence of tokens (strings for sub-words) in a single string.",He,M,Y,Ne,le,rt="Create a mask from the two sequences passed to be used in a sequence-pair classification task. An XLNet",Ee,J,Ue,pe,it="If <code>token_ids_1</code> is <code>None</code>, this method only returns the first portion of the mask (0s).",Fe,H,R,Ve,me,lt=`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer <code>prepare_for_model</code> method.`,Te,K,Me,T,ee,Ge,ce,pt="Runs pre-tokenization with Jieba segmentation tool. It is used in CPM models.",Oe,P,te,Se,de,mt=`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. An XLNet sequence has the following format:`,Xe,_e,ct="<li>single sequence: <code>X &lt;sep&gt; &lt;cls&gt;</code></li> <li>pair of sequences: <code>A &lt;sep&gt; B &lt;sep&gt; &lt;cls&gt;</code></li>",Be,L,ne,Qe,fe,dt="Create a mask from the two sequences passed to be used in a sequence-pair classification task. An XLNet",Ze,N,We,ue,_t="If <code>token_ids_1</code> is <code>None</code>, this method only returns the first portion of the mask (0s).",Le,ke,ye;return f=new Ie({props:{title:"CPM",local:"cpm",headingTag:"h1"}}),x=new Ie({props:{title:"Overview",local:"overview",headingTag:"h2"}}),j=new bt({props:{$$slots:{default:[xt]},$$scope:{ctx:D}}}),B=new Ie({props:{title:"CpmTokenizer",local:"transformers.CpmTokenizer",headingTag:"h2"}}),Q=new V({props:{name:"class transformers.CpmTokenizer",anchor:"transformers.CpmTokenizer",parameters:[{name:"vocab_file",val:""},{name:"do_lower_case",val:" = False"},{name:"remove_space",val:" = True"},{name:"keep_accents",val:" = False"},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"unk_token",val:" = '<unk>'"},{name:"sep_token",val:" = '<sep>'"},{name:"pad_token",val:" = '<pad>'"},{name:"cls_token",val:" = '<cls>'"},{name:"mask_token",val:" = '<mask>'"},{name:"additional_special_tokens",val:" = ['<eop>', '<eod>']"},{name:"sp_model_kwargs",val:": Optional = None"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm.py#L38"}}),Z=new V({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.CpmTokenizer.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.CpmTokenizer.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added.`,name:"token_ids_0"},{anchor:"transformers.CpmTokenizer.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm.py#L245",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),W=new V({props:{name:"convert_tokens_to_string",anchor:"transformers.CpmTokenizer.convert_tokens_to_string",parameters:[{name:"tokens",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm.py#L239"}}),Y=new V({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.CpmTokenizer.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.CpmTokenizer.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.CpmTokenizer.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm.py#L300",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>List of <a href="../glossary#token-type-ids">token type IDs</a> according to the given sequence(s).</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),J=new ft({props:{anchor:"transformers.CpmTokenizer.create_token_type_ids_from_sequences.example",$$slots:{default:[Ct]},$$scope:{ctx:D}}}),R=new V({props:{name:"get_special_tokens_mask",anchor:"transformers.CpmTokenizer.get_special_tokens_mask",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": Optional = None"},{name:"already_has_special_tokens",val:": bool = False"}],parametersDescription:[{anchor:"transformers.CpmTokenizer.get_special_tokens_mask.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.CpmTokenizer.get_special_tokens_mask.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"},{anchor:"transformers.CpmTokenizer.get_special_tokens_mask.already_has_special_tokens",description:`<strong>already_has_special_tokens</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the token list is already formatted with special tokens for the model.`,name:"already_has_special_tokens"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm.py#L271",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),K=new Ie({props:{title:"CpmTokenizerFast",local:"transformers.CpmTokenizerFast",headingTag:"h2"}}),ee=new V({props:{name:"class transformers.CpmTokenizerFast",anchor:"transformers.CpmTokenizerFast",parameters:[{name:"vocab_file",val:" = None"},{name:"tokenizer_file",val:" = None"},{name:"do_lower_case",val:" = False"},{name:"remove_space",val:" = True"},{name:"keep_accents",val:" = False"},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"unk_token",val:" = '<unk>'"},{name:"sep_token",val:" = '<sep>'"},{name:"pad_token",val:" = '<pad>'"},{name:"cls_token",val:" = '<cls>'"},{name:"mask_token",val:" = '<mask>'"},{name:"additional_special_tokens",val:" = ['<eop>', '<eod>']"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm_fast.py#L38"}}),te=new V({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.CpmTokenizerFast.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.CpmTokenizerFast.build_inputs_with_special_tokens.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs to which the special tokens will be added.`,name:"token_ids_0"},{anchor:"transformers.CpmTokenizerFast.build_inputs_with_special_tokens.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm_fast.py#L160",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>List of <a href="../glossary#input-ids">input IDs</a> with the appropriate special tokens.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),ne=new V({props:{name:"create_token_type_ids_from_sequences",anchor:"transformers.CpmTokenizerFast.create_token_type_ids_from_sequences",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.CpmTokenizerFast.create_token_type_ids_from_sequences.token_ids_0",description:`<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014;
List of IDs.`,name:"token_ids_0"},{anchor:"transformers.CpmTokenizerFast.create_token_type_ids_from_sequences.token_ids_1",description:`<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014;
Optional second list of IDs for sequence pairs.`,name:"token_ids_1"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpm/tokenization_cpm_fast.py#L186",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>List of <a href="../glossary#token-type-ids">token type IDs</a> according to the given sequence(s).</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),N=new ft({props:{anchor:"transformers.CpmTokenizerFast.create_token_type_ids_from_sequences.example",$$slots:{default:[wt]},$$scope:{ctx:D}}}),{c(){i=l("meta"),w=a(),d=l("p"),c=a(),g(f.$$.fragment),r=a(),g(x.$$.fragment),he=a(),G=l("p"),G.innerHTML=Re,$e=a(),O=l("p"),O.textContent=Ke,ve=a(),S=l("p"),S.innerHTML=et,be=a(),X=l("p"),X.innerHTML=tt,xe=a(),g(j.$$.fragment),Ce=a(),g(B.$$.fragment),we=a(),u=l("div"),g(Q.$$.fragment),qe=a(),ae=l("p"),ae.textContent=nt,ze=a(),y=l("div"),g(Z.$$.fragment),De=a(),oe=l("p"),oe.textContent=st,je=a(),re=l("ul"),re.innerHTML=at,Ae=a(),A=l("div"),g(W.$$.fragment),Je=a(),ie=l("p"),ie.textContent=ot,He=a(),M=l("div"),g(Y.$$.fragment),Ne=a(),le=l("p"),le.textContent=rt,Ee=a(),g(J.$$.fragment),Ue=a(),pe=l("p"),pe.innerHTML=it,Fe=a(),H=l("div"),g(R.$$.fragment),Ve=a(),me=l("p"),me.innerHTML=lt,Te=a(),g(K.$$.fragment),Me=a(),T=l("div"),g(ee.$$.fragment),Ge=a(),ce=l("p"),ce.textContent=pt,Oe=a(),P=l("div"),g(te.$$.fragment),Se=a(),de=l("p"),de.textContent=mt,Xe=a(),_e=l("ul"),_e.innerHTML=ct,Be=a(),L=l("div"),g(ne.$$.fragment),Qe=a(),fe=l("p"),fe.textContent=dt,Ze=a(),g(N.$$.fragment),We=a(),ue=l("p"),ue.innerHTML=_t,Le=a(),ke=l("p"),this.h()},l(e){const s=vt("svelte-u9bgzb",document.head);i=p(s,"META",{name:!0,content:!0}),s.forEach(n),w=o(e),d=p(e,"P",{}),I(d).forEach(n),c=o(e),k(f.$$.fragment,e),r=o(e),k(x.$$.fragment,e),he=o(e),G=p(e,"P",{"data-svelte-h":!0}),_(G)!=="svelte-1xt3ugf"&&(G.innerHTML=Re),$e=o(e),O=p(e,"P",{"data-svelte-h":!0}),_(O)!=="svelte-1cv3nri"&&(O.textContent=Ke),ve=o(e),S=p(e,"P",{"data-svelte-h":!0}),_(S)!=="svelte-7anbpp"&&(S.innerHTML=et),be=o(e),X=p(e,"P",{"data-svelte-h":!0}),_(X)!=="svelte-16rqoku"&&(X.innerHTML=tt),xe=o(e),k(j.$$.fragment,e),Ce=o(e),k(B.$$.fragment,e),we=o(e),u=p(e,"DIV",{class:!0});var C=I(u);k(Q.$$.fragment,C),qe=o(C),ae=p(C,"P",{"data-svelte-h":!0}),_(ae)!=="svelte-ejpd0l"&&(ae.textContent=nt),ze=o(C),y=p(C,"DIV",{class:!0});var z=I(y);k(Z.$$.fragment,z),De=o(z),oe=p(z,"P",{"data-svelte-h":!0}),_(oe)!=="svelte-1dgk30w"&&(oe.textContent=st),je=o(z),re=p(z,"UL",{"data-svelte-h":!0}),_(re)!=="svelte-zi1mnq"&&(re.innerHTML=at),z.forEach(n),Ae=o(C),A=p(C,"DIV",{class:!0});var se=I(A);k(W.$$.fragment,se),Je=o(se),ie=p(se,"P",{"data-svelte-h":!0}),_(ie)!=="svelte-1ne8awa"&&(ie.textContent=ot),se.forEach(n),He=o(C),M=p(C,"DIV",{class:!0});var E=I(M);k(Y.$$.fragment,E),Ne=o(E),le=p(E,"P",{"data-svelte-h":!0}),_(le)!=="svelte-1nwvqaq"&&(le.textContent=rt),Ee=o(E),k(J.$$.fragment,E),Ue=o(E),pe=p(E,"P",{"data-svelte-h":!0}),_(pe)!=="svelte-owoxgn"&&(pe.innerHTML=it),E.forEach(n),Fe=o(C),H=p(C,"DIV",{class:!0});var Pe=I(H);k(R.$$.fragment,Pe),Ve=o(Pe),me=p(Pe,"P",{"data-svelte-h":!0}),_(me)!=="svelte-1f4f5kp"&&(me.innerHTML=lt),Pe.forEach(n),C.forEach(n),Te=o(e),k(K.$$.fragment,e),Me=o(e),T=p(e,"DIV",{class:!0});var U=I(T);k(ee.$$.fragment,U),Ge=o(U),ce=p(U,"P",{"data-svelte-h":!0}),_(ce)!=="svelte-ejpd0l"&&(ce.textContent=pt),Oe=o(U),P=p(U,"DIV",{class:!0});var ge=I(P);k(te.$$.fragment,ge),Se=o(ge),de=p(ge,"P",{"data-svelte-h":!0}),_(de)!=="svelte-1dgk30w"&&(de.textContent=mt),Xe=o(ge),_e=p(ge,"UL",{"data-svelte-h":!0}),_(_e)!=="svelte-zi1mnq"&&(_e.innerHTML=ct),ge.forEach(n),Be=o(U),L=p(U,"DIV",{class:!0});var F=I(L);k(ne.$$.fragment,F),Qe=o(F),fe=p(F,"P",{"data-svelte-h":!0}),_(fe)!=="svelte-1nwvqaq"&&(fe.textContent=dt),Ze=o(F),k(N.$$.fragment,F),We=o(F),ue=p(F,"P",{"data-svelte-h":!0}),_(ue)!=="svelte-owoxgn"&&(ue.innerHTML=_t),F.forEach(n),U.forEach(n),Le=o(e),ke=p(e,"P",{}),I(ke).forEach(n),this.h()},h(){q(i,"name","hf:doc:metadata"),q(i,"content",Mt),q(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(u,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),q(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,s){t(document.head,i),m(e,w,s),m(e,d,s),m(e,c,s),h(f,e,s),m(e,r,s),h(x,e,s),m(e,he,s),m(e,G,s),m(e,$e,s),m(e,O,s),m(e,ve,s),m(e,S,s),m(e,be,s),m(e,X,s),m(e,xe,s),h(j,e,s),m(e,Ce,s),h(B,e,s),m(e,we,s),m(e,u,s),h(Q,u,null),t(u,qe),t(u,ae),t(u,ze),t(u,y),h(Z,y,null),t(y,De),t(y,oe),t(y,je),t(y,re),t(u,Ae),t(u,A),h(W,A,null),t(A,Je),t(A,ie),t(u,He),t(u,M),h(Y,M,null),t(M,Ne),t(M,le),t(M,Ee),h(J,M,null),t(M,Ue),t(M,pe),t(u,Fe),t(u,H),h(R,H,null),t(H,Ve),t(H,me),m(e,Te,s),h(K,e,s),m(e,Me,s),m(e,T,s),h(ee,T,null),t(T,Ge),t(T,ce),t(T,Oe),t(T,P),h(te,P,null),t(P,Se),t(P,de),t(P,Xe),t(P,_e),t(T,Be),t(T,L),h(ne,L,null),t(L,Qe),t(L,fe),t(L,Ze),h(N,L,null),t(L,We),t(L,ue),m(e,Le,s),m(e,ke,s),ye=!0},p(e,[s]){const C={};s&2&&(C.$$scope={dirty:s,ctx:e}),j.$set(C);const z={};s&2&&(z.$$scope={dirty:s,ctx:e}),J.$set(z);const se={};s&2&&(se.$$scope={dirty:s,ctx:e}),N.$set(se)},i(e){ye||($(f.$$.fragment,e),$(x.$$.fragment,e),$(j.$$.fragment,e),$(B.$$.fragment,e),$(Q.$$.fragment,e),$(Z.$$.fragment,e),$(W.$$.fragment,e),$(Y.$$.fragment,e),$(J.$$.fragment,e),$(R.$$.fragment,e),$(K.$$.fragment,e),$(ee.$$.fragment,e),$(te.$$.fragment,e),$(ne.$$.fragment,e),$(N.$$.fragment,e),ye=!0)},o(e){v(f.$$.fragment,e),v(x.$$.fragment,e),v(j.$$.fragment,e),v(B.$$.fragment,e),v(Q.$$.fragment,e),v(Z.$$.fragment,e),v(W.$$.fragment,e),v(Y.$$.fragment,e),v(J.$$.fragment,e),v(R.$$.fragment,e),v(K.$$.fragment,e),v(ee.$$.fragment,e),v(te.$$.fragment,e),v(ne.$$.fragment,e),v(N.$$.fragment,e),ye=!1},d(e){e&&(n(w),n(d),n(c),n(r),n(he),n(G),n($e),n(O),n(ve),n(S),n(be),n(X),n(xe),n(Ce),n(we),n(u),n(Te),n(Me),n(T),n(Le),n(ke)),n(i),b(f,e),b(x,e),b(j,e),b(B,e),b(Q),b(Z),b(W),b(Y),b(J),b(R),b(K,e),b(ee),b(te),b(ne),b(N)}}}const Mt='{"title":"CPM","local":"cpm","sections":[{"title":"Overview","local":"overview","sections":[],"depth":2},{"title":"CpmTokenizer","local":"transformers.CpmTokenizer","sections":[],"depth":2},{"title":"CpmTokenizerFast","local":"transformers.CpmTokenizerFast","sections":[],"depth":2}],"depth":1}';function Lt(D){return kt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class At extends ht{constructor(i){super(),$t(this,i,Lt,Tt,gt,{})}}export{At as component};
