import{s as qt,o as At,n as Qt}from"../chunks/scheduler.9bc65507.js";import{S as Nt,i as Yt,g as p,s as a,r as o,A as Et,h as i,f as e,c as n,j as zt,u as d,x as r,k as Ft,y as Kt,a as l,v as c,d as f,t as h,w as y}from"../chunks/index.707bf1b6.js";import{T as Dt}from"../chunks/Tip.c2ecdbf4.js";import{C as w}from"../chunks/CodeBlock.54a9f38d.js";import{H as Ut}from"../chunks/Heading.342b1fa6.js";function Ot(Y){let m,_="ランダムに作成されたモデルは、メモリ内に「空の」テンソルで初期化されます。これらのランダムな値は、メモリの特定のチャンクにあったものを使用します（したがって、ランダムな値はその時点でのメモリチャンク内の値です）。モデル/パラメータの種類に適した分布（たとえば、正規分布）に従うランダムな初期化は、ステップ3で初期化されていない重みに対して、できるだけ高速に実行されます！";return{c(){m=p("p"),m.textContent=_},l(M){m=i(M,"P",{"data-svelte-h":!0}),r(m)!=="svelte-qbck2l"&&(m.textContent=_)},m(M,Q){l(M,m,Q)},p:Qt,d(M){M&&e(m)}}}function ts(Y){let m,_,M,Q,g,E,$,Ct="非常に大規模な事前学習済みモデルを使用する場合、RAMの使用量を最小限に抑えることは課題の1つです。通常のPyTorchのワークフローは次のとおりです：",K,b,Tt="<li>ランダムな重みを持つモデルを作成します。</li> <li>事前学習済みの重みをロードします。</li> <li>これらの事前学習済みの重みをランダムなモデルに配置します。</li>",D,u,vt="ステップ1と2の両方がメモリにモデルの完全なバージョンを必要とし、ほとんどの場合は問題ありませんが、モデルのサイズが数ギガバイトになると、これらの2つのコピーをRAMから排除することができなくなる可能性があります。さらに悪いことに、分散トレーニングを実行するために<code>torch.distributed</code>を使用している場合、各プロセスは事前学習済みモデルをロードし、これらの2つのコピーをRAMに保存します。",O,j,tt,x,kt="このガイドでは、Transformersがこの問題に対処するために提供するソリューションを探ります。なお、これは現在も開発が進行中の分野であり、将来、ここで説明されているAPIがわずかに変更される可能性があることに注意してください。",st,U,et,C,Jt="バージョン4.18.0から、10GBを超えるサイズのモデルチェックポイントは自動的に複数の小さな部分に分割されます。<code>model.save_pretrained(save_dir)</code>を実行する際に1つの単一のチェックポイントを持つ代わりに、いくつかの部分的なチェックポイント（それぞれのサイズが&lt;10GB）と、パラメータ名をそれらが格納されているファイルにマップするインデックスが生成されます。",lt,T,Zt="<code>max_shard_size</code>パラメータでシャーディング前の最大サイズを制御できるため、例として通常サイズのモデルと小さなシャードサイズを使用します。従来のBERTモデルを使用してみましょう。",at,v,nt,k,Bt='もし<a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.save_pretrained">save_pretrained()</a>を使用して保存する場合、新しいフォルダが2つのファイルを含む形で作成されます: モデルの設定情報とその重み情報です。',pt,J,it,Z,Rt="最大シャードサイズを200MBに設定します：",mt,B,rt,R,Gt=`モデルの設定の上に、3つの異なる重みファイルと、<code>index.json</code>ファイルが見られます。これは私たちのインデックスです。
このようなチェックポイントは、<a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>メソッドを使用して完全に再ロードできます：`,ot,G,dt,X,Xt="主要な利点は、大規模なモデルの場合、上記のワークフローのステップ2において、各チェックポイントのシャードが前のシャードの後にロードされ、RAMのメモリ使用量をモデルのサイズと最大のシャードのサイズを合わせたものに制限できることです。",ct,I,It="内部では、インデックスファイルが使用され、どのキーがチェックポイントに存在し、対応する重みがどこに格納されているかを判断します。このインデックスは通常のJSONファイルのように読み込むことができ、辞書として取得できます。",ft,H,ht,S,Ht=`メタデータには現時点ではモデルの総サイズのみが含まれています。
将来的には他の情報を追加する予定です：`,yt,W,Mt,L,St="重みマップはこのインデックスの主要な部分であり、各パラメータ名（通常はPyTorchモデルの<code>state_dict</code>で見つかるもの）をその格納されているファイルにマップします：",jt,P,wt,V,Wt=`直接モデル内で<a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>を使用せずに、
シャーディングされたチェックポイントをロードしたい場合（フルチェックポイントの場合に<code>model.load_state_dict()</code>を使用するように行う方法）、<a href="/docs/transformers/main/ja/main_classes/model#transformers.modeling_utils.load_sharded_checkpoint">load_sharded_checkpoint()</a>を使用する必要があります：`,_t,z,gt,F,$t,q,Lt=`シャードされたチェックポイントは、上記のワークフローのステップ2におけるメモリ使用量を削減しますが、
低メモリの環境でそのモデルを使用するために、Accelerateライブラリに基づいた当社のツールを活用することをお勧めします。`,bt,A,Pt='詳細については、以下のガイドをご覧ください：<a href="./main_classes/model#large-model-loading">Accelerateを使用した大規模モデルの読み込み</a>',ut,N,xt;return g=new Ut({props:{title:"Instantiating a big model",local:"instantiating-a-big-model",headingTag:"h1"}}),j=new Dt({props:{$$slots:{default:[Ot]},$$scope:{ctx:Y}}}),U=new Ut({props:{title:"Sharded checkpoints",local:"sharded-checkpoints",headingTag:"h2"}}),v=new w({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS1jYXNlZCUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

model = AutoModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)`,wrap:!1}}),J=new w({props:{code:"aW1wb3J0JTIwb3MlMEFpbXBvcnQlMjB0ZW1wZmlsZSUwQSUwQXdpdGglMjB0ZW1wZmlsZS5UZW1wb3JhcnlEaXJlY3RvcnkoKSUyMGFzJTIwdG1wX2RpciUzQSUwQSUyMCUyMCUyMCUyMG1vZGVsLnNhdmVfcHJldHJhaW5lZCh0bXBfZGlyKSUwQSUyMCUyMCUyMCUyMHByaW50KHNvcnRlZChvcy5saXN0ZGlyKHRtcF9kaXIpKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tempfile

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir)
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(os.listdir(tmp_dir)))
[<span class="hljs-string">&#x27;config.json&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model.bin&#x27;</span>]`,wrap:!1}}),B=new w({props:{code:"d2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjIwME1CJTIyKSUwQSUyMCUyMCUyMCUyMHByaW50KHNvcnRlZChvcy5saXN0ZGlyKHRtcF9kaXIpKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(os.listdir(tmp_dir)))
[<span class="hljs-string">&#x27;config.json&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model-00001-of-00003.bin&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model-00002-of-00003.bin&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model-00003-of-00003.bin&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model.bin.index.json&#x27;</span>]`,wrap:!1}}),G=new w({props:{code:"d2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjIwME1CJTIyKSUwQSUyMCUyMCUyMCUyMG5ld19tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbC5mcm9tX3ByZXRyYWluZWQodG1wX2Rpcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    new_model = AutoModel.from_pretrained(tmp_dir)`,wrap:!1}}),H=new w({props:{code:"aW1wb3J0JTIwanNvbiUwQSUwQXdpdGglMjB0ZW1wZmlsZS5UZW1wb3JhcnlEaXJlY3RvcnkoKSUyMGFzJTIwdG1wX2RpciUzQSUwQSUyMCUyMCUyMCUyMG1vZGVsLnNhdmVfcHJldHJhaW5lZCh0bXBfZGlyJTJDJTIwbWF4X3NoYXJkX3NpemUlM0QlMjIyMDBNQiUyMiklMEElMjAlMjAlMjAlMjB3aXRoJTIwb3Blbihvcy5wYXRoLmpvaW4odG1wX2RpciUyQyUyMCUyMnB5dG9yY2hfbW9kZWwuYmluLmluZGV4Lmpzb24lMjIpJTJDJTIwJTIyciUyMiklMjBhcyUyMGYlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBpbmRleCUyMCUzRCUyMGpzb24ubG9hZChmKSUwQSUwQXByaW50KGluZGV4LmtleXMoKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> json

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(tmp_dir, <span class="hljs-string">&quot;pytorch_model.bin.index.json&quot;</span>), <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>        index = json.load(f)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(index.keys())
dict_keys([<span class="hljs-string">&#x27;metadata&#x27;</span>, <span class="hljs-string">&#x27;weight_map&#x27;</span>])`,wrap:!1}}),W=new w({props:{code:"aW5kZXglNUIlMjJtZXRhZGF0YSUyMiU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>index[<span class="hljs-string">&quot;metadata&quot;</span>]
{<span class="hljs-string">&#x27;total_size&#x27;</span>: <span class="hljs-number">433245184</span>}`,wrap:!1}}),P=new w({props:{code:"aW5kZXglNUIlMjJ3ZWlnaHRfbWFwJTIyJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>index[<span class="hljs-string">&quot;weight_map&quot;</span>]
{<span class="hljs-string">&#x27;embeddings.LayerNorm.bias&#x27;</span>: <span class="hljs-string">&#x27;pytorch_model-00001-of-00003.bin&#x27;</span>,
 <span class="hljs-string">&#x27;embeddings.LayerNorm.weight&#x27;</span>: <span class="hljs-string">&#x27;pytorch_model-00001-of-00003.bin&#x27;</span>,
 ...`,wrap:!1}}),z=new w({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbGluZ191dGlscyUyMGltcG9ydCUyMGxvYWRfc2hhcmRlZF9jaGVja3BvaW50JTBBJTBBd2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjIwME1CJTIyKSUwQSUyMCUyMCUyMCUyMGxvYWRfc2hhcmRlZF9jaGVja3BvaW50KG1vZGVsJTJDJTIwdG1wX2Rpcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.modeling_utils <span class="hljs-keyword">import</span> load_sharded_checkpoint

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    load_sharded_checkpoint(model, tmp_dir)`,wrap:!1}}),F=new Ut({props:{title:"Low memory loading",local:"low-memory-loading",headingTag:"h2"}}),{c(){m=p("meta"),_=a(),M=p("p"),Q=a(),o(g.$$.fragment),E=a(),$=p("p"),$.textContent=Ct,K=a(),b=p("ol"),b.innerHTML=Tt,D=a(),u=p("p"),u.innerHTML=vt,O=a(),o(j.$$.fragment),tt=a(),x=p("p"),x.textContent=kt,st=a(),o(U.$$.fragment),et=a(),C=p("p"),C.innerHTML=Jt,lt=a(),T=p("p"),T.innerHTML=Zt,at=a(),o(v.$$.fragment),nt=a(),k=p("p"),k.innerHTML=Bt,pt=a(),o(J.$$.fragment),it=a(),Z=p("p"),Z.textContent=Rt,mt=a(),o(B.$$.fragment),rt=a(),R=p("p"),R.innerHTML=Gt,ot=a(),o(G.$$.fragment),dt=a(),X=p("p"),X.textContent=Xt,ct=a(),I=p("p"),I.textContent=It,ft=a(),o(H.$$.fragment),ht=a(),S=p("p"),S.textContent=Ht,yt=a(),o(W.$$.fragment),Mt=a(),L=p("p"),L.innerHTML=St,jt=a(),o(P.$$.fragment),wt=a(),V=p("p"),V.innerHTML=Wt,_t=a(),o(z.$$.fragment),gt=a(),o(F.$$.fragment),$t=a(),q=p("p"),q.textContent=Lt,bt=a(),A=p("p"),A.innerHTML=Pt,ut=a(),N=p("p"),this.h()},l(t){const s=Et("svelte-u9bgzb",document.head);m=i(s,"META",{name:!0,content:!0}),s.forEach(e),_=n(t),M=i(t,"P",{}),zt(M).forEach(e),Q=n(t),d(g.$$.fragment,t),E=n(t),$=i(t,"P",{"data-svelte-h":!0}),r($)!=="svelte-1ohy6fz"&&($.textContent=Ct),K=n(t),b=i(t,"OL",{"data-svelte-h":!0}),r(b)!=="svelte-63ajfg"&&(b.innerHTML=Tt),D=n(t),u=i(t,"P",{"data-svelte-h":!0}),r(u)!=="svelte-vzt1dk"&&(u.innerHTML=vt),O=n(t),d(j.$$.fragment,t),tt=n(t),x=i(t,"P",{"data-svelte-h":!0}),r(x)!=="svelte-6plqs6"&&(x.textContent=kt),st=n(t),d(U.$$.fragment,t),et=n(t),C=i(t,"P",{"data-svelte-h":!0}),r(C)!=="svelte-z76oid"&&(C.innerHTML=Jt),lt=n(t),T=i(t,"P",{"data-svelte-h":!0}),r(T)!=="svelte-1sj6luw"&&(T.innerHTML=Zt),at=n(t),d(v.$$.fragment,t),nt=n(t),k=i(t,"P",{"data-svelte-h":!0}),r(k)!=="svelte-1gob20u"&&(k.innerHTML=Bt),pt=n(t),d(J.$$.fragment,t),it=n(t),Z=i(t,"P",{"data-svelte-h":!0}),r(Z)!=="svelte-9p05eq"&&(Z.textContent=Rt),mt=n(t),d(B.$$.fragment,t),rt=n(t),R=i(t,"P",{"data-svelte-h":!0}),r(R)!=="svelte-66fjk2"&&(R.innerHTML=Gt),ot=n(t),d(G.$$.fragment,t),dt=n(t),X=i(t,"P",{"data-svelte-h":!0}),r(X)!=="svelte-3gy4l0"&&(X.textContent=Xt),ct=n(t),I=i(t,"P",{"data-svelte-h":!0}),r(I)!=="svelte-6bnz20"&&(I.textContent=It),ft=n(t),d(H.$$.fragment,t),ht=n(t),S=i(t,"P",{"data-svelte-h":!0}),r(S)!=="svelte-1u7xh92"&&(S.textContent=Ht),yt=n(t),d(W.$$.fragment,t),Mt=n(t),L=i(t,"P",{"data-svelte-h":!0}),r(L)!=="svelte-pi5r2w"&&(L.innerHTML=St),jt=n(t),d(P.$$.fragment,t),wt=n(t),V=i(t,"P",{"data-svelte-h":!0}),r(V)!=="svelte-19esqp9"&&(V.innerHTML=Wt),_t=n(t),d(z.$$.fragment,t),gt=n(t),d(F.$$.fragment,t),$t=n(t),q=i(t,"P",{"data-svelte-h":!0}),r(q)!=="svelte-1bp1ma3"&&(q.textContent=Lt),bt=n(t),A=i(t,"P",{"data-svelte-h":!0}),r(A)!=="svelte-1hzfpqz"&&(A.innerHTML=Pt),ut=n(t),N=i(t,"P",{}),zt(N).forEach(e),this.h()},h(){Ft(m,"name","hf:doc:metadata"),Ft(m,"content",ss)},m(t,s){Kt(document.head,m),l(t,_,s),l(t,M,s),l(t,Q,s),c(g,t,s),l(t,E,s),l(t,$,s),l(t,K,s),l(t,b,s),l(t,D,s),l(t,u,s),l(t,O,s),c(j,t,s),l(t,tt,s),l(t,x,s),l(t,st,s),c(U,t,s),l(t,et,s),l(t,C,s),l(t,lt,s),l(t,T,s),l(t,at,s),c(v,t,s),l(t,nt,s),l(t,k,s),l(t,pt,s),c(J,t,s),l(t,it,s),l(t,Z,s),l(t,mt,s),c(B,t,s),l(t,rt,s),l(t,R,s),l(t,ot,s),c(G,t,s),l(t,dt,s),l(t,X,s),l(t,ct,s),l(t,I,s),l(t,ft,s),c(H,t,s),l(t,ht,s),l(t,S,s),l(t,yt,s),c(W,t,s),l(t,Mt,s),l(t,L,s),l(t,jt,s),c(P,t,s),l(t,wt,s),l(t,V,s),l(t,_t,s),c(z,t,s),l(t,gt,s),c(F,t,s),l(t,$t,s),l(t,q,s),l(t,bt,s),l(t,A,s),l(t,ut,s),l(t,N,s),xt=!0},p(t,[s]){const Vt={};s&2&&(Vt.$$scope={dirty:s,ctx:t}),j.$set(Vt)},i(t){xt||(f(g.$$.fragment,t),f(j.$$.fragment,t),f(U.$$.fragment,t),f(v.$$.fragment,t),f(J.$$.fragment,t),f(B.$$.fragment,t),f(G.$$.fragment,t),f(H.$$.fragment,t),f(W.$$.fragment,t),f(P.$$.fragment,t),f(z.$$.fragment,t),f(F.$$.fragment,t),xt=!0)},o(t){h(g.$$.fragment,t),h(j.$$.fragment,t),h(U.$$.fragment,t),h(v.$$.fragment,t),h(J.$$.fragment,t),h(B.$$.fragment,t),h(G.$$.fragment,t),h(H.$$.fragment,t),h(W.$$.fragment,t),h(P.$$.fragment,t),h(z.$$.fragment,t),h(F.$$.fragment,t),xt=!1},d(t){t&&(e(_),e(M),e(Q),e(E),e($),e(K),e(b),e(D),e(u),e(O),e(tt),e(x),e(st),e(et),e(C),e(lt),e(T),e(at),e(nt),e(k),e(pt),e(it),e(Z),e(mt),e(rt),e(R),e(ot),e(dt),e(X),e(ct),e(I),e(ft),e(ht),e(S),e(yt),e(Mt),e(L),e(jt),e(wt),e(V),e(_t),e(gt),e($t),e(q),e(bt),e(A),e(ut),e(N)),e(m),y(g,t),y(j,t),y(U,t),y(v,t),y(J,t),y(B,t),y(G,t),y(H,t),y(W,t),y(P,t),y(z,t),y(F,t)}}}const ss='{"title":"Instantiating a big model","local":"instantiating-a-big-model","sections":[{"title":"Sharded checkpoints","local":"sharded-checkpoints","sections":[],"depth":2},{"title":"Low memory loading","local":"low-memory-loading","sections":[],"depth":2}],"depth":1}';function es(Y){return At(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ms extends Nt{constructor(m){super(),Yt(this,m,es,ts,qt,{})}}export{ms as component};
