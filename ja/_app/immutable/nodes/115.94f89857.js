import{s as Os,o as ea,n as Ut}from"../chunks/scheduler.9bc65507.js";import{S as ta,i as la,g as i,s,r,A as na,h as o,f as l,c as a,j as Ds,u as f,x as p,k as Ks,l as kn,y as sa,a as n,v as d,d as u,t as b,w as T}from"../chunks/index.707bf1b6.js";import{T as xt}from"../chunks/Tip.c2ecdbf4.js";import{C as $}from"../chunks/CodeBlock.54a9f38d.js";import{H as c}from"../chunks/Heading.342b1fa6.js";function aa(w){let m,y="ã“ã®æ©Ÿèƒ½ã¯å®Ÿé¨“çš„ã§ã‚ã‚Šã€å°†æ¥ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å¤§å¹…ã«å¤‰æ›´ã•ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãŸã¨ãˆã°ã€Flash Attention 2 APIã¯è¿‘ã„å°†æ¥<code>BetterTransformer</code> APIã«ç§»è¡Œã™ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚";return{c(){m=i("p"),m.innerHTML=y},l(M){m=o(M,"P",{"data-svelte-h":!0}),p(m)!=="svelte-7uacjn"&&(m.innerHTML=y)},m(M,J){n(M,m,J)},p:Ut,d(M){M&&l(m)}}}function ia(w){let m,y="Flash Attention 2ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®dtypeãŒ<code>fp16</code>ã¾ãŸã¯<code>bf16</code>ã®å ´åˆã«ã®ã¿ä½¿ç”¨ã§ãã€NVIDIA-GPUãƒ‡ãƒã‚¤ã‚¹ã§ã®ã¿å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆ‡ãªdtypeã«ã‚­ãƒ£ã‚¹ãƒˆã—ã€ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ‡ãƒã‚¤ã‚¹ã«ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚";return{c(){m=i("p"),m.innerHTML=y},l(M){m=o(M,"P",{"data-svelte-h":!0}),p(m)!=="svelte-1q0hw1w"&&(m.innerHTML=y)},m(M,J){n(M,m,J)},p:Ut,d(M){M&&l(m)}}}function oa(w){let m,y="Flash Attentionã¯ã€fp16ã¾ãŸã¯bf16ã®dtypeã‚’ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã«ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚BetterTransformerã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€ãƒ¢ãƒ‡ãƒ«ã‚’é©åˆ‡ãªdtypeã«ã‚­ãƒ£ã‚¹ãƒˆã—ã¦ãã ã•ã„ã€‚";return{c(){m=i("p"),m.textContent=y},l(M){m=o(M,"P",{"data-svelte-h":!0}),p(m)!=="svelte-8snhtv"&&(m.textContent=y)},m(M,J){n(M,m,J)},p:Ut,d(M){M&&l(m)}}}function pa(w){let m,y="Note that this feature can also be used in a multi GPU setup.",M,J,v="ã“ã®æ©Ÿèƒ½ã¯ã€ãƒãƒ«ãƒGPUã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã§ã‚‚ä½¿ç”¨ã§ãã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚";return{c(){m=i("p"),m.textContent=y,M=s(),J=i("p"),J.textContent=v},l(h){m=o(h,"P",{"data-svelte-h":!0}),p(m)!=="svelte-8elnl8"&&(m.textContent=y),M=a(h),J=o(h,"P",{"data-svelte-h":!0}),p(J)!=="svelte-1lcfhr2"&&(J.textContent=v)},m(h,g){n(h,m,g),n(h,M,g),n(h,J,g)},p:Ut,d(h){h&&(l(m),l(M),l(J))}}}function ma(w){let m,y="ã“ã®æ©Ÿèƒ½ã¯ã€ãƒãƒ«ãƒGPUç’°å¢ƒã§ã‚‚ä½¿ç”¨ã§ãã¾ã™ã€‚";return{c(){m=i("p"),m.textContent=y},l(M){m=o(M,"P",{"data-svelte-h":!0}),p(m)!=="svelte-dptqzr"&&(m.textContent=y)},m(M,J){n(M,m,J)},p:Ut,d(M){M&&l(m)}}}function ra(w){let m,y,M,J,v,h,g,Gn='ã“ã®ã‚¬ã‚¤ãƒ‰ã«åŠ ãˆã¦ã€<a href="perf_train_gpu_one">1ã¤ã®GPUã§ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰</a>ã¨<a href="perf_infer_cpu">CPUã§ã®æ¨è«–ã‚¬ã‚¤ãƒ‰</a>ã«é–¢é€£ã™ã‚‹æƒ…å ±ãŒã‚ã‚Šã¾ã™ã€‚',Wt,G,Zt,_,jt,I,In='Flash Attention 2ã¯ã€ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–é€Ÿåº¦ã‚’å¤§å¹…ã«é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚Flash Attention 2ã¯ã€Tri Daoæ°ã«ã‚ˆã£ã¦<a href="https://github.com/Dao-AILab/flash-attention" rel="nofollow">å…¬å¼ã®Flash Attentionãƒªãƒã‚¸ãƒˆãƒª</a>ã§å°å…¥ã•ã‚Œã¾ã—ãŸã€‚Flash Attentionã«é–¢ã™ã‚‹ç§‘å­¦è«–æ–‡ã¯<a href="https://arxiv.org/abs/2205.14135" rel="nofollow">ã“ã¡ã‚‰</a>ã§è¦‹ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚',Bt,F,Fn="Flash Attention 2ã‚’æ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯ã€ä¸Šè¨˜ã®ãƒªãƒã‚¸ãƒˆãƒªã«è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚¬ã‚¤ãƒ‰ã«å¾“ã£ã¦ãã ã•ã„ã€‚",kt,R,Rn="ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦Flash Attention 2ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š",Gt,X,Xn="<li>Llama</li> <li>Falcon</li>",It,V,Vn="ã•ã‚‰ã«å¤šãã®ãƒ¢ãƒ‡ãƒ«ã«Flash Attention 2ã®ã‚µãƒãƒ¼ãƒˆã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã‚’GitHubã§ææ¡ˆã™ã‚‹ã“ã¨ã‚‚ã§ãã€å¤‰æ›´ã‚’çµ±åˆã™ã‚‹ãŸã‚ã«ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é–‹ãã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å«ã‚€ã€æ¨è«–ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã§ãã¾ã™ï¼ˆç¾åœ¨ã®<code>BetterTransformer</code> APIã§ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ï¼‰ã€‚",Ft,C,Rt,H,Xt,L,Hn="ãƒ¢ãƒ‡ãƒ«ã§Flash Attention 2ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã«ã¯ã€<code>from_pretrained</code>ã®å¼•æ•°ã«<code>attn_implementation=&quot;flash_attention_2&quot;</code>ã‚’è¿½åŠ ã—ã¾ã™ã€‚",Vt,P,Ht,A,Ln="ã“ã¡ã‚‰ã¯ã€ç”Ÿæˆã¾ãŸã¯å¾®èª¿æ•´ã®ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã§ã™ã€‚",Lt,N,Pt,z,Pn="ç‰¹ã«é•·ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¯¾ã—ã¦ã€å¾®èª¿æ•´ã¨æ¨è«–ã®éš›ã«ã¯ã€ã‹ãªã‚Šã®é«˜é€ŸåŒ–ãŒæœŸå¾…ã§ãã¾ã™ã€‚ãŸã ã—ã€Flash Attentionã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã—ãªã„ãŸã‚ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ãŒå«ã¾ã‚Œã‚‹å ´åˆã€ãƒãƒƒãƒæ¨è«–ã«ãŠã„ã¦ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ‰‹å‹•ã§ãƒ‘ãƒƒãƒ‰/ã‚¢ãƒ³ãƒ‘ãƒƒãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€ãƒãƒƒãƒç”Ÿæˆã®å¤§å¹…ãªé…å»¶ãŒç™ºç”Ÿã—ã¾ã™ã€‚",At,q,An='ã“ã‚Œã‚’å…‹æœã™ã‚‹ãŸã‚ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã›ãšã«Flash Attentionã‚’ä½¿ç”¨ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ˆãŸã¨ãˆã°ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ‘ãƒƒã‚¯ã™ã‚‹ã“ã¨ã«ã‚ˆã‚Šã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’æœ€å¤§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«é”ã™ã‚‹ã¾ã§é€£çµã™ã‚‹ã“ã¨ãªã©ï¼‰ã€‚ã“ã“ã«<a href="https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_clm.py#L516" rel="nofollow">ä¾‹</a>ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚',Nt,E,Nn='ä»¥ä¸‹ã¯ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®ãªã„å ´åˆã«ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ãŒ4096ã®<a href="https://hf.co/tiiuae/falcon-7b" rel="nofollow">tiiuae/falcon-7b</a>ã«å¯¾ã™ã‚‹å˜ç´”ãªãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã®äºˆæƒ³ã•ã‚Œã‚‹é«˜é€ŸåŒ–ã§ã™ã€‚ã•ã¾ã–ã¾ãªãƒãƒƒãƒã‚µã‚¤ã‚ºãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ï¼š',zt,x,zn='<img src="https://huggingface.co/datasets/ybelkada/documentation-images/resolve/main/falcon-7b-inference-large-seqlen.png"/>',qt,Q,qn='ä»¥ä¸‹ã¯ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã®ãªã„å ´åˆã«ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ãŒ4096ã®<a href="https://hf.co/meta-llama/Llama-7b-hf" rel="nofollow"><code>meta-llama/Llama-7b-hf</code></a>ã«å¯¾ã™ã‚‹å˜ç´”ãªãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã®äºˆæƒ³ã•ã‚Œã‚‹é«˜é€ŸåŒ–ã§ã™ã€‚ã•ã¾ã–ã¾ãªãƒãƒƒãƒã‚µã‚¤ã‚ºãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ï¼š',Et,U,En='<img src="https://huggingface.co/datasets/ybelkada/documentation-images/resolve/main/llama-7b-inference-large-seqlen.png"/>',Qt,Y,Qn="ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å«ã‚€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ï¼ˆãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¾ãŸã¯ç”Ÿæˆã™ã‚‹ï¼‰ã®å ´åˆã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚¹ã‚³ã‚¢ã‚’æ­£ã—ãè¨ˆç®—ã™ã‚‹ãŸã‚ã«å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ã‚¢ãƒ³ãƒ‘ãƒƒãƒ‰/ãƒ‘ãƒƒãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚æ¯”è¼ƒçš„å°ã•ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã®å ´åˆã€ç´”ç²‹ãªãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ãƒ‘ã‚¹ã§ã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãƒˆãƒ¼ã‚¯ãƒ³ãŒ30%æœªæº€ã—ã‹åŸ‹ã‚ã‚‰ã‚Œã¦ã„ãªã„ãŸã‚ã€ã“ã‚Œã¯ã‚ãšã‹ãªé«˜é€ŸåŒ–ã‚’ã‚‚ãŸã‚‰ã—ã¾ã™ã€‚",Yt,W,Yn='<img src="https://huggingface.co/datasets/ybelkada/documentation-images/resolve/main/llama-2-small-seqlen-padding.png"/>',St,S,Sn="ã—ã‹ã—ã€å¤§ããªã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã®å ´åˆã€ç´”ç²‹ãªæ¨è«–ï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚å«ã‚€ï¼‰ã«ã¯èˆˆå‘³æ·±ã„é«˜é€ŸåŒ–ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚",Dt,D,Dn='Flash Attentionã¯ã€ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³è¨ˆç®—ã‚’ã‚ˆã‚Šãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®è‰¯ã„ã‚‚ã®ã«ã—ã€å¤§ããªã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã§ã®CUDA OOMã®å•é¡Œã‚’å›é¿ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚å¤§ããªã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã«å¯¾ã—ã¦æœ€å¤§20ã®ãƒ¡ãƒ¢ãƒªå‰Šæ¸›ã‚’ã‚‚ãŸã‚‰ã™ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://github.com/Dao-AILab/flash-attention" rel="nofollow">å…¬å¼ã®Flash Attentionãƒªãƒã‚¸ãƒˆãƒª</a>ã‚’ã”è¦§ãã ã•ã„ã€‚',Kt,Z,Kn='<img src="https://huggingface.co/datasets/ybelkada/documentation-images/resolve/main/llama-2-large-seqlen-padding.png"/>',Ot,K,el,O,On="ã“ã®æ©Ÿèƒ½ã‚’ãƒ¢ãƒ‡ãƒ«ã®æœ€é©åŒ–ã«å¤šãã®æ—¢å­˜ã®æ©Ÿèƒ½ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»¥ä¸‹ã«ã„ãã¤ã‹ã®ä¾‹ã‚’ç¤ºã—ã¾ã™ï¼š",tl,ee,ll,te,es="ã“ã®æ©Ÿèƒ½ã‚’8ãƒ“ãƒƒãƒˆã®é‡å­åŒ–ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š",nl,le,sl,ne,al,se,ts="ã“ã®æ©Ÿèƒ½ã‚’ 4 ãƒ“ãƒƒãƒˆã®é‡å­åŒ–ã¨çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š",il,ae,ol,ie,pl,oe,ls="ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã¦ã€Flash Attention 2ã‚’ãƒ™ãƒ¼ã‚¹ã«ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹éš›ã«PEFTã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚",ml,pe,rl,me,fl,re,ns='<a href="https://huggingface.co/docs/optimum/bettertransformer/overview" rel="nofollow">BetterTransformer</a>ã¯ã€ğŸ¤— Transformersãƒ¢ãƒ‡ãƒ«ã‚’PyTorchãƒã‚¤ãƒ†ã‚£ãƒ–ã®é«˜é€Ÿãƒ‘ã‚¹å®Ÿè¡Œã«å¤‰æ›ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€Flash Attentionãªã©ã®æœ€é©åŒ–ã•ã‚ŒãŸã‚«ãƒ¼ãƒãƒ«ãŒå†…éƒ¨ã§å‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚',dl,fe,ss="BetterTransformerã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€ãŠã‚ˆã³ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ¢ãƒ‡ãƒ«ã®å˜ä¸€ãŠã‚ˆã³ãƒãƒ«ãƒGPUã§ã®é«˜é€Ÿãªæ¨è«–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚",ul,j,bl,de,Tl,ue,as='PyTorchãƒã‚¤ãƒ†ã‚£ãƒ–ã®<a href="https://pytorch.org/blog/a-better-transformer-for-fast-transformer-encoder-inference/" rel="nofollow"><code>nn.MultiHeadAttention</code></a>ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é«˜é€Ÿãƒ‘ã‚¹ã€BetterTransformerã¨å‘¼ã°ã‚Œã‚‹ã‚‚ã®ã¯ã€<a href="https://huggingface.co/docs/optimum/bettertransformer/overview" rel="nofollow">ğŸ¤— Optimumãƒ©ã‚¤ãƒ–ãƒ©ãƒª</a>ã®çµ±åˆã‚’é€šã˜ã¦Transformersã¨ä¸€ç·’ã«ä½¿ç”¨ã§ãã¾ã™ã€‚',Ml,be,is='PyTorchã®ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³é«˜é€Ÿãƒ‘ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ã‚«ãƒ¼ãƒãƒ«ãƒ•ãƒ¥ãƒ¼ã‚¸ãƒ§ãƒ³ã¨<a href="https://pytorch.org/docs/stable/nested.html" rel="nofollow">ãƒã‚¹ãƒˆã•ã‚ŒãŸãƒ†ãƒ³ã‚½ãƒ«</a>ã®ä½¿ç”¨ã«ã‚ˆã‚Šã€æ¨è«–ã‚’é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚è©³ç´°ãªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æƒ…å ±ã¯<a href="https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2" rel="nofollow">ã“ã®ãƒ–ãƒ­ã‚°è¨˜äº‹</a>ã«ã‚ã‚Šã¾ã™ã€‚',cl,Te,os='<a href="https://github.com/huggingface/optimum" rel="nofollow"><code>optimum</code></a>ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸå¾Œã€æ¨è«–ä¸­ã«Better Transformerã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€é–¢é€£ã™ã‚‹å†…éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™ã“ã¨ã§ç½®ãæ›ãˆã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™<a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.to_bettertransformer">to_bettertransformer()</a>:',Jl,Me,yl,ce,ps='ãƒ¡ã‚½ãƒƒãƒ‰ <a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.reverse_bettertransformer">reverse_bettertransformer()</a> ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã™ã‚‹å‰ã«ä½¿ç”¨ã™ã¹ãã§ã€æ¨™æº–ã®ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒãƒ¼ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ï¼š',$l,Je,hl,ye,ms='BetterTransformer APIã‚’ä½¿ã£ãŸã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ¢ãƒ‡ãƒ«ã®å¯èƒ½æ€§ã«ã¤ã„ã¦è©³ã—ãçŸ¥ã‚‹ã«ã¯ã€<a href="https://medium.com/pytorch/bettertransformer-out-of-the-box-performance-for-huggingface-transformers-3fbe27d50ab2" rel="nofollow">ã“ã®ãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆ</a>ã‚’ã”è¦§ãã ã•ã„ã€‚',wl,$e,gl,he,rs='ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã€ç‰¹ã«ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆGPTã€T5ã€Llamaãªã©ï¼‰ã«ã¨ã£ã¦ã€BetterTransformer APIã¯ã™ã¹ã¦ã®æ³¨æ„æ“ä½œã‚’<a href="https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention" rel="nofollow"><code>torch.nn.functional.scaled_dot_product_attention</code>ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼</a>ï¼ˆSDPAï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«å¤‰æ›ã—ã¾ã™ã€‚ã“ã®ã‚ªãƒšãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯PyTorch 2.0ä»¥é™ã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚',vl,we,fs="ãƒ¢ãƒ‡ãƒ«ã‚’BetterTransformerã«å¤‰æ›ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®æ‰‹é †ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š",_l,ge,Cl,ve,ds='SDPAã¯ã€ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã‚„å•é¡Œã®ã‚µã‚¤ã‚ºã«å¿œã˜ã¦<a href="https://arxiv.org/abs/2205.14135" rel="nofollow">Flash Attention</a>ã‚«ãƒ¼ãƒãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚Flash Attentionã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹ã€ç‰¹å®šã®è¨­å®šï¼ˆãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢ã€å•é¡Œã‚µã‚¤ã‚ºï¼‰ã§ä½¿ç”¨å¯èƒ½ã‹ã©ã†ã‹ã‚’ç¢ºèªã™ã‚‹ã«ã¯ã€<a href="https://pytorch.org/docs/master/backends.html#torch.backends.cuda.sdp_kernel" rel="nofollow"><code>torch.backends.cuda.sdp_kernel</code></a>ã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚',xl,_e,Ul,Ce,us="ã‚‚ã—ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã«ãƒã‚°ãŒè¡¨ç¤ºã•ã‚ŒãŸå ´åˆ",Wl,xe,Zl,Ue,bs="Flash Attention ã®åºƒç¯„ãªã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’æŒã¤ã‹ã‚‚ã—ã‚Œãªã„ PyTorch ã®ãƒŠã‚¤ãƒˆãƒªãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è©¦ã—ã¦ã¿ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",jl,We,Bl,Ze,Ts="Or make sure your model is correctly casted in float16 or bfloat16",kl,je,Ms="ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãfloat16ã¾ãŸã¯bfloat16ã«ã‚­ãƒ£ã‚¹ãƒˆã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",Gl,Be,cs='Have a look at <a href="https://pytorch.org/blog/out-of-the-box-acceleration/" rel="nofollow">this detailed blogpost</a> to read more about what is possible to do with <code>BetterTransformer</code> + SDPA API.',Il,ke,Js='<code>BetterTransformer</code> + SDPA APIã‚’ä½¿ç”¨ã—ã¦ä½•ãŒå¯èƒ½ã‹ã«ã¤ã„ã¦è©³ã—ãèª­ã‚€ã«ã¯ã€<a href="https://pytorch.org/blog/out-of-the-box-acceleration/" rel="nofollow">ã“ã®è©³ç´°ãªãƒ–ãƒ­ã‚°ãƒã‚¹ãƒˆ</a>ã‚’ã”è¦§ãã ã•ã„ã€‚',Fl,Ge,Rl,Ie,ys="FP4æ··åˆç²¾åº¦æ¨è«–ã®ãŸã‚ã®<code>bitsandbytes</code>çµ±åˆ",Xl,Fe,$s="You can install <code>bitsandbytes</code> and benefit from easy model compression on GPUs. Using FP4 quantization you can expect to reduce up to 8x the model size compared to its native full precision version. Check out below how to get started.",Vl,Re,hs="<code>bitsandbytes</code>ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€GPUã§ç°¡å˜ãªãƒ¢ãƒ‡ãƒ«ã®åœ§ç¸®ã‚’åˆ©ç”¨ã§ãã¾ã™ã€‚FP4é‡å­åŒ–ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ãƒã‚¤ãƒ†ã‚£ãƒ–ã®ãƒ•ãƒ«ãƒ—ãƒ¬ã‚·ã‚¸ãƒ§ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨æ¯”è¼ƒã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã‚’æœ€å¤§8å€å‰Šæ¸›ã§ãã‚‹ã“ã¨ãŒæœŸå¾…ã§ãã¾ã™ã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ã€ã©ã®ã‚ˆã†ã«å§‹ã‚ã‚‹ã‹ã‚’ã”è¦§ãã ã•ã„ã€‚",Hl,B,Ll,Xe,Pl,Ve,ws=`<li><p>Latest <code>bitsandbytes</code> library
<code>pip install bitsandbytes&gt;=0.39.0</code></p></li> <li><p>Install latest <code>accelerate</code> from source
<code>pip install git+https://github.com/huggingface/accelerate.git</code></p></li> <li><p>Install latest <code>transformers</code> from source
<code>pip install git+https://github.com/huggingface/transformers.git</code></p></li>`,Al,He,Nl,Le,gs="ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€ç°¡å˜ã«å˜ä¸€ã®GPUã§FP4ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿè¡Œã§ãã¾ã™:",zl,Pe,ql,Ae,vs="æ³¨æ„: <code>device_map</code>ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§ã™ãŒã€æ¨è«–æ™‚ã« <code>device_map = &#39;auto&#39;</code> ã‚’è¨­å®šã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€åˆ©ç”¨å¯èƒ½ãªãƒªã‚½ãƒ¼ã‚¹ã«åŠ¹ç‡çš„ã«ãƒ¢ãƒ‡ãƒ«ãŒãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒã•ã‚Œã¾ã™ã€‚",El,Ne,Ql,ze,_s="æ··åˆ4ãƒ“ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¤‡æ•°ã®GPUã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ–¹æ³•ã¯ã€å˜ä¸€GPUã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨åŒã˜ã§ã™ï¼ˆå˜ä¸€GPUã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨åŒã˜ã‚³ãƒãƒ³ãƒ‰ã§ã™ï¼‰ï¼š",Yl,qe,Sl,Ee,Cs="ã—ã‹ã—ã€<code>accelerate</code>ã‚’ä½¿ç”¨ã—ã¦ã€å„GPUã«å‰²ã‚Šå½“ã¦ã‚‹GPU RAMã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»¥ä¸‹ã®ã‚ˆã†ã«ã€<code>max_memory</code>å¼•æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š",Dl,Qe,Kl,Ye,xs="ã“ã®ä¾‹ã§ã¯ã€æœ€åˆã®GPUã¯600MBã®ãƒ¡ãƒ¢ãƒªã‚’ä½¿ç”¨ã—ã€2ç•ªç›®ã®GPUã¯1GBã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",Ol,Se,en,De,Us='ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã®ã•ã‚‰ãªã‚‹é«˜åº¦ãªä½¿ç”¨æ³•ã«ã¤ã„ã¦ã¯ã€<a href="main_classes/quantization">é‡å­åŒ–</a>ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒšãƒ¼ã‚¸ã‚’ã”è¦§ãã ã•ã„ã€‚',tn,Ke,ln,k,nn,Oe,Ws='è«–æ–‡<a href="https://arxiv.org/abs/2208.07339" rel="nofollow"><code>LLM.int8()ï¼šã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªTransformerå‘ã‘ã®8ãƒ“ãƒƒãƒˆè¡Œåˆ—ä¹—ç®—</code></a>ã«ã‚ˆã‚Œã°ã€Hugging Faceçµ±åˆãŒHubå†…ã®ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã§ã‚ãšã‹æ•°è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€åŠç²¾åº¦ï¼ˆ<code>float16</code>ãŠã‚ˆã³<code>bfloat16</code>ï¼‰ã®é‡ã¿ã®å ´åˆã«<code>nn.Linear</code>ã‚µã‚¤ã‚ºã‚’2å€ã€å˜ç²¾åº¦ï¼ˆ<code>float32</code>ï¼‰ã®é‡ã¿ã®å ´åˆã¯4å€ã«ç¸®å°ã—ã€å¤–ã‚Œå€¤ã«å¯¾ã—ã¦ã»ã¨ã‚“ã©å½±éŸ¿ã‚’ä¸ãˆã¾ã›ã‚“ã€‚',sn,et,Zs='<img src="https://cdn-uploads.huggingface.co/production/uploads/1659861207959-62441d1d9fdefb55a0b7d12c.png" alt="HFxbitsandbytes.png"/>',an,tt,js=`Int8æ··åˆç²¾åº¦è¡Œåˆ—åˆ†è§£ã¯ã€è¡Œåˆ—ä¹—ç®—ã‚’2ã¤ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«åˆ†å‰²ã™ã‚‹ã“ã¨ã«ã‚ˆã£ã¦å‹•ä½œã—ã¾ã™ï¼š(1) ã‚·ã‚¹ãƒ†ãƒãƒ†ã‚£ãƒƒã‚¯ãªç‰¹å¾´å¤–ã‚Œå€¤ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒfp16ã§è¡Œåˆ—ä¹—ç®—ï¼ˆ0.01%ï¼‰ã€(2) int8è¡Œåˆ—ä¹—ç®—ã®é€šå¸¸ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆ99.9%ï¼‰ã€‚ã“ã®æ–¹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€éå¸¸ã«å¤§ããªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦äºˆæ¸¬ã®åŠ£åŒ–ãªã—ã«int8æ¨è«–ãŒå¯èƒ½ã§ã™ã€‚
ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€<a href="https://arxiv.org/abs/2208.07339" rel="nofollow">è«–æ–‡</a>ã¾ãŸã¯<a href="https://huggingface.co/blog/hf-bitsandbytes-integration" rel="nofollow">ã“ã®çµ±åˆã«é–¢ã™ã‚‹ãƒ–ãƒ­ã‚°è¨˜äº‹</a>ã‚’ã”ç¢ºèªãã ã•ã„ã€‚`,on,lt,Bs='<img src="https://cdn-uploads.huggingface.co/production/uploads/1660567469965-62441d1d9fdefb55a0b7d12c.gif" alt="MixedInt8.gif"/>',pn,nt,ks=`ãªãŠã€ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯GPUãŒå¿…è¦ã§ã‚ã‚Šã€ã‚«ãƒ¼ãƒãƒ«ã¯GPUå°‚ç”¨ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ã“ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«ã€ãƒ¢ãƒ‡ãƒ«ã®1/4ï¼ˆã¾ãŸã¯ãƒãƒ¼ãƒ•ç²¾åº¦ã®é‡ã¿ã®å ´åˆã¯1/2ï¼‰ã‚’ä¿å­˜ã™ã‚‹ã®ã«ååˆ†ãªGPUãƒ¡ãƒ¢ãƒªãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹éš›ã®ãƒ˜ãƒ«ãƒ—ã«é–¢ã™ã‚‹è©³ç´°ã¯ã€ä»¥ä¸‹ã®ãƒãƒ¼ãƒˆã‚’ã”è¦§ã„ãŸã ãã‹ã€<a href="#colab-demos">Google Colabã®ãƒ‡ãƒ¢</a>ã‚’ã”è¦§ãã ã•ã„ã€‚`,mn,st,rn,at,Gs=`<li><code>bitsandbytes&lt;0.37.0</code>ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã€NVIDIA GPUã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€8ãƒ“ãƒƒãƒˆãƒ†ãƒ³ã‚½ãƒ«ã‚³ã‚¢ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆTuringã€Ampereã€ã¾ãŸã¯ãã‚Œä»¥é™ã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ¼ã€ä¾‹ï¼šT4ã€RTX20s RTX30sã€A40-A100ãªã©ï¼‰ã€‚<code>bitsandbytes&gt;=0.37.0</code>ã®å ´åˆã€ã™ã¹ã¦ã®GPUãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã‚‹ã¯ãšã§ã™ã€‚</li> <li>æ­£ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®<code>bitsandbytes</code>ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ã«ã¯ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ï¼š
<code>pip install bitsandbytes&gt;=0.31.5</code></li> <li><code>accelerate</code>ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ï¼š
<code>pip install accelerate&gt;=0.12.0</code></li>`,fn,it,dn,ot,Is="å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸå¾Œã€ãƒŸãƒƒã‚¯ã‚¹ 8 ãƒ“ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€æ–¹æ³•ã¯æ¬¡ã®é€šã‚Šã§ã™ï¼š",un,pt,bn,mt,Fs="ä»¥ä¸‹ã¯ã‚·ãƒ³ãƒ—ãƒ«ãªä¾‹ã§ã™ï¼š",Tn,rt,Rs="<li><code>pipeline()</code> é–¢æ•°ã®ä»£ã‚ã‚Šã«ã€ãƒ¢ãƒ‡ãƒ«ã® <code>generate()</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚<code>pipeline()</code> é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã™ã‚‹ã“ã¨ã¯å¯èƒ½ã§ã™ãŒã€æ··åˆ8ãƒ“ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã«æœ€é©åŒ–ã•ã‚Œã¦ãŠã‚‰ãšã€<code>generate()</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã‚Šã‚‚é…ããªã‚Šã¾ã™ã€‚ã¾ãŸã€ä¸€éƒ¨ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æˆ¦ç•¥ï¼ˆä¾‹ï¼šãƒŒã‚¯ãƒ¬ã‚¦ã‚¹ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰ã¯ã€<code>pipeline()</code> é–¢æ•°ã§ã¯æ··åˆ8ãƒ“ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã§ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚</li> <li>ã™ã¹ã¦ã®å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã¨åŒã˜ãƒ‡ãƒã‚¤ã‚¹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚</li>",Mn,ft,cn,dt,Jn,ut,Xs="è¤‡æ•°ã®GPUã«æ··åˆ8ãƒ“ãƒƒãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ–¹æ³•ã¯ã€æ¬¡ã®é€šã‚Šã§ã™ï¼ˆã‚·ãƒ³ã‚°ãƒ«GPUã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨åŒã˜ã‚³ãƒãƒ³ãƒ‰ã§ã™ï¼‰ï¼š",yn,bt,$n,Tt,Vs="<code>accelerate</code>ã‚’ä½¿ç”¨ã—ã¦å„GPUã«å‰²ã‚Šå½“ã¦ã‚‹GPU RAMã‚’åˆ¶å¾¡ã™ã‚‹éš›ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«<code>max_memory</code>å¼•æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ï¼š",hn,Mt,wn,ct,Hs="In this example, the first GPU will use 1GB of memory and the second 2GB.",gn,Jt,vn,yt,Ls="ã“ã®æ–¹æ³•ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€ä»¥å‰ã®Google Colabã§ã¯æ¨è«–ã§ããªã‹ã£ãŸãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦æ¨è«–ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚ä»¥ä¸‹ã¯ã€Google Colabã§8ãƒ“ãƒƒãƒˆé‡å­åŒ–ã‚’ä½¿ç”¨ã—ã¦T5-11bï¼ˆfp32ã§42GBï¼‰ã‚’å®Ÿè¡Œã™ã‚‹ãƒ‡ãƒ¢ã®ãƒªãƒ³ã‚¯ã§ã™ï¼š",_n,$t,Ps='<a href="https://colab.research.google.com/drive/1YORPWx4okIHXnjW7MSAidXN29mPVNT7F?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab: T5-11b demo"/></a>',Cn,ht,As="ã¾ãŸã€BLOOM-3Bã®ãƒ‡ãƒ¢ã‚‚ã”è¦§ã„ãŸã ã‘ã¾ã™ï¼š",xn,wt,Ns='<a href="https://colab.research.google.com/drive/1qOjXfQIAULfKvZqwCen8-MoWKGdSatZ4?usp=sharing" rel="nofollow"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab: BLOOM-3b demo"/></a>',Un,gt,Wn,vt,zs="ç•°ãªã‚‹æ–¹æ³•ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®æœ€é©ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä¾‹ãˆã°ã€BetterTransformerã‚’ä½¿ç”¨ã—ã¦FP4ãƒŸãƒƒã‚¯ã‚¹ãƒ—ãƒ¬ã‚·ã‚¸ãƒ§ãƒ³æ¨è«–ã¨ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚",Zn,_t,jn,Ct,Bn;return v=new c({props:{title:"Efficient Inference on a Single GPU",local:"efficient-inference-on-a-single-gpu",headingTag:"h1"}}),G=new c({props:{title:"Flash Attention 2",local:"flash-attention-2",headingTag:"h2"}}),_=new xt({props:{$$slots:{default:[aa]},$$scope:{ctx:w}}}),C=new xt({props:{$$slots:{default:[ia]},$$scope:{ctx:w}}}),H=new c({props:{title:"Quick usage",local:"quick-usage",headingTag:"h3"}}),P=new $({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTJDJTIwTGxhbWFGb3JDYXVzYWxMTSUwQSUwQW1vZGVsX2lkJTIwJTNEJTIwJTIydGlpdWFlJTJGZmFsY29uLTdiJTIyJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwbW9kZWxfaWQlMkMlMjAlMEElMjAlMjAlMjAlMjB0b3JjaF9kdHlwZSUzRHRvcmNoLmJmbG9hdDE2JTJDJTIwJTBBJTIwJTIwJTIwJTIwYXR0bl9pbXBsZW1lbnRhdGlvbiUzRCUyMmZsYXNoX2F0dGVudGlvbl8yJTIyJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM

model_id = <span class="hljs-string">&quot;tiiuae/falcon-7b&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    torch_dtype=torch.bfloat16, 
    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span>,
)`,wrap:!1}}),N=new c({props:{title:"Expected speedups",local:"expected-speedups",headingTag:"h3"}}),K=new c({props:{title:"Advanced usage",local:"advanced-usage",headingTag:"h3"}}),ee=new c({props:{title:"Combining Flash Attention 2 and 8-bit models",local:"combining-flash-attention-2-and-8-bit-models",headingTag:"h3"}}),le=new $({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTJDJTIwTGxhbWFGb3JDYXVzYWxMTSUwQSUwQW1vZGVsX2lkJTIwJTNEJTIwJTIydGlpdWFlJTJGZmFsY29uLTdiJTIyJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwbW9kZWxfaWQlMkMlMjAlMEElMjAlMjAlMjAlMjBsb2FkX2luXzhiaXQlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYXR0bl9pbXBsZW1lbnRhdGlvbiUzRCUyMmZsYXNoX2F0dGVudGlvbl8yJTIyJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM

model_id = <span class="hljs-string">&quot;tiiuae/falcon-7b&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    load_in_8bit=<span class="hljs-literal">True</span>,
    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span>,
)`,wrap:!1}}),ne=new c({props:{title:"Combining Flash Attention 2 and 4-bit models",local:"combining-flash-attention-2-and-4-bit-models",headingTag:"h3"}}),ae=new $({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTJDJTIwTGxhbWFGb3JDYXVzYWxMTSUwQSUwQW1vZGVsX2lkJTIwJTNEJTIwJTIydGlpdWFlJTJGZmFsY29uLTdiJTIyJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwbW9kZWxfaWQlMkMlMjAlMEElMjAlMjAlMjAlMjBsb2FkX2luXzRiaXQlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYXR0bl9pbXBsZW1lbnRhdGlvbiUzRCUyMmZsYXNoX2F0dGVudGlvbl8yJTIyJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM

model_id = <span class="hljs-string">&quot;tiiuae/falcon-7b&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    load_in_4bit=<span class="hljs-literal">True</span>,
    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span>,
)`,wrap:!1}}),ie=new c({props:{title:"Combining Flash Attention 2 and PEFT",local:"combining-flash-attention-2-and-peft",headingTag:"h3"}}),pe=new $({props:{code:"JTBBJTBBJTBBJTBBJTBBJTIzJTIwdHJhaW4lMjB5b3VyJTIwbW9kZWw=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, LlamaForCausalLM
<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig

model_id = <span class="hljs-string">&quot;tiiuae/falcon-7b&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_id)

model = AutoModelForCausalLM.from_pretrained(
    model_id, 
    load_in_4bit=<span class="hljs-literal">True</span>,
    attn_implementation=<span class="hljs-string">&quot;flash_attention_2&quot;</span>,
)

lora_config = LoraConfig(
    r=<span class="hljs-number">8</span>,
    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span>
)

model.add_adapter(lora_config)

<span class="hljs-meta">... </span><span class="hljs-comment"># train your model</span>`,wrap:!1}}),me=new c({props:{title:"BetterTransformer",local:"bettertransformer",headingTag:"h2"}}),j=new xt({props:{$$slots:{default:[oa]},$$scope:{ctx:w}}}),de=new c({props:{title:"Encoder models",local:"encoder-models",headingTag:"h3"}}),Me=new $({props:{code:"bW9kZWwlMjAlM0QlMjBtb2RlbC50b19iZXR0ZXJ0cmFuc2Zvcm1lcigp",highlighted:"model = model.to_bettertransformer()",wrap:!1}}),Je=new $({props:{code:"bW9kZWwlMjAlM0QlMjBtb2RlbC5yZXZlcnNlX2JldHRlcnRyYW5zZm9ybWVyKCklMEFtb2RlbC5zYXZlX3ByZXRyYWluZWQoJTIyc2F2ZWRfbW9kZWwlMjIp",highlighted:`model = model.reverse_bettertransformer()
model.save_pretrained(<span class="hljs-string">&quot;saved_model&quot;</span>)`,wrap:!1}}),$e=new c({props:{title:"Decoder models",local:"decoder-models",headingTag:"h3"}}),ge=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZvcHQtMzUwbSUyMiklMEElMjMlMjBjb252ZXJ0JTIwdGhlJTIwbW9kZWwlMjB0byUyMEJldHRlclRyYW5zZm9ybWVyJTBBbW9kZWwudG9fYmV0dGVydHJhbnNmb3JtZXIoKSUwQSUwQSUyMyUyMFVzZSUyMGl0JTIwZm9yJTIwdHJhaW5pbmclMjBvciUyMGluZmVyZW5jZQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;facebook/opt-350m&quot;</span>)
<span class="hljs-comment"># convert the model to BetterTransformer</span>
model.to_bettertransformer()

<span class="hljs-comment"># Use it for training or inference</span>`,wrap:!1}}),_e=new $({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZvcHQtMzUwbSUyMiklMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMjJmYWNlYm9vayUyRm9wdC0zNTBtJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5mbG9hdDE2KS50byglMjJjdWRhJTIyKSUwQSUyMyUyMGNvbnZlcnQlMjB0aGUlMjBtb2RlbCUyMHRvJTIwQmV0dGVyVHJhbnNmb3JtZXIlMEFtb2RlbC50b19iZXR0ZXJ0cmFuc2Zvcm1lcigpJTBBJTBBaW5wdXRfdGV4dCUyMCUzRCUyMCUyMkhlbGxvJTIwbXklMjBkb2clMjBpcyUyMGN1dGUlMjBhbmQlMjIlMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoaW5wdXRfdGV4dCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpLnRvKCUyMmN1ZGElMjIpJTBBJTBBJTJCJTIwd2l0aCUyMHRvcmNoLmJhY2tlbmRzLmN1ZGEuc2RwX2tlcm5lbChlbmFibGVfZmxhc2glM0RUcnVlJTJDJTIwZW5hYmxlX21hdGglM0RGYWxzZSUyQyUyMGVuYWJsZV9tZW1fZWZmaWNpZW50JTNERmFsc2UpJTNBJTBBJTIwJTIwJTIwJTIwb3V0cHV0cyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqaW5wdXRzKSUwQSUwQXByaW50KHRva2VuaXplci5kZWNvZGUob3V0cHV0cyU1QjAlNUQlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSkp",highlighted:`import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(&quot;facebook/opt-350m&quot;)
model = AutoModelForCausalLM.from_pretrained(&quot;facebook/opt-350m&quot;, torch_dtype=torch.float16).to(&quot;cuda&quot;)
# convert the model to BetterTransformer
model.to_bettertransformer()

input_text = &quot;Hello my dog is cute and&quot;
inputs = tokenizer(input_text, return_tensors=&quot;pt&quot;).to(&quot;cuda&quot;)

<span class="hljs-addition">+ with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):</span>
    outputs = model.generate(**inputs)

print(tokenizer.decode(outputs[0], skip_special_tokens=True))`,wrap:!1}}),xe=new $({props:{code:"UnVudGltZUVycm9yJTNBJTIwTm8lMjBhdmFpbGFibGUlMjBrZXJuZWwuJTIwJTIwQWJvcnRpbmclMjBleGVjdXRpb24u",highlighted:"RuntimeError: No available kernel.  Aborting execution.",wrap:!1}}),We=new $({props:{code:"cGlwMyUyMGluc3RhbGwlMjAtVSUyMC0tcHJlJTIwdG9yY2glMjB0b3JjaHZpc2lvbiUyMHRvcmNoYXVkaW8lMjAtLWluZGV4LXVybCUyMGh0dHBzJTNBJTJGJTJGZG93bmxvYWQucHl0b3JjaC5vcmclMkZ3aGwlMkZuaWdodGx5JTJGY3UxMTg=",highlighted:"pip3 install -U --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu118",wrap:!1}}),Ge=new c({props:{title:"bitsandbytes integration for FP4 mixed-precision inference",local:"bitsandbytes-integration-for-fp4-mixed-precision-inference",headingTag:"h2"}}),B=new xt({props:{$$slots:{default:[pa]},$$scope:{ctx:w}}}),Xe=new c({props:{title:"Requirements",local:"requirements-for-fp4-mixedprecision-inference",headingTag:"h3"}}),He=new c({props:{title:"Running FP4 models - single GPU setup - Quickstart",local:"running-fp4-models---single-gpu-setup---quickstart",headingTag:"h3"}}),Pe=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWxfbmFtZSUyMCUzRCUyMCUyMmJpZ3NjaWVuY2UlMkZibG9vbS0yYjUlMjIlMEFtb2RlbF80Yml0JTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMGxvYWRfaW5fNGJpdCUzRFRydWUp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model_name = <span class="hljs-string">&quot;bigscience/bloom-2b5&quot;</span>
model_4bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_4bit=<span class="hljs-literal">True</span>)`,wrap:!1}}),Ne=new c({props:{title:"Running FP4 models - multi GPU setup",local:"running-fp4-models---multi-gpu-setup",headingTag:"h3"}}),qe=new $({props:{code:"bW9kZWxfbmFtZSUyMCUzRCUyMCUyMmJpZ3NjaWVuY2UlMkZibG9vbS0yYjUlMjIlMEFtb2RlbF80Yml0JTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMGxvYWRfaW5fNGJpdCUzRFRydWUp",highlighted:`model_name = <span class="hljs-string">&quot;bigscience/bloom-2b5&quot;</span>
model_4bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_4bit=<span class="hljs-literal">True</span>)`,wrap:!1}}),Qe=new $({props:{code:"bWF4X21lbW9yeV9tYXBwaW5nJTIwJTNEJTIwJTdCMCUzQSUyMCUyMjYwME1CJTIyJTJDJTIwMSUzQSUyMCUyMjFHQiUyMiU3RCUwQW1vZGVsX25hbWUlMjAlM0QlMjAlMjJiaWdzY2llbmNlJTJGYmxvb20tM2IlMjIlMEFtb2RlbF80Yml0JTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMG1vZGVsX25hbWUlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMGxvYWRfaW5fNGJpdCUzRFRydWUlMkMlMjBtYXhfbWVtb3J5JTNEbWF4X21lbW9yeV9tYXBwaW5nJTBBKQ==",highlighted:`max_memory_mapping = {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;600MB&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;1GB&quot;</span>}
model_name = <span class="hljs-string">&quot;bigscience/bloom-3b&quot;</span>
model_4bit = AutoModelForCausalLM.from_pretrained(
    model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_4bit=<span class="hljs-literal">True</span>, max_memory=max_memory_mapping
)`,wrap:!1}}),Se=new c({props:{title:"Advanced usage",local:"advanced-usage",headingTag:"h3"}}),Ke=new c({props:{title:"bitsandbytes integration for Int8 mixed-precision matrix decomposition",local:"bitsandbytes-integration-for-int8-mixed-precision-matrix-decomposition",headingTag:"h2"}}),k=new xt({props:{$$slots:{default:[ma]},$$scope:{ctx:w}}}),st=new c({props:{title:"Requirements",local:"requirements-for-int8-mixedprecision-matrix-decomposition",headingTag:"h3"}}),it=new c({props:{title:"Running mixed-Int8 models - single GPU setup",local:"running-mixed-int8-models---single-gpu-setup",headingTag:"h3"}}),pt=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWxfbmFtZSUyMCUzRCUyMCUyMmJpZ3NjaWVuY2UlMkZibG9vbS0yYjUlMjIlMEFtb2RlbF84Yml0JTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMGxvYWRfaW5fOGJpdCUzRFRydWUp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model_name = <span class="hljs-string">&quot;bigscience/bloom-2b5&quot;</span>
model_8bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>)`,wrap:!1}}),ft=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQW1vZGVsX25hbWUlMjAlM0QlMjAlMjJiaWdzY2llbmNlJTJGYmxvb20tMmI1JTIyJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQobW9kZWxfbmFtZSklMEFtb2RlbF84Yml0JTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMGxvYWRfaW5fOGJpdCUzRFRydWUpJTBBJTBBcHJvbXB0JTIwJTNEJTIwJTIySGVsbG8lMkMlMjBteSUyMGxsYW1hJTIwaXMlMjBjdXRlJTIyJTBBaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKHByb21wdCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpLnRvKCUyMmN1ZGElMjIpJTBBZ2VuZXJhdGVkX2lkcyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqaW5wdXRzKSUwQW91dHB1dHMlMjAlM0QlMjB0b2tlbml6ZXIuYmF0Y2hfZGVjb2RlKGdlbmVyYXRlZF9pZHMlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

model_name = <span class="hljs-string">&quot;bigscience/bloom-2b5&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_name)
model_8bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>)

prompt = <span class="hljs-string">&quot;Hello, my llama is cute&quot;</span>
inputs = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)
generated_ids = model.generate(**inputs)
outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)`,wrap:!1}}),dt=new c({props:{title:"Running mixed-int8 models - multi GPU setup",local:"running-mixed-int8-models---multi-gpu-setup",headingTag:"h3"}}),bt=new $({props:{code:"bW9kZWxfbmFtZSUyMCUzRCUyMCUyMmJpZ3NjaWVuY2UlMkZibG9vbS0yYjUlMjIlMEFtb2RlbF84Yml0JTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUlMkMlMjBkZXZpY2VfbWFwJTNEJTIyYXV0byUyMiUyQyUyMGxvYWRfaW5fOGJpdCUzRFRydWUp",highlighted:`model_name = <span class="hljs-string">&quot;bigscience/bloom-2b5&quot;</span>
model_8bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>)`,wrap:!1}}),Mt=new $({props:{code:"bWF4X21lbW9yeV9tYXBwaW5nJTIwJTNEJTIwJTdCMCUzQSUyMCUyMjFHQiUyMiUyQyUyMDElM0ElMjAlMjIyR0IlMjIlN0QlMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIyYmlnc2NpZW5jZSUyRmJsb29tLTNiJTIyJTBBbW9kZWxfOGJpdCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjBtb2RlbF9uYW1lJTJDJTIwZGV2aWNlX21hcCUzRCUyMmF1dG8lMjIlMkMlMjBsb2FkX2luXzhiaXQlM0RUcnVlJTJDJTIwbWF4X21lbW9yeSUzRG1heF9tZW1vcnlfbWFwcGluZyUwQSk=",highlighted:`max_memory_mapping = {<span class="hljs-number">0</span>: <span class="hljs-string">&quot;1GB&quot;</span>, <span class="hljs-number">1</span>: <span class="hljs-string">&quot;2GB&quot;</span>}
model_name = <span class="hljs-string">&quot;bigscience/bloom-3b&quot;</span>
model_8bit = AutoModelForCausalLM.from_pretrained(
    model_name, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>, max_memory=max_memory_mapping
)`,wrap:!1}}),Jt=new c({props:{title:"Colab demos",local:"colab-demos",headingTag:"h3"}}),gt=new c({props:{title:"Advanced usage: mixing FP4 (or Int8) and BetterTransformer",local:"advanced-usage-mixing-fp4-or-int8-and-bettertransformer",headingTag:"h2"}}),_t=new $({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTJDJTIwQml0c0FuZEJ5dGVzQ29uZmlnJTBBJTBBcXVhbnRpemF0aW9uX2NvbmZpZyUyMCUzRCUyMEJpdHNBbmRCeXRlc0NvbmZpZyglMEElMjAlMjAlMjAlMjBsb2FkX2luXzRiaXQlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYm5iXzRiaXRfY29tcHV0ZV9kdHlwZSUzRHRvcmNoLmZsb2F0MTYlMEEpJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZvcHQtMzUwbSUyMiklMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZCglMjJmYWNlYm9vayUyRm9wdC0zNTBtJTIyJTJDJTIwcXVhbnRpemF0aW9uX2NvbmZpZyUzRHF1YW50aXphdGlvbl9jb25maWcpJTBBJTBBaW5wdXRfdGV4dCUyMCUzRCUyMCUyMkhlbGxvJTIwbXklMjBkb2clMjBpcyUyMGN1dGUlMjBhbmQlMjIlMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoaW5wdXRfdGV4dCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpLnRvKCUyMmN1ZGElMjIpJTBBJTBBd2l0aCUyMHRvcmNoLmJhY2tlbmRzLmN1ZGEuc2RwX2tlcm5lbChlbmFibGVfZmxhc2glM0RUcnVlJTJDJTIwZW5hYmxlX21hdGglM0RGYWxzZSUyQyUyMGVuYWJsZV9tZW1fZWZmaWNpZW50JTNERmFsc2UpJTNBJTBBJTIwJTIwJTIwJTIwb3V0cHV0cyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqaW5wdXRzKSUwQSUwQXByaW50KHRva2VuaXplci5kZWNvZGUob3V0cHV0cyU1QjAlNUQlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSkp",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig

quantization_config = BitsAndBytesConfig(
    load_in_4bit=<span class="hljs-literal">True</span>,
    bnb_4bit_compute_dtype=torch.float16
)

tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/opt-350m&quot;</span>)
model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;facebook/opt-350m&quot;</span>, quantization_config=quantization_config)

input_text = <span class="hljs-string">&quot;Hello my dog is cute and&quot;</span>
inputs = tokenizer(input_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(<span class="hljs-string">&quot;cuda&quot;</span>)

<span class="hljs-keyword">with</span> torch.backends.cuda.sdp_kernel(enable_flash=<span class="hljs-literal">True</span>, enable_math=<span class="hljs-literal">False</span>, enable_mem_efficient=<span class="hljs-literal">False</span>):
    outputs = model.generate(**inputs)

<span class="hljs-built_in">print</span>(tokenizer.decode(outputs[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))`,wrap:!1}}),{c(){m=i("meta"),y=s(),M=i("p"),J=s(),r(v.$$.fragment),h=s(),g=i("p"),g.innerHTML=Gn,Wt=s(),r(G.$$.fragment),Zt=s(),r(_.$$.fragment),jt=s(),I=i("p"),I.innerHTML=In,Bt=s(),F=i("p"),F.textContent=Fn,kt=s(),R=i("p"),R.textContent=Rn,Gt=s(),X=i("ul"),X.innerHTML=Xn,It=s(),V=i("p"),V.innerHTML=Vn,Ft=s(),r(C.$$.fragment),Rt=s(),r(H.$$.fragment),Xt=s(),L=i("p"),L.innerHTML=Hn,Vt=s(),r(P.$$.fragment),Ht=s(),A=i("p"),A.textContent=Ln,Lt=s(),r(N.$$.fragment),Pt=s(),z=i("p"),z.textContent=Pn,At=s(),q=i("p"),q.innerHTML=An,Nt=s(),E=i("p"),E.innerHTML=Nn,zt=s(),x=i("div"),x.innerHTML=zn,qt=s(),Q=i("p"),Q.innerHTML=qn,Et=s(),U=i("div"),U.innerHTML=En,Qt=s(),Y=i("p"),Y.textContent=Qn,Yt=s(),W=i("div"),W.innerHTML=Yn,St=s(),S=i("p"),S.textContent=Sn,Dt=s(),D=i("p"),D.innerHTML=Dn,Kt=s(),Z=i("div"),Z.innerHTML=Kn,Ot=s(),r(K.$$.fragment),el=s(),O=i("p"),O.textContent=On,tl=s(),r(ee.$$.fragment),ll=s(),te=i("p"),te.textContent=es,nl=s(),r(le.$$.fragment),sl=s(),r(ne.$$.fragment),al=s(),se=i("p"),se.textContent=ts,il=s(),r(ae.$$.fragment),ol=s(),r(ie.$$.fragment),pl=s(),oe=i("p"),oe.textContent=ls,ml=s(),r(pe.$$.fragment),rl=s(),r(me.$$.fragment),fl=s(),re=i("p"),re.innerHTML=ns,dl=s(),fe=i("p"),fe.textContent=ss,ul=s(),r(j.$$.fragment),bl=s(),r(de.$$.fragment),Tl=s(),ue=i("p"),ue.innerHTML=as,Ml=s(),be=i("p"),be.innerHTML=is,cl=s(),Te=i("p"),Te.innerHTML=os,Jl=s(),r(Me.$$.fragment),yl=s(),ce=i("p"),ce.innerHTML=ps,$l=s(),r(Je.$$.fragment),hl=s(),ye=i("p"),ye.innerHTML=ms,wl=s(),r($e.$$.fragment),gl=s(),he=i("p"),he.innerHTML=rs,vl=s(),we=i("p"),we.textContent=fs,_l=s(),r(ge.$$.fragment),Cl=s(),ve=i("p"),ve.innerHTML=ds,xl=s(),r(_e.$$.fragment),Ul=s(),Ce=i("p"),Ce.textContent=us,Wl=s(),r(xe.$$.fragment),Zl=s(),Ue=i("p"),Ue.textContent=bs,jl=s(),r(We.$$.fragment),Bl=s(),Ze=i("p"),Ze.textContent=Ts,kl=s(),je=i("p"),je.textContent=Ms,Gl=s(),Be=i("p"),Be.innerHTML=cs,Il=s(),ke=i("p"),ke.innerHTML=Js,Fl=s(),r(Ge.$$.fragment),Rl=s(),Ie=i("p"),Ie.innerHTML=ys,Xl=s(),Fe=i("p"),Fe.innerHTML=$s,Vl=s(),Re=i("p"),Re.innerHTML=hs,Hl=s(),r(B.$$.fragment),Ll=s(),r(Xe.$$.fragment),Pl=s(),Ve=i("ul"),Ve.innerHTML=ws,Al=s(),r(He.$$.fragment),Nl=s(),Le=i("p"),Le.textContent=gs,zl=s(),r(Pe.$$.fragment),ql=s(),Ae=i("p"),Ae.innerHTML=vs,El=s(),r(Ne.$$.fragment),Ql=s(),ze=i("p"),ze.textContent=_s,Yl=s(),r(qe.$$.fragment),Sl=s(),Ee=i("p"),Ee.innerHTML=Cs,Dl=s(),r(Qe.$$.fragment),Kl=s(),Ye=i("p"),Ye.textContent=xs,Ol=s(),r(Se.$$.fragment),en=s(),De=i("p"),De.innerHTML=Us,tn=s(),r(Ke.$$.fragment),ln=s(),r(k.$$.fragment),nn=s(),Oe=i("p"),Oe.innerHTML=Ws,sn=s(),et=i("p"),et.innerHTML=Zs,an=s(),tt=i("p"),tt.innerHTML=js,on=s(),lt=i("p"),lt.innerHTML=Bs,pn=s(),nt=i("p"),nt.innerHTML=ks,mn=s(),r(st.$$.fragment),rn=s(),at=i("ul"),at.innerHTML=Gs,fn=s(),r(it.$$.fragment),dn=s(),ot=i("p"),ot.textContent=Is,un=s(),r(pt.$$.fragment),bn=s(),mt=i("p"),mt.textContent=Fs,Tn=s(),rt=i("ul"),rt.innerHTML=Rs,Mn=s(),r(ft.$$.fragment),cn=s(),r(dt.$$.fragment),Jn=s(),ut=i("p"),ut.textContent=Xs,yn=s(),r(bt.$$.fragment),$n=s(),Tt=i("p"),Tt.innerHTML=Vs,hn=s(),r(Mt.$$.fragment),wn=s(),ct=i("p"),ct.textContent=Hs,gn=s(),r(Jt.$$.fragment),vn=s(),yt=i("p"),yt.textContent=Ls,_n=s(),$t=i("p"),$t.innerHTML=Ps,Cn=s(),ht=i("p"),ht.textContent=As,xn=s(),wt=i("p"),wt.innerHTML=Ns,Un=s(),r(gt.$$.fragment),Wn=s(),vt=i("p"),vt.textContent=zs,Zn=s(),r(_t.$$.fragment),jn=s(),Ct=i("p"),this.h()},l(e){const t=na("svelte-u9bgzb",document.head);m=o(t,"META",{name:!0,content:!0}),t.forEach(l),y=a(e),M=o(e,"P",{}),Ds(M).forEach(l),J=a(e),f(v.$$.fragment,e),h=a(e),g=o(e,"P",{"data-svelte-h":!0}),p(g)!=="svelte-fzdu4j"&&(g.innerHTML=Gn),Wt=a(e),f(G.$$.fragment,e),Zt=a(e),f(_.$$.fragment,e),jt=a(e),I=o(e,"P",{"data-svelte-h":!0}),p(I)!=="svelte-1hue4gy"&&(I.innerHTML=In),Bt=a(e),F=o(e,"P",{"data-svelte-h":!0}),p(F)!=="svelte-uc6qdz"&&(F.textContent=Fn),kt=a(e),R=o(e,"P",{"data-svelte-h":!0}),p(R)!=="svelte-10j7r84"&&(R.textContent=Rn),Gt=a(e),X=o(e,"UL",{"data-svelte-h":!0}),p(X)!=="svelte-7xk7rk"&&(X.innerHTML=Xn),It=a(e),V=o(e,"P",{"data-svelte-h":!0}),p(V)!=="svelte-1xg4p19"&&(V.innerHTML=Vn),Ft=a(e),f(C.$$.fragment,e),Rt=a(e),f(H.$$.fragment,e),Xt=a(e),L=o(e,"P",{"data-svelte-h":!0}),p(L)!=="svelte-qebdou"&&(L.innerHTML=Hn),Vt=a(e),f(P.$$.fragment,e),Ht=a(e),A=o(e,"P",{"data-svelte-h":!0}),p(A)!=="svelte-8hn31v"&&(A.textContent=Ln),Lt=a(e),f(N.$$.fragment,e),Pt=a(e),z=o(e,"P",{"data-svelte-h":!0}),p(z)!=="svelte-d598nm"&&(z.textContent=Pn),At=a(e),q=o(e,"P",{"data-svelte-h":!0}),p(q)!=="svelte-95y2nm"&&(q.innerHTML=An),Nt=a(e),E=o(e,"P",{"data-svelte-h":!0}),p(E)!=="svelte-g8drlk"&&(E.innerHTML=Nn),zt=a(e),x=o(e,"DIV",{style:!0,"data-svelte-h":!0}),p(x)!=="svelte-u3wzwi"&&(x.innerHTML=zn),qt=a(e),Q=o(e,"P",{"data-svelte-h":!0}),p(Q)!=="svelte-1v69pah"&&(Q.innerHTML=qn),Et=a(e),U=o(e,"DIV",{style:!0,"data-svelte-h":!0}),p(U)!=="svelte-1yuov6e"&&(U.innerHTML=En),Qt=a(e),Y=o(e,"P",{"data-svelte-h":!0}),p(Y)!=="svelte-1v37jvv"&&(Y.textContent=Qn),Yt=a(e),W=o(e,"DIV",{style:!0,"data-svelte-h":!0}),p(W)!=="svelte-cixhj1"&&(W.innerHTML=Yn),St=a(e),S=o(e,"P",{"data-svelte-h":!0}),p(S)!=="svelte-1nalxxh"&&(S.textContent=Sn),Dt=a(e),D=o(e,"P",{"data-svelte-h":!0}),p(D)!=="svelte-1u8lofd"&&(D.innerHTML=Dn),Kt=a(e),Z=o(e,"DIV",{style:!0,"data-svelte-h":!0}),p(Z)!=="svelte-13f0ql9"&&(Z.innerHTML=Kn),Ot=a(e),f(K.$$.fragment,e),el=a(e),O=o(e,"P",{"data-svelte-h":!0}),p(O)!=="svelte-153ejfa"&&(O.textContent=On),tl=a(e),f(ee.$$.fragment,e),ll=a(e),te=o(e,"P",{"data-svelte-h":!0}),p(te)!=="svelte-rj8paa"&&(te.textContent=es),nl=a(e),f(le.$$.fragment,e),sl=a(e),f(ne.$$.fragment,e),al=a(e),se=o(e,"P",{"data-svelte-h":!0}),p(se)!=="svelte-eee45y"&&(se.textContent=ts),il=a(e),f(ae.$$.fragment,e),ol=a(e),f(ie.$$.fragment,e),pl=a(e),oe=o(e,"P",{"data-svelte-h":!0}),p(oe)!=="svelte-1nd12n2"&&(oe.textContent=ls),ml=a(e),f(pe.$$.fragment,e),rl=a(e),f(me.$$.fragment,e),fl=a(e),re=o(e,"P",{"data-svelte-h":!0}),p(re)!=="svelte-1mxj58t"&&(re.innerHTML=ns),dl=a(e),fe=o(e,"P",{"data-svelte-h":!0}),p(fe)!=="svelte-1ncf36d"&&(fe.textContent=ss),ul=a(e),f(j.$$.fragment,e),bl=a(e),f(de.$$.fragment,e),Tl=a(e),ue=o(e,"P",{"data-svelte-h":!0}),p(ue)!=="svelte-1460ksx"&&(ue.innerHTML=as),Ml=a(e),be=o(e,"P",{"data-svelte-h":!0}),p(be)!=="svelte-obqyae"&&(be.innerHTML=is),cl=a(e),Te=o(e,"P",{"data-svelte-h":!0}),p(Te)!=="svelte-304wy3"&&(Te.innerHTML=os),Jl=a(e),f(Me.$$.fragment,e),yl=a(e),ce=o(e,"P",{"data-svelte-h":!0}),p(ce)!=="svelte-jcksqc"&&(ce.innerHTML=ps),$l=a(e),f(Je.$$.fragment,e),hl=a(e),ye=o(e,"P",{"data-svelte-h":!0}),p(ye)!=="svelte-bx0bhv"&&(ye.innerHTML=ms),wl=a(e),f($e.$$.fragment,e),gl=a(e),he=o(e,"P",{"data-svelte-h":!0}),p(he)!=="svelte-t1pi44"&&(he.innerHTML=rs),vl=a(e),we=o(e,"P",{"data-svelte-h":!0}),p(we)!=="svelte-1k16omg"&&(we.textContent=fs),_l=a(e),f(ge.$$.fragment,e),Cl=a(e),ve=o(e,"P",{"data-svelte-h":!0}),p(ve)!=="svelte-ov9ztb"&&(ve.innerHTML=ds),xl=a(e),f(_e.$$.fragment,e),Ul=a(e),Ce=o(e,"P",{"data-svelte-h":!0}),p(Ce)!=="svelte-1rokqgh"&&(Ce.textContent=us),Wl=a(e),f(xe.$$.fragment,e),Zl=a(e),Ue=o(e,"P",{"data-svelte-h":!0}),p(Ue)!=="svelte-ptizo3"&&(Ue.textContent=bs),jl=a(e),f(We.$$.fragment,e),Bl=a(e),Ze=o(e,"P",{"data-svelte-h":!0}),p(Ze)!=="svelte-1chszbv"&&(Ze.textContent=Ts),kl=a(e),je=o(e,"P",{"data-svelte-h":!0}),p(je)!=="svelte-2wjwue"&&(je.textContent=Ms),Gl=a(e),Be=o(e,"P",{"data-svelte-h":!0}),p(Be)!=="svelte-1c2vyan"&&(Be.innerHTML=cs),Il=a(e),ke=o(e,"P",{"data-svelte-h":!0}),p(ke)!=="svelte-1u8mhyg"&&(ke.innerHTML=Js),Fl=a(e),f(Ge.$$.fragment,e),Rl=a(e),Ie=o(e,"P",{"data-svelte-h":!0}),p(Ie)!=="svelte-15spw9f"&&(Ie.innerHTML=ys),Xl=a(e),Fe=o(e,"P",{"data-svelte-h":!0}),p(Fe)!=="svelte-1f2adro"&&(Fe.innerHTML=$s),Vl=a(e),Re=o(e,"P",{"data-svelte-h":!0}),p(Re)!=="svelte-1y9rpsh"&&(Re.innerHTML=hs),Hl=a(e),f(B.$$.fragment,e),Ll=a(e),f(Xe.$$.fragment,e),Pl=a(e),Ve=o(e,"UL",{"data-svelte-h":!0}),p(Ve)!=="svelte-1aope0v"&&(Ve.innerHTML=ws),Al=a(e),f(He.$$.fragment,e),Nl=a(e),Le=o(e,"P",{"data-svelte-h":!0}),p(Le)!=="svelte-1j88lhl"&&(Le.textContent=gs),zl=a(e),f(Pe.$$.fragment,e),ql=a(e),Ae=o(e,"P",{"data-svelte-h":!0}),p(Ae)!=="svelte-1k9z2lk"&&(Ae.innerHTML=vs),El=a(e),f(Ne.$$.fragment,e),Ql=a(e),ze=o(e,"P",{"data-svelte-h":!0}),p(ze)!=="svelte-16qk9l"&&(ze.textContent=_s),Yl=a(e),f(qe.$$.fragment,e),Sl=a(e),Ee=o(e,"P",{"data-svelte-h":!0}),p(Ee)!=="svelte-1gi1mku"&&(Ee.innerHTML=Cs),Dl=a(e),f(Qe.$$.fragment,e),Kl=a(e),Ye=o(e,"P",{"data-svelte-h":!0}),p(Ye)!=="svelte-1x3md4a"&&(Ye.textContent=xs),Ol=a(e),f(Se.$$.fragment,e),en=a(e),De=o(e,"P",{"data-svelte-h":!0}),p(De)!=="svelte-1r2xmm8"&&(De.innerHTML=Us),tn=a(e),f(Ke.$$.fragment,e),ln=a(e),f(k.$$.fragment,e),nn=a(e),Oe=o(e,"P",{"data-svelte-h":!0}),p(Oe)!=="svelte-1egajcb"&&(Oe.innerHTML=Ws),sn=a(e),et=o(e,"P",{"data-svelte-h":!0}),p(et)!=="svelte-1tsrdqi"&&(et.innerHTML=Zs),an=a(e),tt=o(e,"P",{"data-svelte-h":!0}),p(tt)!=="svelte-q484rg"&&(tt.innerHTML=js),on=a(e),lt=o(e,"P",{"data-svelte-h":!0}),p(lt)!=="svelte-y2mgdg"&&(lt.innerHTML=Bs),pn=a(e),nt=o(e,"P",{"data-svelte-h":!0}),p(nt)!=="svelte-12wp0pi"&&(nt.innerHTML=ks),mn=a(e),f(st.$$.fragment,e),rn=a(e),at=o(e,"UL",{"data-svelte-h":!0}),p(at)!=="svelte-1xtnufy"&&(at.innerHTML=Gs),fn=a(e),f(it.$$.fragment,e),dn=a(e),ot=o(e,"P",{"data-svelte-h":!0}),p(ot)!=="svelte-6ppaxs"&&(ot.textContent=Is),un=a(e),f(pt.$$.fragment,e),bn=a(e),mt=o(e,"P",{"data-svelte-h":!0}),p(mt)!=="svelte-fbzfro"&&(mt.textContent=Fs),Tn=a(e),rt=o(e,"UL",{"data-svelte-h":!0}),p(rt)!=="svelte-aixuph"&&(rt.innerHTML=Rs),Mn=a(e),f(ft.$$.fragment,e),cn=a(e),f(dt.$$.fragment,e),Jn=a(e),ut=o(e,"P",{"data-svelte-h":!0}),p(ut)!=="svelte-8ubh6h"&&(ut.textContent=Xs),yn=a(e),f(bt.$$.fragment,e),$n=a(e),Tt=o(e,"P",{"data-svelte-h":!0}),p(Tt)!=="svelte-bn1lgg"&&(Tt.innerHTML=Vs),hn=a(e),f(Mt.$$.fragment,e),wn=a(e),ct=o(e,"P",{"data-svelte-h":!0}),p(ct)!=="svelte-1fnofha"&&(ct.textContent=Hs),gn=a(e),f(Jt.$$.fragment,e),vn=a(e),yt=o(e,"P",{"data-svelte-h":!0}),p(yt)!=="svelte-xttkwq"&&(yt.textContent=Ls),_n=a(e),$t=o(e,"P",{"data-svelte-h":!0}),p($t)!=="svelte-1yb5ek4"&&($t.innerHTML=Ps),Cn=a(e),ht=o(e,"P",{"data-svelte-h":!0}),p(ht)!=="svelte-310aim"&&(ht.textContent=As),xn=a(e),wt=o(e,"P",{"data-svelte-h":!0}),p(wt)!=="svelte-6z7881"&&(wt.innerHTML=Ns),Un=a(e),f(gt.$$.fragment,e),Wn=a(e),vt=o(e,"P",{"data-svelte-h":!0}),p(vt)!=="svelte-1xkwmw9"&&(vt.textContent=zs),Zn=a(e),f(_t.$$.fragment,e),jn=a(e),Ct=o(e,"P",{}),Ds(Ct).forEach(l),this.h()},h(){Ks(m,"name","hf:doc:metadata"),Ks(m,"content",fa),kn(x,"text-align","center"),kn(U,"text-align","center"),kn(W,"text-align","center"),kn(Z,"text-align","center")},m(e,t){sa(document.head,m),n(e,y,t),n(e,M,t),n(e,J,t),d(v,e,t),n(e,h,t),n(e,g,t),n(e,Wt,t),d(G,e,t),n(e,Zt,t),d(_,e,t),n(e,jt,t),n(e,I,t),n(e,Bt,t),n(e,F,t),n(e,kt,t),n(e,R,t),n(e,Gt,t),n(e,X,t),n(e,It,t),n(e,V,t),n(e,Ft,t),d(C,e,t),n(e,Rt,t),d(H,e,t),n(e,Xt,t),n(e,L,t),n(e,Vt,t),d(P,e,t),n(e,Ht,t),n(e,A,t),n(e,Lt,t),d(N,e,t),n(e,Pt,t),n(e,z,t),n(e,At,t),n(e,q,t),n(e,Nt,t),n(e,E,t),n(e,zt,t),n(e,x,t),n(e,qt,t),n(e,Q,t),n(e,Et,t),n(e,U,t),n(e,Qt,t),n(e,Y,t),n(e,Yt,t),n(e,W,t),n(e,St,t),n(e,S,t),n(e,Dt,t),n(e,D,t),n(e,Kt,t),n(e,Z,t),n(e,Ot,t),d(K,e,t),n(e,el,t),n(e,O,t),n(e,tl,t),d(ee,e,t),n(e,ll,t),n(e,te,t),n(e,nl,t),d(le,e,t),n(e,sl,t),d(ne,e,t),n(e,al,t),n(e,se,t),n(e,il,t),d(ae,e,t),n(e,ol,t),d(ie,e,t),n(e,pl,t),n(e,oe,t),n(e,ml,t),d(pe,e,t),n(e,rl,t),d(me,e,t),n(e,fl,t),n(e,re,t),n(e,dl,t),n(e,fe,t),n(e,ul,t),d(j,e,t),n(e,bl,t),d(de,e,t),n(e,Tl,t),n(e,ue,t),n(e,Ml,t),n(e,be,t),n(e,cl,t),n(e,Te,t),n(e,Jl,t),d(Me,e,t),n(e,yl,t),n(e,ce,t),n(e,$l,t),d(Je,e,t),n(e,hl,t),n(e,ye,t),n(e,wl,t),d($e,e,t),n(e,gl,t),n(e,he,t),n(e,vl,t),n(e,we,t),n(e,_l,t),d(ge,e,t),n(e,Cl,t),n(e,ve,t),n(e,xl,t),d(_e,e,t),n(e,Ul,t),n(e,Ce,t),n(e,Wl,t),d(xe,e,t),n(e,Zl,t),n(e,Ue,t),n(e,jl,t),d(We,e,t),n(e,Bl,t),n(e,Ze,t),n(e,kl,t),n(e,je,t),n(e,Gl,t),n(e,Be,t),n(e,Il,t),n(e,ke,t),n(e,Fl,t),d(Ge,e,t),n(e,Rl,t),n(e,Ie,t),n(e,Xl,t),n(e,Fe,t),n(e,Vl,t),n(e,Re,t),n(e,Hl,t),d(B,e,t),n(e,Ll,t),d(Xe,e,t),n(e,Pl,t),n(e,Ve,t),n(e,Al,t),d(He,e,t),n(e,Nl,t),n(e,Le,t),n(e,zl,t),d(Pe,e,t),n(e,ql,t),n(e,Ae,t),n(e,El,t),d(Ne,e,t),n(e,Ql,t),n(e,ze,t),n(e,Yl,t),d(qe,e,t),n(e,Sl,t),n(e,Ee,t),n(e,Dl,t),d(Qe,e,t),n(e,Kl,t),n(e,Ye,t),n(e,Ol,t),d(Se,e,t),n(e,en,t),n(e,De,t),n(e,tn,t),d(Ke,e,t),n(e,ln,t),d(k,e,t),n(e,nn,t),n(e,Oe,t),n(e,sn,t),n(e,et,t),n(e,an,t),n(e,tt,t),n(e,on,t),n(e,lt,t),n(e,pn,t),n(e,nt,t),n(e,mn,t),d(st,e,t),n(e,rn,t),n(e,at,t),n(e,fn,t),d(it,e,t),n(e,dn,t),n(e,ot,t),n(e,un,t),d(pt,e,t),n(e,bn,t),n(e,mt,t),n(e,Tn,t),n(e,rt,t),n(e,Mn,t),d(ft,e,t),n(e,cn,t),d(dt,e,t),n(e,Jn,t),n(e,ut,t),n(e,yn,t),d(bt,e,t),n(e,$n,t),n(e,Tt,t),n(e,hn,t),d(Mt,e,t),n(e,wn,t),n(e,ct,t),n(e,gn,t),d(Jt,e,t),n(e,vn,t),n(e,yt,t),n(e,_n,t),n(e,$t,t),n(e,Cn,t),n(e,ht,t),n(e,xn,t),n(e,wt,t),n(e,Un,t),d(gt,e,t),n(e,Wn,t),n(e,vt,t),n(e,Zn,t),d(_t,e,t),n(e,jn,t),n(e,Ct,t),Bn=!0},p(e,[t]){const qs={};t&2&&(qs.$$scope={dirty:t,ctx:e}),_.$set(qs);const Es={};t&2&&(Es.$$scope={dirty:t,ctx:e}),C.$set(Es);const Qs={};t&2&&(Qs.$$scope={dirty:t,ctx:e}),j.$set(Qs);const Ys={};t&2&&(Ys.$$scope={dirty:t,ctx:e}),B.$set(Ys);const Ss={};t&2&&(Ss.$$scope={dirty:t,ctx:e}),k.$set(Ss)},i(e){Bn||(u(v.$$.fragment,e),u(G.$$.fragment,e),u(_.$$.fragment,e),u(C.$$.fragment,e),u(H.$$.fragment,e),u(P.$$.fragment,e),u(N.$$.fragment,e),u(K.$$.fragment,e),u(ee.$$.fragment,e),u(le.$$.fragment,e),u(ne.$$.fragment,e),u(ae.$$.fragment,e),u(ie.$$.fragment,e),u(pe.$$.fragment,e),u(me.$$.fragment,e),u(j.$$.fragment,e),u(de.$$.fragment,e),u(Me.$$.fragment,e),u(Je.$$.fragment,e),u($e.$$.fragment,e),u(ge.$$.fragment,e),u(_e.$$.fragment,e),u(xe.$$.fragment,e),u(We.$$.fragment,e),u(Ge.$$.fragment,e),u(B.$$.fragment,e),u(Xe.$$.fragment,e),u(He.$$.fragment,e),u(Pe.$$.fragment,e),u(Ne.$$.fragment,e),u(qe.$$.fragment,e),u(Qe.$$.fragment,e),u(Se.$$.fragment,e),u(Ke.$$.fragment,e),u(k.$$.fragment,e),u(st.$$.fragment,e),u(it.$$.fragment,e),u(pt.$$.fragment,e),u(ft.$$.fragment,e),u(dt.$$.fragment,e),u(bt.$$.fragment,e),u(Mt.$$.fragment,e),u(Jt.$$.fragment,e),u(gt.$$.fragment,e),u(_t.$$.fragment,e),Bn=!0)},o(e){b(v.$$.fragment,e),b(G.$$.fragment,e),b(_.$$.fragment,e),b(C.$$.fragment,e),b(H.$$.fragment,e),b(P.$$.fragment,e),b(N.$$.fragment,e),b(K.$$.fragment,e),b(ee.$$.fragment,e),b(le.$$.fragment,e),b(ne.$$.fragment,e),b(ae.$$.fragment,e),b(ie.$$.fragment,e),b(pe.$$.fragment,e),b(me.$$.fragment,e),b(j.$$.fragment,e),b(de.$$.fragment,e),b(Me.$$.fragment,e),b(Je.$$.fragment,e),b($e.$$.fragment,e),b(ge.$$.fragment,e),b(_e.$$.fragment,e),b(xe.$$.fragment,e),b(We.$$.fragment,e),b(Ge.$$.fragment,e),b(B.$$.fragment,e),b(Xe.$$.fragment,e),b(He.$$.fragment,e),b(Pe.$$.fragment,e),b(Ne.$$.fragment,e),b(qe.$$.fragment,e),b(Qe.$$.fragment,e),b(Se.$$.fragment,e),b(Ke.$$.fragment,e),b(k.$$.fragment,e),b(st.$$.fragment,e),b(it.$$.fragment,e),b(pt.$$.fragment,e),b(ft.$$.fragment,e),b(dt.$$.fragment,e),b(bt.$$.fragment,e),b(Mt.$$.fragment,e),b(Jt.$$.fragment,e),b(gt.$$.fragment,e),b(_t.$$.fragment,e),Bn=!1},d(e){e&&(l(y),l(M),l(J),l(h),l(g),l(Wt),l(Zt),l(jt),l(I),l(Bt),l(F),l(kt),l(R),l(Gt),l(X),l(It),l(V),l(Ft),l(Rt),l(Xt),l(L),l(Vt),l(Ht),l(A),l(Lt),l(Pt),l(z),l(At),l(q),l(Nt),l(E),l(zt),l(x),l(qt),l(Q),l(Et),l(U),l(Qt),l(Y),l(Yt),l(W),l(St),l(S),l(Dt),l(D),l(Kt),l(Z),l(Ot),l(el),l(O),l(tl),l(ll),l(te),l(nl),l(sl),l(al),l(se),l(il),l(ol),l(pl),l(oe),l(ml),l(rl),l(fl),l(re),l(dl),l(fe),l(ul),l(bl),l(Tl),l(ue),l(Ml),l(be),l(cl),l(Te),l(Jl),l(yl),l(ce),l($l),l(hl),l(ye),l(wl),l(gl),l(he),l(vl),l(we),l(_l),l(Cl),l(ve),l(xl),l(Ul),l(Ce),l(Wl),l(Zl),l(Ue),l(jl),l(Bl),l(Ze),l(kl),l(je),l(Gl),l(Be),l(Il),l(ke),l(Fl),l(Rl),l(Ie),l(Xl),l(Fe),l(Vl),l(Re),l(Hl),l(Ll),l(Pl),l(Ve),l(Al),l(Nl),l(Le),l(zl),l(ql),l(Ae),l(El),l(Ql),l(ze),l(Yl),l(Sl),l(Ee),l(Dl),l(Kl),l(Ye),l(Ol),l(en),l(De),l(tn),l(ln),l(nn),l(Oe),l(sn),l(et),l(an),l(tt),l(on),l(lt),l(pn),l(nt),l(mn),l(rn),l(at),l(fn),l(dn),l(ot),l(un),l(bn),l(mt),l(Tn),l(rt),l(Mn),l(cn),l(Jn),l(ut),l(yn),l($n),l(Tt),l(hn),l(wn),l(ct),l(gn),l(vn),l(yt),l(_n),l($t),l(Cn),l(ht),l(xn),l(wt),l(Un),l(Wn),l(vt),l(Zn),l(jn),l(Ct)),l(m),T(v,e),T(G,e),T(_,e),T(C,e),T(H,e),T(P,e),T(N,e),T(K,e),T(ee,e),T(le,e),T(ne,e),T(ae,e),T(ie,e),T(pe,e),T(me,e),T(j,e),T(de,e),T(Me,e),T(Je,e),T($e,e),T(ge,e),T(_e,e),T(xe,e),T(We,e),T(Ge,e),T(B,e),T(Xe,e),T(He,e),T(Pe,e),T(Ne,e),T(qe,e),T(Qe,e),T(Se,e),T(Ke,e),T(k,e),T(st,e),T(it,e),T(pt,e),T(ft,e),T(dt,e),T(bt,e),T(Mt,e),T(Jt,e),T(gt,e),T(_t,e)}}}const fa='{"title":"Efficient Inference on a Single GPU","local":"efficient-inference-on-a-single-gpu","sections":[{"title":"Flash Attention 2","local":"flash-attention-2","sections":[{"title":"Quick usage","local":"quick-usage","sections":[],"depth":3},{"title":"Expected speedups","local":"expected-speedups","sections":[],"depth":3},{"title":"Advanced usage","local":"advanced-usage","sections":[],"depth":3},{"title":"Combining Flash Attention 2 and 8-bit models","local":"combining-flash-attention-2-and-8-bit-models","sections":[],"depth":3},{"title":"Combining Flash Attention 2 and 4-bit models","local":"combining-flash-attention-2-and-4-bit-models","sections":[],"depth":3},{"title":"Combining Flash Attention 2 and PEFT","local":"combining-flash-attention-2-and-peft","sections":[],"depth":3}],"depth":2},{"title":"BetterTransformer","local":"bettertransformer","sections":[{"title":"Encoder models","local":"encoder-models","sections":[],"depth":3},{"title":"Decoder models","local":"decoder-models","sections":[],"depth":3}],"depth":2},{"title":"bitsandbytes integration for FP4 mixed-precision inference","local":"bitsandbytes-integration-for-fp4-mixed-precision-inference","sections":[{"title":"Requirements","local":"requirements-for-fp4-mixedprecision-inference","sections":[],"depth":3},{"title":"Running FP4 models - single GPU setup - Quickstart","local":"running-fp4-models---single-gpu-setup---quickstart","sections":[],"depth":3},{"title":"Running FP4 models - multi GPU setup","local":"running-fp4-models---multi-gpu-setup","sections":[],"depth":3},{"title":"Advanced usage","local":"advanced-usage","sections":[],"depth":3}],"depth":2},{"title":"bitsandbytes integration for Int8 mixed-precision matrix decomposition","local":"bitsandbytes-integration-for-int8-mixed-precision-matrix-decomposition","sections":[{"title":"Requirements","local":"requirements-for-int8-mixedprecision-matrix-decomposition","sections":[],"depth":3},{"title":"Running mixed-Int8 models - single GPU setup","local":"running-mixed-int8-models---single-gpu-setup","sections":[],"depth":3},{"title":"Running mixed-int8 models - multi GPU setup","local":"running-mixed-int8-models---multi-gpu-setup","sections":[],"depth":3},{"title":"Colab demos","local":"colab-demos","sections":[],"depth":3}],"depth":2},{"title":"Advanced usage: mixing FP4 (or Int8) and BetterTransformer","local":"advanced-usage-mixing-fp4-or-int8-and-bettertransformer","sections":[],"depth":2}],"depth":1}';function da(w){return ea(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ja extends ta{constructor(m){super(),la(this,m,da,ra,Os,{})}}export{Ja as component};
