import{s as Ae,o as He,n as Me}from"../chunks/scheduler.9bc65507.js";import{S as Re,i as Xe,g as d,s as m,r as g,A as Ee,h as $,f as t,c as i,j as Fe,u as y,x as w,k as Ue,y as Le,a as l,v as M,d as _,t as v,w as Z}from"../chunks/index.707bf1b6.js";import{T as Ge}from"../chunks/Tip.c2ecdbf4.js";import{C as G}from"../chunks/CodeBlock.54a9f38d.js";import{F as Ne,M as Ve}from"../chunks/Markdown.8ab98a13.js";import{H as O}from"../chunks/Heading.342b1fa6.js";function Ye(J){let a,u=`アーキテクチャはモデルの骨格を指し、チェックポイントは特定のアーキテクチャの重みです。
たとえば、<a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a>はアーキテクチャであり、<code>google-bert/bert-base-uncased</code>はチェックポイントです。
モデルはアーキテクチャまたはチェックポイントのどちらを指す一般的な用語です。`;return{c(){a=d("p"),a.innerHTML=u},l(n){a=$(n,"P",{"data-svelte-h":!0}),w(a)!=="svelte-67bfjz"&&(a.innerHTML=u)},m(n,p){l(n,a,p)},p:Me,d(n){n&&t(a)}}}function ze(J){let a,u=`PyTorchモデルの場合、  <code>from_pretrained()</code>メソッドは内部で<code>torch.load()</code>を使用し、内部的には<code>pickle</code>を使用しており、セキュリティの問題が知られています。
一般的には、信頼性のないソースから取得した可能性があるモデルや改ざんされた可能性のあるモデルをロードしないでください。
このセキュリティリスクは、<code>Hugging Face Hub</code>でホストされている公開モデルに対して部分的に緩和されており、各コミットでマルウェアのスキャンが行われています。
GPGを使用した署名済みコミットの検証などのベストプラクティスについては、Hubのドキュメンテーションを参照してください。`,n,p,f="TensorFlowおよびFlaxのチェックポイントには影響がなく、<code>from_pretrained</code>メソッドの<code>from_tf</code>および<code>from_flax</code>引数を使用してPyTorchアーキテクチャ内でロードできます。";return{c(){a=d("p"),a.innerHTML=u,n=m(),p=d("p"),p.innerHTML=f},l(c){a=$(c,"P",{"data-svelte-h":!0}),w(a)!=="svelte-ts070b"&&(a.innerHTML=u),n=i(c),p=$(c,"P",{"data-svelte-h":!0}),w(p)!=="svelte-8g2s5o"&&(p.innerHTML=f)},m(c,x){l(c,a,x),l(c,n,x),l(c,p,x)},p:Me,d(c){c&&(t(a),t(n),t(p))}}}function Pe(J){let a,u=`最後に、<code>AutoModelFor</code>クラスは特定のタスクに対して事前学習済みモデルをロードできます（使用可能なタスクの完全な一覧については<a href="model_doc/auto">こちら</a>を参照）。
たとえば、<a href="/docs/transformers/main/ja/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained">AutoModelForSequenceClassification.from_pretrained()</a>を使用してシーケンス分類用のモデルをロードできます：`,n,p,f,c,x="同じチェックポイントを再利用して異なるタスクのアーキテクチャをロードできます：",F,j,C,h,k,W,o=`一般的に、事前学習済みモデルのインスタンスをロードするために<code>AutoTokenizer</code>クラスと<code>AutoModelFor</code>クラスの使用をお勧めします。
これにより、常に正しいアーキテクチャをロードできます。
次の<a href="preprocessing">tutorial</a>では、新しくロードしたトークナイザ、画像プロセッサ、特徴量抽出器、およびプロセッサを使用して、ファインチューニング用にデータセットを前処理する方法を学びます。`,b;return p=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),j=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),h=new Ge({props:{warning:!0,$$slots:{default:[ze]},$$scope:{ctx:J}}}),{c(){a=d("p"),a.innerHTML=u,n=m(),g(p.$$.fragment),f=m(),c=d("p"),c.textContent=x,F=m(),g(j.$$.fragment),C=m(),g(h.$$.fragment),k=m(),W=d("p"),W.innerHTML=o},l(r){a=$(r,"P",{"data-svelte-h":!0}),w(a)!=="svelte-1ymptvi"&&(a.innerHTML=u),n=i(r),y(p.$$.fragment,r),f=i(r),c=$(r,"P",{"data-svelte-h":!0}),w(c)!=="svelte-1tpango"&&(c.textContent=x),F=i(r),y(j.$$.fragment,r),C=i(r),y(h.$$.fragment,r),k=i(r),W=$(r,"P",{"data-svelte-h":!0}),w(W)!=="svelte-3t6p8p"&&(W.innerHTML=o)},m(r,T){l(r,a,T),l(r,n,T),M(p,r,T),l(r,f,T),l(r,c,T),l(r,F,T),M(j,r,T),l(r,C,T),M(h,r,T),l(r,k,T),l(r,W,T),b=!0},p(r,T){const U={};T&2&&(U.$$scope={dirty:T,ctx:r}),h.$set(U)},i(r){b||(_(p.$$.fragment,r),_(j.$$.fragment,r),_(h.$$.fragment,r),b=!0)},o(r){v(p.$$.fragment,r),v(j.$$.fragment,r),v(h.$$.fragment,r),b=!1},d(r){r&&(t(a),t(n),t(f),t(c),t(F),t(C),t(k),t(W)),Z(p,r),Z(j,r),Z(h,r)}}}function qe(J){let a,u;return a=new Ve({props:{$$slots:{default:[Pe]},$$scope:{ctx:J}}}),{c(){g(a.$$.fragment)},l(n){y(a.$$.fragment,n)},m(n,p){M(a,n,p),u=!0},p(n,p){const f={};p&2&&(f.$$scope={dirty:p,ctx:n}),a.$set(f)},i(n){u||(_(a.$$.fragment,n),u=!0)},o(n){v(a.$$.fragment,n),u=!1},d(n){Z(a,n)}}}function Ie(J){let a,u=`最後に、<code>TFAutoModelFor</code>クラスは特定のタスクに対して事前学習済みモデルをロードできます（使用可能なタスクの完全な一覧についてはこちらを参照）。
たとえば、<a href="/docs/transformers/main/ja/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained">TFAutoModelForSequenceClassification.from_pretrained()</a>を使用してシーケンス分類用のモデルをロードできます：`,n,p,f,c,x="同じチェックポイントを再利用して異なるタスクのアーキテクチャをロードできます：",F,j,C,h,k=`一般的には、事前学習済みモデルのインスタンスをロードするために<code>AutoTokenizer</code>クラスと<code>TFAutoModelFor</code>クラスの使用をお勧めします。
これにより、常に正しいアーキテクチャをロードできます。
次の<a href="preproccesing">tutorial</a>では、新しくロードしたトークナイザ、画像プロセッサ、特徴量抽出器、およびプロセッサを使用して、ファインチューニング用にデータセットを前処理する方法を学びます。`,W;return p=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),j=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){a=d("p"),a.innerHTML=u,n=m(),g(p.$$.fragment),f=m(),c=d("p"),c.textContent=x,F=m(),g(j.$$.fragment),C=m(),h=d("p"),h.innerHTML=k},l(o){a=$(o,"P",{"data-svelte-h":!0}),w(a)!=="svelte-1cepnq9"&&(a.innerHTML=u),n=i(o),y(p.$$.fragment,o),f=i(o),c=$(o,"P",{"data-svelte-h":!0}),w(c)!=="svelte-1tpango"&&(c.textContent=x),F=i(o),y(j.$$.fragment,o),C=i(o),h=$(o,"P",{"data-svelte-h":!0}),w(h)!=="svelte-1jy5kde"&&(h.innerHTML=k)},m(o,b){l(o,a,b),l(o,n,b),M(p,o,b),l(o,f,b),l(o,c,b),l(o,F,b),M(j,o,b),l(o,C,b),l(o,h,b),W=!0},p:Me,i(o){W||(_(p.$$.fragment,o),_(j.$$.fragment,o),W=!0)},o(o){v(p.$$.fragment,o),v(j.$$.fragment,o),W=!1},d(o){o&&(t(a),t(n),t(f),t(c),t(F),t(C),t(h)),Z(p,o),Z(j,o)}}}function Qe(J){let a,u;return a=new Ve({props:{$$slots:{default:[Ie]},$$scope:{ctx:J}}}),{c(){g(a.$$.fragment)},l(n){y(a.$$.fragment,n)},m(n,p){M(a,n,p),u=!0},p(n,p){const f={};p&2&&(f.$$scope={dirty:p,ctx:n}),a.$set(f)},i(n){u||(_(a.$$.fragment,n),u=!0)},o(n){v(a.$$.fragment,n),u=!1},d(n){Z(a,n)}}}function Be(J){let a,u,n,p,f,c,x,F=`さまざまなTransformerアーキテクチャが存在するため、自分のタスクに合ったモデルを作成するのは難しいことがあります。
🤗 Transformersのコア哲学の一環として、ライブラリを使用しやすく、シンプルで柔軟にするために、
<code>AutoClass</code>は与えられたチェックポイントから正しいアーキテクチャを自動的に推論してロードします。
<code>from_pretrained()</code>メソッドを使用すると、事前学習済みモデルを素早くロードできるため、モデルをゼロからトレーニングするために時間とリソースを費やす必要がありません。
この種のチェックポイントに依存しないコードを生成することは、
コードが1つのチェックポイントで動作すれば、アーキテクチャが異なっていても、同じタスクに向けてトレーニングされた場合は別のチェックポイントでも動作することを意味します。`,j,C,h,k,W="このチュートリアルでは、以下を学習します：",o,b,r="<li>事前学習済みトークナイザをロードする。</li> <li>事前学習済み画像プロセッサをロードする。</li> <li>事前学習済み特徴量抽出器をロードする。</li> <li>事前学習済みプロセッサをロードする。</li> <li>事前学習済みモデルをロードする。</li>",T,U,te,A,_e="ほとんどのNLPタスクはトークナイザで始まります。トークナイザは入力をモデルで処理できる形式に変換します。",se,H,ve='<a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoTokenizer.from_pretrained">AutoTokenizer.from_pretrained()</a>を使用してトークナイザをロードします：',ae,R,le,X,Ze="次に、以下のように入力をトークナイズします：",ne,E,re,L,pe,N,we="ビジョンタスクの場合、画像プロセッサが画像を正しい入力形式に変換します。",oe,Y,me,z,ie,P,Te="オーディオタスクの場合、特徴量抽出器がオーディオ信号を正しい入力形式に変換します。",ce,q,Ce='<a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained">AutoFeatureExtractor.from_pretrained()</a>を使用して特徴量抽出器をロードします.',ue,I,fe,Q,de,B,xe=`マルチモーダルタスクの場合、2つの前処理ツールを組み合わせるプロセッサが必要です。たとえば、
<a href="model_doc/layoutlmv2">LayoutLMV2</a>モデルは画像を処理するための画像プロセッサとテキストを処理するためのトークナイザが必要です。
プロセッサはこれらの両方を組み合わせます。`,$e,S,ke='<a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoProcessor.from_pretrained">AutoProcessor.from_pretrained()</a>を使用してプロセッサをロードします：',be,K,he,D,je,V,ge,ee,ye;return f=new O({props:{title:"AutoClassを使用して事前学習済みインスタンスをロードする",local:"autoclassを使用して事前学習済みインスタンスをロードする",headingTag:"h1"}}),C=new Ge({props:{$$slots:{default:[Ye]},$$scope:{ctx:J}}}),U=new O({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h2"}}),R=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),E=new G({props:{code:"c2VxdWVuY2UlMjAlM0QlMjAlMjJJbiUyMGElMjBob2xlJTIwaW4lMjB0aGUlMjBncm91bmQlMjB0aGVyZSUyMGxpdmVkJTIwYSUyMGhvYmJpdC4lMjIlMEFwcmludCh0b2tlbml6ZXIoc2VxdWVuY2UpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),L=new O({props:{title:"AutoImageProcessor",local:"autoimageprocessor",headingTag:"h2"}}),Y=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGdml0LWJhc2UtcGF0Y2gxNi0yMjQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224&quot;</span>)`,wrap:!1}}),z=new O({props:{title:"AutoFeatureExtractor",local:"autofeatureextractor",headingTag:"h2"}}),I=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZWhjYWxhYnJlcyUyRndhdjJ2ZWMyLWxnLXhsc3ItZW4tc3BlZWNoLWVtb3Rpb24tcmVjb2duaXRpb24lMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),Q=new O({props:{title:"AutoProcessor",local:"autoprocessor",headingTag:"h2"}}),K=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZsYXlvdXRsbXYyLWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`,wrap:!1}}),D=new O({props:{title:"AutoModel",local:"automodel",headingTag:"h2"}}),V=new Ne({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Qe],pytorch:[qe]},$$scope:{ctx:J}}}),{c(){a=d("meta"),u=m(),n=d("p"),p=m(),g(f.$$.fragment),c=m(),x=d("p"),x.innerHTML=F,j=m(),g(C.$$.fragment),h=m(),k=d("p"),k.textContent=W,o=m(),b=d("ul"),b.innerHTML=r,T=m(),g(U.$$.fragment),te=m(),A=d("p"),A.textContent=_e,se=m(),H=d("p"),H.innerHTML=ve,ae=m(),g(R.$$.fragment),le=m(),X=d("p"),X.textContent=Ze,ne=m(),g(E.$$.fragment),re=m(),g(L.$$.fragment),pe=m(),N=d("p"),N.textContent=we,oe=m(),g(Y.$$.fragment),me=m(),g(z.$$.fragment),ie=m(),P=d("p"),P.textContent=Te,ce=m(),q=d("p"),q.innerHTML=Ce,ue=m(),g(I.$$.fragment),fe=m(),g(Q.$$.fragment),de=m(),B=d("p"),B.innerHTML=xe,$e=m(),S=d("p"),S.innerHTML=ke,be=m(),g(K.$$.fragment),he=m(),g(D.$$.fragment),je=m(),g(V.$$.fragment),ge=m(),ee=d("p"),this.h()},l(e){const s=Ee("svelte-u9bgzb",document.head);a=$(s,"META",{name:!0,content:!0}),s.forEach(t),u=i(e),n=$(e,"P",{}),Fe(n).forEach(t),p=i(e),y(f.$$.fragment,e),c=i(e),x=$(e,"P",{"data-svelte-h":!0}),w(x)!=="svelte-1c2g9e5"&&(x.innerHTML=F),j=i(e),y(C.$$.fragment,e),h=i(e),k=$(e,"P",{"data-svelte-h":!0}),w(k)!=="svelte-1ynjf2f"&&(k.textContent=W),o=i(e),b=$(e,"UL",{"data-svelte-h":!0}),w(b)!=="svelte-9qif62"&&(b.innerHTML=r),T=i(e),y(U.$$.fragment,e),te=i(e),A=$(e,"P",{"data-svelte-h":!0}),w(A)!=="svelte-13tjdrf"&&(A.textContent=_e),se=i(e),H=$(e,"P",{"data-svelte-h":!0}),w(H)!=="svelte-osuuxm"&&(H.innerHTML=ve),ae=i(e),y(R.$$.fragment,e),le=i(e),X=$(e,"P",{"data-svelte-h":!0}),w(X)!=="svelte-stayvz"&&(X.textContent=Ze),ne=i(e),y(E.$$.fragment,e),re=i(e),y(L.$$.fragment,e),pe=i(e),N=$(e,"P",{"data-svelte-h":!0}),w(N)!=="svelte-7ri6lq"&&(N.textContent=we),oe=i(e),y(Y.$$.fragment,e),me=i(e),y(z.$$.fragment,e),ie=i(e),P=$(e,"P",{"data-svelte-h":!0}),w(P)!=="svelte-1lzhwa3"&&(P.textContent=Te),ce=i(e),q=$(e,"P",{"data-svelte-h":!0}),w(q)!=="svelte-1aj3yy2"&&(q.innerHTML=Ce),ue=i(e),y(I.$$.fragment,e),fe=i(e),y(Q.$$.fragment,e),de=i(e),B=$(e,"P",{"data-svelte-h":!0}),w(B)!=="svelte-19hdpt"&&(B.innerHTML=xe),$e=i(e),S=$(e,"P",{"data-svelte-h":!0}),w(S)!=="svelte-hedd06"&&(S.innerHTML=ke),be=i(e),y(K.$$.fragment,e),he=i(e),y(D.$$.fragment,e),je=i(e),y(V.$$.fragment,e),ge=i(e),ee=$(e,"P",{}),Fe(ee).forEach(t),this.h()},h(){Ue(a,"name","hf:doc:metadata"),Ue(a,"content",Se)},m(e,s){Le(document.head,a),l(e,u,s),l(e,n,s),l(e,p,s),M(f,e,s),l(e,c,s),l(e,x,s),l(e,j,s),M(C,e,s),l(e,h,s),l(e,k,s),l(e,o,s),l(e,b,s),l(e,T,s),M(U,e,s),l(e,te,s),l(e,A,s),l(e,se,s),l(e,H,s),l(e,ae,s),M(R,e,s),l(e,le,s),l(e,X,s),l(e,ne,s),M(E,e,s),l(e,re,s),M(L,e,s),l(e,pe,s),l(e,N,s),l(e,oe,s),M(Y,e,s),l(e,me,s),M(z,e,s),l(e,ie,s),l(e,P,s),l(e,ce,s),l(e,q,s),l(e,ue,s),M(I,e,s),l(e,fe,s),M(Q,e,s),l(e,de,s),l(e,B,s),l(e,$e,s),l(e,S,s),l(e,be,s),M(K,e,s),l(e,he,s),M(D,e,s),l(e,je,s),M(V,e,s),l(e,ge,s),l(e,ee,s),ye=!0},p(e,[s]){const We={};s&2&&(We.$$scope={dirty:s,ctx:e}),C.$set(We);const Je={};s&2&&(Je.$$scope={dirty:s,ctx:e}),V.$set(Je)},i(e){ye||(_(f.$$.fragment,e),_(C.$$.fragment,e),_(U.$$.fragment,e),_(R.$$.fragment,e),_(E.$$.fragment,e),_(L.$$.fragment,e),_(Y.$$.fragment,e),_(z.$$.fragment,e),_(I.$$.fragment,e),_(Q.$$.fragment,e),_(K.$$.fragment,e),_(D.$$.fragment,e),_(V.$$.fragment,e),ye=!0)},o(e){v(f.$$.fragment,e),v(C.$$.fragment,e),v(U.$$.fragment,e),v(R.$$.fragment,e),v(E.$$.fragment,e),v(L.$$.fragment,e),v(Y.$$.fragment,e),v(z.$$.fragment,e),v(I.$$.fragment,e),v(Q.$$.fragment,e),v(K.$$.fragment,e),v(D.$$.fragment,e),v(V.$$.fragment,e),ye=!1},d(e){e&&(t(u),t(n),t(p),t(c),t(x),t(j),t(h),t(k),t(o),t(b),t(T),t(te),t(A),t(se),t(H),t(ae),t(le),t(X),t(ne),t(re),t(pe),t(N),t(oe),t(me),t(ie),t(P),t(ce),t(q),t(ue),t(fe),t(de),t(B),t($e),t(S),t(be),t(he),t(je),t(ge),t(ee)),t(a),Z(f,e),Z(C,e),Z(U,e),Z(R,e),Z(E,e),Z(L,e),Z(Y,e),Z(z,e),Z(I,e),Z(Q,e),Z(K,e),Z(D,e),Z(V,e)}}}const Se='{"title":"AutoClassを使用して事前学習済みインスタンスをロードする","local":"autoclassを使用して事前学習済みインスタンスをロードする","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":2},{"title":"AutoImageProcessor","local":"autoimageprocessor","sections":[],"depth":2},{"title":"AutoFeatureExtractor","local":"autofeatureextractor","sections":[],"depth":2},{"title":"AutoProcessor","local":"autoprocessor","sections":[],"depth":2},{"title":"AutoModel","local":"automodel","sections":[],"depth":2}],"depth":1}';function Ke(J){return He(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class lt extends Re{constructor(a){super(),Xe(this,a,Ke,Be,Ae,{})}}export{lt as component};
