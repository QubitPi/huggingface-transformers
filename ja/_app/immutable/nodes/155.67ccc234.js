import{s as ra,o as ia,n as cs}from"../chunks/scheduler.9bc65507.js";import{S as ca,i as oa,g,s as i,r as j,A as ma,h as w,f as a,c,j as aa,u as h,x as J,k as ta,y as Ma,a as e,v as d,d as u,t as f,w as y,m as na,n as pa}from"../chunks/index.707bf1b6.js";import{T as vl}from"../chunks/Tip.c2ecdbf4.js";import{Y as ea}from"../chunks/Youtube.e1129c6f.js";import{C as _}from"../chunks/CodeBlock.54a9f38d.js";import{D as ja}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as Bl,M as Ls}from"../chunks/Markdown.8ab98a13.js";import{H as qs}from"../chunks/Heading.342b1fa6.js";function ha(C){let t,o,l='<a href="../model_doc/albert">ALBERT</a>, <a href="../model_doc/bert">BERT</a>, <a href="../model_doc/big_bird">BigBird</a>, <a href="../model_doc/biogpt">BioGpt</a>, <a href="../model_doc/bloom">BLOOM</a>, <a href="../model_doc/bros">BROS</a>, <a href="../model_doc/camembert">CamemBERT</a>, <a href="../model_doc/canine">CANINE</a>, <a href="../model_doc/convbert">ConvBERT</a>, <a href="../model_doc/data2vec-text">Data2VecText</a>, <a href="../model_doc/deberta">DeBERTa</a>, <a href="../model_doc/deberta-v2">DeBERTa-v2</a>, <a href="../model_doc/distilbert">DistilBERT</a>, <a href="../model_doc/electra">ELECTRA</a>, <a href="../model_doc/ernie">ERNIE</a>, <a href="../model_doc/ernie_m">ErnieM</a>, <a href="../model_doc/esm">ESM</a>, <a href="../model_doc/falcon">Falcon</a>, <a href="../model_doc/flaubert">FlauBERT</a>, <a href="../model_doc/fnet">FNet</a>, <a href="../model_doc/funnel">Funnel Transformer</a>, <a href="../model_doc/gpt-sw3">GPT-Sw3</a>, <a href="../model_doc/gpt2">OpenAI GPT-2</a>, <a href="../model_doc/gpt_bigcode">GPTBigCode</a>, <a href="../model_doc/gpt_neo">GPT Neo</a>, <a href="../model_doc/gpt_neox">GPT NeoX</a>, <a href="../model_doc/ibert">I-BERT</a>, <a href="../model_doc/layoutlm">LayoutLM</a>, <a href="../model_doc/layoutlmv2">LayoutLMv2</a>, <a href="../model_doc/layoutlmv3">LayoutLMv3</a>, <a href="../model_doc/lilt">LiLT</a>, <a href="../model_doc/longformer">Longformer</a>, <a href="../model_doc/luke">LUKE</a>, <a href="../model_doc/markuplm">MarkupLM</a>, <a href="../model_doc/mega">MEGA</a>, <a href="../model_doc/megatron-bert">Megatron-BERT</a>, <a href="../model_doc/mobilebert">MobileBERT</a>, <a href="../model_doc/mpnet">MPNet</a>, <a href="../model_doc/mpt">MPT</a>, <a href="../model_doc/mra">MRA</a>, <a href="../model_doc/nezha">Nezha</a>, <a href="../model_doc/nystromformer">Nyströmformer</a>, <a href="../model_doc/qdqbert">QDQBert</a>, <a href="../model_doc/rembert">RemBERT</a>, <a href="../model_doc/roberta">RoBERTa</a>, <a href="../model_doc/roberta-prelayernorm">RoBERTa-PreLayerNorm</a>, <a href="../model_doc/roc_bert">RoCBert</a>, <a href="../model_doc/roformer">RoFormer</a>, <a href="../model_doc/squeezebert">SqueezeBERT</a>, <a href="../model_doc/xlm">XLM</a>, <a href="../model_doc/xlm-roberta">XLM-RoBERTa</a>, <a href="../model_doc/xlm-roberta-xl">XLM-RoBERTa-XL</a>, <a href="../model_doc/xlnet">XLNet</a>, <a href="../model_doc/xmod">X-MOD</a>, <a href="../model_doc/yoso">YOSO</a>';return{c(){t=na(`このチュートリアルで説明するタスクは、次のモデル アーキテクチャでサポートされています。

`),o=g("p"),o.innerHTML=l},l(m){t=pa(m,`このチュートリアルで説明するタスクは、次のモデル アーキテクチャでサポートされています。

`),o=w(m,"P",{"data-svelte-h":!0}),J(o)!=="svelte-1kspzor"&&(o.innerHTML=l)},m(m,b){e(m,t,b),e(m,o,b)},p:cs,d(m){m&&(a(t),a(o))}}}function da(C){let t,o;return t=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGF0YUNvbGxhdG9yRm9yVG9rZW5DbGFzc2lmaWNhdGlvbih0b2tlbml6ZXIlM0R0b2tlbml6ZXIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)`,wrap:!1}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p:cs,i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function ua(C){let t,o;return t=new Ls({props:{$$slots:{default:[da]},$$scope:{ctx:C}}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p(l,m){const b={};m&2&&(b.$$scope={dirty:m,ctx:l}),t.$set(b)},i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function fa(C){let t,o;return t=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGF0YUNvbGxhdG9yRm9yVG9rZW5DbGFzc2lmaWNhdGlvbih0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p:cs,i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function ya(C){let t,o;return t=new Ls({props:{$$slots:{default:[fa]},$$scope:{ctx:C}}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p(l,m){const b={};m&2&&(b.$$scope={dirty:m,ctx:l}),t.$set(b)},i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function ba(C){let t,o='<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> を使用したモデルの微調整に慣れていない場合は、<a href="../training#train-with-pytorch-trainer">ここ</a> の基本的なチュートリアルをご覧ください。';return{c(){t=g("p"),t.innerHTML=o},l(l){t=w(l,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1ubngji"&&(t.innerHTML=o)},m(l,m){e(l,t,m)},p:cs,d(l){l&&a(t)}}}function ga(C){let t,o,l,m='これでモデルのトレーニングを開始する準備が整いました。 <a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoModelForTokenClassification">AutoModelForTokenClassification</a> を使用して、予期されるラベルの数とラベル マッピングを指定して DistilBERT を読み込みます。',b,k,A,v,I="この時点で残っているステップは 3 つだけです。",B,x,E='<li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> でトレーニング ハイパーパラメータを定義します。唯一の必須パラメータは、モデルの保存場所を指定する <code>output_dir</code> です。 <code>push_to_hub=True</code>を設定して、このモデルをハブにプッシュします (モデルをアップロードするには、Hugging Face にサインインする必要があります)。各エポックの終了時に、<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> は連続スコアを評価し、トレーニング チェックポイントを保存します。</li> <li>トレーニング引数を、モデル、データセット、トークナイザー、データ照合器、および <code>compute_metrics</code> 関数とともに <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> に渡します。</li> <li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train">train()</a> を呼び出してモデルを微調整します。</li>',G,$,R,r,U='トレーニングが完了したら、 <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> メソッドを使用してモデルをハブに共有し、誰もがモデルを使用できるようにします。',V,X,W;return t=new vl({props:{$$slots:{default:[ba]},$$scope:{ctx:C}}}),k=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMkMlMjBUcmFpbmluZ0FyZ3VtZW50cyUyQyUyMFRyYWluZXIlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMiUyQyUyMG51bV9sYWJlbHMlM0QxMyUyQyUyMGlkMmxhYmVsJTNEaWQybGFiZWwlMkMlMjBsYWJlbDJpZCUzRGxhYmVsMmlkJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>, num_labels=<span class="hljs-number">13</span>, id2label=id2label, label2id=label2id
<span class="hljs-meta">... </span>)`,wrap:!1}}),$=new _({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX3dudXRfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjBsZWFybmluZ19yYXRlJTNEMmUtNSUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMG51bV90cmFpbl9lcG9jaHMlM0QyJTJDJTBBJTIwJTIwJTIwJTIwd2VpZ2h0X2RlY2F5JTNEMC4wMSUyQyUwQSUyMCUyMCUyMCUyMGV2YWx1YXRpb25fc3RyYXRlZ3klM0QlMjJlcG9jaCUyMiUyQyUwQSUyMCUyMCUyMCUyMHNhdmVfc3RyYXRlZ3klM0QlMjJlcG9jaCUyMiUyQyUwQSUyMCUyMCUyMCUyMGxvYWRfYmVzdF9tb2RlbF9hdF9lbmQlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0R0b2tlbml6ZWRfd251dCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEdG9rZW5pemVkX3dudXQlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwdG9rZW5pemVyJTNEdG9rZW5pemVyJTJDJTBBJTIwJTIwJTIwJTIwZGF0YV9jb2xsYXRvciUzRGRhdGFfY29sbGF0b3IlMkMlMEElMjAlMjAlMjAlMjBjb21wdXRlX21ldHJpY3MlM0Rjb21wdXRlX21ldHJpY3MlMkMlMEEpJTBBJTBBdHJhaW5lci50cmFpbigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_wnut_model&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    load_best_model_at_end=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=tokenized_wnut[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=tokenized_wnut[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),X=new _({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){j(t.$$.fragment),o=i(),l=g("p"),l.innerHTML=m,b=i(),j(k.$$.fragment),A=i(),v=g("p"),v.textContent=I,B=i(),x=g("ol"),x.innerHTML=E,G=i(),j($.$$.fragment),R=i(),r=g("p"),r.innerHTML=U,V=i(),j(X.$$.fragment)},l(M){h(t.$$.fragment,M),o=c(M),l=w(M,"P",{"data-svelte-h":!0}),J(l)!=="svelte-1vtne9l"&&(l.innerHTML=m),b=c(M),h(k.$$.fragment,M),A=c(M),v=w(M,"P",{"data-svelte-h":!0}),J(v)!=="svelte-5p19xw"&&(v.textContent=I),B=c(M),x=w(M,"OL",{"data-svelte-h":!0}),J(x)!=="svelte-renpej"&&(x.innerHTML=E),G=c(M),h($.$$.fragment,M),R=c(M),r=w(M,"P",{"data-svelte-h":!0}),J(r)!=="svelte-ngexm3"&&(r.innerHTML=U),V=c(M),h(X.$$.fragment,M)},m(M,Z){d(t,M,Z),e(M,o,Z),e(M,l,Z),e(M,b,Z),d(k,M,Z),e(M,A,Z),e(M,v,Z),e(M,B,Z),e(M,x,Z),e(M,G,Z),d($,M,Z),e(M,R,Z),e(M,r,Z),e(M,V,Z),d(X,M,Z),W=!0},p(M,Z){const F={};Z&2&&(F.$$scope={dirty:Z,ctx:M}),t.$set(F)},i(M){W||(u(t.$$.fragment,M),u(k.$$.fragment,M),u($.$$.fragment,M),u(X.$$.fragment,M),W=!0)},o(M){f(t.$$.fragment,M),f(k.$$.fragment,M),f($.$$.fragment,M),f(X.$$.fragment,M),W=!1},d(M){M&&(a(o),a(l),a(b),a(A),a(v),a(B),a(x),a(G),a(R),a(r),a(V)),y(t,M),y(k,M),y($,M),y(X,M)}}}function wa(C){let t,o;return t=new Ls({props:{$$slots:{default:[ga]},$$scope:{ctx:C}}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p(l,m){const b={};m&2&&(b.$$scope={dirty:m,ctx:l}),t.$set(b)},i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function Ja(C){let t,o='Keras を使用したモデルの微調整に慣れていない場合は、<a href="../training#train-a-tensorflow-model-with-keras">こちら</a> の基本的なチュートリアルをご覧ください。';return{c(){t=g("p"),t.innerHTML=o},l(l){t=w(l,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1jwo7q8"&&(t.innerHTML=o)},m(l,m){e(l,t,m)},p:cs,d(l){l&&a(t)}}}function Ta(C){let t,o,l,m,b,k='次に、<a href="/docs/transformers/main/ja/model_doc/auto#transformers.TFAutoModelForTokenClassification">TFAutoModelForTokenClassification</a> を使用して、予期されるラベルの数とラベル マッピングを指定して DistilBERT をロードできます。',A,v,I,B,x='<a href="/docs/transformers/main/ja/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset">prepare_tf_dataset()</a> を使用して、データセットを <code>tf.data.Dataset</code> 形式に変換します。',E,G,$,R,r='<a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a> を使用してトレーニング用のモデルを設定します。 Transformers モデルにはすべてデフォルトのタスク関連の損失関数があるため、次の場合を除き、損失関数を指定する必要はないことに注意してください。',U,V,X,W,M='トレーニングを開始する前にセットアップする最後の 2 つのことは、予測から連続スコアを計算することと、モデルをハブにプッシュする方法を提供することです。どちらも <a href="../main_classes/keras_callbacks">Keras コールバック</a> を使用して行われます。',Z,F,os='<code>compute_metrics</code> 関数を <a href="/docs/transformers/main/ja/main_classes/keras_callbacks#transformers.KerasMetricCallback">KerasMetricCallback</a> に渡します。',H,z,N,ls,ms='<a href="/docs/transformers/main/ja/main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a> でモデルとトークナイザーをプッシュする場所を指定します。',Q,Y,q,L,as="次に、コールバックをまとめてバンドルします。",Ms,S,D,P,ts='ついに、モデルのトレーニングを開始する準備が整いました。トレーニングおよび検証データセット、エポック数、コールバックを指定して <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a> を呼び出し、モデルを微調整します。',js,K,O,ss,es="トレーニングが完了すると、モデルは自動的にハブにアップロードされ、誰でも使用できるようになります。",hs;return t=new vl({props:{$$slots:{default:[Ja]},$$scope:{ctx:C}}}),l=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMEElMEFiYXRjaF9zaXplJTIwJTNEJTIwMTYlMEFudW1fdHJhaW5fZXBvY2hzJTIwJTNEJTIwMyUwQW51bV90cmFpbl9zdGVwcyUyMCUzRCUyMChsZW4odG9rZW5pemVkX3dudXQlNUIlMjJ0cmFpbiUyMiU1RCklMjAlMkYlMkYlMjBiYXRjaF9zaXplKSUyMColMjBudW1fdHJhaW5fZXBvY2hzJTBBb3B0aW1pemVyJTJDJTIwbHJfc2NoZWR1bGUlMjAlM0QlMjBjcmVhdGVfb3B0aW1pemVyKCUwQSUyMCUyMCUyMCUyMGluaXRfbHIlM0QyZS01JTJDJTBBJTIwJTIwJTIwJTIwbnVtX3RyYWluX3N0ZXBzJTNEbnVtX3RyYWluX3N0ZXBzJTJDJTBBJTIwJTIwJTIwJTIwd2VpZ2h0X2RlY2F5X3JhdGUlM0QwLjAxJTJDJTBBJTIwJTIwJTIwJTIwbnVtX3dhcm11cF9zdGVwcyUzRDAlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>batch_size = <span class="hljs-number">16</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_train_epochs = <span class="hljs-number">3</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_train_steps = (<span class="hljs-built_in">len</span>(tokenized_wnut[<span class="hljs-string">&quot;train&quot;</span>]) // batch_size) * num_train_epochs
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer, lr_schedule = create_optimizer(
<span class="hljs-meta">... </span>    init_lr=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    num_train_steps=num_train_steps,
<span class="hljs-meta">... </span>    weight_decay_rate=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    num_warmup_steps=<span class="hljs-number">0</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),v=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIlMkMlMjBudW1fbGFiZWxzJTNEMTMlMkMlMjBpZDJsYWJlbCUzRGlkMmxhYmVsJTJDJTIwbGFiZWwyaWQlM0RsYWJlbDJpZCUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>, num_labels=<span class="hljs-number">13</span>, id2label=id2label, label2id=label2id
<span class="hljs-meta">... </span>)`,wrap:!1}}),G=new _({props:{code:"dGZfdHJhaW5fc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMHRva2VuaXplZF93bnV0JTVCJTIydHJhaW4lMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBzaHVmZmxlJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMGJhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMGNvbGxhdGVfZm4lM0RkYXRhX2NvbGxhdG9yJTJDJTBBKSUwQSUwQXRmX3ZhbGlkYXRpb25fc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMHRva2VuaXplZF93bnV0JTVCJTIydmFsaWRhdGlvbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RGYWxzZSUyQyUwQSUyMCUyMCUyMCUyMGJhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMGNvbGxhdGVfZm4lM0RkYXRhX2NvbGxhdG9yJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_wnut[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_wnut[<span class="hljs-string">&quot;validation&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),V=new _({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplciklMjAlMjAlMjMlMjBObyUyMGxvc3MlMjBhcmd1bWVudCE=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)  <span class="hljs-comment"># No loss argument!</span>`,wrap:!1}}),z=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBLZXJhc01ldHJpY0NhbGxiYWNrJTBBJTBBbWV0cmljX2NhbGxiYWNrJTIwJTNEJTIwS2VyYXNNZXRyaWNDYWxsYmFjayhtZXRyaWNfZm4lM0Rjb21wdXRlX21ldHJpY3MlMkMlMjBldmFsX2RhdGFzZXQlM0R0Zl92YWxpZGF0aW9uX3NldCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> KerasMetricCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)`,wrap:!1}}),Y=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBQdXNoVG9IdWJDYWxsYmFjayUwQSUwQXB1c2hfdG9faHViX2NhbGxiYWNrJTIwJTNEJTIwUHVzaFRvSHViQ2FsbGJhY2soJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMm15X2F3ZXNvbWVfd251dF9tb2RlbCUyMiUyQyUwQSUyMCUyMCUyMCUyMHRva2VuaXplciUzRHRva2VuaXplciUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>push_to_hub_callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_wnut_model&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>)`,wrap:!1}}),S=new _({props:{code:"Y2FsbGJhY2tzJTIwJTNEJTIwJTVCbWV0cmljX2NhbGxiYWNrJTJDJTIwcHVzaF90b19odWJfY2FsbGJhY2slNUQ=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>callbacks = [metric_callback, push_to_hub_callback]',wrap:!1}}),K=new _({props:{code:"bW9kZWwuZml0KHglM0R0Zl90cmFpbl9zZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl92YWxpZGF0aW9uX3NldCUyQyUyMGVwb2NocyUzRDMlMkMlMjBjYWxsYmFja3MlM0RjYWxsYmFja3Mp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=<span class="hljs-number">3</span>, callbacks=callbacks)',wrap:!1}}),{c(){j(t.$$.fragment),o=na(`
TensorFlow でモデルを微調整するには、オプティマイザー関数、学習率スケジュール、およびいくつかのトレーニング ハイパーパラメーターをセットアップすることから始めます。

	`),j(l.$$.fragment),m=i(),b=g("p"),b.innerHTML=k,A=i(),j(v.$$.fragment),I=i(),B=g("p"),B.innerHTML=x,E=i(),j(G.$$.fragment),$=i(),R=g("p"),R.innerHTML=r,U=i(),j(V.$$.fragment),X=i(),W=g("p"),W.innerHTML=M,Z=i(),F=g("p"),F.innerHTML=os,H=i(),j(z.$$.fragment),N=i(),ls=g("p"),ls.innerHTML=ms,Q=i(),j(Y.$$.fragment),q=i(),L=g("p"),L.textContent=as,Ms=i(),j(S.$$.fragment),D=i(),P=g("p"),P.innerHTML=ts,js=i(),j(K.$$.fragment),O=i(),ss=g("p"),ss.textContent=es},l(p){h(t.$$.fragment,p),o=pa(p,`
TensorFlow でモデルを微調整するには、オプティマイザー関数、学習率スケジュール、およびいくつかのトレーニング ハイパーパラメーターをセットアップすることから始めます。

	`),h(l.$$.fragment,p),m=c(p),b=w(p,"P",{"data-svelte-h":!0}),J(b)!=="svelte-9c8yyk"&&(b.innerHTML=k),A=c(p),h(v.$$.fragment,p),I=c(p),B=w(p,"P",{"data-svelte-h":!0}),J(B)!=="svelte-1mdvspu"&&(B.innerHTML=x),E=c(p),h(G.$$.fragment,p),$=c(p),R=w(p,"P",{"data-svelte-h":!0}),J(R)!=="svelte-1pd5few"&&(R.innerHTML=r),U=c(p),h(V.$$.fragment,p),X=c(p),W=w(p,"P",{"data-svelte-h":!0}),J(W)!=="svelte-ggt0vi"&&(W.innerHTML=M),Z=c(p),F=w(p,"P",{"data-svelte-h":!0}),J(F)!=="svelte-ht78yi"&&(F.innerHTML=os),H=c(p),h(z.$$.fragment,p),N=c(p),ls=w(p,"P",{"data-svelte-h":!0}),J(ls)!=="svelte-1rwfgpb"&&(ls.innerHTML=ms),Q=c(p),h(Y.$$.fragment,p),q=c(p),L=w(p,"P",{"data-svelte-h":!0}),J(L)!=="svelte-r16oc5"&&(L.textContent=as),Ms=c(p),h(S.$$.fragment,p),D=c(p),P=w(p,"P",{"data-svelte-h":!0}),J(P)!=="svelte-ffgub5"&&(P.innerHTML=ts),js=c(p),h(K.$$.fragment,p),O=c(p),ss=w(p,"P",{"data-svelte-h":!0}),J(ss)!=="svelte-vh7z0v"&&(ss.textContent=es)},m(p,T){d(t,p,T),e(p,o,T),d(l,p,T),e(p,m,T),e(p,b,T),e(p,A,T),d(v,p,T),e(p,I,T),e(p,B,T),e(p,E,T),d(G,p,T),e(p,$,T),e(p,R,T),e(p,U,T),d(V,p,T),e(p,X,T),e(p,W,T),e(p,Z,T),e(p,F,T),e(p,H,T),d(z,p,T),e(p,N,T),e(p,ls,T),e(p,Q,T),d(Y,p,T),e(p,q,T),e(p,L,T),e(p,Ms,T),d(S,p,T),e(p,D,T),e(p,P,T),e(p,js,T),d(K,p,T),e(p,O,T),e(p,ss,T),hs=!0},p(p,T){const ds={};T&2&&(ds.$$scope={dirty:T,ctx:p}),t.$set(ds)},i(p){hs||(u(t.$$.fragment,p),u(l.$$.fragment,p),u(v.$$.fragment,p),u(G.$$.fragment,p),u(V.$$.fragment,p),u(z.$$.fragment,p),u(Y.$$.fragment,p),u(S.$$.fragment,p),u(K.$$.fragment,p),hs=!0)},o(p){f(t.$$.fragment,p),f(l.$$.fragment,p),f(v.$$.fragment,p),f(G.$$.fragment,p),f(V.$$.fragment,p),f(z.$$.fragment,p),f(Y.$$.fragment,p),f(S.$$.fragment,p),f(K.$$.fragment,p),hs=!1},d(p){p&&(a(o),a(m),a(b),a(A),a(I),a(B),a(E),a($),a(R),a(U),a(X),a(W),a(Z),a(F),a(H),a(N),a(ls),a(Q),a(q),a(L),a(Ms),a(D),a(P),a(js),a(O),a(ss)),y(t,p),y(l,p),y(v,p),y(G,p),y(V,p),y(z,p),y(Y,p),y(S,p),y(K,p)}}}function Ua(C){let t,o;return t=new Ls({props:{$$slots:{default:[Ta]},$$scope:{ctx:C}}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p(l,m){const b={};m&2&&(b.$$scope={dirty:m,ctx:l}),t.$set(b)},i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function $a(C){let t,o=`トークン分類のモデルを微調整する方法のより詳細な例については、対応するセクションを参照してください。
<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification.ipynb" rel="nofollow">PyTorch ノートブック</a>
または <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/token_classification-tf.ipynb" rel="nofollow">TensorFlow ノートブック</a>。`;return{c(){t=g("p"),t.innerHTML=o},l(l){t=w(l,"P",{"data-svelte-h":!0}),J(t)!=="svelte-bbxcky"&&(t.innerHTML=o)},m(l,m){e(l,t,m)},p:cs,d(l){l&&a(t)}}}function xa(C){let t,o="テキストをトークン化して PyTorch テンソルを返します。",l,m,b,k,A="入力をモデルに渡し、<code>logits</code>を返します。",v,I,B,x,E="最も高い確率でクラスを取得し、モデルの <code>id2label</code> マッピングを使用してそれをテキスト ラベルに変換します。",G,$,R;return m=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfd251dF9tb2RlbCUyMiklMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIodGV4dCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_wnut_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),I=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMnN0ZXZobGl1JTJGbXlfYXdlc29tZV93bnV0X21vZGVsJTIyKSUwQXdpdGglMjB0b3JjaC5ub19ncmFkKCklM0ElMEElMjAlMjAlMjAlMjBsb2dpdHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cykubG9naXRz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_wnut_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits`,wrap:!1}}),$=new _({props:{code:"cHJlZGljdGlvbnMlMjAlM0QlMjB0b3JjaC5hcmdtYXgobG9naXRzJTJDJTIwZGltJTNEMiklMEFwcmVkaWN0ZWRfdG9rZW5fY2xhc3MlMjAlM0QlMjAlNUJtb2RlbC5jb25maWcuaWQybGFiZWwlNUJ0Lml0ZW0oKSU1RCUyMGZvciUyMHQlMjBpbiUyMHByZWRpY3Rpb25zJTVCMCU1RCU1RCUwQXByZWRpY3RlZF90b2tlbl9jbGFzcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predictions = torch.argmax(logits, dim=<span class="hljs-number">2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class = [model.config.id2label[t.item()] <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> predictions[<span class="hljs-number">0</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class
[<span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;B-location&#x27;</span>,
 <span class="hljs-string">&#x27;I-location&#x27;</span>,
 <span class="hljs-string">&#x27;B-group&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;B-location&#x27;</span>,
 <span class="hljs-string">&#x27;B-location&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>]`,wrap:!1}}),{c(){t=g("p"),t.textContent=o,l=i(),j(m.$$.fragment),b=i(),k=g("p"),k.innerHTML=A,v=i(),j(I.$$.fragment),B=i(),x=g("p"),x.innerHTML=E,G=i(),j($.$$.fragment)},l(r){t=w(r,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1n0k6or"&&(t.textContent=o),l=c(r),h(m.$$.fragment,r),b=c(r),k=w(r,"P",{"data-svelte-h":!0}),J(k)!=="svelte-1rvunpz"&&(k.innerHTML=A),v=c(r),h(I.$$.fragment,r),B=c(r),x=w(r,"P",{"data-svelte-h":!0}),J(x)!=="svelte-37ihfr"&&(x.innerHTML=E),G=c(r),h($.$$.fragment,r)},m(r,U){e(r,t,U),e(r,l,U),d(m,r,U),e(r,b,U),e(r,k,U),e(r,v,U),d(I,r,U),e(r,B,U),e(r,x,U),e(r,G,U),d($,r,U),R=!0},p:cs,i(r){R||(u(m.$$.fragment,r),u(I.$$.fragment,r),u($.$$.fragment,r),R=!0)},o(r){f(m.$$.fragment,r),f(I.$$.fragment,r),f($.$$.fragment,r),R=!1},d(r){r&&(a(t),a(l),a(b),a(k),a(v),a(B),a(x),a(G)),y(m,r),y(I,r),y($,r)}}}function _a(C){let t,o;return t=new Ls({props:{$$slots:{default:[xa]},$$scope:{ctx:C}}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p(l,m){const b={};m&2&&(b.$$scope={dirty:m,ctx:l}),t.$set(b)},i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function Ca(C){let t,o="テキストをトークン化し、TensorFlow テンソルを返します。",l,m,b,k,A="入力をモデルに渡し、<code>logits</code>を返します。",v,I,B,x,E="最も高い確率でクラスを取得し、モデルの <code>id2label</code> マッピングを使用してそれをテキスト ラベルに変換します。",G,$,R;return m=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfd251dF9tb2RlbCUyMiklMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIodGV4dCUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIydGYlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_wnut_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),I=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfd251dF9tb2RlbCUyMiklMEFsb2dpdHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cykubG9naXRz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_wnut_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits`,wrap:!1}}),$=new _({props:{code:"cHJlZGljdGVkX3Rva2VuX2NsYXNzX2lkcyUyMCUzRCUyMHRmLm1hdGguYXJnbWF4KGxvZ2l0cyUyQyUyMGF4aXMlM0QtMSklMEFwcmVkaWN0ZWRfdG9rZW5fY2xhc3MlMjAlM0QlMjAlNUJtb2RlbC5jb25maWcuaWQybGFiZWwlNUJ0JTVEJTIwZm9yJTIwdCUyMGluJTIwcHJlZGljdGVkX3Rva2VuX2NsYXNzX2lkcyU1QjAlNUQubnVtcHkoKS50b2xpc3QoKSU1RCUwQXByZWRpY3RlZF90b2tlbl9jbGFzcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class_ids = tf.math.argmax(logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class = [model.config.id2label[t] <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> predicted_token_class_ids[<span class="hljs-number">0</span>].numpy().tolist()]
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_token_class
[<span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;B-location&#x27;</span>,
 <span class="hljs-string">&#x27;I-location&#x27;</span>,
 <span class="hljs-string">&#x27;B-group&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;B-location&#x27;</span>,
 <span class="hljs-string">&#x27;B-location&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>,
 <span class="hljs-string">&#x27;O&#x27;</span>]`,wrap:!1}}),{c(){t=g("p"),t.textContent=o,l=i(),j(m.$$.fragment),b=i(),k=g("p"),k.innerHTML=A,v=i(),j(I.$$.fragment),B=i(),x=g("p"),x.innerHTML=E,G=i(),j($.$$.fragment)},l(r){t=w(r,"P",{"data-svelte-h":!0}),J(t)!=="svelte-1bnmfqq"&&(t.textContent=o),l=c(r),h(m.$$.fragment,r),b=c(r),k=w(r,"P",{"data-svelte-h":!0}),J(k)!=="svelte-1rvunpz"&&(k.innerHTML=A),v=c(r),h(I.$$.fragment,r),B=c(r),x=w(r,"P",{"data-svelte-h":!0}),J(x)!=="svelte-37ihfr"&&(x.innerHTML=E),G=c(r),h($.$$.fragment,r)},m(r,U){e(r,t,U),e(r,l,U),d(m,r,U),e(r,b,U),e(r,k,U),e(r,v,U),d(I,r,U),e(r,B,U),e(r,x,U),e(r,G,U),d($,r,U),R=!0},p:cs,i(r){R||(u(m.$$.fragment,r),u(I.$$.fragment,r),u($.$$.fragment,r),R=!0)},o(r){f(m.$$.fragment,r),f(I.$$.fragment,r),f($.$$.fragment,r),R=!1},d(r){r&&(a(t),a(l),a(b),a(k),a(v),a(B),a(x),a(G)),y(m,r),y(I,r),y($,r)}}}function ka(C){let t,o;return t=new Ls({props:{$$slots:{default:[Ca]},$$scope:{ctx:C}}}),{c(){j(t.$$.fragment)},l(l){h(t.$$.fragment,l)},m(l,m){d(t,l,m),o=!0},p(l,m){const b={};m&2&&(b.$$scope={dirty:m,ctx:l}),t.$set(b)},i(l){o||(u(t.$$.fragment,l),o=!0)},o(l){f(t.$$.fragment,l),o=!1},d(l){y(t,l)}}}function Ia(C){let t,o,l,m,b,k,A,v,I,B,x,E="トークン分類では、文内の個々のトークンにラベルを割り当てます。最も一般的なトークン分類タスクの 1 つは、固有表現認識 (NER) です。 NER は、人、場所、組織など、文内の各エンティティのラベルを見つけようとします。",G,$,R="このガイドでは、次の方法を説明します。",r,U,V='<li><a href="https://huggingface.co/datasets/wnut_17" rel="nofollow">WNUT 17</a> データセットで <a href="https://huggingface.co/distilbert/distilbert-base-uncased" rel="nofollow">DistilBERT</a> を微調整して、新しいエンティティを検出します。</li> <li>微調整されたモデルを推論に使用します。</li>',X,W,M,Z,F="始める前に、必要なライブラリがすべてインストールされていることを確認してください。",os,H,z,N,ls="モデルをアップロードしてコミュニティと共有できるように、Hugging Face アカウントにログインすることをお勧めします。プロンプトが表示されたら、トークンを入力してログインします。",ms,Q,Y,q,L,as,Ms="まず、🤗 データセット ライブラリから WNUT 17 データセットをロードします。",S,D,P,ts,js="次に、例を見てみましょう。",K,O,ss,es,hs="<code>ner_tags</code>内の各数字はエンティティを表します。数値をラベル名に変換して、エンティティが何であるかを調べます。",p,T,ds,us,Gl="各 <code>ner_tag</code> の前に付く文字は、エンティティのトークンの位置を示します。",Ds,fs,Rl=`<li><code>B-</code> はエンティティの始まりを示します。</li> <li><code>I-</code> は、トークンが同じエンティティ内に含まれていることを示します (たとえば、<code>State</code> トークンは次のようなエンティティの一部です)
<code>Empire State Building</code>）。</li> <li><code>0</code> は、トークンがどのエンティティにも対応しないことを示します。</li>`,Ps,ys,Ks,bs,Os,gs,Al="次のステップでは、DistilBERT トークナイザーをロードして<code>tokens</code>フィールドを前処理します。",sl,ws,ll,Js,Wl="上の <code>tokens</code>フィールドの例で見たように、入力はすでにトークン化されているようです。しかし、実際には入力はまだトークン化されていないため、単語をサブワードにトークン化するには<code>is_split_into_words=True</code> を設定する必要があります。例えば：",al,Ts,tl,Us,Xl="ただし、これによりいくつかの特別なトークン <code>[CLS]</code> と <code>[SEP]</code> が追加され、サブワードのトークン化により入力とラベルの間に不一致が生じます。 1 つのラベルに対応する 1 つの単語を 2 つのサブワードに分割できるようになりました。次の方法でトークンとラベルを再調整する必要があります。",el,$s,El='<li><a href="https://huggingface.co/docs/transformers/main_classes/tokenizer#transformers.BatchEncoding.word_ids" rel="nofollow"><code>word_ids</code></a> メソッドを使用して、すべてのトークンを対応する単語にマッピングします。</li> <li>特別なトークン <code>[CLS]</code> と <code>[SEP]</code> にラベル <code>-100</code> を割り当て、それらが PyTorch 損失関数によって無視されるようにします (<a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html" rel="nofollow">CrossEntropyLoss</a>)。</li> <li>特定の単語の最初のトークンのみにラベルを付けます。同じ単語の他のサブトークンに <code>-100</code>を割り当てます。</li>',nl,xs,Vl="トークンとラベルを再調整し、シーケンスを DistilBERT の最大入力長以下に切り詰める関数を作成する方法を次に示します。",pl,_s,rl,Cs,Fl="データセット全体に前処理関数を適用するには、🤗 Datasets <code>map</code> 関数を使用します。 <code>batched=True</code> を設定してデータセットの複数の要素を一度に処理することで、<code>map</code> 関数を高速化できます。",il,ks,cl,Is,Hl="次に、<code>DataCollat​​orWithPadding</code> を使用してサンプルのバッチを作成します。データセット全体を最大長までパディングするのではなく、照合中にバッチ内の最長の長さまで文を <em>動的にパディング</em> する方が効率的です。",ol,ns,ml,Zs,Ml,vs,zl='トレーニング中にメトリクスを含めると、多くの場合、モデルのパフォーマンスを評価するのに役立ちます。 🤗 <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> ライブラリを使用して、評価メソッドをすばやくロードできます。このタスクでは、<a href="https://huggingface.co/spaces/evaluate-metric/seqeval" rel="nofollow">seqeval</a> フレームワークを読み込みます (🤗 Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">クイック ツアー</a> を参照してください) ) メトリクスの読み込みと計算の方法について詳しくは、こちらをご覧ください)。 Seqeval は実際に、精度、再現率、F1、精度などのいくつかのスコアを生成します。',jl,Bs,hl,Gs,Nl="まず NER ラベルを取得してから、真の予測と真のラベルを <code>compute</code> に渡してスコアを計算する関数を作成します。",dl,Rs,ul,As,Ql="これで<code>compute_metrics</code>関数の準備が整いました。トレーニングをセットアップするときにこの関数に戻ります。",fl,Ws,yl,Xs,Yl="モデルのトレーニングを開始する前に、<code>id2label</code>と<code>label2id</code>を使用して、予想される ID とそのラベルのマップを作成します。",bl,Es,gl,ps,wl,rs,Jl,Vs,Tl,Fs,ql="モデルを微調整したので、それを推論に使用できるようになりました。",Ul,Hs,Ll="推論を実行したいテキストをいくつか取得します。",$l,zs,xl,Ns,Sl='推論用に微調整されたモデルを試す最も簡単な方法は、それを <a href="/docs/transformers/main/ja/main_classes/pipelines#transformers.pipeline">pipeline()</a> で使用することです。モデルを使用して NER の<code>pipeline</code>をインスタンス化し、テキストをそれに渡します。',_l,Qs,Cl,Ys,Dl="必要に応じて、<code>pipeline</code>の結果を手動で複製することもできます。",kl,is,Il,Ss,Zl;return b=new qs({props:{title:"Token classification",local:"token-classification",headingTag:"h1"}}),A=new ja({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/token_classification.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/token_classification.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/token_classification.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/token_classification.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/token_classification.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/token_classification.ipynb"}]}}),I=new ea({props:{id:"wVHdVlPScxA"}}),W=new vl({props:{$$slots:{default:[ha]},$$scope:{ctx:C}}}),H=new _({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGUlMjBzZXFldmFs",highlighted:"pip install transformers datasets evaluate seqeval",wrap:!1}}),Q=new _({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),q=new qs({props:{title:"Load WNUT 17 dataset",local:"load-wnut-17-dataset",headingTag:"h2"}}),D=new _({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBd251dCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJ3bnV0XzE3JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>wnut = load_dataset(<span class="hljs-string">&quot;wnut_17&quot;</span>)`,wrap:!1}}),O=new _({props:{code:"d251dCU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>wnut[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;0&#x27;</span>,
 <span class="hljs-string">&#x27;ner_tags&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">8</span>, <span class="hljs-number">8</span>, <span class="hljs-number">0</span>, <span class="hljs-number">7</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;tokens&#x27;</span>: [<span class="hljs-string">&#x27;@paulwalk&#x27;</span>, <span class="hljs-string">&#x27;It&#x27;</span>, <span class="hljs-string">&quot;&#x27;s&quot;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;view&#x27;</span>, <span class="hljs-string">&#x27;from&#x27;</span>, <span class="hljs-string">&#x27;where&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&quot;&#x27;m&quot;</span>, <span class="hljs-string">&#x27;living&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>, <span class="hljs-string">&#x27;two&#x27;</span>, <span class="hljs-string">&#x27;weeks&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;Empire&#x27;</span>, <span class="hljs-string">&#x27;State&#x27;</span>, <span class="hljs-string">&#x27;Building&#x27;</span>, <span class="hljs-string">&#x27;=&#x27;</span>, <span class="hljs-string">&#x27;ESB&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;Pretty&#x27;</span>, <span class="hljs-string">&#x27;bad&#x27;</span>, <span class="hljs-string">&#x27;storm&#x27;</span>, <span class="hljs-string">&#x27;here&#x27;</span>, <span class="hljs-string">&#x27;last&#x27;</span>, <span class="hljs-string">&#x27;evening&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>]
}`,wrap:!1}}),T=new _({props:{code:"bGFiZWxfbGlzdCUyMCUzRCUyMHdudXQlNUIlMjJ0cmFpbiUyMiU1RC5mZWF0dXJlcyU1QmYlMjJuZXJfdGFncyUyMiU1RC5mZWF0dXJlLm5hbWVzJTBBbGFiZWxfbGlzdA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>label_list = wnut[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">f&quot;ner_tags&quot;</span>].feature.names
<span class="hljs-meta">&gt;&gt;&gt; </span>label_list
[
    <span class="hljs-string">&quot;O&quot;</span>,
    <span class="hljs-string">&quot;B-corporation&quot;</span>,
    <span class="hljs-string">&quot;I-corporation&quot;</span>,
    <span class="hljs-string">&quot;B-creative-work&quot;</span>,
    <span class="hljs-string">&quot;I-creative-work&quot;</span>,
    <span class="hljs-string">&quot;B-group&quot;</span>,
    <span class="hljs-string">&quot;I-group&quot;</span>,
    <span class="hljs-string">&quot;B-location&quot;</span>,
    <span class="hljs-string">&quot;I-location&quot;</span>,
    <span class="hljs-string">&quot;B-person&quot;</span>,
    <span class="hljs-string">&quot;I-person&quot;</span>,
    <span class="hljs-string">&quot;B-product&quot;</span>,
    <span class="hljs-string">&quot;I-product&quot;</span>,
]`,wrap:!1}}),ys=new qs({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),bs=new ea({props:{id:"iY2AZYdZAr0"}}),ws=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),Ts=new _({props:{code:"ZXhhbXBsZSUyMCUzRCUyMHdudXQlNUIlMjJ0cmFpbiUyMiU1RCU1QjAlNUQlMEF0b2tlbml6ZWRfaW5wdXQlMjAlM0QlMjB0b2tlbml6ZXIoZXhhbXBsZSU1QiUyMnRva2VucyUyMiU1RCUyQyUyMGlzX3NwbGl0X2ludG9fd29yZHMlM0RUcnVlKSUwQXRva2VucyUyMCUzRCUyMHRva2VuaXplci5jb252ZXJ0X2lkc190b190b2tlbnModG9rZW5pemVkX2lucHV0JTVCJTIyaW5wdXRfaWRzJTIyJTVEKSUwQXRva2Vucw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>example = wnut[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_input = tokenizer(example[<span class="hljs-string">&quot;tokens&quot;</span>], is_split_into_words=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokens = tokenizer.convert_ids_to_tokens(tokenized_input[<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>tokens
[<span class="hljs-string">&#x27;[CLS]&#x27;</span>, <span class="hljs-string">&#x27;@&#x27;</span>, <span class="hljs-string">&#x27;paul&#x27;</span>, <span class="hljs-string">&#x27;##walk&#x27;</span>, <span class="hljs-string">&#x27;it&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;s&#x27;</span>, <span class="hljs-string">&#x27;the&#x27;</span>, <span class="hljs-string">&#x27;view&#x27;</span>, <span class="hljs-string">&#x27;from&#x27;</span>, <span class="hljs-string">&#x27;where&#x27;</span>, <span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&quot;&#x27;&quot;</span>, <span class="hljs-string">&#x27;m&#x27;</span>, <span class="hljs-string">&#x27;living&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>, <span class="hljs-string">&#x27;two&#x27;</span>, <span class="hljs-string">&#x27;weeks&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;empire&#x27;</span>, <span class="hljs-string">&#x27;state&#x27;</span>, <span class="hljs-string">&#x27;building&#x27;</span>, <span class="hljs-string">&#x27;=&#x27;</span>, <span class="hljs-string">&#x27;es&#x27;</span>, <span class="hljs-string">&#x27;##b&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;pretty&#x27;</span>, <span class="hljs-string">&#x27;bad&#x27;</span>, <span class="hljs-string">&#x27;storm&#x27;</span>, <span class="hljs-string">&#x27;here&#x27;</span>, <span class="hljs-string">&#x27;last&#x27;</span>, <span class="hljs-string">&#x27;evening&#x27;</span>, <span class="hljs-string">&#x27;.&#x27;</span>, <span class="hljs-string">&#x27;[SEP]&#x27;</span>]`,wrap:!1}}),_s=new _({props:{code:"ZGVmJTIwdG9rZW5pemVfYW5kX2FsaWduX2xhYmVscyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjB0b2tlbml6ZWRfaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKGV4YW1wbGVzJTVCJTIydG9rZW5zJTIyJTVEJTJDJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMjBpc19zcGxpdF9pbnRvX3dvcmRzJTNEVHJ1ZSklMEElMEElMjAlMjAlMjAlMjBsYWJlbHMlMjAlM0QlMjAlNUIlNUQlMEElMjAlMjAlMjAlMjBmb3IlMjBpJTJDJTIwbGFiZWwlMjBpbiUyMGVudW1lcmF0ZShleGFtcGxlcyU1QmYlMjJuZXJfdGFncyUyMiU1RCklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjB3b3JkX2lkcyUyMCUzRCUyMHRva2VuaXplZF9pbnB1dHMud29yZF9pZHMoYmF0Y2hfaW5kZXglM0RpKSUyMCUyMCUyMyUyME1hcCUyMHRva2VucyUyMHRvJTIwdGhlaXIlMjByZXNwZWN0aXZlJTIwd29yZC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBwcmV2aW91c193b3JkX2lkeCUyMCUzRCUyME5vbmUlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsYWJlbF9pZHMlMjAlM0QlMjAlNUIlNUQlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBmb3IlMjB3b3JkX2lkeCUyMGluJTIwd29yZF9pZHMlM0ElMjAlMjAlMjMlMjBTZXQlMjB0aGUlMjBzcGVjaWFsJTIwdG9rZW5zJTIwdG8lMjAtMTAwLiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGlmJTIwd29yZF9pZHglMjBpcyUyME5vbmUlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsYWJlbF9pZHMuYXBwZW5kKC0xMDApJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwZWxpZiUyMHdvcmRfaWR4JTIwISUzRCUyMHByZXZpb3VzX3dvcmRfaWR4JTNBJTIwJTIwJTIzJTIwT25seSUyMGxhYmVsJTIwdGhlJTIwZmlyc3QlMjB0b2tlbiUyMG9mJTIwYSUyMGdpdmVuJTIwd29yZC4lMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsYWJlbF9pZHMuYXBwZW5kKGxhYmVsJTVCd29yZF9pZHglNUQpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwZWxzZSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxhYmVsX2lkcy5hcHBlbmQoLTEwMCklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBwcmV2aW91c193b3JkX2lkeCUyMCUzRCUyMHdvcmRfaWR4JTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbGFiZWxzLmFwcGVuZChsYWJlbF9pZHMpJTBBJTBBJTIwJTIwJTIwJTIwdG9rZW5pemVkX2lucHV0cyU1QiUyMmxhYmVscyUyMiU1RCUyMCUzRCUyMGxhYmVscyUwQSUyMCUyMCUyMCUyMHJldHVybiUyMHRva2VuaXplZF9pbnB1dHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_and_align_labels</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    tokenized_inputs = tokenizer(examples[<span class="hljs-string">&quot;tokens&quot;</span>], truncation=<span class="hljs-literal">True</span>, is_split_into_words=<span class="hljs-literal">True</span>)

<span class="hljs-meta">... </span>    labels = []
<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(examples[<span class="hljs-string">f&quot;ner_tags&quot;</span>]):
<span class="hljs-meta">... </span>        word_ids = tokenized_inputs.word_ids(batch_index=i)  <span class="hljs-comment"># Map tokens to their respective word.</span>
<span class="hljs-meta">... </span>        previous_word_idx = <span class="hljs-literal">None</span>
<span class="hljs-meta">... </span>        label_ids = []
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> word_idx <span class="hljs-keyword">in</span> word_ids:  <span class="hljs-comment"># Set the special tokens to -100.</span>
<span class="hljs-meta">... </span>            <span class="hljs-keyword">if</span> word_idx <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
<span class="hljs-meta">... </span>                label_ids.append(-<span class="hljs-number">100</span>)
<span class="hljs-meta">... </span>            <span class="hljs-keyword">elif</span> word_idx != previous_word_idx:  <span class="hljs-comment"># Only label the first token of a given word.</span>
<span class="hljs-meta">... </span>                label_ids.append(label[word_idx])
<span class="hljs-meta">... </span>            <span class="hljs-keyword">else</span>:
<span class="hljs-meta">... </span>                label_ids.append(-<span class="hljs-number">100</span>)
<span class="hljs-meta">... </span>            previous_word_idx = word_idx
<span class="hljs-meta">... </span>        labels.append(label_ids)

<span class="hljs-meta">... </span>    tokenized_inputs[<span class="hljs-string">&quot;labels&quot;</span>] = labels
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenized_inputs`,wrap:!1}}),ks=new _({props:{code:"dG9rZW5pemVkX3dudXQlMjAlM0QlMjB3bnV0Lm1hcCh0b2tlbml6ZV9hbmRfYWxpZ25fbGFiZWxzJTJDJTIwYmF0Y2hlZCUzRFRydWUp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_wnut = wnut.<span class="hljs-built_in">map</span>(tokenize_and_align_labels, batched=<span class="hljs-literal">True</span>)',wrap:!1}}),ns=new Bl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ya],pytorch:[ua]},$$scope:{ctx:C}}}),Zs=new qs({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),Bs=new _({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEFzZXFldmFsJTIwJTNEJTIwZXZhbHVhdGUubG9hZCglMjJzZXFldmFsJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>seqeval = evaluate.load(<span class="hljs-string">&quot;seqeval&quot;</span>)`,wrap:!1}}),Rs=new _({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBbGFiZWxzJTIwJTNEJTIwJTVCbGFiZWxfbGlzdCU1QmklNUQlMjBmb3IlMjBpJTIwaW4lMjBleGFtcGxlJTVCZiUyMm5lcl90YWdzJTIyJTVEJTVEJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKHApJTNBJTBBJTIwJTIwJTIwJTIwcHJlZGljdGlvbnMlMkMlMjBsYWJlbHMlMjAlM0QlMjBwJTBBJTIwJTIwJTIwJTIwcHJlZGljdGlvbnMlMjAlM0QlMjBucC5hcmdtYXgocHJlZGljdGlvbnMlMkMlMjBheGlzJTNEMiklMEElMEElMjAlMjAlMjAlMjB0cnVlX3ByZWRpY3Rpb25zJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTVCbGFiZWxfbGlzdCU1QnAlNUQlMjBmb3IlMjAocCUyQyUyMGwpJTIwaW4lMjB6aXAocHJlZGljdGlvbiUyQyUyMGxhYmVsKSUyMGlmJTIwbCUyMCElM0QlMjAtMTAwJTVEJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwZm9yJTIwcHJlZGljdGlvbiUyQyUyMGxhYmVsJTIwaW4lMjB6aXAocHJlZGljdGlvbnMlMkMlMjBsYWJlbHMpJTBBJTIwJTIwJTIwJTIwJTVEJTBBJTIwJTIwJTIwJTIwdHJ1ZV9sYWJlbHMlMjAlM0QlMjAlNUIlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlNUJsYWJlbF9saXN0JTVCbCU1RCUyMGZvciUyMChwJTJDJTIwbCklMjBpbiUyMHppcChwcmVkaWN0aW9uJTJDJTIwbGFiZWwpJTIwaWYlMjBsJTIwISUzRCUyMC0xMDAlNUQlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBmb3IlMjBwcmVkaWN0aW9uJTJDJTIwbGFiZWwlMjBpbiUyMHppcChwcmVkaWN0aW9ucyUyQyUyMGxhYmVscyklMEElMjAlMjAlMjAlMjAlNUQlMEElMEElMjAlMjAlMjAlMjByZXN1bHRzJTIwJTNEJTIwc2VxZXZhbC5jb21wdXRlKHByZWRpY3Rpb25zJTNEdHJ1ZV9wcmVkaWN0aW9ucyUyQyUyMHJlZmVyZW5jZXMlM0R0cnVlX2xhYmVscyklMEElMjAlMjAlMjAlMjByZXR1cm4lMjAlN0IlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJwcmVjaXNpb24lMjIlM0ElMjByZXN1bHRzJTVCJTIyb3ZlcmFsbF9wcmVjaXNpb24lMjIlNUQlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJyZWNhbGwlMjIlM0ElMjByZXN1bHRzJTVCJTIyb3ZlcmFsbF9yZWNhbGwlMjIlNUQlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjJmMSUyMiUzQSUyMHJlc3VsdHMlNUIlMjJvdmVyYWxsX2YxJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIyYWNjdXJhY3klMjIlM0ElMjByZXN1bHRzJTVCJTIyb3ZlcmFsbF9hY2N1cmFjeSUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMCU3RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-meta">&gt;&gt;&gt; </span>labels = [label_list[i] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> example[<span class="hljs-string">f&quot;ner_tags&quot;</span>]]


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">p</span>):
<span class="hljs-meta">... </span>    predictions, labels = p
<span class="hljs-meta">... </span>    predictions = np.argmax(predictions, axis=<span class="hljs-number">2</span>)

<span class="hljs-meta">... </span>    true_predictions = [
<span class="hljs-meta">... </span>        [label_list[p] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>    true_labels = [
<span class="hljs-meta">... </span>        [label_list[l] <span class="hljs-keyword">for</span> (p, l) <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(prediction, label) <span class="hljs-keyword">if</span> l != -<span class="hljs-number">100</span>]
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> prediction, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(predictions, labels)
<span class="hljs-meta">... </span>    ]

<span class="hljs-meta">... </span>    results = seqeval.compute(predictions=true_predictions, references=true_labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;precision&quot;</span>: results[<span class="hljs-string">&quot;overall_precision&quot;</span>],
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;recall&quot;</span>: results[<span class="hljs-string">&quot;overall_recall&quot;</span>],
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;f1&quot;</span>: results[<span class="hljs-string">&quot;overall_f1&quot;</span>],
<span class="hljs-meta">... </span>        <span class="hljs-string">&quot;accuracy&quot;</span>: results[<span class="hljs-string">&quot;overall_accuracy&quot;</span>],
<span class="hljs-meta">... </span>    }`,wrap:!1}}),Ws=new qs({props:{title:"Train",local:"train",headingTag:"h2"}}),Es=new _({props:{code:"aWQybGFiZWwlMjAlM0QlMjAlN0IlMEElMjAlMjAlMjAlMjAwJTNBJTIwJTIyTyUyMiUyQyUwQSUyMCUyMCUyMCUyMDElM0ElMjAlMjJCLWNvcnBvcmF0aW9uJTIyJTJDJTBBJTIwJTIwJTIwJTIwMiUzQSUyMCUyMkktY29ycG9yYXRpb24lMjIlMkMlMEElMjAlMjAlMjAlMjAzJTNBJTIwJTIyQi1jcmVhdGl2ZS13b3JrJTIyJTJDJTBBJTIwJTIwJTIwJTIwNCUzQSUyMCUyMkktY3JlYXRpdmUtd29yayUyMiUyQyUwQSUyMCUyMCUyMCUyMDUlM0ElMjAlMjJCLWdyb3VwJTIyJTJDJTBBJTIwJTIwJTIwJTIwNiUzQSUyMCUyMkktZ3JvdXAlMjIlMkMlMEElMjAlMjAlMjAlMjA3JTNBJTIwJTIyQi1sb2NhdGlvbiUyMiUyQyUwQSUyMCUyMCUyMCUyMDglM0ElMjAlMjJJLWxvY2F0aW9uJTIyJTJDJTBBJTIwJTIwJTIwJTIwOSUzQSUyMCUyMkItcGVyc29uJTIyJTJDJTBBJTIwJTIwJTIwJTIwMTAlM0ElMjAlMjJJLXBlcnNvbiUyMiUyQyUwQSUyMCUyMCUyMCUyMDExJTNBJTIwJTIyQi1wcm9kdWN0JTIyJTJDJTBBJTIwJTIwJTIwJTIwMTIlM0ElMjAlMjJJLXByb2R1Y3QlMjIlMkMlMEElN0QlMEFsYWJlbDJpZCUyMCUzRCUyMCU3QiUwQSUyMCUyMCUyMCUyMCUyMk8lMjIlM0ElMjAwJTJDJTBBJTIwJTIwJTIwJTIwJTIyQi1jb3Jwb3JhdGlvbiUyMiUzQSUyMDElMkMlMEElMjAlMjAlMjAlMjAlMjJJLWNvcnBvcmF0aW9uJTIyJTNBJTIwMiUyQyUwQSUyMCUyMCUyMCUyMCUyMkItY3JlYXRpdmUtd29yayUyMiUzQSUyMDMlMkMlMEElMjAlMjAlMjAlMjAlMjJJLWNyZWF0aXZlLXdvcmslMjIlM0ElMjA0JTJDJTBBJTIwJTIwJTIwJTIwJTIyQi1ncm91cCUyMiUzQSUyMDUlMkMlMEElMjAlMjAlMjAlMjAlMjJJLWdyb3VwJTIyJTNBJTIwNiUyQyUwQSUyMCUyMCUyMCUyMCUyMkItbG9jYXRpb24lMjIlM0ElMjA3JTJDJTBBJTIwJTIwJTIwJTIwJTIySS1sb2NhdGlvbiUyMiUzQSUyMDglMkMlMEElMjAlMjAlMjAlMjAlMjJCLXBlcnNvbiUyMiUzQSUyMDklMkMlMEElMjAlMjAlMjAlMjAlMjJJLXBlcnNvbiUyMiUzQSUyMDEwJTJDJTBBJTIwJTIwJTIwJTIwJTIyQi1wcm9kdWN0JTIyJTNBJTIwMTElMkMlMEElMjAlMjAlMjAlMjAlMjJJLXByb2R1Y3QlMjIlM0ElMjAxMiUyQyUwQSU3RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>id2label = {
<span class="hljs-meta">... </span>    <span class="hljs-number">0</span>: <span class="hljs-string">&quot;O&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">1</span>: <span class="hljs-string">&quot;B-corporation&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">2</span>: <span class="hljs-string">&quot;I-corporation&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">3</span>: <span class="hljs-string">&quot;B-creative-work&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">4</span>: <span class="hljs-string">&quot;I-creative-work&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">5</span>: <span class="hljs-string">&quot;B-group&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">6</span>: <span class="hljs-string">&quot;I-group&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">7</span>: <span class="hljs-string">&quot;B-location&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">8</span>: <span class="hljs-string">&quot;I-location&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">9</span>: <span class="hljs-string">&quot;B-person&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">10</span>: <span class="hljs-string">&quot;I-person&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">11</span>: <span class="hljs-string">&quot;B-product&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-number">12</span>: <span class="hljs-string">&quot;I-product&quot;</span>,
<span class="hljs-meta">... </span>}
<span class="hljs-meta">&gt;&gt;&gt; </span>label2id = {
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;O&quot;</span>: <span class="hljs-number">0</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;B-corporation&quot;</span>: <span class="hljs-number">1</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;I-corporation&quot;</span>: <span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;B-creative-work&quot;</span>: <span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;I-creative-work&quot;</span>: <span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;B-group&quot;</span>: <span class="hljs-number">5</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;I-group&quot;</span>: <span class="hljs-number">6</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;B-location&quot;</span>: <span class="hljs-number">7</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;I-location&quot;</span>: <span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;B-person&quot;</span>: <span class="hljs-number">9</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;I-person&quot;</span>: <span class="hljs-number">10</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;B-product&quot;</span>: <span class="hljs-number">11</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;I-product&quot;</span>: <span class="hljs-number">12</span>,
<span class="hljs-meta">... </span>}`,wrap:!1}}),ps=new Bl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ua],pytorch:[wa]},$$scope:{ctx:C}}}),rs=new vl({props:{$$slots:{default:[$a]},$$scope:{ctx:C}}}),Vs=new qs({props:{title:"Inference",local:"inference",headingTag:"h2"}}),zs=new _({props:{code:"dGV4dCUyMCUzRCUyMCUyMlRoZSUyMEdvbGRlbiUyMFN0YXRlJTIwV2FycmlvcnMlMjBhcmUlMjBhbiUyMEFtZXJpY2FuJTIwcHJvZmVzc2lvbmFsJTIwYmFza2V0YmFsbCUyMHRlYW0lMjBiYXNlZCUyMGluJTIwU2FuJTIwRnJhbmNpc2NvLiUyMg==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>text = <span class="hljs-string">&quot;The Golden State Warriors are an American professional basketball team based in San Francisco.&quot;</span>',wrap:!1}}),Qs=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMm5lciUyMiUyQyUyMG1vZGVsJTNEJTIyc3RldmhsaXUlMkZteV9hd2Vzb21lX3dudXRfbW9kZWwlMjIpJTBBY2xhc3NpZmllcih0ZXh0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;ner&quot;</span>, model=<span class="hljs-string">&quot;stevhliu/my_awesome_wnut_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(text)
[{<span class="hljs-string">&#x27;entity&#x27;</span>: <span class="hljs-string">&#x27;B-location&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.42658573</span>,
  <span class="hljs-string">&#x27;index&#x27;</span>: <span class="hljs-number">2</span>,
  <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;golden&#x27;</span>,
  <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">4</span>,
  <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">10</span>},
 {<span class="hljs-string">&#x27;entity&#x27;</span>: <span class="hljs-string">&#x27;I-location&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.35856336</span>,
  <span class="hljs-string">&#x27;index&#x27;</span>: <span class="hljs-number">3</span>,
  <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;state&#x27;</span>,
  <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">11</span>,
  <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">16</span>},
 {<span class="hljs-string">&#x27;entity&#x27;</span>: <span class="hljs-string">&#x27;B-group&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.3064001</span>,
  <span class="hljs-string">&#x27;index&#x27;</span>: <span class="hljs-number">4</span>,
  <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;warriors&#x27;</span>,
  <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">17</span>,
  <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">25</span>},
 {<span class="hljs-string">&#x27;entity&#x27;</span>: <span class="hljs-string">&#x27;B-location&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.65523505</span>,
  <span class="hljs-string">&#x27;index&#x27;</span>: <span class="hljs-number">13</span>,
  <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;san&#x27;</span>,
  <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">80</span>,
  <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">83</span>},
 {<span class="hljs-string">&#x27;entity&#x27;</span>: <span class="hljs-string">&#x27;B-location&#x27;</span>,
  <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.4668663</span>,
  <span class="hljs-string">&#x27;index&#x27;</span>: <span class="hljs-number">14</span>,
  <span class="hljs-string">&#x27;word&#x27;</span>: <span class="hljs-string">&#x27;francisco&#x27;</span>,
  <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">84</span>,
  <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">93</span>}]`,wrap:!1}}),is=new Bl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ka],pytorch:[_a]},$$scope:{ctx:C}}}),{c(){t=g("meta"),o=i(),l=g("p"),m=i(),j(b.$$.fragment),k=i(),j(A.$$.fragment),v=i(),j(I.$$.fragment),B=i(),x=g("p"),x.textContent=E,G=i(),$=g("p"),$.textContent=R,r=i(),U=g("ol"),U.innerHTML=V,X=i(),j(W.$$.fragment),M=i(),Z=g("p"),Z.textContent=F,os=i(),j(H.$$.fragment),z=i(),N=g("p"),N.textContent=ls,ms=i(),j(Q.$$.fragment),Y=i(),j(q.$$.fragment),L=i(),as=g("p"),as.textContent=Ms,S=i(),j(D.$$.fragment),P=i(),ts=g("p"),ts.textContent=js,K=i(),j(O.$$.fragment),ss=i(),es=g("p"),es.innerHTML=hs,p=i(),j(T.$$.fragment),ds=i(),us=g("p"),us.innerHTML=Gl,Ds=i(),fs=g("ul"),fs.innerHTML=Rl,Ps=i(),j(ys.$$.fragment),Ks=i(),j(bs.$$.fragment),Os=i(),gs=g("p"),gs.innerHTML=Al,sl=i(),j(ws.$$.fragment),ll=i(),Js=g("p"),Js.innerHTML=Wl,al=i(),j(Ts.$$.fragment),tl=i(),Us=g("p"),Us.innerHTML=Xl,el=i(),$s=g("ol"),$s.innerHTML=El,nl=i(),xs=g("p"),xs.textContent=Vl,pl=i(),j(_s.$$.fragment),rl=i(),Cs=g("p"),Cs.innerHTML=Fl,il=i(),j(ks.$$.fragment),cl=i(),Is=g("p"),Is.innerHTML=Hl,ol=i(),j(ns.$$.fragment),ml=i(),j(Zs.$$.fragment),Ml=i(),vs=g("p"),vs.innerHTML=zl,jl=i(),j(Bs.$$.fragment),hl=i(),Gs=g("p"),Gs.innerHTML=Nl,dl=i(),j(Rs.$$.fragment),ul=i(),As=g("p"),As.innerHTML=Ql,fl=i(),j(Ws.$$.fragment),yl=i(),Xs=g("p"),Xs.innerHTML=Yl,bl=i(),j(Es.$$.fragment),gl=i(),j(ps.$$.fragment),wl=i(),j(rs.$$.fragment),Jl=i(),j(Vs.$$.fragment),Tl=i(),Fs=g("p"),Fs.textContent=ql,Ul=i(),Hs=g("p"),Hs.textContent=Ll,$l=i(),j(zs.$$.fragment),xl=i(),Ns=g("p"),Ns.innerHTML=Sl,_l=i(),j(Qs.$$.fragment),Cl=i(),Ys=g("p"),Ys.innerHTML=Dl,kl=i(),j(is.$$.fragment),Il=i(),Ss=g("p"),this.h()},l(s){const n=ma("svelte-u9bgzb",document.head);t=w(n,"META",{name:!0,content:!0}),n.forEach(a),o=c(s),l=w(s,"P",{}),aa(l).forEach(a),m=c(s),h(b.$$.fragment,s),k=c(s),h(A.$$.fragment,s),v=c(s),h(I.$$.fragment,s),B=c(s),x=w(s,"P",{"data-svelte-h":!0}),J(x)!=="svelte-1pzr9oy"&&(x.textContent=E),G=c(s),$=w(s,"P",{"data-svelte-h":!0}),J($)!=="svelte-w5jzhi"&&($.textContent=R),r=c(s),U=w(s,"OL",{"data-svelte-h":!0}),J(U)!=="svelte-s4jtml"&&(U.innerHTML=V),X=c(s),h(W.$$.fragment,s),M=c(s),Z=w(s,"P",{"data-svelte-h":!0}),J(Z)!=="svelte-1lya3k8"&&(Z.textContent=F),os=c(s),h(H.$$.fragment,s),z=c(s),N=w(s,"P",{"data-svelte-h":!0}),J(N)!=="svelte-193zy02"&&(N.textContent=ls),ms=c(s),h(Q.$$.fragment,s),Y=c(s),h(q.$$.fragment,s),L=c(s),as=w(s,"P",{"data-svelte-h":!0}),J(as)!=="svelte-l7eyn2"&&(as.textContent=Ms),S=c(s),h(D.$$.fragment,s),P=c(s),ts=w(s,"P",{"data-svelte-h":!0}),J(ts)!=="svelte-1r6oj5w"&&(ts.textContent=js),K=c(s),h(O.$$.fragment,s),ss=c(s),es=w(s,"P",{"data-svelte-h":!0}),J(es)!=="svelte-oegc1b"&&(es.innerHTML=hs),p=c(s),h(T.$$.fragment,s),ds=c(s),us=w(s,"P",{"data-svelte-h":!0}),J(us)!=="svelte-ojxi8i"&&(us.innerHTML=Gl),Ds=c(s),fs=w(s,"UL",{"data-svelte-h":!0}),J(fs)!=="svelte-84dn3u"&&(fs.innerHTML=Rl),Ps=c(s),h(ys.$$.fragment,s),Ks=c(s),h(bs.$$.fragment,s),Os=c(s),gs=w(s,"P",{"data-svelte-h":!0}),J(gs)!=="svelte-cnh8zx"&&(gs.innerHTML=Al),sl=c(s),h(ws.$$.fragment,s),ll=c(s),Js=w(s,"P",{"data-svelte-h":!0}),J(Js)!=="svelte-1iw1brp"&&(Js.innerHTML=Wl),al=c(s),h(Ts.$$.fragment,s),tl=c(s),Us=w(s,"P",{"data-svelte-h":!0}),J(Us)!=="svelte-5b435g"&&(Us.innerHTML=Xl),el=c(s),$s=w(s,"OL",{"data-svelte-h":!0}),J($s)!=="svelte-11v861c"&&($s.innerHTML=El),nl=c(s),xs=w(s,"P",{"data-svelte-h":!0}),J(xs)!=="svelte-173aflj"&&(xs.textContent=Vl),pl=c(s),h(_s.$$.fragment,s),rl=c(s),Cs=w(s,"P",{"data-svelte-h":!0}),J(Cs)!=="svelte-1rpvj99"&&(Cs.innerHTML=Fl),il=c(s),h(ks.$$.fragment,s),cl=c(s),Is=w(s,"P",{"data-svelte-h":!0}),J(Is)!=="svelte-qd498c"&&(Is.innerHTML=Hl),ol=c(s),h(ns.$$.fragment,s),ml=c(s),h(Zs.$$.fragment,s),Ml=c(s),vs=w(s,"P",{"data-svelte-h":!0}),J(vs)!=="svelte-1ym9fv4"&&(vs.innerHTML=zl),jl=c(s),h(Bs.$$.fragment,s),hl=c(s),Gs=w(s,"P",{"data-svelte-h":!0}),J(Gs)!=="svelte-1wshevw"&&(Gs.innerHTML=Nl),dl=c(s),h(Rs.$$.fragment,s),ul=c(s),As=w(s,"P",{"data-svelte-h":!0}),J(As)!=="svelte-18cw5xr"&&(As.innerHTML=Ql),fl=c(s),h(Ws.$$.fragment,s),yl=c(s),Xs=w(s,"P",{"data-svelte-h":!0}),J(Xs)!=="svelte-i6dg18"&&(Xs.innerHTML=Yl),bl=c(s),h(Es.$$.fragment,s),gl=c(s),h(ps.$$.fragment,s),wl=c(s),h(rs.$$.fragment,s),Jl=c(s),h(Vs.$$.fragment,s),Tl=c(s),Fs=w(s,"P",{"data-svelte-h":!0}),J(Fs)!=="svelte-cyrfc8"&&(Fs.textContent=ql),Ul=c(s),Hs=w(s,"P",{"data-svelte-h":!0}),J(Hs)!=="svelte-tzt2ke"&&(Hs.textContent=Ll),$l=c(s),h(zs.$$.fragment,s),xl=c(s),Ns=w(s,"P",{"data-svelte-h":!0}),J(Ns)!=="svelte-pzwrt3"&&(Ns.innerHTML=Sl),_l=c(s),h(Qs.$$.fragment,s),Cl=c(s),Ys=w(s,"P",{"data-svelte-h":!0}),J(Ys)!=="svelte-p649vi"&&(Ys.innerHTML=Dl),kl=c(s),h(is.$$.fragment,s),Il=c(s),Ss=w(s,"P",{}),aa(Ss).forEach(a),this.h()},h(){ta(t,"name","hf:doc:metadata"),ta(t,"content",Za)},m(s,n){Ma(document.head,t),e(s,o,n),e(s,l,n),e(s,m,n),d(b,s,n),e(s,k,n),d(A,s,n),e(s,v,n),d(I,s,n),e(s,B,n),e(s,x,n),e(s,G,n),e(s,$,n),e(s,r,n),e(s,U,n),e(s,X,n),d(W,s,n),e(s,M,n),e(s,Z,n),e(s,os,n),d(H,s,n),e(s,z,n),e(s,N,n),e(s,ms,n),d(Q,s,n),e(s,Y,n),d(q,s,n),e(s,L,n),e(s,as,n),e(s,S,n),d(D,s,n),e(s,P,n),e(s,ts,n),e(s,K,n),d(O,s,n),e(s,ss,n),e(s,es,n),e(s,p,n),d(T,s,n),e(s,ds,n),e(s,us,n),e(s,Ds,n),e(s,fs,n),e(s,Ps,n),d(ys,s,n),e(s,Ks,n),d(bs,s,n),e(s,Os,n),e(s,gs,n),e(s,sl,n),d(ws,s,n),e(s,ll,n),e(s,Js,n),e(s,al,n),d(Ts,s,n),e(s,tl,n),e(s,Us,n),e(s,el,n),e(s,$s,n),e(s,nl,n),e(s,xs,n),e(s,pl,n),d(_s,s,n),e(s,rl,n),e(s,Cs,n),e(s,il,n),d(ks,s,n),e(s,cl,n),e(s,Is,n),e(s,ol,n),d(ns,s,n),e(s,ml,n),d(Zs,s,n),e(s,Ml,n),e(s,vs,n),e(s,jl,n),d(Bs,s,n),e(s,hl,n),e(s,Gs,n),e(s,dl,n),d(Rs,s,n),e(s,ul,n),e(s,As,n),e(s,fl,n),d(Ws,s,n),e(s,yl,n),e(s,Xs,n),e(s,bl,n),d(Es,s,n),e(s,gl,n),d(ps,s,n),e(s,wl,n),d(rs,s,n),e(s,Jl,n),d(Vs,s,n),e(s,Tl,n),e(s,Fs,n),e(s,Ul,n),e(s,Hs,n),e(s,$l,n),d(zs,s,n),e(s,xl,n),e(s,Ns,n),e(s,_l,n),d(Qs,s,n),e(s,Cl,n),e(s,Ys,n),e(s,kl,n),d(is,s,n),e(s,Il,n),e(s,Ss,n),Zl=!0},p(s,[n]){const Pl={};n&2&&(Pl.$$scope={dirty:n,ctx:s}),W.$set(Pl);const Kl={};n&2&&(Kl.$$scope={dirty:n,ctx:s}),ns.$set(Kl);const Ol={};n&2&&(Ol.$$scope={dirty:n,ctx:s}),ps.$set(Ol);const sa={};n&2&&(sa.$$scope={dirty:n,ctx:s}),rs.$set(sa);const la={};n&2&&(la.$$scope={dirty:n,ctx:s}),is.$set(la)},i(s){Zl||(u(b.$$.fragment,s),u(A.$$.fragment,s),u(I.$$.fragment,s),u(W.$$.fragment,s),u(H.$$.fragment,s),u(Q.$$.fragment,s),u(q.$$.fragment,s),u(D.$$.fragment,s),u(O.$$.fragment,s),u(T.$$.fragment,s),u(ys.$$.fragment,s),u(bs.$$.fragment,s),u(ws.$$.fragment,s),u(Ts.$$.fragment,s),u(_s.$$.fragment,s),u(ks.$$.fragment,s),u(ns.$$.fragment,s),u(Zs.$$.fragment,s),u(Bs.$$.fragment,s),u(Rs.$$.fragment,s),u(Ws.$$.fragment,s),u(Es.$$.fragment,s),u(ps.$$.fragment,s),u(rs.$$.fragment,s),u(Vs.$$.fragment,s),u(zs.$$.fragment,s),u(Qs.$$.fragment,s),u(is.$$.fragment,s),Zl=!0)},o(s){f(b.$$.fragment,s),f(A.$$.fragment,s),f(I.$$.fragment,s),f(W.$$.fragment,s),f(H.$$.fragment,s),f(Q.$$.fragment,s),f(q.$$.fragment,s),f(D.$$.fragment,s),f(O.$$.fragment,s),f(T.$$.fragment,s),f(ys.$$.fragment,s),f(bs.$$.fragment,s),f(ws.$$.fragment,s),f(Ts.$$.fragment,s),f(_s.$$.fragment,s),f(ks.$$.fragment,s),f(ns.$$.fragment,s),f(Zs.$$.fragment,s),f(Bs.$$.fragment,s),f(Rs.$$.fragment,s),f(Ws.$$.fragment,s),f(Es.$$.fragment,s),f(ps.$$.fragment,s),f(rs.$$.fragment,s),f(Vs.$$.fragment,s),f(zs.$$.fragment,s),f(Qs.$$.fragment,s),f(is.$$.fragment,s),Zl=!1},d(s){s&&(a(o),a(l),a(m),a(k),a(v),a(B),a(x),a(G),a($),a(r),a(U),a(X),a(M),a(Z),a(os),a(z),a(N),a(ms),a(Y),a(L),a(as),a(S),a(P),a(ts),a(K),a(ss),a(es),a(p),a(ds),a(us),a(Ds),a(fs),a(Ps),a(Ks),a(Os),a(gs),a(sl),a(ll),a(Js),a(al),a(tl),a(Us),a(el),a($s),a(nl),a(xs),a(pl),a(rl),a(Cs),a(il),a(cl),a(Is),a(ol),a(ml),a(Ml),a(vs),a(jl),a(hl),a(Gs),a(dl),a(ul),a(As),a(fl),a(yl),a(Xs),a(bl),a(gl),a(wl),a(Jl),a(Tl),a(Fs),a(Ul),a(Hs),a($l),a(xl),a(Ns),a(_l),a(Cl),a(Ys),a(kl),a(Il),a(Ss)),a(t),y(b,s),y(A,s),y(I,s),y(W,s),y(H,s),y(Q,s),y(q,s),y(D,s),y(O,s),y(T,s),y(ys,s),y(bs,s),y(ws,s),y(Ts,s),y(_s,s),y(ks,s),y(ns,s),y(Zs,s),y(Bs,s),y(Rs,s),y(Ws,s),y(Es,s),y(ps,s),y(rs,s),y(Vs,s),y(zs,s),y(Qs,s),y(is,s)}}}const Za='{"title":"Token classification","local":"token-classification","sections":[{"title":"Load WNUT 17 dataset","local":"load-wnut-17-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function va(C){return ia(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Fa extends ca{constructor(t){super(),oa(this,t,va,Ia,ra,{})}}export{Fa as component};
