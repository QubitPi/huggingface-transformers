import{s as ra,o as ma,n as vt}from"../chunks/scheduler.9bc65507.js";import{S as ca,i as oa,g as c,s as l,r as u,A as ua,h as o,f as a,c as n,j as la,u as f,x as y,k as na,y as fa,a as e,v as h,d,t as g,w as j,m as ha,n as da}from"../chunks/index.707bf1b6.js";import{T as kt}from"../chunks/Tip.c2ecdbf4.js";import{Y as ga}from"../chunks/Youtube.e1129c6f.js";import{C as _}from"../chunks/CodeBlock.54a9f38d.js";import{D as ja}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as pa,M as ia}from"../chunks/Markdown.8ab98a13.js";import{H as Cs}from"../chunks/Heading.342b1fa6.js";function Ma(v){let p,b,i='<a href="../model_doc/audio-spectrogram-transformer">Audio Spectrogram Transformer</a>, <a href="../model_doc/data2vec-audio">Data2VecAudio</a>, <a href="../model_doc/hubert">Hubert</a>, <a href="../model_doc/sew">SEW</a>, <a href="../model_doc/sew-d">SEW-D</a>, <a href="../model_doc/unispeech">UniSpeech</a>, <a href="../model_doc/unispeech-sat">UniSpeechSat</a>, <a href="../model_doc/wav2vec2">Wav2Vec2</a>, <a href="../model_doc/wav2vec2-conformer">Wav2Vec2-Conformer</a>, <a href="../model_doc/wavlm">WavLM</a>, <a href="../model_doc/whisper">Whisper</a>';return{c(){p=ha(`ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§èª¬æ˜ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯ã€æ¬¡ã®ãƒ¢ãƒ‡ãƒ« ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

`),b=c("p"),b.innerHTML=i},l(M){p=da(M,`ã“ã®ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã§èª¬æ˜ã™ã‚‹ã‚¿ã‚¹ã‚¯ã¯ã€æ¬¡ã®ãƒ¢ãƒ‡ãƒ« ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã§ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚

`),b=o(M,"P",{"data-svelte-h":!0}),y(b)!=="svelte-1x7pfyj"&&(b.innerHTML=i)},m(M,$){e(M,p,$),e(M,b,$)},p:vt,d(M){M&&(a(p),a(b))}}}function ba(v){let p,b='<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€<a href="../training#train-with-pytorch-trainer">ã“ã¡ã‚‰</a> ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚';return{c(){p=c("p"),p.innerHTML=b},l(i){p=o(i,"P",{"data-svelte-h":!0}),y(p)!=="svelte-u6v1yb"&&(p.innerHTML=b)},m(i,M){e(i,p,M)},p:vt,d(i){i&&a(p)}}}function ya(v){let p,b,i,M='ã“ã‚Œã§ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ <a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoModelForAudioClassification">AutoModelForAudioClassification</a> ã‚’ä½¿ç”¨ã—ã¦ã€äºˆæœŸã•ã‚Œã‚‹ãƒ©ãƒ™ãƒ«ã®æ•°ã¨ãƒ©ãƒ™ãƒ« ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ Wav2Vec2 ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚',$,U,k,Z,W="ã“ã®æ™‚ç‚¹ã§æ®‹ã£ã¦ã„ã‚‹æ‰‹é †ã¯æ¬¡ã® 3 ã¤ã ã‘ã§ã™ã€‚",C,J,V='<li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã¾ã™ã€‚å”¯ä¸€ã®å¿…é ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å ´æ‰€ã‚’æŒ‡å®šã™ã‚‹ <code>output_dir</code> ã§ã™ã€‚ <code>push_to_hub=True</code>ã‚’è¨­å®šã—ã¦ã€ã“ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã«ãƒ—ãƒƒã‚·ãƒ¥ã—ã¾ã™ (ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€Hugging Face ã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™)ã€‚å„ã‚¨ãƒãƒƒã‚¯ã®çµ‚äº†æ™‚ã«ã€<code>ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼</code> ã¯ç²¾åº¦ã‚’è©•ä¾¡ã—ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚° ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ã—ã¾ã™ã€‚</li> <li>ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°å¼•æ•°ã‚’ã€ãƒ¢ãƒ‡ãƒ«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã€ãƒ‡ãƒ¼ã‚¿ç…§åˆå™¨ã€ãŠã‚ˆã³ <code>compute_metrics</code> é–¢æ•°ã¨ã¨ã‚‚ã« <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> ã«æ¸¡ã—ã¾ã™ã€‚</li> <li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train">train()</a> ã‚’å‘¼ã³å‡ºã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ã¾ã™ã€‚</li>',I,T,R,m,x='ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ãŸã‚‰ã€ <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒãƒ–ã«å…±æœ‰ã—ã€èª°ã‚‚ãŒãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚',H,G,X;return p=new kt({props:{$$slots:{default:[ba]},$$scope:{ctx:v}}}),U=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckF1ZGlvQ2xhc3NpZmljYXRpb24lMkMlMjBUcmFpbmluZ0FyZ3VtZW50cyUyQyUyMFRyYWluZXIlMEElMEFudW1fbGFiZWxzJTIwJTNEJTIwbGVuKGlkMmxhYmVsKSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQXVkaW9DbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZmFjZWJvb2slMkZ3YXYydmVjMi1iYXNlJTIyJTJDJTIwbnVtX2xhYmVscyUzRG51bV9sYWJlbHMlMkMlMjBsYWJlbDJpZCUzRGxhYmVsMmlkJTJDJTIwaWQybGFiZWwlM0RpZDJsYWJlbCUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForAudioClassification, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>num_labels = <span class="hljs-built_in">len</span>(id2label)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>, num_labels=num_labels, label2id=label2id, id2label=id2label
<span class="hljs-meta">... </span>)`,wrap:!1}}),T=new _({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX21pbmRfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjBldmFsdWF0aW9uX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBsZWFybmluZ19yYXRlJTNEM2UtNSUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDMyJTJDJTBBJTIwJTIwJTIwJTIwZ3JhZGllbnRfYWNjdW11bGF0aW9uX3N0ZXBzJTNENCUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEMzIlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMTAlMkMlMEElMjAlMjAlMjAlMjB3YXJtdXBfcmF0aW8lM0QwLjElMkMlMEElMjAlMjAlMjAlMjBsb2dnaW5nX3N0ZXBzJTNEMTAlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMG1ldHJpY19mb3JfYmVzdF9tb2RlbCUzRCUyMmFjY3VyYWN5JTIyJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0RlbmNvZGVkX21pbmRzJTVCJTIydHJhaW4lMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0RlbmNvZGVkX21pbmRzJTVCJTIydGVzdCUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHRva2VuaXplciUzRGZlYXR1cmVfZXh0cmFjdG9yJTJDJTBBJTIwJTIwJTIwJTIwY29tcHV0ZV9tZXRyaWNzJTNEY29tcHV0ZV9tZXRyaWNzJTJDJTBBKSUwQSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_mind_model&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">3e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">32</span>,
<span class="hljs-meta">... </span>    gradient_accumulation_steps=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">32</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">10</span>,
<span class="hljs-meta">... </span>    warmup_ratio=<span class="hljs-number">0.1</span>,
<span class="hljs-meta">... </span>    logging_steps=<span class="hljs-number">10</span>,
<span class="hljs-meta">... </span>    load_best_model_at_end=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    metric_for_best_model=<span class="hljs-string">&quot;accuracy&quot;</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=encoded_minds[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=encoded_minds[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=feature_extractor,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),G=new _({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){u(p.$$.fragment),b=l(),i=c("p"),i.innerHTML=M,$=l(),u(U.$$.fragment),k=l(),Z=c("p"),Z.textContent=W,C=l(),J=c("ol"),J.innerHTML=V,I=l(),u(T.$$.fragment),R=l(),m=c("p"),m.innerHTML=x,H=l(),u(G.$$.fragment)},l(r){f(p.$$.fragment,r),b=n(r),i=o(r,"P",{"data-svelte-h":!0}),y(i)!=="svelte-1ygen11"&&(i.innerHTML=M),$=n(r),f(U.$$.fragment,r),k=n(r),Z=o(r,"P",{"data-svelte-h":!0}),y(Z)!=="svelte-1j8bgyv"&&(Z.textContent=W),C=n(r),J=o(r,"OL",{"data-svelte-h":!0}),y(J)!=="svelte-1w5x017"&&(J.innerHTML=V),I=n(r),f(T.$$.fragment,r),R=n(r),m=o(r,"P",{"data-svelte-h":!0}),y(m)!=="svelte-ngexm3"&&(m.innerHTML=x),H=n(r),f(G.$$.fragment,r)},m(r,w){h(p,r,w),e(r,b,w),e(r,i,w),e(r,$,w),h(U,r,w),e(r,k,w),e(r,Z,w),e(r,C,w),e(r,J,w),e(r,I,w),h(T,r,w),e(r,R,w),e(r,m,w),e(r,H,w),h(G,r,w),X=!0},p(r,w){const Is={};w&2&&(Is.$$scope={dirty:w,ctx:r}),p.$set(Is)},i(r){X||(d(p.$$.fragment,r),d(U.$$.fragment,r),d(T.$$.fragment,r),d(G.$$.fragment,r),X=!0)},o(r){g(p.$$.fragment,r),g(U.$$.fragment,r),g(T.$$.fragment,r),g(G.$$.fragment,r),X=!1},d(r){r&&(a(b),a(i),a($),a(k),a(Z),a(C),a(J),a(I),a(R),a(m),a(H)),j(p,r),j(U,r),j(T,r),j(G,r)}}}function $a(v){let p,b;return p=new ia({props:{$$slots:{default:[ya]},$$scope:{ctx:v}}}),{c(){u(p.$$.fragment)},l(i){f(p.$$.fragment,i)},m(i,M){h(p,i,M),b=!0},p(i,M){const $={};M&2&&($.$$scope={dirty:M,ctx:i}),p.$set($)},i(i){b||(d(p.$$.fragment,i),b=!0)},o(i){g(p.$$.fragment,i),b=!1},d(i){j(p,i)}}}function wa(v){let p,b='éŸ³å£°åˆ†é¡ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã™ã‚‹æ–¹æ³•ã®è©³ç´°ãªä¾‹ã«ã¤ã„ã¦ã¯ã€å¯¾å¿œã™ã‚‹ <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/audio_classification.ipynb" rel="nofollow">PyTorch notebook</a>.';return{c(){p=c("p"),p.innerHTML=b},l(i){p=o(i,"P",{"data-svelte-h":!0}),y(p)!=="svelte-nc5jhf"&&(p.innerHTML=b)},m(i,M){e(i,p,M)},p:vt,d(i){i&&a(p)}}}function Ja(v){let p,b="ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰å‡¦ç†ã—ã€<code>input</code>ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚",i,M,$,U,k="å…¥åŠ›ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ã€ãƒ­ã‚¸ãƒƒãƒˆã‚’è¿”ã—ã¾ã™ã€‚",Z,W,C,J,V="æœ€ã‚‚é«˜ã„ç¢ºç‡ã§ã‚¯ãƒ©ã‚¹ã‚’å–å¾—ã—ã€ãƒ¢ãƒ‡ãƒ«ã® <code>id2label</code> ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’ä½¿ç”¨ã—ã¦ãã‚Œã‚’ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ã—ã¾ã™ã€‚",I,T,R;return M=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTIyc3RldmhsaXUlMkZteV9hd2Vzb21lX21pbmRzX21vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMGZlYXR1cmVfZXh0cmFjdG9yKGRhdGFzZXQlNUIwJTVEJTVCJTIyYXVkaW8lMjIlNUQlNUIlMjJhcnJheSUyMiU1RCUyQyUyMHNhbXBsaW5nX3JhdGUlM0RzYW1wbGluZ19yYXRlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_minds_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = feature_extractor(dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>], sampling_rate=sampling_rate, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),W=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckF1ZGlvQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckF1ZGlvQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMnN0ZXZobGl1JTJGbXlfYXdlc29tZV9taW5kc19tb2RlbCUyMiklMEF3aXRoJTIwdG9yY2gubm9fZ3JhZCgpJTNBJTBBJTIwJTIwJTIwJTIwbG9naXRzJTIwJTNEJTIwbW9kZWwoKippbnB1dHMpLmxvZ2l0cw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForAudioClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForAudioClassification.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_minds_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits`,wrap:!1}}),T=new _({props:{code:"aW1wb3J0JTIwdG9yY2glMEElMEFwcmVkaWN0ZWRfY2xhc3NfaWRzJTIwJTNEJTIwdG9yY2guYXJnbWF4KGxvZ2l0cykuaXRlbSgpJTBBcHJlZGljdGVkX2xhYmVsJTIwJTNEJTIwbW9kZWwuY29uZmlnLmlkMmxhYmVsJTVCcHJlZGljdGVkX2NsYXNzX2lkcyU1RCUwQXByZWRpY3RlZF9sYWJlbA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class_ids = torch.argmax(logits).item()
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_label = model.config.id2label[predicted_class_ids]
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_label
<span class="hljs-string">&#x27;cash_deposit&#x27;</span>`,wrap:!1}}),{c(){p=c("p"),p.innerHTML=b,i=l(),u(M.$$.fragment),$=l(),U=c("p"),U.textContent=k,Z=l(),u(W.$$.fragment),C=l(),J=c("p"),J.innerHTML=V,I=l(),u(T.$$.fragment)},l(m){p=o(m,"P",{"data-svelte-h":!0}),y(p)!=="svelte-1lbojgb"&&(p.innerHTML=b),i=n(m),f(M.$$.fragment,m),$=n(m),U=o(m,"P",{"data-svelte-h":!0}),y(U)!=="svelte-jwtn5w"&&(U.textContent=k),Z=n(m),f(W.$$.fragment,m),C=n(m),J=o(m,"P",{"data-svelte-h":!0}),y(J)!=="svelte-x53zvr"&&(J.innerHTML=V),I=n(m),f(T.$$.fragment,m)},m(m,x){e(m,p,x),e(m,i,x),h(M,m,x),e(m,$,x),e(m,U,x),e(m,Z,x),h(W,m,x),e(m,C,x),e(m,J,x),e(m,I,x),h(T,m,x),R=!0},p:vt,i(m){R||(d(M.$$.fragment,m),d(W.$$.fragment,m),d(T.$$.fragment,m),R=!0)},o(m){g(M.$$.fragment,m),g(W.$$.fragment,m),g(T.$$.fragment,m),R=!1},d(m){m&&(a(p),a(i),a($),a(U),a(Z),a(C),a(J),a(I)),j(M,m),j(W,m),j(T,m)}}}function Ta(v){let p,b;return p=new ia({props:{$$slots:{default:[Ja]},$$scope:{ctx:v}}}),{c(){u(p.$$.fragment)},l(i){f(p.$$.fragment,i)},m(i,M){h(p,i,M),b=!0},p(i,M){const $={};M&2&&($.$$scope={dirty:M,ctx:i}),p.$set($)},i(i){b||(d(p.$$.fragment,i),b=!0)},o(i){g(p.$$.fragment,i),b=!1},d(i){j(p,i)}}}function _a(v){let p,b,i,M,$,U,k,Z,W,C,J,V="éŸ³å£°åˆ†é¡ã§ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¨åŒæ§˜ã«ã€å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å‡ºåŠ›ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ ãƒ©ãƒ™ãƒ«ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚å”¯ä¸€ã®é•ã„ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®ä»£ã‚ã‚Šã«ç”Ÿã®ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªæ³¢å½¢ãŒã‚ã‚‹ã“ã¨ã§ã™ã€‚éŸ³å£°åˆ†é¡ã®å®Ÿéš›çš„ãªå¿œç”¨ä¾‹ã«ã¯ã€è©±è€…ã®æ„å›³ã€è¨€èªåˆ†é¡ã€ã•ã‚‰ã«ã¯éŸ³ã«ã‚ˆã‚‹å‹•ç‰©ã®ç¨®é¡ã®è­˜åˆ¥ãªã©ãŒã‚ã‚Šã¾ã™ã€‚",I,T,R="ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€æ¬¡ã®æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚",m,x,H='<li><a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ <a href="https://huggingface.co/facebook/wav2vec2-base" rel="nofollow">Wav2Vec2</a> ã‚’å¾®èª¿æ•´ã—ã¦è©±è€…ã®æ„å›³ã‚’åˆ†é¡ã—ã¾ã™ã€‚</li> <li>å¾®èª¿æ•´ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚</li>',G,X,r,w,Is="å§‹ã‚ã‚‹å‰ã«ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚",Rs,B,Gs,E,Ct="ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨å…±æœ‰ã§ãã‚‹ã‚ˆã†ã«ã€Hugging Face ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’å…¥åŠ›ã—ã¦ãƒ­ã‚°ã‚¤ãƒ³ã—ã¾ã™ã€‚",Vs,Q,Ys,A,Fs,z,It="ã¾ãšã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚",Ns,q,Hs,S,Xt="<code>train_test_split</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã® <code>train</code> ã‚’ã‚ˆã‚Šå°ã•ãªãƒˆãƒ¬ã‚¤ãƒ³ã¨ãƒ†ã‚¹ãƒˆ ã‚»ãƒƒãƒˆã«åˆ†å‰²ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã•ã‚‰ã«æ™‚é–“ã‚’è²»ã‚„ã™å‰ã«ã€å®Ÿé¨“ã—ã¦ã™ã¹ã¦ãŒæ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹æ©Ÿä¼šãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚",Bs,L,Es,P,Rt="æ¬¡ã«ã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",Qs,D,As,K,Gt="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã¯<code>lang_id</code>ã‚„<code>english_transcription</code>ãªã©ã®å¤šãã®æœ‰ç”¨ãªæƒ…å ±ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ãŒã€ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯<code>audio</code>ã¨<code>intent_class</code>ã«ç„¦ç‚¹ã‚’å½“ã¦ã¾ã™ã€‚ <code>remove_columns</code> ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ä»–ã®åˆ—ã‚’å‰Šé™¤ã—ã¾ã™ã€‚",zs,O,qs,ss,Vt="ã“ã“ã§ä¾‹ã‚’è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ã€‚",Ss,ts,Ls,as,Yt="æ¬¡ã® 2 ã¤ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚",Ps,es,Ft="<li><code>audio</code>: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ãŸã‚ã«å‘¼ã³å‡ºã™å¿…è¦ãŒã‚ã‚‹éŸ³å£°ä¿¡å·ã® 1 æ¬¡å…ƒã® <code>array</code>ã€‚</li> <li><code>intent_class</code>: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã®ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã®ã‚¯ãƒ©ã‚¹ ID ã‚’è¡¨ã—ã¾ã™ã€‚</li>",Ds,ls,Nt="ãƒ¢ãƒ‡ãƒ«ãŒãƒ©ãƒ™ãƒ« ID ã‹ã‚‰ãƒ©ãƒ™ãƒ«åã‚’å–å¾—ã—ã‚„ã™ãã™ã‚‹ãŸã‚ã«ã€ãƒ©ãƒ™ãƒ«åã‚’æ•´æ•°ã«ã€ã¾ãŸã¯ãã®é€†ã«ãƒãƒƒãƒ—ã™ã‚‹è¾æ›¸ã‚’ä½œæˆã—ã¾ã™ã€‚",Ks,ns,Os,ps,Ht="ã“ã‚Œã§ã€ãƒ©ãƒ™ãƒ« ID ã‚’ãƒ©ãƒ™ãƒ«åã«å¤‰æ›ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚",st,is,tt,rs,at,ms,Bt="æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯ã€Wav2Vec2 ç‰¹å¾´æŠ½å‡ºãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªä¿¡å·ã‚’å‡¦ç†ã—ã¾ã™ã€‚",et,cs,lt,os,Et='MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8000khz ã§ã™ (ã“ã®æƒ…å ±ã¯ <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã‚«ãƒ¼ãƒ‰</a> ã§ç¢ºèªã§ãã¾ã™)ã€‚ã¤ã¾ã‚Šã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å†ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸ Wav2Vec2 ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€16000kHz ã«è¨­å®šã—ã¾ã™ã€‚',nt,us,pt,fs,Qt="æ¬¡ã«ã€æ¬¡ã®å‰å‡¦ç†é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚",it,hs,At='<li><code>audio</code>åˆ—ã‚’å‘¼ã³å‡ºã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã€å¿…è¦ã«å¿œã˜ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚</li> <li>ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆãŒã€ãƒ¢ãƒ‡ãƒ«ãŒäº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¨ä¸€è‡´ã™ã‚‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚ã“ã®æƒ…å ±ã¯ã€Wav2Vec2 <a href="https://huggingface.co/facebook/wav2vec2-base" rel="nofollow">ãƒ¢ãƒ‡ãƒ« ã‚«ãƒ¼ãƒ‰</a> ã§è¦‹ã¤ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚</li> <li>å…¥åŠ›ã®æœ€å¤§é•·ã‚’è¨­å®šã—ã¦ã€é•·ã„å…¥åŠ›ã‚’åˆ‡ã‚Šæ¨ã¦ãšã«ãƒãƒƒãƒå‡¦ç†ã—ã¾ã™ã€‚</li>',rt,ds,mt,gs,zt="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã«å‰å‡¦ç†é–¢æ•°ã‚’é©ç”¨ã™ã‚‹ã«ã¯ã€ğŸ¤— Datasets <code>map</code> é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ <code>batched=True</code> ã‚’è¨­å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®è¤‡æ•°ã®è¦ç´ ã‚’ä¸€åº¦ã«å‡¦ç†ã™ã‚‹ã“ã¨ã§ã€<code>map</code> ã‚’é«˜é€ŸåŒ–ã§ãã¾ã™ã€‚ä¸è¦ãªåˆ—ã‚’å‰Šé™¤ã—ã€<code>intent_class</code> ã®åå‰ã‚’ <code>label</code> ã«å¤‰æ›´ã—ã¾ã™ã€‚ã“ã‚Œã¯ãƒ¢ãƒ‡ãƒ«ãŒæœŸå¾…ã™ã‚‹åå‰ã§ã‚ã‚‹ãŸã‚ã§ã™ã€‚",ct,js,ot,Ms,ut,bs,qt='ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’å«ã‚ã‚‹ã¨ã€å¤šãã®å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚ ğŸ¤— <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ã€è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã™ã°ã‚„ããƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚ã“ã®ã‚¿ã‚¹ã‚¯ã§ã¯ã€<a href="https://huggingface.co/spaces/evaluate-metric/accuracy" rel="nofollow">accuracy</a> ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’èª­ã¿è¾¼ã¿ã¾ã™ (ğŸ¤— Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">ã‚¯ã‚¤ãƒƒã‚¯ ãƒ„ã‚¢ãƒ¼</a> ã‚’å‚ç…§ã—ã¦ãã ã•ã„) ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®èª­ã¿è¾¼ã¿ã¨è¨ˆç®—æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€æ¬¡ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚',ft,ys,ht,$s,St="æ¬¡ã«ã€äºˆæ¸¬ã¨ãƒ©ãƒ™ãƒ«ã‚’ <code>compute</code> ã«æ¸¡ã—ã¦ç²¾åº¦ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚",dt,ws,gt,Js,Lt="ã“ã‚Œã§<code>compute_metrics</code>é–¢æ•°ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã¨ãã«ã“ã®é–¢æ•°ã«æˆ»ã‚Šã¾ã™ã€‚",jt,Ts,Mt,Y,bt,F,yt,_s,$t,xs,Pt="ãƒ¢ãƒ‡ãƒ«ã‚’å¾®èª¿æ•´ã—ãŸã®ã§ã€ãã‚Œã‚’æ¨è«–ã«ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚",wt,Us,Dt="æ¨è«–ã‚’å®Ÿè¡Œã—ãŸã„éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ã€ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¨ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã™ã‚‹ã“ã¨ã‚’å¿˜ã‚Œãªã„ã§ãã ã•ã„ã€‚",Jt,Ws,Tt,Zs,Kt='æ¨è«–ç”¨ã«å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã¯ã€ãã‚Œã‚’ <a href="/docs/transformers/main/ja/main_classes/pipelines#transformers.pipeline">pipeline()</a> ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦éŸ³å£°åˆ†é¡ç”¨ã®<code>pipeline</code>ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã€ãã‚Œã«éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¸¡ã—ã¾ã™ã€‚',_t,vs,xt,ks,Ot="å¿…è¦ã«å¿œã˜ã¦ã€<code>pipeline</code> ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚",Ut,N,Wt,Xs,Zt;return $=new Cs({props:{title:"Audio classification",local:"audio-classification",headingTag:"h1"}}),k=new ja({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/audio_classification.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/audio_classification.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/audio_classification.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/audio_classification.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/audio_classification.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/audio_classification.ipynb"}]}}),W=new ga({props:{id:"KWwzcmG98Ds"}}),X=new kt({props:{$$slots:{default:[Ma]},$$scope:{ctx:v}}}),B=new _({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),Q=new _({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),A=new Cs({props:{title:"Load MInDS-14 dataset",local:"load-minds-14-dataset",headingTag:"h2"}}),q=new _({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFtaW5kcyUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJQb2x5QUklMkZtaW5kczE0JTIyJTJDJTIwbmFtZSUzRCUyMmVuLVVTJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>minds = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),L=new _({props:{code:"bWluZHMlMjAlM0QlMjBtaW5kcy50cmFpbl90ZXN0X3NwbGl0KHRlc3Rfc2l6ZSUzRDAuMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),D=new _({props:{code:"bWluZHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>minds
DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;path&#x27;</span>, <span class="hljs-string">&#x27;audio&#x27;</span>, <span class="hljs-string">&#x27;transcription&#x27;</span>, <span class="hljs-string">&#x27;english_transcription&#x27;</span>, <span class="hljs-string">&#x27;intent_class&#x27;</span>, <span class="hljs-string">&#x27;lang_id&#x27;</span>],
        num_rows: <span class="hljs-number">450</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;path&#x27;</span>, <span class="hljs-string">&#x27;audio&#x27;</span>, <span class="hljs-string">&#x27;transcription&#x27;</span>, <span class="hljs-string">&#x27;english_transcription&#x27;</span>, <span class="hljs-string">&#x27;intent_class&#x27;</span>, <span class="hljs-string">&#x27;lang_id&#x27;</span>],
        num_rows: <span class="hljs-number">113</span>
    })
})`,wrap:!1}}),O=new _({props:{code:"bWluZHMlMjAlM0QlMjBtaW5kcy5yZW1vdmVfY29sdW1ucyglNUIlMjJwYXRoJTIyJTJDJTIwJTIydHJhbnNjcmlwdGlvbiUyMiUyQyUyMCUyMmVuZ2xpc2hfdHJhbnNjcmlwdGlvbiUyMiUyQyUyMCUyMmxhbmdfaWQlMjIlNUQp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.remove_columns([<span class="hljs-string">&quot;path&quot;</span>, <span class="hljs-string">&quot;transcription&quot;</span>, <span class="hljs-string">&quot;english_transcription&quot;</span>, <span class="hljs-string">&quot;lang_id&quot;</span>])',wrap:!1}}),ts=new _({props:{code:"bWluZHMlNUIlMjJ0cmFpbiUyMiU1RCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>minds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>: {<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        , ..., -<span class="hljs-number">0.00048828</span>,
         -<span class="hljs-number">0.00024414</span>, -<span class="hljs-number">0.00024414</span>], dtype=float32),
  <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav&#x27;</span>,
  <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">8000</span>},
 <span class="hljs-string">&#x27;intent_class&#x27;</span>: <span class="hljs-number">2</span>}`,wrap:!1}}),ns=new _({props:{code:"bGFiZWxzJTIwJTNEJTIwbWluZHMlNUIlMjJ0cmFpbiUyMiU1RC5mZWF0dXJlcyU1QiUyMmludGVudF9jbGFzcyUyMiU1RC5uYW1lcyUwQWxhYmVsMmlkJTJDJTIwaWQybGFiZWwlMjAlM0QlMjBkaWN0KCklMkMlMjBkaWN0KCklMEFmb3IlMjBpJTJDJTIwbGFiZWwlMjBpbiUyMGVudW1lcmF0ZShsYWJlbHMpJTNBJTBBJTIwJTIwJTIwJTIwbGFiZWwyaWQlNUJsYWJlbCU1RCUyMCUzRCUyMHN0cihpKSUwQSUyMCUyMCUyMCUyMGlkMmxhYmVsJTVCc3RyKGkpJTVEJTIwJTNEJTIwbGFiZWw=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = minds[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;intent_class&quot;</span>].names
<span class="hljs-meta">&gt;&gt;&gt; </span>label2id, id2label = <span class="hljs-built_in">dict</span>(), <span class="hljs-built_in">dict</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):
<span class="hljs-meta">... </span>    label2id[label] = <span class="hljs-built_in">str</span>(i)
<span class="hljs-meta">... </span>    id2label[<span class="hljs-built_in">str</span>(i)] = label`,wrap:!1}}),is=new _({props:{code:"aWQybGFiZWwlNUJzdHIoMiklNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>id2label[<span class="hljs-built_in">str</span>(<span class="hljs-number">2</span>)]
<span class="hljs-string">&#x27;app_error&#x27;</span>`,wrap:!1}}),rs=new Cs({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),cs=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZ3YXYydmVjMi1iYXNlJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`,wrap:!1}}),us=new _({props:{code:"bWluZHMlMjAlM0QlMjBtaW5kcy5jYXN0X2NvbHVtbiglMjJhdWRpbyUyMiUyQyUyMEF1ZGlvKHNhbXBsaW5nX3JhdGUlM0QxNl8wMDApKSUwQW1pbmRzJTVCJTIydHJhaW4lMjIlNUQlNUIwJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>minds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>: {<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">2.2098757e-05</span>,  <span class="hljs-number">4.6582241e-05</span>, -<span class="hljs-number">2.2803260e-05</span>, ...,
         -<span class="hljs-number">2.8419291e-04</span>, -<span class="hljs-number">2.3305941e-04</span>, -<span class="hljs-number">1.1425107e-04</span>], dtype=float32),
  <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602b9a5fbb1e6d0fbce91f52.wav&#x27;</span>,
  <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>},
 <span class="hljs-string">&#x27;intent_class&#x27;</span>: <span class="hljs-number">2</span>}`,wrap:!1}}),ds=new _({props:{code:"ZGVmJTIwcHJlcHJvY2Vzc19mdW5jdGlvbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBhdWRpb19hcnJheXMlMjAlM0QlMjAlNUJ4JTVCJTIyYXJyYXklMjIlNUQlMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlcyU1QiUyMmF1ZGlvJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwaW5wdXRzJTIwJTNEJTIwZmVhdHVyZV9leHRyYWN0b3IoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwYXVkaW9fYXJyYXlzJTJDJTIwc2FtcGxpbmdfcmF0ZSUzRGZlYXR1cmVfZXh0cmFjdG9yLnNhbXBsaW5nX3JhdGUlMkMlMjBtYXhfbGVuZ3RoJTNEMTYwMDAlMkMlMjB0cnVuY2F0aW9uJTNEVHJ1ZSUwQSUyMCUyMCUyMCUyMCklMEElMjAlMjAlMjAlMjByZXR1cm4lMjBpbnB1dHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    audio_arrays = [x[<span class="hljs-string">&quot;array&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;audio&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = feature_extractor(
<span class="hljs-meta">... </span>        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=<span class="hljs-number">16000</span>, truncation=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>    )
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`,wrap:!1}}),js=new _({props:{code:"ZW5jb2RlZF9taW5kcyUyMCUzRCUyMG1pbmRzLm1hcChwcmVwcm9jZXNzX2Z1bmN0aW9uJTJDJTIwcmVtb3ZlX2NvbHVtbnMlM0QlMjJhdWRpbyUyMiUyQyUyMGJhdGNoZWQlM0RUcnVlKSUwQWVuY29kZWRfbWluZHMlMjAlM0QlMjBlbmNvZGVkX21pbmRzLnJlbmFtZV9jb2x1bW4oJTIyaW50ZW50X2NsYXNzJTIyJTJDJTIwJTIybGFiZWwlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_minds = minds.<span class="hljs-built_in">map</span>(preprocess_function, remove_columns=<span class="hljs-string">&quot;audio&quot;</span>, batched=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_minds = encoded_minds.rename_column(<span class="hljs-string">&quot;intent_class&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>)`,wrap:!1}}),Ms=new Cs({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),ys=new _({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEFhY2N1cmFjeSUyMCUzRCUyMGV2YWx1YXRlLmxvYWQoJTIyYWNjdXJhY3klMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>accuracy = evaluate.load(<span class="hljs-string">&quot;accuracy&quot;</span>)`,wrap:!1}}),ws=new _({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKGV2YWxfcHJlZCklM0ElMEElMjAlMjAlMjAlMjBwcmVkaWN0aW9ucyUyMCUzRCUyMG5wLmFyZ21heChldmFsX3ByZWQucHJlZGljdGlvbnMlMkMlMjBheGlzJTNEMSklMEElMjAlMjAlMjAlMjByZXR1cm4lMjBhY2N1cmFjeS5jb21wdXRlKHByZWRpY3Rpb25zJTNEcHJlZGljdGlvbnMlMkMlMjByZWZlcmVuY2VzJTNEZXZhbF9wcmVkLmxhYmVsX2lkcyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    predictions = np.argmax(eval_pred.predictions, axis=<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> accuracy.compute(predictions=predictions, references=eval_pred.label_ids)`,wrap:!1}}),Ts=new Cs({props:{title:"Train",local:"train",headingTag:"h2"}}),Y=new pa({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[$a]},$$scope:{ctx:v}}}),F=new kt({props:{$$slots:{default:[wa]},$$scope:{ctx:v}}}),_s=new Cs({props:{title:"Inference",local:"inference",headingTag:"h2"}}),Ws=new _({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjBuYW1lJTNEJTIyZW4tVVMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKSUwQWRhdGFzZXQlMjAlM0QlMjBkYXRhc2V0LmNhc3RfY29sdW1uKCUyMmF1ZGlvJTIyJTJDJTIwQXVkaW8oc2FtcGxpbmdfcmF0ZSUzRDE2MDAwKSklMEFzYW1wbGluZ19yYXRlJTIwJTNEJTIwZGF0YXNldC5mZWF0dXJlcyU1QiUyMmF1ZGlvJTIyJTVELnNhbXBsaW5nX3JhdGUlMEFhdWRpb19maWxlJTIwJTNEJTIwZGF0YXNldCU1QjAlNUQlNUIlMjJhdWRpbyUyMiU1RCU1QiUyMnBhdGglMjIlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>sampling_rate = dataset.features[<span class="hljs-string">&quot;audio&quot;</span>].sampling_rate
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`,wrap:!1}}),vs=new _({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMmF1ZGlvLWNsYXNzaWZpY2F0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfbWluZHNfbW9kZWwlMjIpJTBBY2xhc3NpZmllcihhdWRpb19maWxlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;audio-classification&quot;</span>, model=<span class="hljs-string">&quot;stevhliu/my_awesome_minds_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(audio_file)
[
    {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.09766869246959686</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cash_deposit&#x27;</span>},
    {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.07998877018690109</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;app_error&#x27;</span>},
    {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0781070664525032</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;joint_account&#x27;</span>},
    {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.07667109370231628</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;pay_bill&#x27;</span>},
    {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.0755252093076706</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;balance&#x27;</span>}
]`,wrap:!1}}),N=new pa({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[Ta]},$$scope:{ctx:v}}}),{c(){p=c("meta"),b=l(),i=c("p"),M=l(),u($.$$.fragment),U=l(),u(k.$$.fragment),Z=l(),u(W.$$.fragment),C=l(),J=c("p"),J.textContent=V,I=l(),T=c("p"),T.textContent=R,m=l(),x=c("ol"),x.innerHTML=H,G=l(),u(X.$$.fragment),r=l(),w=c("p"),w.textContent=Is,Rs=l(),u(B.$$.fragment),Gs=l(),E=c("p"),E.textContent=Ct,Vs=l(),u(Q.$$.fragment),Ys=l(),u(A.$$.fragment),Fs=l(),z=c("p"),z.textContent=It,Ns=l(),u(q.$$.fragment),Hs=l(),S=c("p"),S.innerHTML=Xt,Bs=l(),u(L.$$.fragment),Es=l(),P=c("p"),P.textContent=Rt,Qs=l(),u(D.$$.fragment),As=l(),K=c("p"),K.innerHTML=Gt,zs=l(),u(O.$$.fragment),qs=l(),ss=c("p"),ss.textContent=Vt,Ss=l(),u(ts.$$.fragment),Ls=l(),as=c("p"),as.textContent=Yt,Ps=l(),es=c("ul"),es.innerHTML=Ft,Ds=l(),ls=c("p"),ls.textContent=Nt,Ks=l(),u(ns.$$.fragment),Os=l(),ps=c("p"),ps.textContent=Ht,st=l(),u(is.$$.fragment),tt=l(),u(rs.$$.fragment),at=l(),ms=c("p"),ms.textContent=Bt,et=l(),u(cs.$$.fragment),lt=l(),os=c("p"),os.innerHTML=Et,nt=l(),u(us.$$.fragment),pt=l(),fs=c("p"),fs.textContent=Qt,it=l(),hs=c("ol"),hs.innerHTML=At,rt=l(),u(ds.$$.fragment),mt=l(),gs=c("p"),gs.innerHTML=zt,ct=l(),u(js.$$.fragment),ot=l(),u(Ms.$$.fragment),ut=l(),bs=c("p"),bs.innerHTML=qt,ft=l(),u(ys.$$.fragment),ht=l(),$s=c("p"),$s.innerHTML=St,dt=l(),u(ws.$$.fragment),gt=l(),Js=c("p"),Js.innerHTML=Lt,jt=l(),u(Ts.$$.fragment),Mt=l(),u(Y.$$.fragment),bt=l(),u(F.$$.fragment),yt=l(),u(_s.$$.fragment),$t=l(),xs=c("p"),xs.textContent=Pt,wt=l(),Us=c("p"),Us.textContent=Dt,Jt=l(),u(Ws.$$.fragment),Tt=l(),Zs=c("p"),Zs.innerHTML=Kt,_t=l(),u(vs.$$.fragment),xt=l(),ks=c("p"),ks.innerHTML=Ot,Ut=l(),u(N.$$.fragment),Wt=l(),Xs=c("p"),this.h()},l(s){const t=ua("svelte-u9bgzb",document.head);p=o(t,"META",{name:!0,content:!0}),t.forEach(a),b=n(s),i=o(s,"P",{}),la(i).forEach(a),M=n(s),f($.$$.fragment,s),U=n(s),f(k.$$.fragment,s),Z=n(s),f(W.$$.fragment,s),C=n(s),J=o(s,"P",{"data-svelte-h":!0}),y(J)!=="svelte-8wnnrc"&&(J.textContent=V),I=n(s),T=o(s,"P",{"data-svelte-h":!0}),y(T)!=="svelte-w5jzhi"&&(T.textContent=R),m=n(s),x=o(s,"OL",{"data-svelte-h":!0}),y(x)!=="svelte-1ask5b9"&&(x.innerHTML=H),G=n(s),f(X.$$.fragment,s),r=n(s),w=o(s,"P",{"data-svelte-h":!0}),y(w)!=="svelte-1lya3k8"&&(w.textContent=Is),Rs=n(s),f(B.$$.fragment,s),Gs=n(s),E=o(s,"P",{"data-svelte-h":!0}),y(E)!=="svelte-193zy02"&&(E.textContent=Ct),Vs=n(s),f(Q.$$.fragment,s),Ys=n(s),f(A.$$.fragment,s),Fs=n(s),z=o(s,"P",{"data-svelte-h":!0}),y(z)!=="svelte-175h6bn"&&(z.textContent=It),Ns=n(s),f(q.$$.fragment,s),Hs=n(s),S=o(s,"P",{"data-svelte-h":!0}),y(S)!=="svelte-4rd872"&&(S.innerHTML=Xt),Bs=n(s),f(L.$$.fragment,s),Es=n(s),P=o(s,"P",{"data-svelte-h":!0}),y(P)!=="svelte-1px2i3t"&&(P.textContent=Rt),Qs=n(s),f(D.$$.fragment,s),As=n(s),K=o(s,"P",{"data-svelte-h":!0}),y(K)!=="svelte-13u82xc"&&(K.innerHTML=Gt),zs=n(s),f(O.$$.fragment,s),qs=n(s),ss=o(s,"P",{"data-svelte-h":!0}),y(ss)!=="svelte-1tlby18"&&(ss.textContent=Vt),Ss=n(s),f(ts.$$.fragment,s),Ls=n(s),as=o(s,"P",{"data-svelte-h":!0}),y(as)!=="svelte-gnvpca"&&(as.textContent=Yt),Ps=n(s),es=o(s,"UL",{"data-svelte-h":!0}),y(es)!=="svelte-1b9n6bc"&&(es.innerHTML=Ft),Ds=n(s),ls=o(s,"P",{"data-svelte-h":!0}),y(ls)!=="svelte-1xwss2e"&&(ls.textContent=Nt),Ks=n(s),f(ns.$$.fragment,s),Os=n(s),ps=o(s,"P",{"data-svelte-h":!0}),y(ps)!=="svelte-wrnhuq"&&(ps.textContent=Ht),st=n(s),f(is.$$.fragment,s),tt=n(s),f(rs.$$.fragment,s),at=n(s),ms=o(s,"P",{"data-svelte-h":!0}),y(ms)!=="svelte-8a7fkd"&&(ms.textContent=Bt),et=n(s),f(cs.$$.fragment,s),lt=n(s),os=o(s,"P",{"data-svelte-h":!0}),y(os)!=="svelte-83kdwu"&&(os.innerHTML=Et),nt=n(s),f(us.$$.fragment,s),pt=n(s),fs=o(s,"P",{"data-svelte-h":!0}),y(fs)!=="svelte-16wi3kv"&&(fs.textContent=Qt),it=n(s),hs=o(s,"OL",{"data-svelte-h":!0}),y(hs)!=="svelte-3k203q"&&(hs.innerHTML=At),rt=n(s),f(ds.$$.fragment,s),mt=n(s),gs=o(s,"P",{"data-svelte-h":!0}),y(gs)!=="svelte-1o2k96z"&&(gs.innerHTML=zt),ct=n(s),f(js.$$.fragment,s),ot=n(s),f(Ms.$$.fragment,s),ut=n(s),bs=o(s,"P",{"data-svelte-h":!0}),y(bs)!=="svelte-1xd1ltl"&&(bs.innerHTML=qt),ft=n(s),f(ys.$$.fragment,s),ht=n(s),$s=o(s,"P",{"data-svelte-h":!0}),y($s)!=="svelte-o90xg4"&&($s.innerHTML=St),dt=n(s),f(ws.$$.fragment,s),gt=n(s),Js=o(s,"P",{"data-svelte-h":!0}),y(Js)!=="svelte-18cw5xr"&&(Js.innerHTML=Lt),jt=n(s),f(Ts.$$.fragment,s),Mt=n(s),f(Y.$$.fragment,s),bt=n(s),f(F.$$.fragment,s),yt=n(s),f(_s.$$.fragment,s),$t=n(s),xs=o(s,"P",{"data-svelte-h":!0}),y(xs)!=="svelte-cyrfc8"&&(xs.textContent=Pt),wt=n(s),Us=o(s,"P",{"data-svelte-h":!0}),y(Us)!=="svelte-frlt8d"&&(Us.textContent=Dt),Jt=n(s),f(Ws.$$.fragment,s),Tt=n(s),Zs=o(s,"P",{"data-svelte-h":!0}),y(Zs)!=="svelte-1soovt5"&&(Zs.innerHTML=Kt),_t=n(s),f(vs.$$.fragment,s),xt=n(s),ks=o(s,"P",{"data-svelte-h":!0}),y(ks)!=="svelte-1lwhma4"&&(ks.innerHTML=Ot),Ut=n(s),f(N.$$.fragment,s),Wt=n(s),Xs=o(s,"P",{}),la(Xs).forEach(a),this.h()},h(){na(p,"name","hf:doc:metadata"),na(p,"content",xa)},m(s,t){fa(document.head,p),e(s,b,t),e(s,i,t),e(s,M,t),h($,s,t),e(s,U,t),h(k,s,t),e(s,Z,t),h(W,s,t),e(s,C,t),e(s,J,t),e(s,I,t),e(s,T,t),e(s,m,t),e(s,x,t),e(s,G,t),h(X,s,t),e(s,r,t),e(s,w,t),e(s,Rs,t),h(B,s,t),e(s,Gs,t),e(s,E,t),e(s,Vs,t),h(Q,s,t),e(s,Ys,t),h(A,s,t),e(s,Fs,t),e(s,z,t),e(s,Ns,t),h(q,s,t),e(s,Hs,t),e(s,S,t),e(s,Bs,t),h(L,s,t),e(s,Es,t),e(s,P,t),e(s,Qs,t),h(D,s,t),e(s,As,t),e(s,K,t),e(s,zs,t),h(O,s,t),e(s,qs,t),e(s,ss,t),e(s,Ss,t),h(ts,s,t),e(s,Ls,t),e(s,as,t),e(s,Ps,t),e(s,es,t),e(s,Ds,t),e(s,ls,t),e(s,Ks,t),h(ns,s,t),e(s,Os,t),e(s,ps,t),e(s,st,t),h(is,s,t),e(s,tt,t),h(rs,s,t),e(s,at,t),e(s,ms,t),e(s,et,t),h(cs,s,t),e(s,lt,t),e(s,os,t),e(s,nt,t),h(us,s,t),e(s,pt,t),e(s,fs,t),e(s,it,t),e(s,hs,t),e(s,rt,t),h(ds,s,t),e(s,mt,t),e(s,gs,t),e(s,ct,t),h(js,s,t),e(s,ot,t),h(Ms,s,t),e(s,ut,t),e(s,bs,t),e(s,ft,t),h(ys,s,t),e(s,ht,t),e(s,$s,t),e(s,dt,t),h(ws,s,t),e(s,gt,t),e(s,Js,t),e(s,jt,t),h(Ts,s,t),e(s,Mt,t),h(Y,s,t),e(s,bt,t),h(F,s,t),e(s,yt,t),h(_s,s,t),e(s,$t,t),e(s,xs,t),e(s,wt,t),e(s,Us,t),e(s,Jt,t),h(Ws,s,t),e(s,Tt,t),e(s,Zs,t),e(s,_t,t),h(vs,s,t),e(s,xt,t),e(s,ks,t),e(s,Ut,t),h(N,s,t),e(s,Wt,t),e(s,Xs,t),Zt=!0},p(s,[t]){const sa={};t&2&&(sa.$$scope={dirty:t,ctx:s}),X.$set(sa);const ta={};t&2&&(ta.$$scope={dirty:t,ctx:s}),Y.$set(ta);const aa={};t&2&&(aa.$$scope={dirty:t,ctx:s}),F.$set(aa);const ea={};t&2&&(ea.$$scope={dirty:t,ctx:s}),N.$set(ea)},i(s){Zt||(d($.$$.fragment,s),d(k.$$.fragment,s),d(W.$$.fragment,s),d(X.$$.fragment,s),d(B.$$.fragment,s),d(Q.$$.fragment,s),d(A.$$.fragment,s),d(q.$$.fragment,s),d(L.$$.fragment,s),d(D.$$.fragment,s),d(O.$$.fragment,s),d(ts.$$.fragment,s),d(ns.$$.fragment,s),d(is.$$.fragment,s),d(rs.$$.fragment,s),d(cs.$$.fragment,s),d(us.$$.fragment,s),d(ds.$$.fragment,s),d(js.$$.fragment,s),d(Ms.$$.fragment,s),d(ys.$$.fragment,s),d(ws.$$.fragment,s),d(Ts.$$.fragment,s),d(Y.$$.fragment,s),d(F.$$.fragment,s),d(_s.$$.fragment,s),d(Ws.$$.fragment,s),d(vs.$$.fragment,s),d(N.$$.fragment,s),Zt=!0)},o(s){g($.$$.fragment,s),g(k.$$.fragment,s),g(W.$$.fragment,s),g(X.$$.fragment,s),g(B.$$.fragment,s),g(Q.$$.fragment,s),g(A.$$.fragment,s),g(q.$$.fragment,s),g(L.$$.fragment,s),g(D.$$.fragment,s),g(O.$$.fragment,s),g(ts.$$.fragment,s),g(ns.$$.fragment,s),g(is.$$.fragment,s),g(rs.$$.fragment,s),g(cs.$$.fragment,s),g(us.$$.fragment,s),g(ds.$$.fragment,s),g(js.$$.fragment,s),g(Ms.$$.fragment,s),g(ys.$$.fragment,s),g(ws.$$.fragment,s),g(Ts.$$.fragment,s),g(Y.$$.fragment,s),g(F.$$.fragment,s),g(_s.$$.fragment,s),g(Ws.$$.fragment,s),g(vs.$$.fragment,s),g(N.$$.fragment,s),Zt=!1},d(s){s&&(a(b),a(i),a(M),a(U),a(Z),a(C),a(J),a(I),a(T),a(m),a(x),a(G),a(r),a(w),a(Rs),a(Gs),a(E),a(Vs),a(Ys),a(Fs),a(z),a(Ns),a(Hs),a(S),a(Bs),a(Es),a(P),a(Qs),a(As),a(K),a(zs),a(qs),a(ss),a(Ss),a(Ls),a(as),a(Ps),a(es),a(Ds),a(ls),a(Ks),a(Os),a(ps),a(st),a(tt),a(at),a(ms),a(et),a(lt),a(os),a(nt),a(pt),a(fs),a(it),a(hs),a(rt),a(mt),a(gs),a(ct),a(ot),a(ut),a(bs),a(ft),a(ht),a($s),a(dt),a(gt),a(Js),a(jt),a(Mt),a(bt),a(yt),a($t),a(xs),a(wt),a(Us),a(Jt),a(Tt),a(Zs),a(_t),a(xt),a(ks),a(Ut),a(Wt),a(Xs)),a(p),j($,s),j(k,s),j(W,s),j(X,s),j(B,s),j(Q,s),j(A,s),j(q,s),j(L,s),j(D,s),j(O,s),j(ts,s),j(ns,s),j(is,s),j(rs,s),j(cs,s),j(us,s),j(ds,s),j(js,s),j(Ms,s),j(ys,s),j(ws,s),j(Ts,s),j(Y,s),j(F,s),j(_s,s),j(Ws,s),j(vs,s),j(N,s)}}}const xa='{"title":"Audio classification","local":"audio-classification","sections":[{"title":"Load MInDS-14 dataset","local":"load-minds-14-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function Ua(v){return ma(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ga extends ca{constructor(p){super(),oa(this,p,Ua,_a,ra,{})}}export{Ga as component};
