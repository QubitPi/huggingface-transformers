import{s as Ye,o as Le,n as ts}from"../chunks/scheduler.9bc65507.js";import{S as qe,i as Se,g as $,s as m,r as M,A as Pe,h as w,f as t,c as i,j as Ae,u,x as T,k as Ne,y as De,a as l,v as g,d as j,t as b,w as y,m as Ke,n as Oe}from"../chunks/index.707bf1b6.js";import{T as ye}from"../chunks/Tip.c2ecdbf4.js";import{Y as Qe}from"../chunks/Youtube.e1129c6f.js";import{C as v}from"../chunks/CodeBlock.54a9f38d.js";import{D as st}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as $e,M as Bs}from"../chunks/Markdown.8ab98a13.js";import{H as Vs}from"../chunks/Heading.342b1fa6.js";function et(Z){let e,c,a='<a href="../model_doc/albert">ALBERT</a>, <a href="../model_doc/bart">BART</a>, <a href="../model_doc/bert">BERT</a>, <a href="../model_doc/big_bird">BigBird</a>, <a href="../model_doc/camembert">CamemBERT</a>, <a href="../model_doc/convbert">ConvBERT</a>, <a href="../model_doc/data2vec-text">Data2VecText</a>, <a href="../model_doc/deberta">DeBERTa</a>, <a href="../model_doc/deberta-v2">DeBERTa-v2</a>, <a href="../model_doc/distilbert">DistilBERT</a>, <a href="../model_doc/electra">ELECTRA</a>, <a href="../model_doc/ernie">ERNIE</a>, <a href="../model_doc/esm">ESM</a>, <a href="../model_doc/flaubert">FlauBERT</a>, <a href="../model_doc/fnet">FNet</a>, <a href="../model_doc/funnel">Funnel Transformer</a>, <a href="../model_doc/ibert">I-BERT</a>, <a href="../model_doc/layoutlm">LayoutLM</a>, <a href="../model_doc/longformer">Longformer</a>, <a href="../model_doc/luke">LUKE</a>, <a href="../model_doc/mbart">mBART</a>, <a href="../model_doc/mega">MEGA</a>, <a href="../model_doc/megatron-bert">Megatron-BERT</a>, <a href="../model_doc/mobilebert">MobileBERT</a>, <a href="../model_doc/mpnet">MPNet</a>, <a href="../model_doc/mra">MRA</a>, <a href="../model_doc/mvp">MVP</a>, <a href="../model_doc/nezha">Nezha</a>, <a href="../model_doc/nystromformer">Nyströmformer</a>, <a href="../model_doc/perceiver">Perceiver</a>, <a href="../model_doc/qdqbert">QDQBert</a>, <a href="../model_doc/reformer">Reformer</a>, <a href="../model_doc/rembert">RemBERT</a>, <a href="../model_doc/roberta">RoBERTa</a>, <a href="../model_doc/roberta-prelayernorm">RoBERTa-PreLayerNorm</a>, <a href="../model_doc/roc_bert">RoCBert</a>, <a href="../model_doc/roformer">RoFormer</a>, <a href="../model_doc/squeezebert">SqueezeBERT</a>, <a href="../model_doc/tapas">TAPAS</a>, <a href="../model_doc/wav2vec2">Wav2Vec2</a>, <a href="../model_doc/xlm">XLM</a>, <a href="../model_doc/xlm-roberta">XLM-RoBERTa</a>, <a href="../model_doc/xlm-roberta-xl">XLM-RoBERTa-XL</a>, <a href="../model_doc/xmod">X-MOD</a>, <a href="../model_doc/yoso">YOSO</a>';return{c(){e=Ke(`このガイドと同じ手順に従って、マスクされた言語モデリング用に他のアーキテクチャを微調整できます。
次のアーキテクチャのいずれかを選択します。

`),c=$("p"),c.innerHTML=a},l(o){e=Oe(o,`このガイドと同じ手順に従って、マスクされた言語モデリング用に他のアーキテクチャを微調整できます。
次のアーキテクチャのいずれかを選択します。

`),c=w(o,"P",{"data-svelte-h":!0}),T(c)!=="svelte-e35b6o"&&(c.innerHTML=a)},m(o,d){l(o,e,d),l(o,c,d)},p:ts,d(o){o&&(t(e),t(c))}}}function tt(Z){let e,c="シーケンス終了トークンをパディング トークンとして使用し、データを反復するたびにランダムにトークンをマスクするために <code>mlm_probability</code> を指定します。",a,o,d;return o=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvckxhbmd1YWdlTW9kZWxpbmclMEElMEF0b2tlbml6ZXIucGFkX3Rva2VuJTIwJTNEJTIwdG9rZW5pemVyLmVvc190b2tlbiUwQWRhdGFfY29sbGF0b3IlMjAlM0QlMjBEYXRhQ29sbGF0b3JGb3JMYW5ndWFnZU1vZGVsaW5nKHRva2VuaXplciUzRHRva2VuaXplciUyQyUyMG1sbV9wcm9iYWJpbGl0eSUzRDAuMTUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.pad_token = tokenizer.eos_token
<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=<span class="hljs-number">0.15</span>)`,wrap:!1}}),{c(){e=$("p"),e.innerHTML=c,a=m(),M(o.$$.fragment)},l(h){e=w(h,"P",{"data-svelte-h":!0}),T(e)!=="svelte-dtctdf"&&(e.innerHTML=c),a=i(h),u(o.$$.fragment,h)},m(h,G){l(h,e,G),l(h,a,G),g(o,h,G),d=!0},p:ts,i(h){d||(j(o.$$.fragment,h),d=!0)},o(h){b(o.$$.fragment,h),d=!1},d(h){h&&(t(e),t(a)),y(o,h)}}}function at(Z){let e,c;return e=new Bs({props:{$$slots:{default:[tt]},$$scope:{ctx:Z}}}),{c(){M(e.$$.fragment)},l(a){u(e.$$.fragment,a)},m(a,o){g(e,a,o),c=!0},p(a,o){const d={};o&2&&(d.$$scope={dirty:o,ctx:a}),e.$set(d)},i(a){c||(j(e.$$.fragment,a),c=!0)},o(a){b(e.$$.fragment,a),c=!1},d(a){y(e,a)}}}function lt(Z){let e,c="シーケンス終了トークンをパディング トークンとして使用し、データを反復するたびにランダムにトークンをマスクするために <code>mlm_probability</code> を指定します。",a,o,d;return o=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvckxhbmd1YWdlTW9kZWxpbmclMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGF0YUNvbGxhdG9yRm9yTGFuZ3VhZ2VNb2RlbGluZyh0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMjBtbG1fcHJvYmFiaWxpdHklM0QwLjE1JTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=<span class="hljs-number">0.15</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),{c(){e=$("p"),e.innerHTML=c,a=m(),M(o.$$.fragment)},l(h){e=w(h,"P",{"data-svelte-h":!0}),T(e)!=="svelte-dtctdf"&&(e.innerHTML=c),a=i(h),u(o.$$.fragment,h)},m(h,G){l(h,e,G),l(h,a,G),g(o,h,G),d=!0},p:ts,i(h){d||(j(o.$$.fragment,h),d=!0)},o(h){b(o.$$.fragment,h),d=!1},d(h){h&&(t(e),t(a)),y(o,h)}}}function nt(Z){let e,c;return e=new Bs({props:{$$slots:{default:[lt]},$$scope:{ctx:Z}}}),{c(){M(e.$$.fragment)},l(a){u(e.$$.fragment,a)},m(a,o){g(e,a,o),c=!0},p(a,o){const d={};o&2&&(d.$$scope={dirty:o,ctx:a}),e.$set(d)},i(a){c||(j(e.$$.fragment,a),c=!0)},o(a){b(e.$$.fragment,a),c=!1},d(a){y(e,a)}}}function pt(Z){let e,c='<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> を使用したモデルの微調整に慣れていない場合は、<a href="../training#train-with-pytorch-trainer">ここ</a> の基本的なチュートリアルをご覧ください。';return{c(){e=$("p"),e.innerHTML=c},l(a){e=w(a,"P",{"data-svelte-h":!0}),T(e)!=="svelte-1ubngji"&&(e.innerHTML=c)},m(a,o){l(a,e,o)},p:ts,d(a){a&&t(e)}}}function rt(Z){let e,c,a,o='これでモデルのトレーニングを開始する準備が整いました。 <a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoModelForMaskedLM">AutoModelForMaskedLM</a> を使用して DistilRoBERTa をロードします。',d,h,G,R,C="この時点で残っている手順は次の 3 つだけです。",I,_,F='<li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> でトレーニング ハイパーパラメータを定義します。唯一の必須パラメータは、モデルの保存場所を指定する <code>output_dir</code> です。 <code>push_to_hub=True</code>を設定して、このモデルをハブにプッシュします (モデルをアップロードするには、Hugging Face にサインインする必要があります)。</li> <li>トレーニング引数をモデル、データセット、データ照合器とともに <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> に渡します。</li> <li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train">train()</a> を呼び出してモデルを微調整します。</li>',W,U,B,p,k='トレーニングが完了したら、 <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.evaluate">evaluate()</a> メソッドを使用してモデルを評価し、その複雑さを取得します。',E,H,V,X,A='次に、 <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> メソッドを使用してモデルをハブに共有し、誰もがモデルを使用できるようにします。',N,Q,z;return e=new ye({props:{$$slots:{default:[pt]},$$scope:{ctx:Z}}}),h=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvck1hc2tlZExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNYXNrZWRMTS5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbHJvYmVydGEtYmFzZSUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilbert/distilroberta-base&quot;</span>)`,wrap:!1}}),U=new v({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX2VsaTVfbWxtX21vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwZXZhbHVhdGlvbl9zdHJhdGVneSUzRCUyMmVwb2NoJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMyUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheSUzRDAuMDElMkMlMEElMjAlMjAlMjAlMjBwdXNoX3RvX2h1YiUzRFRydWUlMkMlMEEpJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRGxtX2RhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfZGF0YXNldCUzRGxtX2RhdGFzZXQlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZGF0YV9jb2xsYXRvciUzRGRhdGFfY29sbGF0b3IlMkMlMEEpJTBBJTBBdHJhaW5lci50cmFpbigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_eli5_mlm_model&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=lm_dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=lm_dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),H=new v({props:{code:"aW1wb3J0JTIwbWF0aCUwQSUwQWV2YWxfcmVzdWx0cyUyMCUzRCUyMHRyYWluZXIuZXZhbHVhdGUoKSUwQXByaW50KGYlMjJQZXJwbGV4aXR5JTNBJTIwJTdCbWF0aC5leHAoZXZhbF9yZXN1bHRzJTVCJ2V2YWxfbG9zcyclNUQpJTNBLjJmJTdEJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> math

<span class="hljs-meta">&gt;&gt;&gt; </span>eval_results = trainer.evaluate()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Perplexity: <span class="hljs-subst">{math.exp(eval_results[<span class="hljs-string">&#x27;eval_loss&#x27;</span>]):<span class="hljs-number">.2</span>f}</span>&quot;</span>)
Perplexity: <span class="hljs-number">8.76</span>`,wrap:!1}}),Q=new v({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){M(e.$$.fragment),c=m(),a=$("p"),a.innerHTML=o,d=m(),M(h.$$.fragment),G=m(),R=$("p"),R.textContent=C,I=m(),_=$("ol"),_.innerHTML=F,W=m(),M(U.$$.fragment),B=m(),p=$("p"),p.innerHTML=k,E=m(),M(H.$$.fragment),V=m(),X=$("p"),X.innerHTML=A,N=m(),M(Q.$$.fragment)},l(f){u(e.$$.fragment,f),c=i(f),a=w(f,"P",{"data-svelte-h":!0}),T(a)!=="svelte-5q4jrn"&&(a.innerHTML=o),d=i(f),u(h.$$.fragment,f),G=i(f),R=w(f,"P",{"data-svelte-h":!0}),T(R)!=="svelte-1j8bgyv"&&(R.textContent=C),I=i(f),_=w(f,"OL",{"data-svelte-h":!0}),T(_)!=="svelte-1yjbkwa"&&(_.innerHTML=F),W=i(f),u(U.$$.fragment,f),B=i(f),p=w(f,"P",{"data-svelte-h":!0}),T(p)!=="svelte-w8pdej"&&(p.innerHTML=k),E=i(f),u(H.$$.fragment,f),V=i(f),X=w(f,"P",{"data-svelte-h":!0}),T(X)!=="svelte-hy4bys"&&(X.innerHTML=A),N=i(f),u(Q.$$.fragment,f)},m(f,J){g(e,f,J),l(f,c,J),l(f,a,J),l(f,d,J),g(h,f,J),l(f,G,J),l(f,R,J),l(f,I,J),l(f,_,J),l(f,W,J),g(U,f,J),l(f,B,J),l(f,p,J),l(f,E,J),g(H,f,J),l(f,V,J),l(f,X,J),l(f,N,J),g(Q,f,J),z=!0},p(f,J){const Y={};J&2&&(Y.$$scope={dirty:J,ctx:f}),e.$set(Y)},i(f){z||(j(e.$$.fragment,f),j(h.$$.fragment,f),j(U.$$.fragment,f),j(H.$$.fragment,f),j(Q.$$.fragment,f),z=!0)},o(f){b(e.$$.fragment,f),b(h.$$.fragment,f),b(U.$$.fragment,f),b(H.$$.fragment,f),b(Q.$$.fragment,f),z=!1},d(f){f&&(t(c),t(a),t(d),t(G),t(R),t(I),t(_),t(W),t(B),t(p),t(E),t(V),t(X),t(N)),y(e,f),y(h,f),y(U,f),y(H,f),y(Q,f)}}}function ot(Z){let e,c;return e=new Bs({props:{$$slots:{default:[rt]},$$scope:{ctx:Z}}}),{c(){M(e.$$.fragment)},l(a){u(e.$$.fragment,a)},m(a,o){g(e,a,o),c=!0},p(a,o){const d={};o&2&&(d.$$scope={dirty:o,ctx:a}),e.$set(d)},i(a){c||(j(e.$$.fragment,a),c=!0)},o(a){b(e.$$.fragment,a),c=!1},d(a){y(e,a)}}}function mt(Z){let e,c='Keras を使用したモデルの微調整に慣れていない場合は、<a href="../training#train-a-tensorflow-model-with-keras">こちら</a> の基本的なチュートリアルをご覧ください。';return{c(){e=$("p"),e.innerHTML=c},l(a){e=w(a,"P",{"data-svelte-h":!0}),T(e)!=="svelte-1jwo7q8"&&(e.innerHTML=c)},m(a,o){l(a,e,o)},p:ts,d(a){a&&t(e)}}}function it(Z){let e,c,a,o="TensorFlow でモデルを微調整するには、オプティマイザー関数、学習率スケジュール、およびいくつかのトレーニング ハイパーパラメーターをセットアップすることから始めます。",d,h,G,R,C='次に、<a href="/docs/transformers/main/ja/model_doc/auto#transformers.TFAutoModelForMaskedLM">TFAutoModelForMaskedLM</a> を使用して DistilRoBERTa をロードできます。',I,_,F,W,U='<a href="/docs/transformers/main/ja/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset">prepare_tf_dataset()</a> を使用して、データセットを <code>tf.data.Dataset</code> 形式に変換します。',B,p,k,E,H='<a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a> を使用してトレーニング用のモデルを設定します。 Transformers モデルにはすべてデフォルトのタスク関連の損失関数があるため、次の場合を除き、損失関数を指定する必要はないことに注意してください。',V,X,A,N,Q='This can be done by specifying where to push your model and tokenizer in the <a href="/docs/transformers/main/ja/main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a>:',z,f,J,Y,as='ついに、モデルのトレーニングを開始する準備が整いました。トレーニングおよび検証データセット、エポック数、コールバックを指定して <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a> を呼び出し、モデルを微調整します。',L,q,S,P,D="トレーニングが完了すると、モデルは自動的にハブにアップロードされ、誰でも使用できるようになります。",ls;return e=new ye({props:{$$slots:{default:[mt]},$$scope:{ctx:Z}}}),h=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMkMlMjBBZGFtV2VpZ2h0RGVjYXklMEElMEFvcHRpbWl6ZXIlMjAlM0QlMjBBZGFtV2VpZ2h0RGVjYXkobGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMjB3ZWlnaHRfZGVjYXlfcmF0ZSUzRDAuMDEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer, AdamWeightDecay

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamWeightDecay(learning_rate=<span class="hljs-number">2e-5</span>, weight_decay_rate=<span class="hljs-number">0.01</span>)`,wrap:!1}}),_=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yTWFza2VkTE0lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yTWFza2VkTE0uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxyb2JlcnRhLWJhc2UlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;distilbert/distilroberta-base&quot;</span>)`,wrap:!1}}),p=new v({props:{code:"dGZfdHJhaW5fc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGxtX2RhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwY29sbGF0ZV9mbiUzRGRhdGFfY29sbGF0b3IlMkMlMEEpJTBBJTBBdGZfdGVzdF9zZXQlMjAlM0QlMjBtb2RlbC5wcmVwYXJlX3RmX2RhdGFzZXQoJTBBJTIwJTIwJTIwJTIwbG1fZGF0YXNldCU1QiUyMnRlc3QlMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBzaHVmZmxlJTNERmFsc2UlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBjb2xsYXRlX2ZuJTNEZGF0YV9jb2xsYXRvciUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    lm_dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_test_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    lm_dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),X=new v({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplciklMjAlMjAlMjMlMjBObyUyMGxvc3MlMjBhcmd1bWVudCE=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)  <span class="hljs-comment"># No loss argument!</span>`,wrap:!1}}),f=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBQdXNoVG9IdWJDYWxsYmFjayUwQSUwQWNhbGxiYWNrJTIwJTNEJTIwUHVzaFRvSHViQ2FsbGJhY2soJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMm15X2F3ZXNvbWVfZWxpNV9tbG1fbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_eli5_mlm_model&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>)`,wrap:!1}}),q=new v({props:{code:"bW9kZWwuZml0KHglM0R0Zl90cmFpbl9zZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl90ZXN0X3NldCUyQyUyMGVwb2NocyUzRDMlMkMlMjBjYWxsYmFja3MlM0QlNUJjYWxsYmFjayU1RCk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=<span class="hljs-number">3</span>, callbacks=[callback])',wrap:!1}}),{c(){M(e.$$.fragment),c=m(),a=$("p"),a.textContent=o,d=m(),M(h.$$.fragment),G=m(),R=$("p"),R.innerHTML=C,I=m(),M(_.$$.fragment),F=m(),W=$("p"),W.innerHTML=U,B=m(),M(p.$$.fragment),k=m(),E=$("p"),E.innerHTML=H,V=m(),M(X.$$.fragment),A=m(),N=$("p"),N.innerHTML=Q,z=m(),M(f.$$.fragment),J=m(),Y=$("p"),Y.innerHTML=as,L=m(),M(q.$$.fragment),S=m(),P=$("p"),P.textContent=D},l(r){u(e.$$.fragment,r),c=i(r),a=w(r,"P",{"data-svelte-h":!0}),T(a)!=="svelte-7f4w1i"&&(a.textContent=o),d=i(r),u(h.$$.fragment,r),G=i(r),R=w(r,"P",{"data-svelte-h":!0}),T(R)!=="svelte-z78i38"&&(R.innerHTML=C),I=i(r),u(_.$$.fragment,r),F=i(r),W=w(r,"P",{"data-svelte-h":!0}),T(W)!=="svelte-1mdvspu"&&(W.innerHTML=U),B=i(r),u(p.$$.fragment,r),k=i(r),E=w(r,"P",{"data-svelte-h":!0}),T(E)!=="svelte-1pd5few"&&(E.innerHTML=H),V=i(r),u(X.$$.fragment,r),A=i(r),N=w(r,"P",{"data-svelte-h":!0}),T(N)!=="svelte-1afhgiv"&&(N.innerHTML=Q),z=i(r),u(f.$$.fragment,r),J=i(r),Y=w(r,"P",{"data-svelte-h":!0}),T(Y)!=="svelte-ffgub5"&&(Y.innerHTML=as),L=i(r),u(q.$$.fragment,r),S=i(r),P=w(r,"P",{"data-svelte-h":!0}),T(P)!=="svelte-vh7z0v"&&(P.textContent=D)},m(r,x){g(e,r,x),l(r,c,x),l(r,a,x),l(r,d,x),g(h,r,x),l(r,G,x),l(r,R,x),l(r,I,x),g(_,r,x),l(r,F,x),l(r,W,x),l(r,B,x),g(p,r,x),l(r,k,x),l(r,E,x),l(r,V,x),g(X,r,x),l(r,A,x),l(r,N,x),l(r,z,x),g(f,r,x),l(r,J,x),l(r,Y,x),l(r,L,x),g(q,r,x),l(r,S,x),l(r,P,x),ls=!0},p(r,x){const ns={};x&2&&(ns.$$scope={dirty:x,ctx:r}),e.$set(ns)},i(r){ls||(j(e.$$.fragment,r),j(h.$$.fragment,r),j(_.$$.fragment,r),j(p.$$.fragment,r),j(X.$$.fragment,r),j(f.$$.fragment,r),j(q.$$.fragment,r),ls=!0)},o(r){b(e.$$.fragment,r),b(h.$$.fragment,r),b(_.$$.fragment,r),b(p.$$.fragment,r),b(X.$$.fragment,r),b(f.$$.fragment,r),b(q.$$.fragment,r),ls=!1},d(r){r&&(t(c),t(a),t(d),t(G),t(R),t(I),t(F),t(W),t(B),t(k),t(E),t(V),t(A),t(N),t(z),t(J),t(Y),t(L),t(S),t(P)),y(e,r),y(h,r),y(_,r),y(p,r),y(X,r),y(f,r),y(q,r)}}}function ct(Z){let e,c;return e=new Bs({props:{$$slots:{default:[it]},$$scope:{ctx:Z}}}),{c(){M(e.$$.fragment)},l(a){u(e.$$.fragment,a)},m(a,o){g(e,a,o),c=!0},p(a,o){const d={};o&2&&(d.$$scope={dirty:o,ctx:a}),e.$set(d)},i(a){c||(j(e.$$.fragment,a),c=!0)},o(a){b(e.$$.fragment,a),c=!1},d(a){y(e,a)}}}function ft(Z){let e,c=`マスクされた言語モデリング用にモデルを微調整する方法のより詳細な例については、対応するドキュメントを参照してください。
<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb" rel="nofollow">PyTorch ノートブック</a>
または <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb" rel="nofollow">TensorFlow ノートブック</a>。`;return{c(){e=$("p"),e.innerHTML=c},l(a){e=w(a,"P",{"data-svelte-h":!0}),T(e)!=="svelte-ypf7aj"&&(e.innerHTML=c)},m(a,o){l(a,e,o)},p:ts,d(a){a&&t(e)}}}function ht(Z){let e,c="テキストをトークン化し、<code>input_ids</code>を PyTorch テンソルとして返します。 <code>&lt;mask&gt;</code> トークンの位置も指定する必要があります。",a,o,d,h,G="入力をモデルに渡し、マスクされたトークンの<code>logits</code>を返します。",R,C,I,_,F="次に、マスクされた 3 つのトークンを最も高い確率で返し、出力します。",W,U,B;return o=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfZWxpNV9tbG1fbW9kZWwlMjIpJTBBaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKHRleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKSUwQW1hc2tfdG9rZW5faW5kZXglMjAlM0QlMjB0b3JjaC53aGVyZShpbnB1dHMlNUIlMjJpbnB1dF9pZHMlMjIlNUQlMjAlM0QlM0QlMjB0b2tlbml6ZXIubWFza190b2tlbl9pZCklNUIxJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_eli5_mlm_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_token_index = torch.where(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>] == tokenizer.mask_token_id)[<span class="hljs-number">1</span>]`,wrap:!1}}),C=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvck1hc2tlZExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNYXNrZWRMTS5mcm9tX3ByZXRyYWluZWQoJTIyc3RldmhsaXUlMkZteV9hd2Vzb21lX2VsaTVfbWxtX21vZGVsJTIyKSUwQWxvZ2l0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKS5sb2dpdHMlMEFtYXNrX3Rva2VuX2xvZ2l0cyUyMCUzRCUyMGxvZ2l0cyU1QjAlMkMlMjBtYXNrX3Rva2VuX2luZGV4JTJDJTIwJTNBJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_eli5_mlm_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_token_logits = logits[<span class="hljs-number">0</span>, mask_token_index, :]`,wrap:!1}}),U=new v({props:{code:"dG9wXzNfdG9rZW5zJTIwJTNEJTIwdG9yY2gudG9wayhtYXNrX3Rva2VuX2xvZ2l0cyUyQyUyMDMlMkMlMjBkaW0lM0QxKS5pbmRpY2VzJTVCMCU1RC50b2xpc3QoKSUwQSUwQWZvciUyMHRva2VuJTIwaW4lMjB0b3BfM190b2tlbnMlM0ElMEElMjAlMjAlMjAlMjBwcmludCh0ZXh0LnJlcGxhY2UodG9rZW5pemVyLm1hc2tfdG9rZW4lMkMlMjB0b2tlbml6ZXIuZGVjb2RlKCU1QnRva2VuJTVEKSkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>top_3_tokens = torch.topk(mask_token_logits, <span class="hljs-number">3</span>, dim=<span class="hljs-number">1</span>).indices[<span class="hljs-number">0</span>].tolist()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> top_3_tokens:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(text.replace(tokenizer.mask_token, tokenizer.decode([token])))
The Milky Way <span class="hljs-keyword">is</span> a spiral galaxy.
The Milky Way <span class="hljs-keyword">is</span> a massive galaxy.
The Milky Way <span class="hljs-keyword">is</span> a small galaxy.`,wrap:!1}}),{c(){e=$("p"),e.innerHTML=c,a=m(),M(o.$$.fragment),d=m(),h=$("p"),h.innerHTML=G,R=m(),M(C.$$.fragment),I=m(),_=$("p"),_.textContent=F,W=m(),M(U.$$.fragment)},l(p){e=w(p,"P",{"data-svelte-h":!0}),T(e)!=="svelte-1p5tmxy"&&(e.innerHTML=c),a=i(p),u(o.$$.fragment,p),d=i(p),h=w(p,"P",{"data-svelte-h":!0}),T(h)!=="svelte-8pqnod"&&(h.innerHTML=G),R=i(p),u(C.$$.fragment,p),I=i(p),_=w(p,"P",{"data-svelte-h":!0}),T(_)!=="svelte-1jeaz8n"&&(_.textContent=F),W=i(p),u(U.$$.fragment,p)},m(p,k){l(p,e,k),l(p,a,k),g(o,p,k),l(p,d,k),l(p,h,k),l(p,R,k),g(C,p,k),l(p,I,k),l(p,_,k),l(p,W,k),g(U,p,k),B=!0},p:ts,i(p){B||(j(o.$$.fragment,p),j(C.$$.fragment,p),j(U.$$.fragment,p),B=!0)},o(p){b(o.$$.fragment,p),b(C.$$.fragment,p),b(U.$$.fragment,p),B=!1},d(p){p&&(t(e),t(a),t(d),t(h),t(R),t(I),t(_),t(W)),y(o,p),y(C,p),y(U,p)}}}function dt(Z){let e,c;return e=new Bs({props:{$$slots:{default:[ht]},$$scope:{ctx:Z}}}),{c(){M(e.$$.fragment)},l(a){u(e.$$.fragment,a)},m(a,o){g(e,a,o),c=!0},p(a,o){const d={};o&2&&(d.$$scope={dirty:o,ctx:a}),e.$set(d)},i(a){c||(j(e.$$.fragment,a),c=!0)},o(a){b(e.$$.fragment,a),c=!1},d(a){y(e,a)}}}function Mt(Z){let e,c="テキストをトークン化し、<code>input_ids</code>を TensorFlow テンソルとして返します。 <code>&lt;mask&gt;</code> トークンの位置も指定する必要があります。",a,o,d,h,G="入力をモデルに渡し、マスクされたトークンの<code>logits</code>を返します。",R,C,I,_,F="次に、マスクされた 3 つのトークンを最も高い確率で返し、出力します。",W,U,B;return o=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfZWxpNV9tbG1fbW9kZWwlMjIpJTBBaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKHRleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKSUwQW1hc2tfdG9rZW5faW5kZXglMjAlM0QlMjB0Zi53aGVyZShpbnB1dHMlNUIlMjJpbnB1dF9pZHMlMjIlNUQlMjAlM0QlM0QlMjB0b2tlbml6ZXIubWFza190b2tlbl9pZCklNUIwJTJDJTIwMSU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_eli5_mlm_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_token_index = tf.where(inputs[<span class="hljs-string">&quot;input_ids&quot;</span>] == tokenizer.mask_token_id)[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]`,wrap:!1}}),C=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yTWFza2VkTE0lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yTWFza2VkTE0uZnJvbV9wcmV0cmFpbmVkKCUyMnN0ZXZobGl1JTJGbXlfYXdlc29tZV9lbGk1X21sbV9tb2RlbCUyMiklMEFsb2dpdHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cykubG9naXRzJTBBbWFza190b2tlbl9sb2dpdHMlMjAlM0QlMjBsb2dpdHMlNUIwJTJDJTIwbWFza190b2tlbl9pbmRleCUyQyUyMCUzQSU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMaskedLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMaskedLM.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_eli5_mlm_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_token_logits = logits[<span class="hljs-number">0</span>, mask_token_index, :]`,wrap:!1}}),U=new v({props:{code:"dG9wXzNfdG9rZW5zJTIwJTNEJTIwdGYubWF0aC50b3BfayhtYXNrX3Rva2VuX2xvZ2l0cyUyQyUyMDMpLmluZGljZXMubnVtcHkoKSUwQSUwQWZvciUyMHRva2VuJTIwaW4lMjB0b3BfM190b2tlbnMlM0ElMEElMjAlMjAlMjAlMjBwcmludCh0ZXh0LnJlcGxhY2UodG9rZW5pemVyLm1hc2tfdG9rZW4lMkMlMjB0b2tlbml6ZXIuZGVjb2RlKCU1QnRva2VuJTVEKSkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>top_3_tokens = tf.math.top_k(mask_token_logits, <span class="hljs-number">3</span>).indices.numpy()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> top_3_tokens:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(text.replace(tokenizer.mask_token, tokenizer.decode([token])))
The Milky Way <span class="hljs-keyword">is</span> a spiral galaxy.
The Milky Way <span class="hljs-keyword">is</span> a massive galaxy.
The Milky Way <span class="hljs-keyword">is</span> a small galaxy.`,wrap:!1}}),{c(){e=$("p"),e.innerHTML=c,a=m(),M(o.$$.fragment),d=m(),h=$("p"),h.innerHTML=G,R=m(),M(C.$$.fragment),I=m(),_=$("p"),_.textContent=F,W=m(),M(U.$$.fragment)},l(p){e=w(p,"P",{"data-svelte-h":!0}),T(e)!=="svelte-td21lc"&&(e.innerHTML=c),a=i(p),u(o.$$.fragment,p),d=i(p),h=w(p,"P",{"data-svelte-h":!0}),T(h)!=="svelte-8pqnod"&&(h.innerHTML=G),R=i(p),u(C.$$.fragment,p),I=i(p),_=w(p,"P",{"data-svelte-h":!0}),T(_)!=="svelte-1jeaz8n"&&(_.textContent=F),W=i(p),u(U.$$.fragment,p)},m(p,k){l(p,e,k),l(p,a,k),g(o,p,k),l(p,d,k),l(p,h,k),l(p,R,k),g(C,p,k),l(p,I,k),l(p,_,k),l(p,W,k),g(U,p,k),B=!0},p:ts,i(p){B||(j(o.$$.fragment,p),j(C.$$.fragment,p),j(U.$$.fragment,p),B=!0)},o(p){b(o.$$.fragment,p),b(C.$$.fragment,p),b(U.$$.fragment,p),B=!1},d(p){p&&(t(e),t(a),t(d),t(h),t(R),t(I),t(_),t(W)),y(o,p),y(C,p),y(U,p)}}}function ut(Z){let e,c;return e=new Bs({props:{$$slots:{default:[Mt]},$$scope:{ctx:Z}}}),{c(){M(e.$$.fragment)},l(a){u(e.$$.fragment,a)},m(a,o){g(e,a,o),c=!0},p(a,o){const d={};o&2&&(d.$$scope={dirty:o,ctx:a}),e.$set(d)},i(a){c||(j(e.$$.fragment,a),c=!0)},o(a){b(e.$$.fragment,a),c=!1},d(a){y(e,a)}}}function gt(Z){let e,c,a,o,d,h,G,R,C,I,_,F=`マスクされた言語モデリングはシーケンス内のマスクされたトークンを予測し、モデルはトークンを双方向に処理できます。これ
これは、モデルが左右のトークンに完全にアクセスできることを意味します。マスクされた言語モデリングは、次のようなタスクに最適です。
シーケンス全体の文脈をよく理解する必要があります。 BERT はマスクされた言語モデルの一例です。`,W,U,B="このガイドでは、次の方法を説明します。",p,k,E='<li><a href="https://huggingface.co/distilbert/distilroberta-base" rel="nofollow">ELI5</a> の <a href="https://www.reddit.com/r/askscience/" rel="nofollow">r/askscience</a> サブセットで <a href="https://huggingface.co/distilbert/distilroberta-base" rel="nofollow">DistilRoBERTa</a> を微調整します。 ://huggingface.co/datasets/eli5) データセット。</li> <li>微調整したモデルを推論に使用します。</li>',H,V,X,A,N="始める前に、必要なライブラリがすべてインストールされていることを確認してください。",Q,z,f,J,Y="モデルをアップロードしてコミュニティと共有できるように、Hugging Face アカウントにログインすることをお勧めします。プロンプトが表示されたら、トークンを入力してログインします。",as,L,q,S,P,D,ls=`まず、ELI5 データセットの r/askscience サブセットの小さいサブセットを 🤗 データセット ライブラリからロードします。これで
データセット全体のトレーニングにさらに時間を費やす前に、実験してすべてが機能することを確認する機会が与えられます。`,r,x,ns,ps,we="<code>train_test_split</code> メソッドを使用して、データセットの <code>train_asks</code> をトレイン セットとテスト セットに分割します。",zs,rs,Fs,os,Te="次に、例を見てみましょう。",Es,ms,Hs,is,_e="これは多くのことのように見えるかもしれませんが、実際に関心があるのは<code>text</code>フィールドだけです。言語モデリング タスクの優れた点は、次の単語がラベル * であるため、ラベル (教師なしタスクとも呼ばれます) が必要ないことです。",As,cs,Ns,fs,Qs,hs,ke="マスクされた言語モデリングの場合、次のステップは、<code>text</code>サブフィールドを処理するために DistilRoBERTa トークナイザーをロードすることです。",Ys,ds,Ls,Ms,xe=`上の例からわかるように、<code>text</code>フィールドは実際には<code>answers</code>内にネストされています。これは、次のことを行う必要があることを意味します
<a href="https://huggingface.co/docs/datasets/process.html#flatten" rel="nofollow"><code>flatten</code></a> メソッドを使用して、ネストされた構造から <code>text</code> サブフィールドを抽出します。`,qs,us,Ss,gs,Je=`<code>answers</code>接頭辞で示されるように、各サブフィールドは個別の列になり、<code>text</code>フィールドはリストになりました。その代わり
各文を個別にトークン化する場合は、リストを文字列に変換して、それらをまとめてトークン化できるようにします。`,Ps,js,Ue="以下は、各例の文字列のリストを結合し、結果をトークン化する最初の前処理関数です。",Ds,bs,Ks,ys,Ze="この前処理関数をデータセット全体に適用するには、🤗 Datasets <code>map</code> メソッドを使用します。 <code>map</code> 関数を高速化するには、<code>batched=True</code> を設定してデータセットの複数の要素を一度に処理し、<code>num_proc</code> でプロセスの数を増やします。不要な列を削除します。",Os,$s,se,ws,Ge="このデータセットにはトークン シーケンスが含まれていますが、その一部はモデルの最大入力長よりも長くなります。",ee,Ts,ve="2 番目の前処理関数を使用して、",te,_s,Re="<li>すべてのシーケンスを連結します</li> <li>連結されたシーケンスを<code>block_size</code>で定義された短いチャンクに分割します。これは、最大入力長より短く、GPU RAM に十分な長さである必要があります。</li>",ae,ks,le,xs,Ce="データセット全体に<code>group_texts</code>関数を適用します。",ne,Js,pe,Us,We="次に、<code>DataCollat​​orForLanguageModeling</code> を使用してサンプルのバッチを作成します。データセット全体を最大長までパディングするのではなく、照合中にバッチ内の最長の長さまで文を <em>動的にパディング</em> する方が効率的です。",re,K,oe,Zs,me,O,ie,ss,ce,Gs,fe,vs,Ie="モデルを微調整したので、それを推論に使用できるようになりました。",he,Rs,Be="モデルに空白を埋めるテキストを考え出し、特別な <code>&lt;mask&gt;</code> トークンを使用して空白を示します。",de,Cs,Me,Ws,Xe='推論用に微調整されたモデルを試す最も簡単な方法は、それを <a href="/docs/transformers/main/ja/main_classes/pipelines#transformers.pipeline">pipeline()</a> で使用することです。モデルを使用してフィルマスクの<code>pipeline</code>をインスタンス化し、テキストをそれに渡します。必要に応じて、<code>top_k</code>パラメータを使用して、返す予測の数を指定できます。',ue,Is,ge,es,je,Xs,be;return d=new Vs({props:{title:"Masked language modeling",local:"masked-language-modeling",headingTag:"h1"}}),G=new st({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/masked_language_modeling.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/masked_language_modeling.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/masked_language_modeling.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/masked_language_modeling.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/masked_language_modeling.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/masked_language_modeling.ipynb"}]}}),C=new Qe({props:{id:"mqElG5QJWUg"}}),V=new ye({props:{$$slots:{default:[et]},$$scope:{ctx:Z}}}),z=new v({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),L=new v({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),S=new Vs({props:{title:"Load ELI5 dataset",local:"load-eli5-dataset",headingTag:"h2"}}),x=new v({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZWxpNSUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJlbGk1JTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbl9hc2tzJTVCJTNBNTAwMCU1RCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = load_dataset(<span class="hljs-string">&quot;eli5&quot;</span>, split=<span class="hljs-string">&quot;train_asks[:5000]&quot;</span>)`,wrap:!1}}),rs=new v({props:{code:"ZWxpNSUyMCUzRCUyMGVsaTUudHJhaW5fdGVzdF9zcGxpdCh0ZXN0X3NpemUlM0QwLjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = eli5.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),ms=new v({props:{code:"ZWxpNSU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>eli5[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers&#x27;</span>: {<span class="hljs-string">&#x27;a_id&#x27;</span>: [<span class="hljs-string">&#x27;c3d1aib&#x27;</span>, <span class="hljs-string">&#x27;c3d4lya&#x27;</span>],
  <span class="hljs-string">&#x27;score&#x27;</span>: [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],
  <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&quot;The velocity needed to remain in orbit is equal to the square root of Newton&#x27;s constant times the mass of earth divided by the distance from the center of the earth. I don&#x27;t know the altitude of that specific mission, but they&#x27;re usually around 300 km. That means he&#x27;s going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up.&quot;</span>,
   <span class="hljs-string">&quot;Hope you don&#x27;t mind me asking another question, but why aren&#x27;t there any stars visible in this photo?&quot;</span>]},
 <span class="hljs-string">&#x27;answers_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: []},
 <span class="hljs-string">&#x27;document&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
 <span class="hljs-string">&#x27;q_id&#x27;</span>: <span class="hljs-string">&#x27;nyxfp&#x27;</span>,
 <span class="hljs-string">&#x27;selftext&#x27;</span>: <span class="hljs-string">&#x27;_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?&#x27;</span>,
 <span class="hljs-string">&#x27;selftext_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: [<span class="hljs-string">&#x27;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg&#x27;</span>]},
 <span class="hljs-string">&#x27;subreddit&#x27;</span>: <span class="hljs-string">&#x27;askscience&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Few questions about this space walk photograph.&#x27;</span>,
 <span class="hljs-string">&#x27;title_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: []}}`,wrap:!1}}),cs=new Vs({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),fs=new Qe({props:{id:"8PmhEIXhBvI"}}),ds=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlscm9iZXJ0YS1iYXNlJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilroberta-base&quot;</span>)`,wrap:!1}}),us=new v({props:{code:"ZWxpNSUyMCUzRCUyMGVsaTUuZmxhdHRlbigpJTBBZWxpNSU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = eli5.flatten()
<span class="hljs-meta">&gt;&gt;&gt; </span>eli5[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers.a_id&#x27;</span>: [<span class="hljs-string">&#x27;c3d1aib&#x27;</span>, <span class="hljs-string">&#x27;c3d4lya&#x27;</span>],
 <span class="hljs-string">&#x27;answers.score&#x27;</span>: [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],
 <span class="hljs-string">&#x27;answers.text&#x27;</span>: [<span class="hljs-string">&quot;The velocity needed to remain in orbit is equal to the square root of Newton&#x27;s constant times the mass of earth divided by the distance from the center of the earth. I don&#x27;t know the altitude of that specific mission, but they&#x27;re usually around 300 km. That means he&#x27;s going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up.&quot;</span>,
  <span class="hljs-string">&quot;Hope you don&#x27;t mind me asking another question, but why aren&#x27;t there any stars visible in this photo?&quot;</span>],
 <span class="hljs-string">&#x27;answers_urls.url&#x27;</span>: [],
 <span class="hljs-string">&#x27;document&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
 <span class="hljs-string">&#x27;q_id&#x27;</span>: <span class="hljs-string">&#x27;nyxfp&#x27;</span>,
 <span class="hljs-string">&#x27;selftext&#x27;</span>: <span class="hljs-string">&#x27;_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?&#x27;</span>,
 <span class="hljs-string">&#x27;selftext_urls.url&#x27;</span>: [<span class="hljs-string">&#x27;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg&#x27;</span>],
 <span class="hljs-string">&#x27;subreddit&#x27;</span>: <span class="hljs-string">&#x27;askscience&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Few questions about this space walk photograph.&#x27;</span>,
 <span class="hljs-string">&#x27;title_urls.url&#x27;</span>: []}`,wrap:!1}}),bs=new v({props:{code:"ZGVmJTIwcHJlcHJvY2Vzc19mdW5jdGlvbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjByZXR1cm4lMjB0b2tlbml6ZXIoJTVCJTIyJTIwJTIyLmpvaW4oeCklMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlcyU1QiUyMmFuc3dlcnMudGV4dCUyMiU1RCU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer([<span class="hljs-string">&quot; &quot;</span>.join(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;answers.text&quot;</span>]])`,wrap:!1}}),$s=new v({props:{code:"dG9rZW5pemVkX2VsaTUlMjAlM0QlMjBlbGk1Lm1hcCglMEElMjAlMjAlMjAlMjBwcmVwcm9jZXNzX2Z1bmN0aW9uJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hlZCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBudW1fcHJvYyUzRDQlMkMlMEElMjAlMjAlMjAlMjByZW1vdmVfY29sdW1ucyUzRGVsaTUlNUIlMjJ0cmFpbiUyMiU1RC5jb2x1bW5fbmFtZXMlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_eli5 = eli5.<span class="hljs-built_in">map</span>(
<span class="hljs-meta">... </span>    preprocess_function,
<span class="hljs-meta">... </span>    batched=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    num_proc=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    remove_columns=eli5[<span class="hljs-string">&quot;train&quot;</span>].column_names,
<span class="hljs-meta">... </span>)`,wrap:!1}}),ks=new v({props:{code:"YmxvY2tfc2l6ZSUyMCUzRCUyMDEyOCUwQSUwQSUwQWRlZiUyMGdyb3VwX3RleHRzKGV4YW1wbGVzKSUzQSUwQSUyMCUyMCUyMCUyMCUyMyUyMENvbmNhdGVuYXRlJTIwYWxsJTIwdGV4dHMuJTBBJTIwJTIwJTIwJTIwY29uY2F0ZW5hdGVkX2V4YW1wbGVzJTIwJTNEJTIwJTdCayUzQSUyMHN1bShleGFtcGxlcyU1QmslNUQlMkMlMjAlNUIlNUQpJTIwZm9yJTIwayUyMGluJTIwZXhhbXBsZXMua2V5cygpJTdEJTBBJTIwJTIwJTIwJTIwdG90YWxfbGVuZ3RoJTIwJTNEJTIwbGVuKGNvbmNhdGVuYXRlZF9leGFtcGxlcyU1Qmxpc3QoZXhhbXBsZXMua2V5cygpKSU1QjAlNUQlNUQpJTBBJTIwJTIwJTIwJTIwJTIzJTIwV2UlMjBkcm9wJTIwdGhlJTIwc21hbGwlMjByZW1haW5kZXIlMkMlMjB3ZSUyMGNvdWxkJTIwYWRkJTIwcGFkZGluZyUyMGlmJTIwdGhlJTIwbW9kZWwlMjBzdXBwb3J0ZWQlMjBpdCUyMGluc3RlYWQlMjBvZiUyMHRoaXMlMjBkcm9wJTJDJTIweW91JTIwY2FuJTBBJTIwJTIwJTIwJTIwJTIzJTIwY3VzdG9taXplJTIwdGhpcyUyMHBhcnQlMjB0byUyMHlvdXIlMjBuZWVkcy4lMEElMjAlMjAlMjAlMjBpZiUyMHRvdGFsX2xlbmd0aCUyMCUzRSUzRCUyMGJsb2NrX3NpemUlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjB0b3RhbF9sZW5ndGglMjAlM0QlMjAodG90YWxfbGVuZ3RoJTIwJTJGJTJGJTIwYmxvY2tfc2l6ZSklMjAqJTIwYmxvY2tfc2l6ZSUwQSUyMCUyMCUyMCUyMCUyMyUyMFNwbGl0JTIwYnklMjBjaHVua3MlMjBvZiUyMGJsb2NrX3NpemUuJTBBJTIwJTIwJTIwJTIwcmVzdWx0JTIwJTNEJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwayUzQSUyMCU1QnQlNUJpJTIwJTNBJTIwaSUyMCUyQiUyMGJsb2NrX3NpemUlNUQlMjBmb3IlMjBpJTIwaW4lMjByYW5nZSgwJTJDJTIwdG90YWxfbGVuZ3RoJTJDJTIwYmxvY2tfc2l6ZSklNUQlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBmb3IlMjBrJTJDJTIwdCUyMGluJTIwY29uY2F0ZW5hdGVkX2V4YW1wbGVzLml0ZW1zKCklMEElMjAlMjAlMjAlMjAlN0QlMEElMjAlMjAlMjAlMjByZXR1cm4lMjByZXN1bHQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>block_size = <span class="hljs-number">128</span>


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-comment"># Concatenate all texts.</span>
<span class="hljs-meta">... </span>    concatenated_examples = {k: <span class="hljs-built_in">sum</span>(examples[k], []) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()}
<span class="hljs-meta">... </span>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])
<span class="hljs-meta">... </span>    <span class="hljs-comment"># We drop the small remainder, we could add padding if the model supported it instead of this drop, you can</span>
<span class="hljs-meta">... </span>    <span class="hljs-comment"># customize this part to your needs.</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> total_length &gt;= block_size:
<span class="hljs-meta">... </span>        total_length = (total_length // block_size) * block_size
<span class="hljs-meta">... </span>    <span class="hljs-comment"># Split by chunks of block_size.</span>
<span class="hljs-meta">... </span>    result = {
<span class="hljs-meta">... </span>        k: [t[i : i + block_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, total_length, block_size)]
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> concatenated_examples.items()
<span class="hljs-meta">... </span>    }
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> result`,wrap:!1}}),Js=new v({props:{code:"bG1fZGF0YXNldCUyMCUzRCUyMHRva2VuaXplZF9lbGk1Lm1hcChncm91cF90ZXh0cyUyQyUyMGJhdGNoZWQlM0RUcnVlJTJDJTIwbnVtX3Byb2MlM0Q0KQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lm_dataset = tokenized_eli5.<span class="hljs-built_in">map</span>(group_texts, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">4</span>)',wrap:!1}}),K=new $e({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[nt],pytorch:[at]},$$scope:{ctx:Z}}}),Zs=new Vs({props:{title:"Train",local:"train",headingTag:"h2"}}),O=new $e({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ct],pytorch:[ot]},$$scope:{ctx:Z}}}),ss=new ye({props:{$$slots:{default:[ft]},$$scope:{ctx:Z}}}),Gs=new Vs({props:{title:"Inference",local:"inference",headingTag:"h2"}}),Cs=new v({props:{code:"dGV4dCUyMCUzRCUyMCUyMlRoZSUyME1pbGt5JTIwV2F5JTIwaXMlMjBhJTIwJTNDbWFzayUzRSUyMGdhbGF4eS4lMjI=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>text = <span class="hljs-string">&quot;The Milky Way is a &lt;mask&gt; galaxy.&quot;</span>',wrap:!1}}),Is=new v({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBbWFza19maWxsZXIlMjAlM0QlMjBwaXBlbGluZSglMjJmaWxsLW1hc2slMjIlMkMlMjAlMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfZWxpNV9tbG1fbW9kZWwlMjIpJTBBbWFza19maWxsZXIodGV4dCUyQyUyMHRvcF9rJTNEMyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>mask_filler = pipeline(<span class="hljs-string">&quot;fill-mask&quot;</span>, <span class="hljs-string">&quot;stevhliu/my_awesome_eli5_mlm_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>mask_filler(text, top_k=<span class="hljs-number">3</span>)
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.5150994658470154</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">21300</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; spiral&#x27;</span>,
  <span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;The Milky Way is a spiral galaxy.&#x27;</span>},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.07087188959121704</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">2232</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; massive&#x27;</span>,
  <span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;The Milky Way is a massive galaxy.&#x27;</span>},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.06434620916843414</span>,
  <span class="hljs-string">&#x27;token&#x27;</span>: <span class="hljs-number">650</span>,
  <span class="hljs-string">&#x27;token_str&#x27;</span>: <span class="hljs-string">&#x27; small&#x27;</span>,
  <span class="hljs-string">&#x27;sequence&#x27;</span>: <span class="hljs-string">&#x27;The Milky Way is a small galaxy.&#x27;</span>}]`,wrap:!1}}),es=new $e({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ut],pytorch:[dt]},$$scope:{ctx:Z}}}),{c(){e=$("meta"),c=m(),a=$("p"),o=m(),M(d.$$.fragment),h=m(),M(G.$$.fragment),R=m(),M(C.$$.fragment),I=m(),_=$("p"),_.textContent=F,W=m(),U=$("p"),U.textContent=B,p=m(),k=$("ol"),k.innerHTML=E,H=m(),M(V.$$.fragment),X=m(),A=$("p"),A.textContent=N,Q=m(),M(z.$$.fragment),f=m(),J=$("p"),J.textContent=Y,as=m(),M(L.$$.fragment),q=m(),M(S.$$.fragment),P=m(),D=$("p"),D.textContent=ls,r=m(),M(x.$$.fragment),ns=m(),ps=$("p"),ps.innerHTML=we,zs=m(),M(rs.$$.fragment),Fs=m(),os=$("p"),os.textContent=Te,Es=m(),M(ms.$$.fragment),Hs=m(),is=$("p"),is.innerHTML=_e,As=m(),M(cs.$$.fragment),Ns=m(),M(fs.$$.fragment),Qs=m(),hs=$("p"),hs.innerHTML=ke,Ys=m(),M(ds.$$.fragment),Ls=m(),Ms=$("p"),Ms.innerHTML=xe,qs=m(),M(us.$$.fragment),Ss=m(),gs=$("p"),gs.innerHTML=Je,Ps=m(),js=$("p"),js.textContent=Ue,Ds=m(),M(bs.$$.fragment),Ks=m(),ys=$("p"),ys.innerHTML=Ze,Os=m(),M($s.$$.fragment),se=m(),ws=$("p"),ws.textContent=Ge,ee=m(),Ts=$("p"),Ts.textContent=ve,te=m(),_s=$("ul"),_s.innerHTML=Re,ae=m(),M(ks.$$.fragment),le=m(),xs=$("p"),xs.innerHTML=Ce,ne=m(),M(Js.$$.fragment),pe=m(),Us=$("p"),Us.innerHTML=We,re=m(),M(K.$$.fragment),oe=m(),M(Zs.$$.fragment),me=m(),M(O.$$.fragment),ie=m(),M(ss.$$.fragment),ce=m(),M(Gs.$$.fragment),fe=m(),vs=$("p"),vs.textContent=Ie,he=m(),Rs=$("p"),Rs.innerHTML=Be,de=m(),M(Cs.$$.fragment),Me=m(),Ws=$("p"),Ws.innerHTML=Xe,ue=m(),M(Is.$$.fragment),ge=m(),M(es.$$.fragment),je=m(),Xs=$("p"),this.h()},l(s){const n=Pe("svelte-u9bgzb",document.head);e=w(n,"META",{name:!0,content:!0}),n.forEach(t),c=i(s),a=w(s,"P",{}),Ae(a).forEach(t),o=i(s),u(d.$$.fragment,s),h=i(s),u(G.$$.fragment,s),R=i(s),u(C.$$.fragment,s),I=i(s),_=w(s,"P",{"data-svelte-h":!0}),T(_)!=="svelte-6gq7id"&&(_.textContent=F),W=i(s),U=w(s,"P",{"data-svelte-h":!0}),T(U)!=="svelte-w5jzhi"&&(U.textContent=B),p=i(s),k=w(s,"OL",{"data-svelte-h":!0}),T(k)!=="svelte-nfl7pm"&&(k.innerHTML=E),H=i(s),u(V.$$.fragment,s),X=i(s),A=w(s,"P",{"data-svelte-h":!0}),T(A)!=="svelte-1lya3k8"&&(A.textContent=N),Q=i(s),u(z.$$.fragment,s),f=i(s),J=w(s,"P",{"data-svelte-h":!0}),T(J)!=="svelte-193zy02"&&(J.textContent=Y),as=i(s),u(L.$$.fragment,s),q=i(s),u(S.$$.fragment,s),P=i(s),D=w(s,"P",{"data-svelte-h":!0}),T(D)!=="svelte-1m8npvc"&&(D.textContent=ls),r=i(s),u(x.$$.fragment,s),ns=i(s),ps=w(s,"P",{"data-svelte-h":!0}),T(ps)!=="svelte-1ohvh79"&&(ps.innerHTML=we),zs=i(s),u(rs.$$.fragment,s),Fs=i(s),os=w(s,"P",{"data-svelte-h":!0}),T(os)!=="svelte-1r6oj5w"&&(os.textContent=Te),Es=i(s),u(ms.$$.fragment,s),Hs=i(s),is=w(s,"P",{"data-svelte-h":!0}),T(is)!=="svelte-kb5u2z"&&(is.innerHTML=_e),As=i(s),u(cs.$$.fragment,s),Ns=i(s),u(fs.$$.fragment,s),Qs=i(s),hs=w(s,"P",{"data-svelte-h":!0}),T(hs)!=="svelte-32hazt"&&(hs.innerHTML=ke),Ys=i(s),u(ds.$$.fragment,s),Ls=i(s),Ms=w(s,"P",{"data-svelte-h":!0}),T(Ms)!=="svelte-fjd9et"&&(Ms.innerHTML=xe),qs=i(s),u(us.$$.fragment,s),Ss=i(s),gs=w(s,"P",{"data-svelte-h":!0}),T(gs)!=="svelte-jgh86y"&&(gs.innerHTML=Je),Ps=i(s),js=w(s,"P",{"data-svelte-h":!0}),T(js)!=="svelte-177qfmt"&&(js.textContent=Ue),Ds=i(s),u(bs.$$.fragment,s),Ks=i(s),ys=w(s,"P",{"data-svelte-h":!0}),T(ys)!=="svelte-1l40k3u"&&(ys.innerHTML=Ze),Os=i(s),u($s.$$.fragment,s),se=i(s),ws=w(s,"P",{"data-svelte-h":!0}),T(ws)!=="svelte-1bsb6if"&&(ws.textContent=Ge),ee=i(s),Ts=w(s,"P",{"data-svelte-h":!0}),T(Ts)!=="svelte-1jnll4i"&&(Ts.textContent=ve),te=i(s),_s=w(s,"UL",{"data-svelte-h":!0}),T(_s)!=="svelte-1r1l6ld"&&(_s.innerHTML=Re),ae=i(s),u(ks.$$.fragment,s),le=i(s),xs=w(s,"P",{"data-svelte-h":!0}),T(xs)!=="svelte-1vmzqwi"&&(xs.innerHTML=Ce),ne=i(s),u(Js.$$.fragment,s),pe=i(s),Us=w(s,"P",{"data-svelte-h":!0}),T(Us)!=="svelte-1yn7k6t"&&(Us.innerHTML=We),re=i(s),u(K.$$.fragment,s),oe=i(s),u(Zs.$$.fragment,s),me=i(s),u(O.$$.fragment,s),ie=i(s),u(ss.$$.fragment,s),ce=i(s),u(Gs.$$.fragment,s),fe=i(s),vs=w(s,"P",{"data-svelte-h":!0}),T(vs)!=="svelte-cyrfc8"&&(vs.textContent=Ie),he=i(s),Rs=w(s,"P",{"data-svelte-h":!0}),T(Rs)!=="svelte-5jelel"&&(Rs.innerHTML=Be),de=i(s),u(Cs.$$.fragment,s),Me=i(s),Ws=w(s,"P",{"data-svelte-h":!0}),T(Ws)!=="svelte-rx6q9t"&&(Ws.innerHTML=Xe),ue=i(s),u(Is.$$.fragment,s),ge=i(s),u(es.$$.fragment,s),je=i(s),Xs=w(s,"P",{}),Ae(Xs).forEach(t),this.h()},h(){Ne(e,"name","hf:doc:metadata"),Ne(e,"content",jt)},m(s,n){De(document.head,e),l(s,c,n),l(s,a,n),l(s,o,n),g(d,s,n),l(s,h,n),g(G,s,n),l(s,R,n),g(C,s,n),l(s,I,n),l(s,_,n),l(s,W,n),l(s,U,n),l(s,p,n),l(s,k,n),l(s,H,n),g(V,s,n),l(s,X,n),l(s,A,n),l(s,Q,n),g(z,s,n),l(s,f,n),l(s,J,n),l(s,as,n),g(L,s,n),l(s,q,n),g(S,s,n),l(s,P,n),l(s,D,n),l(s,r,n),g(x,s,n),l(s,ns,n),l(s,ps,n),l(s,zs,n),g(rs,s,n),l(s,Fs,n),l(s,os,n),l(s,Es,n),g(ms,s,n),l(s,Hs,n),l(s,is,n),l(s,As,n),g(cs,s,n),l(s,Ns,n),g(fs,s,n),l(s,Qs,n),l(s,hs,n),l(s,Ys,n),g(ds,s,n),l(s,Ls,n),l(s,Ms,n),l(s,qs,n),g(us,s,n),l(s,Ss,n),l(s,gs,n),l(s,Ps,n),l(s,js,n),l(s,Ds,n),g(bs,s,n),l(s,Ks,n),l(s,ys,n),l(s,Os,n),g($s,s,n),l(s,se,n),l(s,ws,n),l(s,ee,n),l(s,Ts,n),l(s,te,n),l(s,_s,n),l(s,ae,n),g(ks,s,n),l(s,le,n),l(s,xs,n),l(s,ne,n),g(Js,s,n),l(s,pe,n),l(s,Us,n),l(s,re,n),g(K,s,n),l(s,oe,n),g(Zs,s,n),l(s,me,n),g(O,s,n),l(s,ie,n),g(ss,s,n),l(s,ce,n),g(Gs,s,n),l(s,fe,n),l(s,vs,n),l(s,he,n),l(s,Rs,n),l(s,de,n),g(Cs,s,n),l(s,Me,n),l(s,Ws,n),l(s,ue,n),g(Is,s,n),l(s,ge,n),g(es,s,n),l(s,je,n),l(s,Xs,n),be=!0},p(s,[n]){const Ve={};n&2&&(Ve.$$scope={dirty:n,ctx:s}),V.$set(Ve);const ze={};n&2&&(ze.$$scope={dirty:n,ctx:s}),K.$set(ze);const Fe={};n&2&&(Fe.$$scope={dirty:n,ctx:s}),O.$set(Fe);const Ee={};n&2&&(Ee.$$scope={dirty:n,ctx:s}),ss.$set(Ee);const He={};n&2&&(He.$$scope={dirty:n,ctx:s}),es.$set(He)},i(s){be||(j(d.$$.fragment,s),j(G.$$.fragment,s),j(C.$$.fragment,s),j(V.$$.fragment,s),j(z.$$.fragment,s),j(L.$$.fragment,s),j(S.$$.fragment,s),j(x.$$.fragment,s),j(rs.$$.fragment,s),j(ms.$$.fragment,s),j(cs.$$.fragment,s),j(fs.$$.fragment,s),j(ds.$$.fragment,s),j(us.$$.fragment,s),j(bs.$$.fragment,s),j($s.$$.fragment,s),j(ks.$$.fragment,s),j(Js.$$.fragment,s),j(K.$$.fragment,s),j(Zs.$$.fragment,s),j(O.$$.fragment,s),j(ss.$$.fragment,s),j(Gs.$$.fragment,s),j(Cs.$$.fragment,s),j(Is.$$.fragment,s),j(es.$$.fragment,s),be=!0)},o(s){b(d.$$.fragment,s),b(G.$$.fragment,s),b(C.$$.fragment,s),b(V.$$.fragment,s),b(z.$$.fragment,s),b(L.$$.fragment,s),b(S.$$.fragment,s),b(x.$$.fragment,s),b(rs.$$.fragment,s),b(ms.$$.fragment,s),b(cs.$$.fragment,s),b(fs.$$.fragment,s),b(ds.$$.fragment,s),b(us.$$.fragment,s),b(bs.$$.fragment,s),b($s.$$.fragment,s),b(ks.$$.fragment,s),b(Js.$$.fragment,s),b(K.$$.fragment,s),b(Zs.$$.fragment,s),b(O.$$.fragment,s),b(ss.$$.fragment,s),b(Gs.$$.fragment,s),b(Cs.$$.fragment,s),b(Is.$$.fragment,s),b(es.$$.fragment,s),be=!1},d(s){s&&(t(c),t(a),t(o),t(h),t(R),t(I),t(_),t(W),t(U),t(p),t(k),t(H),t(X),t(A),t(Q),t(f),t(J),t(as),t(q),t(P),t(D),t(r),t(ns),t(ps),t(zs),t(Fs),t(os),t(Es),t(Hs),t(is),t(As),t(Ns),t(Qs),t(hs),t(Ys),t(Ls),t(Ms),t(qs),t(Ss),t(gs),t(Ps),t(js),t(Ds),t(Ks),t(ys),t(Os),t(se),t(ws),t(ee),t(Ts),t(te),t(_s),t(ae),t(le),t(xs),t(ne),t(pe),t(Us),t(re),t(oe),t(me),t(ie),t(ce),t(fe),t(vs),t(he),t(Rs),t(de),t(Me),t(Ws),t(ue),t(ge),t(je),t(Xs)),t(e),y(d,s),y(G,s),y(C,s),y(V,s),y(z,s),y(L,s),y(S,s),y(x,s),y(rs,s),y(ms,s),y(cs,s),y(fs,s),y(ds,s),y(us,s),y(bs,s),y($s,s),y(ks,s),y(Js,s),y(K,s),y(Zs,s),y(O,s),y(ss,s),y(Gs,s),y(Cs,s),y(Is,s),y(es,s)}}}const jt='{"title":"Masked language modeling","local":"masked-language-modeling","sections":[{"title":"Load ELI5 dataset","local":"load-eli5-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function bt(Z){return Le(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ut extends qe{constructor(e){super(),Se(this,e,bt,gt,Ye,{})}}export{Ut as component};
