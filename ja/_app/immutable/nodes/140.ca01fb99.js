import{s as nl,o as pl,n as il}from"../chunks/scheduler.9bc65507.js";import{S as rl,i as Ml,g as p,s as a,r as M,A as ml,h as i,f as l,c as n,j as al,u as m,x as r,k as kt,y as ol,a as s,v as o,d as c,t as y,w as d}from"../chunks/index.707bf1b6.js";import{T as cl}from"../chunks/Tip.c2ecdbf4.js";import{C as f}from"../chunks/CodeBlock.54a9f38d.js";import{D as yl}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{H as he}from"../chunks/Heading.342b1fa6.js";function dl(ge){let w,h="多くの画像キャプション データセットには、画像ごとに複数のキャプションが含まれています。このような場合、一般的な戦略は、トレーニング中に利用可能なキャプションの中からランダムにキャプションをサンプリングすることです。";return{c(){w=p("p"),w.textContent=h},l(J){w=i(J,"P",{"data-svelte-h":!0}),r(w)!=="svelte-6nosxd"&&(w.textContent=h)},m(J,Ue){s(J,w,Ue)},p:il,d(J){J&&l(w)}}}function fl(ge){let w,h,J,Ue,U,$e,j,Ce,g,Bt=`画像のキャプション付けは、特定の画像のキャプションを予測するタスクです。一般的な現実世界のアプリケーションには次のものがあります。
視覚障害者がさまざまな状況を乗り越えられるよう支援します。したがって、画像のキャプション
画像を説明することで人々のコンテンツへのアクセシビリティを向上させるのに役立ちます。`,_e,$,Wt="このガイドでは、次の方法を説明します。",ke,C,It="<li>画像キャプション モデルを微調整します。</li> <li>微調整されたモデルを推論に使用します。</li>",Be,_,vt="始める前に、必要なライブラリがすべてインストールされていることを確認してください。",We,k,Ie,B,Zt="モデルをアップロードしてコミュニティと共有できるように、Hugging Face アカウントにログインすることをお勧めします。プロンプトが表示されたら、トークンを入力してログインします。",ve,W,Ze,I,Ge,v,Gt=`🤗 データセット ライブラリを使用して、{image-caption} ペアで構成されるデータセットを読み込みます。独自の画像キャプション データセットを作成するには
PyTorch では、<a href="https://github.com/NielsRogge/Transformers-Tutorials/blob/master/GIT/Fine_tune_GIT_on_an_image_captioning_dataset.ipynb" rel="nofollow">このノートブック</a> を参照できます。`,xe,Z,Re,G,Xe,x,xt="データセットには <code>image</code>と<code>text</code>の 2 つの機能があります。",He,u,Ve,R,Rt="<code>train_test_split</code> メソッドを使用して、データセットのトレイン スプリットをトレイン セットとテスト セットに分割します。",Ye,X,Ee,H,Xt="トレーニング セットからのいくつかのサンプルを視覚化してみましょう。",Qe,V,Ne,b,Ht='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/sample_training_images_image_cap.png" alt="Sample training images"/>',ze,Y,Fe,E,Vt="データセットには 2 つのモダリティ (画像とテキスト) があるため、前処理パイプラインは画像とキャプションを前処理します。",Ae,Q,Yt="これを行うには、微調整しようとしているモデルに関連付けられたプロセッサ クラスをロードします。",Se,N,qe,z,Et="プロセッサは内部で画像を前処理し (サイズ変更やピクセル スケーリングを含む)、キャプションをトークン化します。",Le,F,Pe,A,Qt="データセットの準備ができたら、微調整用にモデルをセットアップできます。",Ke,S,De,q,Nt='<a href="https://huggingface.co/microsoft/git-base" rel="nofollow">“microsoft/git-base”</a> を <a href="https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM" rel="nofollow"><code>AutoModelForCausalLM</code></a> オブジェクト。',Oe,L,et,P,tt,K,lt,D,zt='画像キャプション モデルは通常、<a href="https://huggingface.co/spaces/evaluate-metric/rouge" rel="nofollow">Rouge Score</a> または <a href="https://huggingface.co/spaces/evaluate-metric/" rel="nofollow">Word Error Rate</a> で評価されます。そうだった）。このガイドでは、Word Error Rate (WER) を使用します。',st,O,Ft='これを行うには 🤗 Evaluate ライブラリを使用します。 WER の潜在的な制限やその他の問題点については、<a href="https://huggingface.co/spaces/evaluate-metric/wer" rel="nofollow">このガイド</a> を参照してください。',at,ee,nt,te,pt,le,At='これで、モデルの微調整を開始する準備が整いました。これには 🤗 <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> を使用します。',it,se,St='まず、<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> を使用してトレーニング引数を定義します。',rt,ae,Mt,ne,qt="Trainer 次に、次に、データセットとモデルと一緒に 🤗 に渡します。",mt,pe,ot,ie,Lt='トレーニングを開始するには、<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> オブジェクトの <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train">train()</a> を呼び出すだけです。',ct,re,yt,Me,Pt="トレーニングが進むにつれて、トレーニングの損失がスムーズに減少することがわかります。",dt,me,Kt='トレーニングが完了したら、 <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> メソッドを使用してモデルをハブに共有し、誰もがモデルを使用できるようにします。',ft,oe,wt,ce,Jt,ye,Dt="<code>test_ds</code> からサンプル画像を取得してモデルをテストします。",ut,de,bt,T,Ot='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/test_image_image_cap.png" alt="Test image"/>',Tt,fe,el="モデル用の画像を準備します。",ht,we,Ut,Je,tl="<code>generate</code> を呼び出して予測をデコードします。",jt,ue,gt,be,$t,Te,ll="微調整されたモデルにより、非常に優れたキャプションが生成されたようです。",Ct,je,_t;return U=new he({props:{title:"Image captioning",local:"image-captioning",headingTag:"h1"}}),j=new yl({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/image_captioning.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/image_captioning.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/image_captioning.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/image_captioning.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/image_captioning.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/image_captioning.ipynb"}]}}),k=new f({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGUlMjAtcSUwQXBpcCUyMGluc3RhbGwlMjBqaXdlciUyMC1x",highlighted:`pip install transformers datasets evaluate -q
pip install jiwer -q`,wrap:!1}}),W=new f({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

notebook_login()`,wrap:!1}}),I=new he({props:{title:"Load the Pokémon BLIP captions dataset",local:"load-the-pokémon-blip-captions-dataset",headingTag:"h2"}}),Z=new f({props:{code:"ZHMlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIybGFtYmRhbGFicyUyRnBva2Vtb24tYmxpcC1jYXB0aW9ucyUyMiklMEFkcw==",highlighted:`ds = load_dataset(<span class="hljs-string">&quot;lambdalabs/pokemon-blip-captions&quot;</span>)
ds`,wrap:!1}}),G=new f({props:{code:"RGF0YXNldERpY3QoJTdCJTBBJTIwJTIwJTIwJTIwdHJhaW4lM0ElMjBEYXRhc2V0KCU3QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGZlYXR1cmVzJTNBJTIwJTVCJ2ltYWdlJyUyQyUyMCd0ZXh0JyU1RCUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG51bV9yb3dzJTNBJTIwODMzJTBBJTIwJTIwJTIwJTIwJTdEKSUwQSU3RCk=",highlighted:`DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;image&#x27;</span>, <span class="hljs-string">&#x27;text&#x27;</span>],
        num_rows: 833
    })
})`,wrap:!1}}),u=new cl({props:{$$slots:{default:[dl]},$$scope:{ctx:ge}}}),X=new f({props:{code:"ZHMlMjAlM0QlMjBkcyU1QiUyMnRyYWluJTIyJTVELnRyYWluX3Rlc3Rfc3BsaXQodGVzdF9zaXplJTNEMC4xKSUwQXRyYWluX2RzJTIwJTNEJTIwZHMlNUIlMjJ0cmFpbiUyMiU1RCUwQXRlc3RfZHMlMjAlM0QlMjBkcyU1QiUyMnRlc3QlMjIlNUQ=",highlighted:`ds = ds[<span class="hljs-string">&quot;train&quot;</span>].train_test_split(test_size=<span class="hljs-number">0.1</span>)
train_ds = ds[<span class="hljs-string">&quot;train&quot;</span>]
test_ds = ds[<span class="hljs-string">&quot;test&quot;</span>]`,wrap:!1}}),V=new f({props:{code:"ZnJvbSUyMHRleHR3cmFwJTIwaW1wb3J0JTIwd3JhcCUwQWltcG9ydCUyMG1hdHBsb3RsaWIucHlwbG90JTIwYXMlMjBwbHQlMEFpbXBvcnQlMjBudW1weSUyMGFzJTIwbnAlMEElMEElMEFkZWYlMjBwbG90X2ltYWdlcyhpbWFnZXMlMkMlMjBjYXB0aW9ucyklM0ElMEElMjAlMjAlMjAlMjBwbHQuZmlndXJlKGZpZ3NpemUlM0QoMjAlMkMlMjAyMCkpJTBBJTIwJTIwJTIwJTIwZm9yJTIwaSUyMGluJTIwcmFuZ2UobGVuKGltYWdlcykpJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwYXglMjAlM0QlMjBwbHQuc3VicGxvdCgxJTJDJTIwbGVuKGltYWdlcyklMkMlMjBpJTIwJTJCJTIwMSklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBjYXB0aW9uJTIwJTNEJTIwY2FwdGlvbnMlNUJpJTVEJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwY2FwdGlvbiUyMCUzRCUyMCUyMiU1Q24lMjIuam9pbih3cmFwKGNhcHRpb24lMkMlMjAxMikpJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcGx0LnRpdGxlKGNhcHRpb24pJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcGx0Lmltc2hvdyhpbWFnZXMlNUJpJTVEKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHBsdC5heGlzKCUyMm9mZiUyMiklMEElMEElMEFzYW1wbGVfaW1hZ2VzX3RvX3Zpc3VhbGl6ZSUyMCUzRCUyMCU1Qm5wLmFycmF5KHRyYWluX2RzJTVCaSU1RCU1QiUyMmltYWdlJTIyJTVEKSUyMGZvciUyMGklMjBpbiUyMHJhbmdlKDUpJTVEJTBBc2FtcGxlX2NhcHRpb25zJTIwJTNEJTIwJTVCdHJhaW5fZHMlNUJpJTVEJTVCJTIydGV4dCUyMiU1RCUyMGZvciUyMGklMjBpbiUyMHJhbmdlKDUpJTVEJTBBcGxvdF9pbWFnZXMoc2FtcGxlX2ltYWdlc190b192aXN1YWxpemUlMkMlMjBzYW1wbGVfY2FwdGlvbnMp",highlighted:`<span class="hljs-keyword">from</span> textwrap <span class="hljs-keyword">import</span> wrap
<span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-keyword">def</span> <span class="hljs-title function_">plot_images</span>(<span class="hljs-params">images, captions</span>):
    plt.figure(figsize=(<span class="hljs-number">20</span>, <span class="hljs-number">20</span>))
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(images)):
        ax = plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-built_in">len</span>(images), i + <span class="hljs-number">1</span>)
        caption = captions[i]
        caption = <span class="hljs-string">&quot;\\n&quot;</span>.join(wrap(caption, <span class="hljs-number">12</span>))
        plt.title(caption)
        plt.imshow(images[i])
        plt.axis(<span class="hljs-string">&quot;off&quot;</span>)


sample_images_to_visualize = [np.array(train_ds[i][<span class="hljs-string">&quot;image&quot;</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]
sample_captions = [train_ds[i][<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>)]
plot_images(sample_images_to_visualize, sample_captions)`,wrap:!1}}),Y=new he({props:{title:"Preprocess the dataset",local:"preprocess-the-dataset",headingTag:"h2"}}),N=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFjaGVja3BvaW50JTIwJTNEJTIwJTIybWljcm9zb2Z0JTJGZ2l0LWJhc2UlMjIlMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZChjaGVja3BvaW50KQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

checkpoint = <span class="hljs-string">&quot;microsoft/git-base&quot;</span>
processor = AutoProcessor.from_pretrained(checkpoint)`,wrap:!1}}),F=new f({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlX2JhdGNoKSUzQSUwQSUyMCUyMCUyMCUyMGltYWdlcyUyMCUzRCUyMCU1QnglMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlX2JhdGNoJTVCJTIyaW1hZ2UlMjIlNUQlNUQlMEElMjAlMjAlMjAlMjBjYXB0aW9ucyUyMCUzRCUyMCU1QnglMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlX2JhdGNoJTVCJTIydGV4dCUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGlucHV0cyUyMCUzRCUyMHByb2Nlc3NvcihpbWFnZXMlM0RpbWFnZXMlMkMlMjB0ZXh0JTNEY2FwdGlvbnMlMkMlMjBwYWRkaW5nJTNEJTIybWF4X2xlbmd0aCUyMiklMEElMjAlMjAlMjAlMjBpbnB1dHMudXBkYXRlKCU3QiUyMmxhYmVscyUyMiUzQSUyMGlucHV0cyU1QiUyMmlucHV0X2lkcyUyMiU1RCU3RCklMEElMjAlMjAlMjAlMjByZXR1cm4lMjBpbnB1dHMlMEElMEElMEF0cmFpbl9kcy5zZXRfdHJhbnNmb3JtKHRyYW5zZm9ybXMpJTBBdGVzdF9kcy5zZXRfdHJhbnNmb3JtKHRyYW5zZm9ybXMp",highlighted:`<span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">example_batch</span>):
    images = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]]
    captions = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;text&quot;</span>]]
    inputs = processor(images=images, text=captions, padding=<span class="hljs-string">&quot;max_length&quot;</span>)
    inputs.update({<span class="hljs-string">&quot;labels&quot;</span>: inputs[<span class="hljs-string">&quot;input_ids&quot;</span>]})
    <span class="hljs-keyword">return</span> inputs


train_ds.set_transform(transforms)
test_ds.set_transform(transforms)`,wrap:!1}}),S=new he({props:{title:"Load a base model",local:"load-a-base-model",headingTag:"h2"}}),L=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoY2hlY2twb2ludCk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(checkpoint)`,wrap:!1}}),P=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoY2hlY2twb2ludCk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained(checkpoint)`,wrap:!1}}),K=new he({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),ee=new f({props:{code:"ZnJvbSUyMGV2YWx1YXRlJTIwaW1wb3J0JTIwbG9hZCUwQWltcG9ydCUyMHRvcmNoJTBBJTBBd2VyJTIwJTNEJTIwbG9hZCglMjJ3ZXIlMjIpJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKGV2YWxfcHJlZCklM0ElMEElMjAlMjAlMjAlMjBsb2dpdHMlMkMlMjBsYWJlbHMlMjAlM0QlMjBldmFsX3ByZWQlMEElMjAlMjAlMjAlMjBwcmVkaWN0ZWQlMjAlM0QlMjBsb2dpdHMuYXJnbWF4KC0xKSUwQSUyMCUyMCUyMCUyMGRlY29kZWRfbGFiZWxzJTIwJTNEJTIwcHJvY2Vzc29yLmJhdGNoX2RlY29kZShsYWJlbHMlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSklMEElMjAlMjAlMjAlMjBkZWNvZGVkX3ByZWRpY3Rpb25zJTIwJTNEJTIwcHJvY2Vzc29yLmJhdGNoX2RlY29kZShwcmVkaWN0ZWQlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSklMEElMjAlMjAlMjAlMjB3ZXJfc2NvcmUlMjAlM0QlMjB3ZXIuY29tcHV0ZShwcmVkaWN0aW9ucyUzRGRlY29kZWRfcHJlZGljdGlvbnMlMkMlMjByZWZlcmVuY2VzJTNEZGVjb2RlZF9sYWJlbHMpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwJTdCJTIyd2VyX3Njb3JlJTIyJTNBJTIwd2VyX3Njb3JlJTdE",highlighted:`<span class="hljs-keyword">from</span> evaluate <span class="hljs-keyword">import</span> load
<span class="hljs-keyword">import</span> torch

wer = load(<span class="hljs-string">&quot;wer&quot;</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    logits, labels = eval_pred
    predicted = logits.argmax(-<span class="hljs-number">1</span>)
    decoded_labels = processor.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)
    decoded_predictions = processor.batch_decode(predicted, skip_special_tokens=<span class="hljs-literal">True</span>)
    wer_score = wer.compute(predictions=decoded_predictions, references=decoded_labels)
    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;wer_score&quot;</span>: wer_score}`,wrap:!1}}),te=new he({props:{title:"Train!",local:"train",headingTag:"h2"}}),ae=new f({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTJDJTIwVHJhaW5lciUwQSUwQW1vZGVsX25hbWUlMjAlM0QlMjBjaGVja3BvaW50LnNwbGl0KCUyMiUyRiUyMiklNUIxJTVEJTBBJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0RmJTIyJTdCbW9kZWxfbmFtZSU3RC1wb2tlbW9uJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDVlLTUlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNENTAlMkMlMEElMjAlMjAlMjAlMjBmcDE2JTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDMyJTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0QzMiUyQyUwQSUyMCUyMCUyMCUyMGdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyUzRDIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3RvdGFsX2xpbWl0JTNEMyUyQyUwQSUyMCUyMCUyMCUyMGV2YWx1YXRpb25fc3RyYXRlZ3klM0QlMjJzdGVwcyUyMiUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfc3RlcHMlM0Q1MCUyQyUwQSUyMCUyMCUyMCUyMHNhdmVfc3RyYXRlZ3klM0QlMjJzdGVwcyUyMiUyQyUwQSUyMCUyMCUyMCUyMHNhdmVfc3RlcHMlM0Q1MCUyQyUwQSUyMCUyMCUyMCUyMGxvZ2dpbmdfc3RlcHMlM0Q1MCUyQyUwQSUyMCUyMCUyMCUyMHJlbW92ZV91bnVzZWRfY29sdW1ucyUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwbGFiZWxfbmFtZXMlM0QlNUIlMjJsYWJlbHMlMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments, Trainer

model_name = checkpoint.split(<span class="hljs-string">&quot;/&quot;</span>)[<span class="hljs-number">1</span>]

training_args = TrainingArguments(
    output_dir=<span class="hljs-string">f&quot;<span class="hljs-subst">{model_name}</span>-pokemon&quot;</span>,
    learning_rate=<span class="hljs-number">5e-5</span>,
    num_train_epochs=<span class="hljs-number">50</span>,
    fp16=<span class="hljs-literal">True</span>,
    per_device_train_batch_size=<span class="hljs-number">32</span>,
    per_device_eval_batch_size=<span class="hljs-number">32</span>,
    gradient_accumulation_steps=<span class="hljs-number">2</span>,
    save_total_limit=<span class="hljs-number">3</span>,
    evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,
    eval_steps=<span class="hljs-number">50</span>,
    save_strategy=<span class="hljs-string">&quot;steps&quot;</span>,
    save_steps=<span class="hljs-number">50</span>,
    logging_steps=<span class="hljs-number">50</span>,
    remove_unused_columns=<span class="hljs-literal">False</span>,
    push_to_hub=<span class="hljs-literal">True</span>,
    label_names=[<span class="hljs-string">&quot;labels&quot;</span>],
    load_best_model_at_end=<span class="hljs-literal">True</span>,
)`,wrap:!1}}),pe=new f({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHRyYWluX2RzJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEdGVzdF9kcyUyQyUwQSUyMCUyMCUyMCUyMGNvbXB1dGVfbWV0cmljcyUzRGNvbXB1dGVfbWV0cmljcyUyQyUwQSk=",highlighted:`trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=test_ds,
    compute_metrics=compute_metrics,
)`,wrap:!1}}),re=new f({props:{code:"dHJhaW5lci50cmFpbigp",highlighted:"trainer.train()",wrap:!1}}),oe=new f({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:"trainer.push_to_hub()",wrap:!1}}),ce=new he({props:{title:"Inference",local:"inference",headingTag:"h2"}}),de=new f({props:{code:"ZnJvbSUyMFBJTCUyMGltcG9ydCUyMEltYWdlJTBBaW1wb3J0JTIwcmVxdWVzdHMlMEElMEF1cmwlMjAlM0QlMjAlMjJodHRwcyUzQSUyRiUyRmh1Z2dpbmdmYWNlLmNvJTJGZGF0YXNldHMlMkZzYXlha3BhdWwlMkZzYW1wbGUtZGF0YXNldHMlMkZyZXNvbHZlJTJGbWFpbiUyRnBva2Vtb24ucG5nJTIyJTBBaW1hZ2UlMjAlM0QlMjBJbWFnZS5vcGVuKHJlcXVlc3RzLmdldCh1cmwlMkMlMjBzdHJlYW0lM0RUcnVlKS5yYXcpJTBBaW1hZ2U=",highlighted:`<span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-keyword">import</span> requests

url = <span class="hljs-string">&quot;https://huggingface.co/datasets/sayakpaul/sample-datasets/resolve/main/pokemon.png&quot;</span>
image = Image.<span class="hljs-built_in">open</span>(requests.get(url, stream=<span class="hljs-literal">True</span>).raw)
image`,wrap:!1}}),we=new f({props:{code:"ZGV2aWNlJTIwJTNEJTIwJTIyY3VkYSUyMiUyMGlmJTIwdG9yY2guY3VkYS5pc19hdmFpbGFibGUoKSUyMGVsc2UlMjAlMjJjcHUlMjIlMEElMEFpbnB1dHMlMjAlM0QlMjBwcm9jZXNzb3IoaW1hZ2VzJTNEaW1hZ2UlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKS50byhkZXZpY2UpJTBBcGl4ZWxfdmFsdWVzJTIwJTNEJTIwaW5wdXRzLnBpeGVsX3ZhbHVlcw==",highlighted:`device = <span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>

inputs = processor(images=image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).to(device)
pixel_values = inputs.pixel_values`,wrap:!1}}),ue=new f({props:{code:"Z2VuZXJhdGVkX2lkcyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKHBpeGVsX3ZhbHVlcyUzRHBpeGVsX3ZhbHVlcyUyQyUyMG1heF9sZW5ndGglM0Q1MCklMEFnZW5lcmF0ZWRfY2FwdGlvbiUyMCUzRCUyMHByb2Nlc3Nvci5iYXRjaF9kZWNvZGUoZ2VuZXJhdGVkX2lkcyUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSU1QjAlNUQlMEFwcmludChnZW5lcmF0ZWRfY2FwdGlvbik=",highlighted:`generated_ids = model.generate(pixel_values=pixel_values, max_length=<span class="hljs-number">50</span>)
generated_caption = processor.batch_decode(generated_ids, skip_special_tokens=<span class="hljs-literal">True</span>)[<span class="hljs-number">0</span>]
<span class="hljs-built_in">print</span>(generated_caption)`,wrap:!1}}),be=new f({props:{code:"YSUyMGRyYXdpbmclMjBvZiUyMGElMjBwaW5rJTIwYW5kJTIwYmx1ZSUyMHBva2Vtb24=",highlighted:"a drawing of a pink and blue pokemon",wrap:!1}}),{c(){w=p("meta"),h=a(),J=p("p"),Ue=a(),M(U.$$.fragment),$e=a(),M(j.$$.fragment),Ce=a(),g=p("p"),g.textContent=Bt,_e=a(),$=p("p"),$.textContent=Wt,ke=a(),C=p("ul"),C.innerHTML=It,Be=a(),_=p("p"),_.textContent=vt,We=a(),M(k.$$.fragment),Ie=a(),B=p("p"),B.textContent=Zt,ve=a(),M(W.$$.fragment),Ze=a(),M(I.$$.fragment),Ge=a(),v=p("p"),v.innerHTML=Gt,xe=a(),M(Z.$$.fragment),Re=a(),M(G.$$.fragment),Xe=a(),x=p("p"),x.innerHTML=xt,He=a(),M(u.$$.fragment),Ve=a(),R=p("p"),R.innerHTML=Rt,Ye=a(),M(X.$$.fragment),Ee=a(),H=p("p"),H.textContent=Xt,Qe=a(),M(V.$$.fragment),Ne=a(),b=p("div"),b.innerHTML=Ht,ze=a(),M(Y.$$.fragment),Fe=a(),E=p("p"),E.textContent=Vt,Ae=a(),Q=p("p"),Q.textContent=Yt,Se=a(),M(N.$$.fragment),qe=a(),z=p("p"),z.textContent=Et,Le=a(),M(F.$$.fragment),Pe=a(),A=p("p"),A.textContent=Qt,Ke=a(),M(S.$$.fragment),De=a(),q=p("p"),q.innerHTML=Nt,Oe=a(),M(L.$$.fragment),et=a(),M(P.$$.fragment),tt=a(),M(K.$$.fragment),lt=a(),D=p("p"),D.innerHTML=zt,st=a(),O=p("p"),O.innerHTML=Ft,at=a(),M(ee.$$.fragment),nt=a(),M(te.$$.fragment),pt=a(),le=p("p"),le.innerHTML=At,it=a(),se=p("p"),se.innerHTML=St,rt=a(),M(ae.$$.fragment),Mt=a(),ne=p("p"),ne.textContent=qt,mt=a(),M(pe.$$.fragment),ot=a(),ie=p("p"),ie.innerHTML=Lt,ct=a(),M(re.$$.fragment),yt=a(),Me=p("p"),Me.textContent=Pt,dt=a(),me=p("p"),me.innerHTML=Kt,ft=a(),M(oe.$$.fragment),wt=a(),M(ce.$$.fragment),Jt=a(),ye=p("p"),ye.innerHTML=Dt,ut=a(),M(de.$$.fragment),bt=a(),T=p("div"),T.innerHTML=Ot,Tt=a(),fe=p("p"),fe.textContent=el,ht=a(),M(we.$$.fragment),Ut=a(),Je=p("p"),Je.innerHTML=tl,jt=a(),M(ue.$$.fragment),gt=a(),M(be.$$.fragment),$t=a(),Te=p("p"),Te.textContent=ll,Ct=a(),je=p("p"),this.h()},l(e){const t=ml("svelte-u9bgzb",document.head);w=i(t,"META",{name:!0,content:!0}),t.forEach(l),h=n(e),J=i(e,"P",{}),al(J).forEach(l),Ue=n(e),m(U.$$.fragment,e),$e=n(e),m(j.$$.fragment,e),Ce=n(e),g=i(e,"P",{"data-svelte-h":!0}),r(g)!=="svelte-1p0rp9p"&&(g.textContent=Bt),_e=n(e),$=i(e,"P",{"data-svelte-h":!0}),r($)!=="svelte-w5jzhi"&&($.textContent=Wt),ke=n(e),C=i(e,"UL",{"data-svelte-h":!0}),r(C)!=="svelte-9iba6s"&&(C.innerHTML=It),Be=n(e),_=i(e,"P",{"data-svelte-h":!0}),r(_)!=="svelte-1lya3k8"&&(_.textContent=vt),We=n(e),m(k.$$.fragment,e),Ie=n(e),B=i(e,"P",{"data-svelte-h":!0}),r(B)!=="svelte-193zy02"&&(B.textContent=Zt),ve=n(e),m(W.$$.fragment,e),Ze=n(e),m(I.$$.fragment,e),Ge=n(e),v=i(e,"P",{"data-svelte-h":!0}),r(v)!=="svelte-qgn9jw"&&(v.innerHTML=Gt),xe=n(e),m(Z.$$.fragment,e),Re=n(e),m(G.$$.fragment,e),Xe=n(e),x=i(e,"P",{"data-svelte-h":!0}),r(x)!=="svelte-yyzvcj"&&(x.innerHTML=xt),He=n(e),m(u.$$.fragment,e),Ve=n(e),R=i(e,"P",{"data-svelte-h":!0}),r(R)!=="svelte-jq14pt"&&(R.innerHTML=Rt),Ye=n(e),m(X.$$.fragment,e),Ee=n(e),H=i(e,"P",{"data-svelte-h":!0}),r(H)!=="svelte-80oyiw"&&(H.textContent=Xt),Qe=n(e),m(V.$$.fragment,e),Ne=n(e),b=i(e,"DIV",{class:!0,"data-svelte-h":!0}),r(b)!=="svelte-1qemygy"&&(b.innerHTML=Ht),ze=n(e),m(Y.$$.fragment,e),Fe=n(e),E=i(e,"P",{"data-svelte-h":!0}),r(E)!=="svelte-xo16vn"&&(E.textContent=Vt),Ae=n(e),Q=i(e,"P",{"data-svelte-h":!0}),r(Q)!=="svelte-sn04hr"&&(Q.textContent=Yt),Se=n(e),m(N.$$.fragment,e),qe=n(e),z=i(e,"P",{"data-svelte-h":!0}),r(z)!=="svelte-d4wa2b"&&(z.textContent=Et),Le=n(e),m(F.$$.fragment,e),Pe=n(e),A=i(e,"P",{"data-svelte-h":!0}),r(A)!=="svelte-13xhvmf"&&(A.textContent=Qt),Ke=n(e),m(S.$$.fragment,e),De=n(e),q=i(e,"P",{"data-svelte-h":!0}),r(q)!=="svelte-10063ke"&&(q.innerHTML=Nt),Oe=n(e),m(L.$$.fragment,e),et=n(e),m(P.$$.fragment,e),tt=n(e),m(K.$$.fragment,e),lt=n(e),D=i(e,"P",{"data-svelte-h":!0}),r(D)!=="svelte-sq2btk"&&(D.innerHTML=zt),st=n(e),O=i(e,"P",{"data-svelte-h":!0}),r(O)!=="svelte-a0z1wk"&&(O.innerHTML=Ft),at=n(e),m(ee.$$.fragment,e),nt=n(e),m(te.$$.fragment,e),pt=n(e),le=i(e,"P",{"data-svelte-h":!0}),r(le)!=="svelte-15ghqik"&&(le.innerHTML=At),it=n(e),se=i(e,"P",{"data-svelte-h":!0}),r(se)!=="svelte-1vmyz81"&&(se.innerHTML=St),rt=n(e),m(ae.$$.fragment,e),Mt=n(e),ne=i(e,"P",{"data-svelte-h":!0}),r(ne)!=="svelte-1ed0ahl"&&(ne.textContent=qt),mt=n(e),m(pe.$$.fragment,e),ot=n(e),ie=i(e,"P",{"data-svelte-h":!0}),r(ie)!=="svelte-1rub8x2"&&(ie.innerHTML=Lt),ct=n(e),m(re.$$.fragment,e),yt=n(e),Me=i(e,"P",{"data-svelte-h":!0}),r(Me)!=="svelte-1dxqkna"&&(Me.textContent=Pt),dt=n(e),me=i(e,"P",{"data-svelte-h":!0}),r(me)!=="svelte-ngexm3"&&(me.innerHTML=Kt),ft=n(e),m(oe.$$.fragment,e),wt=n(e),m(ce.$$.fragment,e),Jt=n(e),ye=i(e,"P",{"data-svelte-h":!0}),r(ye)!=="svelte-ddk3b2"&&(ye.innerHTML=Dt),ut=n(e),m(de.$$.fragment,e),bt=n(e),T=i(e,"DIV",{class:!0,"data-svelte-h":!0}),r(T)!=="svelte-16i041b"&&(T.innerHTML=Ot),Tt=n(e),fe=i(e,"P",{"data-svelte-h":!0}),r(fe)!=="svelte-1ir3qqf"&&(fe.textContent=el),ht=n(e),m(we.$$.fragment,e),Ut=n(e),Je=i(e,"P",{"data-svelte-h":!0}),r(Je)!=="svelte-1r7c47b"&&(Je.innerHTML=tl),jt=n(e),m(ue.$$.fragment,e),gt=n(e),m(be.$$.fragment,e),$t=n(e),Te=i(e,"P",{"data-svelte-h":!0}),r(Te)!=="svelte-1xn05po"&&(Te.textContent=ll),Ct=n(e),je=i(e,"P",{}),al(je).forEach(l),this.h()},h(){kt(w,"name","hf:doc:metadata"),kt(w,"content",wl),kt(b,"class","flex justify-center"),kt(T,"class","flex justify-center")},m(e,t){ol(document.head,w),s(e,h,t),s(e,J,t),s(e,Ue,t),o(U,e,t),s(e,$e,t),o(j,e,t),s(e,Ce,t),s(e,g,t),s(e,_e,t),s(e,$,t),s(e,ke,t),s(e,C,t),s(e,Be,t),s(e,_,t),s(e,We,t),o(k,e,t),s(e,Ie,t),s(e,B,t),s(e,ve,t),o(W,e,t),s(e,Ze,t),o(I,e,t),s(e,Ge,t),s(e,v,t),s(e,xe,t),o(Z,e,t),s(e,Re,t),o(G,e,t),s(e,Xe,t),s(e,x,t),s(e,He,t),o(u,e,t),s(e,Ve,t),s(e,R,t),s(e,Ye,t),o(X,e,t),s(e,Ee,t),s(e,H,t),s(e,Qe,t),o(V,e,t),s(e,Ne,t),s(e,b,t),s(e,ze,t),o(Y,e,t),s(e,Fe,t),s(e,E,t),s(e,Ae,t),s(e,Q,t),s(e,Se,t),o(N,e,t),s(e,qe,t),s(e,z,t),s(e,Le,t),o(F,e,t),s(e,Pe,t),s(e,A,t),s(e,Ke,t),o(S,e,t),s(e,De,t),s(e,q,t),s(e,Oe,t),o(L,e,t),s(e,et,t),o(P,e,t),s(e,tt,t),o(K,e,t),s(e,lt,t),s(e,D,t),s(e,st,t),s(e,O,t),s(e,at,t),o(ee,e,t),s(e,nt,t),o(te,e,t),s(e,pt,t),s(e,le,t),s(e,it,t),s(e,se,t),s(e,rt,t),o(ae,e,t),s(e,Mt,t),s(e,ne,t),s(e,mt,t),o(pe,e,t),s(e,ot,t),s(e,ie,t),s(e,ct,t),o(re,e,t),s(e,yt,t),s(e,Me,t),s(e,dt,t),s(e,me,t),s(e,ft,t),o(oe,e,t),s(e,wt,t),o(ce,e,t),s(e,Jt,t),s(e,ye,t),s(e,ut,t),o(de,e,t),s(e,bt,t),s(e,T,t),s(e,Tt,t),s(e,fe,t),s(e,ht,t),o(we,e,t),s(e,Ut,t),s(e,Je,t),s(e,jt,t),o(ue,e,t),s(e,gt,t),o(be,e,t),s(e,$t,t),s(e,Te,t),s(e,Ct,t),s(e,je,t),_t=!0},p(e,[t]){const sl={};t&2&&(sl.$$scope={dirty:t,ctx:e}),u.$set(sl)},i(e){_t||(c(U.$$.fragment,e),c(j.$$.fragment,e),c(k.$$.fragment,e),c(W.$$.fragment,e),c(I.$$.fragment,e),c(Z.$$.fragment,e),c(G.$$.fragment,e),c(u.$$.fragment,e),c(X.$$.fragment,e),c(V.$$.fragment,e),c(Y.$$.fragment,e),c(N.$$.fragment,e),c(F.$$.fragment,e),c(S.$$.fragment,e),c(L.$$.fragment,e),c(P.$$.fragment,e),c(K.$$.fragment,e),c(ee.$$.fragment,e),c(te.$$.fragment,e),c(ae.$$.fragment,e),c(pe.$$.fragment,e),c(re.$$.fragment,e),c(oe.$$.fragment,e),c(ce.$$.fragment,e),c(de.$$.fragment,e),c(we.$$.fragment,e),c(ue.$$.fragment,e),c(be.$$.fragment,e),_t=!0)},o(e){y(U.$$.fragment,e),y(j.$$.fragment,e),y(k.$$.fragment,e),y(W.$$.fragment,e),y(I.$$.fragment,e),y(Z.$$.fragment,e),y(G.$$.fragment,e),y(u.$$.fragment,e),y(X.$$.fragment,e),y(V.$$.fragment,e),y(Y.$$.fragment,e),y(N.$$.fragment,e),y(F.$$.fragment,e),y(S.$$.fragment,e),y(L.$$.fragment,e),y(P.$$.fragment,e),y(K.$$.fragment,e),y(ee.$$.fragment,e),y(te.$$.fragment,e),y(ae.$$.fragment,e),y(pe.$$.fragment,e),y(re.$$.fragment,e),y(oe.$$.fragment,e),y(ce.$$.fragment,e),y(de.$$.fragment,e),y(we.$$.fragment,e),y(ue.$$.fragment,e),y(be.$$.fragment,e),_t=!1},d(e){e&&(l(h),l(J),l(Ue),l($e),l(Ce),l(g),l(_e),l($),l(ke),l(C),l(Be),l(_),l(We),l(Ie),l(B),l(ve),l(Ze),l(Ge),l(v),l(xe),l(Re),l(Xe),l(x),l(He),l(Ve),l(R),l(Ye),l(Ee),l(H),l(Qe),l(Ne),l(b),l(ze),l(Fe),l(E),l(Ae),l(Q),l(Se),l(qe),l(z),l(Le),l(Pe),l(A),l(Ke),l(De),l(q),l(Oe),l(et),l(tt),l(lt),l(D),l(st),l(O),l(at),l(nt),l(pt),l(le),l(it),l(se),l(rt),l(Mt),l(ne),l(mt),l(ot),l(ie),l(ct),l(yt),l(Me),l(dt),l(me),l(ft),l(wt),l(Jt),l(ye),l(ut),l(bt),l(T),l(Tt),l(fe),l(ht),l(Ut),l(Je),l(jt),l(gt),l($t),l(Te),l(Ct),l(je)),l(w),d(U,e),d(j,e),d(k,e),d(W,e),d(I,e),d(Z,e),d(G,e),d(u,e),d(X,e),d(V,e),d(Y,e),d(N,e),d(F,e),d(S,e),d(L,e),d(P,e),d(K,e),d(ee,e),d(te,e),d(ae,e),d(pe,e),d(re,e),d(oe,e),d(ce,e),d(de,e),d(we,e),d(ue,e),d(be,e)}}}const wl='{"title":"Image captioning","local":"image-captioning","sections":[{"title":"Load the Pokémon BLIP captions dataset","local":"load-the-pokémon-blip-captions-dataset","sections":[],"depth":2},{"title":"Preprocess the dataset","local":"preprocess-the-dataset","sections":[],"depth":2},{"title":"Load a base model","local":"load-a-base-model","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Train!","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function Jl(ge){return pl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class gl extends rl{constructor(w){super(),Ml(this,w,Jl,fl,nl,{})}}export{gl as component};
