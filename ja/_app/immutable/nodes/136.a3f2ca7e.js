import{s as gt,o as Jt,n as Hs}from"../chunks/scheduler.9bc65507.js";import{S as bt,i as wt,g as m,s as n,r as M,A as Ut,h as o,f as t,c as p,j as jt,u as d,x as J,k as yt,y as Tt,a as l,v as h,d as j,t as y,w as u,m as $t,n as _t}from"../chunks/index.707bf1b6.js";import{T as Ha}from"../chunks/Tip.c2ecdbf4.js";import{Y as Ct}from"../chunks/Youtube.e1129c6f.js";import{C as U}from"../chunks/CodeBlock.54a9f38d.js";import{D as It}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as ut,M as ft}from"../chunks/Markdown.8ab98a13.js";import{H as Bs}from"../chunks/Heading.342b1fa6.js";function vt(I){let e,f,r='<a href="../model_doc/data2vec-audio">Data2VecAudio</a>, <a href="../model_doc/hubert">Hubert</a>, <a href="../model_doc/mctct">M-CTC-T</a>, <a href="../model_doc/sew">SEW</a>, <a href="../model_doc/sew-d">SEW-D</a>, <a href="../model_doc/unispeech">UniSpeech</a>, <a href="../model_doc/unispeech-sat">UniSpeechSat</a>, <a href="../model_doc/wav2vec2">Wav2Vec2</a>, <a href="../model_doc/wav2vec2-conformer">Wav2Vec2-Conformer</a>, <a href="../model_doc/wavlm">WavLM</a>';return{c(){e=$t(`このチュートリアルで説明するタスクは、次のモデル アーキテクチャでサポートされています。

`),f=m("p"),f.innerHTML=r},l(g){e=_t(g,`このチュートリアルで説明するタスクは、次のモデル アーキテクチャでサポートされています。

`),f=o(g,"P",{"data-svelte-h":!0}),J(f)!=="svelte-1xfq5e"&&(f.innerHTML=r)},m(g,b){l(g,e,b),l(g,f,b)},p:Hs,d(g){g&&(t(e),t(f))}}}function Rt(I){let e,f='<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> を使用したモデルの微調整に慣れていない場合は、<a href="../training#train-with-pytorch-trainer">ここ</a> の基本的なチュートリアルをご覧ください。';return{c(){e=m("p"),e.innerHTML=f},l(r){e=o(r,"P",{"data-svelte-h":!0}),J(e)!=="svelte-1ubngji"&&(e.innerHTML=f)},m(r,g){l(r,e,g)},p:Hs,d(r){r&&t(e)}}}function Zt(I){let e,f,r,g='これでモデルのトレーニングを開始する準備が整いました。 <a href="/docs/transformers/main/ja/model_doc/auto#transformers.AutoModelForCTC">AutoModelForCTC</a> で Wav2Vec2 をロードします。 <code>ctc_loss_reduction</code> パラメータで適用する削減を指定します。多くの場合、デフォルトの合計ではなく平均を使用する方が適切です。',b,C,Z,R,v="この時点で残っている手順は次の 3 つだけです。",k,T,X='<li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> でトレーニング ハイパーパラメータを定義します。唯一の必須パラメータは、モデルの保存場所を指定する <code>output_dir</code> です。 <code>push_to_hub=True</code>を設定して、このモデルをハブにプッシュします (モデルをアップロードするには、Hugging Face にサインインする必要があります)。各エポックの終了時に、<code>トレーナー</code> は WER を評価し、トレーニング チェックポイントを保存します。</li> <li>トレーニング引数を、モデル、データセット、トークナイザー、データ照合器、および <code>compute_metrics</code> 関数とともに <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> に渡します。</li> <li><a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.train">train()</a> を呼び出してモデルを微調整します。</li>',W,$,G,i,_='トレーニングが完了したら、 <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> メソッドを使用してモデルをハブに共有し、誰もがモデルを使用できるようにします。',Q,B,x;return e=new Ha({props:{$$slots:{default:[Rt]},$$scope:{ctx:I}}}),C=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNUQyUyQyUyMFRyYWluaW5nQXJndW1lbnRzJTJDJTIwVHJhaW5lciUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQ1RDLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjAlMjJmYWNlYm9vayUyRndhdjJ2ZWMyLWJhc2UlMjIlMkMlMEElMjAlMjAlMjAlMjBjdGNfbG9zc19yZWR1Y3Rpb24lM0QlMjJtZWFuJTIyJTJDJTBBJTIwJTIwJTIwJTIwcGFkX3Rva2VuX2lkJTNEcHJvY2Vzc29yLnRva2VuaXplci5wYWRfdG9rZW5faWQlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCTC, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>,
<span class="hljs-meta">... </span>    ctc_loss_reduction=<span class="hljs-string">&quot;mean&quot;</span>,
<span class="hljs-meta">... </span>    pad_token_id=processor.tokenizer.pad_token_id,
<span class="hljs-meta">... </span>)`,wrap:!1}}),$=new U({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX2Fzcl9taW5kX21vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNEOCUyQyUwQSUyMCUyMCUyMCUyMGdyYWRpZW50X2FjY3VtdWxhdGlvbl9zdGVwcyUzRDIlMkMlMEElMjAlMjAlMjAlMjBsZWFybmluZ19yYXRlJTNEMWUtNSUyQyUwQSUyMCUyMCUyMCUyMHdhcm11cF9zdGVwcyUzRDUwMCUyQyUwQSUyMCUyMCUyMCUyMG1heF9zdGVwcyUzRDIwMDAlMkMlMEElMjAlMjAlMjAlMjBncmFkaWVudF9jaGVja3BvaW50aW5nJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMGZwMTYlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwZ3JvdXBfYnlfbGVuZ3RoJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMGV2YWx1YXRpb25fc3RyYXRlZ3klM0QlMjJzdGVwcyUyMiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEOCUyQyUwQSUyMCUyMCUyMCUyMHNhdmVfc3RlcHMlM0QxMDAwJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9zdGVwcyUzRDEwMDAlMkMlMEElMjAlMjAlMjAlMjBsb2dnaW5nX3N0ZXBzJTNEMjUlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMG1ldHJpY19mb3JfYmVzdF9tb2RlbCUzRCUyMndlciUyMiUyQyUwQSUyMCUyMCUyMCUyMGdyZWF0ZXJfaXNfYmV0dGVyJTNERmFsc2UlMkMlMEElMjAlMjAlMjAlMjBwdXNoX3RvX2h1YiUzRFRydWUlMkMlMEEpJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRGVuY29kZWRfbWluZHMlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfZGF0YXNldCUzRGVuY29kZWRfbWluZHMlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwdG9rZW5pemVyJTNEcHJvY2Vzc29yJTJDJTBBJTIwJTIwJTIwJTIwZGF0YV9jb2xsYXRvciUzRGRhdGFfY29sbGF0b3IlMkMlMEElMjAlMjAlMjAlMjBjb21wdXRlX21ldHJpY3MlM0Rjb21wdXRlX21ldHJpY3MlMkMlMEEpJTBBJTBBdHJhaW5lci50cmFpbigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_asr_mind_model&quot;</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    gradient_accumulation_steps=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">1e-5</span>,
<span class="hljs-meta">... </span>    warmup_steps=<span class="hljs-number">500</span>,
<span class="hljs-meta">... </span>    max_steps=<span class="hljs-number">2000</span>,
<span class="hljs-meta">... </span>    gradient_checkpointing=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    fp16=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    group_by_length=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    save_steps=<span class="hljs-number">1000</span>,
<span class="hljs-meta">... </span>    eval_steps=<span class="hljs-number">1000</span>,
<span class="hljs-meta">... </span>    logging_steps=<span class="hljs-number">25</span>,
<span class="hljs-meta">... </span>    load_best_model_at_end=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    metric_for_best_model=<span class="hljs-string">&quot;wer&quot;</span>,
<span class="hljs-meta">... </span>    greater_is_better=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=encoded_minds[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=encoded_minds[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=processor,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),B=new U({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){M(e.$$.fragment),f=n(),r=m("p"),r.innerHTML=g,b=n(),M(C.$$.fragment),Z=n(),R=m("p"),R.textContent=v,k=n(),T=m("ol"),T.innerHTML=X,W=n(),M($.$$.fragment),G=n(),i=m("p"),i.innerHTML=_,Q=n(),M(B.$$.fragment)},l(c){d(e.$$.fragment,c),f=p(c),r=o(c,"P",{"data-svelte-h":!0}),J(r)!=="svelte-10i0n1c"&&(r.innerHTML=g),b=p(c),d(C.$$.fragment,c),Z=p(c),R=o(c,"P",{"data-svelte-h":!0}),J(R)!=="svelte-1j8bgyv"&&(R.textContent=v),k=p(c),T=o(c,"OL",{"data-svelte-h":!0}),J(T)!=="svelte-ue36a7"&&(T.innerHTML=X),W=p(c),d($.$$.fragment,c),G=p(c),i=o(c,"P",{"data-svelte-h":!0}),J(i)!=="svelte-ngexm3"&&(i.innerHTML=_),Q=p(c),d(B.$$.fragment,c)},m(c,w){h(e,c,w),l(c,f,w),l(c,r,w),l(c,b,w),h(C,c,w),l(c,Z,w),l(c,R,w),l(c,k,w),l(c,T,w),l(c,W,w),h($,c,w),l(c,G,w),l(c,i,w),l(c,Q,w),h(B,c,w),x=!0},p(c,w){const Xs={};w&2&&(Xs.$$scope={dirty:w,ctx:c}),e.$set(Xs)},i(c){x||(j(e.$$.fragment,c),j(C.$$.fragment,c),j($.$$.fragment,c),j(B.$$.fragment,c),x=!0)},o(c){y(e.$$.fragment,c),y(C.$$.fragment,c),y($.$$.fragment,c),y(B.$$.fragment,c),x=!1},d(c){c&&(t(f),t(r),t(b),t(Z),t(R),t(k),t(T),t(W),t(G),t(i),t(Q)),u(e,c),u(C,c),u($,c),u(B,c)}}}function kt(I){let e,f;return e=new ft({props:{$$slots:{default:[Zt]},$$scope:{ctx:I}}}),{c(){M(e.$$.fragment)},l(r){d(e.$$.fragment,r)},m(r,g){h(e,r,g),f=!0},p(r,g){const b={};g&2&&(b.$$scope={dirty:g,ctx:r}),e.$set(b)},i(r){f||(j(e.$$.fragment,r),f=!0)},o(r){y(e.$$.fragment,r),f=!1},d(r){u(e,r)}}}function Wt(I){let e,f='自動音声認識用にモデルを微調整する方法のより詳細な例については、英語 ASR および英語のこのブログ <a href="https://huggingface.co/blog/fine-tune-wav2vec2-english" rel="nofollow">投稿</a> を参照してください。多言語 ASR については、この <a href="https://huggingface.co/blog/fine-tune-xlsr-wav2vec2" rel="nofollow">投稿</a> を参照してください。';return{c(){e=m("p"),e.innerHTML=f},l(r){e=o(r,"P",{"data-svelte-h":!0}),J(e)!=="svelte-1luj7ds"&&(e.innerHTML=f)},m(r,g){l(r,e,g)},p:Hs,d(r){r&&t(e)}}}function xt(I){let e,f="転写はまあまあですが、もっと良くなる可能性があります。さらに良い結果を得るには、より多くの例でモデルを微調整してみてください。";return{c(){e=m("p"),e.textContent=f},l(r){e=o(r,"P",{"data-svelte-h":!0}),J(e)!=="svelte-1v18xvo"&&(e.textContent=f)},m(r,g){l(r,e,g)},p:Hs,d(r){r&&t(e)}}}function Gt(I){let e,f="プロセッサをロードしてオーディオ ファイルと文字起こしを前処理し、<code>input</code>を PyTorch テンソルとして返します。",r,g,b,C,Z="Pass your inputs to the model and return the logits:",R,v,k,T,X="最も高い確率で予測された <code>input_ids</code> を取得し、プロセッサを使用して予測された <code>input_ids</code> をデコードしてテキストに戻します。",W,$,G;return g=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfYXNyX21pbmRfbW9kZWwlMjIpJTBBaW5wdXRzJTIwJTNEJTIwcHJvY2Vzc29yKGRhdGFzZXQlNUIwJTVEJTVCJTIyYXVkaW8lMjIlNUQlNUIlMjJhcnJheSUyMiU1RCUyQyUyMHNhbXBsaW5nX3JhdGUlM0RzYW1wbGluZ19yYXRlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_asr_mind_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = processor(dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>], sampling_rate=sampling_rate, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),v=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNUQyUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQ1RDLmZyb21fcHJldHJhaW5lZCglMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfYXNyX21pbmRfbW9kZWwlMjIpJTBBd2l0aCUyMHRvcmNoLm5vX2dyYWQoKSUzQSUwQSUyMCUyMCUyMCUyMGxvZ2l0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKS5sb2dpdHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCTC

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCTC.from_pretrained(<span class="hljs-string">&quot;stevhliu/my_awesome_asr_mind_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits`,wrap:!1}}),$=new U({props:{code:"aW1wb3J0JTIwdG9yY2glMEElMEFwcmVkaWN0ZWRfaWRzJTIwJTNEJTIwdG9yY2guYXJnbWF4KGxvZ2l0cyUyQyUyMGRpbSUzRC0xKSUwQXRyYW5zY3JpcHRpb24lMjAlM0QlMjBwcm9jZXNzb3IuYmF0Y2hfZGVjb2RlKHByZWRpY3RlZF9pZHMpJTBBdHJhbnNjcmlwdGlvbg==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_ids = torch.argmax(logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>transcription = processor.batch_decode(predicted_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span>transcription
[<span class="hljs-string">&#x27;I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER&#x27;</span>]`,wrap:!1}}),{c(){e=m("p"),e.innerHTML=f,r=n(),M(g.$$.fragment),b=n(),C=m("p"),C.textContent=Z,R=n(),M(v.$$.fragment),k=n(),T=m("p"),T.innerHTML=X,W=n(),M($.$$.fragment)},l(i){e=o(i,"P",{"data-svelte-h":!0}),J(e)!=="svelte-1baxoat"&&(e.innerHTML=f),r=p(i),d(g.$$.fragment,i),b=p(i),C=o(i,"P",{"data-svelte-h":!0}),J(C)!=="svelte-1at92g"&&(C.textContent=Z),R=p(i),d(v.$$.fragment,i),k=p(i),T=o(i,"P",{"data-svelte-h":!0}),J(T)!=="svelte-n29toq"&&(T.innerHTML=X),W=p(i),d($.$$.fragment,i)},m(i,_){l(i,e,_),l(i,r,_),h(g,i,_),l(i,b,_),l(i,C,_),l(i,R,_),h(v,i,_),l(i,k,_),l(i,T,_),l(i,W,_),h($,i,_),G=!0},p:Hs,i(i){G||(j(g.$$.fragment,i),j(v.$$.fragment,i),j($.$$.fragment,i),G=!0)},o(i){y(g.$$.fragment,i),y(v.$$.fragment,i),y($.$$.fragment,i),G=!1},d(i){i&&(t(e),t(r),t(b),t(C),t(R),t(k),t(T),t(W)),u(g,i),u(v,i),u($,i)}}}function Bt(I){let e,f;return e=new ft({props:{$$slots:{default:[Gt]},$$scope:{ctx:I}}}),{c(){M(e.$$.fragment)},l(r){d(e.$$.fragment,r)},m(r,g){h(e,r,g),f=!0},p(r,g){const b={};g&2&&(b.$$scope={dirty:g,ctx:r}),e.$set(b)},i(r){f||(j(e.$$.fragment,r),f=!0)},o(r){y(e.$$.fragment,r),f=!1},d(r){u(e,r)}}}function Xt(I){let e,f,r,g,b,C,Z,R,v,k,T,X="自動音声認識 (ASR) は音声信号をテキストに変換し、一連の音声入力をテキスト出力にマッピングします。 Siri や Alexa などの仮想アシスタントは ASR モデルを使用してユーザーを日常的に支援しており、ライブキャプションや会議中のメモ取りなど、他にも便利なユーザー向けアプリケーションが数多くあります。",W,$,G="このガイドでは、次の方法を説明します。",i,_,Q='<li><a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> データセットの <a href="https://huggingface.co/facebook/wav2vec2-base" rel="nofollow">Wav2Vec2</a> を微調整して、音声をテキストに書き起こします。</li> <li>微調整したモデルを推論に使用します。</li>',B,x,c,w,Xs="始める前に、必要なライブラリがすべてインストールされていることを確認してください。",Ys,E,Ns,z,Ya="モデルをアップロードしてコミュニティと共有できるように、Hugging Face アカウントにログインすることをお勧めします。プロンプトが表示されたら、トークンを入力してログインします。",Qs,A,Es,F,zs,q,Na='まず、🤗 データセット ライブラリから <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> データセットの小さいサブセットをロードします。これにより、完全なデータセットのトレーニングにさらに時間を費やす前に、実験してすべてが機能することを確認する機会が得られます。',As,S,Fs,L,Qa="<code>~Dataset.train_test_split</code> メソッドを使用して、データセットの <code>train</code> 分割をトレイン セットとテスト セットに分割します。",qs,P,Ss,D,Ea="次に、データセットを見てみましょう。",Ls,K,Ps,O,za="データセットには<code>lang_id</code>や<code>english_transcription</code>などの多くの有用な情報が含まれていますが、このガイドでは「<code>audio</code>」と「<code>transciption</code>」に焦点を当てます。 <code>remove_columns</code> メソッドを使用して他の列を削除します。",Ds,ss,Ks,as,Aa="もう一度例を見てみましょう。",Os,ts,sa,ls,Fa="次の 2 つのフィールドがあります。",aa,es,qa="<li><code>audio</code>: 音声ファイルをロードしてリサンプリングするために呼び出す必要がある音声信号の 1 次元の <code>array</code>。</li> <li><code>transcription</code>: ターゲットテキスト。</li>",ta,ns,la,ps,Sa="次のステップでは、Wav2Vec2 プロセッサをロードしてオーディオ信号を処理します。",ea,rs,na,cs,La='MInDS-14 データセットのサンプリング レートは 8000kHz です (この情報は <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">データセット カード</a> で確認できます)。つまり、データセットを再サンプリングする必要があります。事前トレーニングされた Wav2Vec2 モデルを使用するには、16000kHz に設定します。',pa,is,ra,ms,Pa="上の <code>transcription</code> でわかるように、テキストには大文字と小文字が混在しています。 Wav2Vec2 トークナイザーは大文字のみでトレーニングされるため、テキストがトークナイザーの語彙と一致することを確認する必要があります。",ca,os,ia,Ms,Da="次に、次の前処理関数を作成します。",ma,ds,Ka="<li><code>audio</code>列を呼び出して、オーディオ ファイルをロードしてリサンプリングします。</li> <li>オーディオ ファイルから <code>input_values</code> を抽出し、プロセッサを使用して <code>transcription</code> 列をトークン化します。</li>",oa,hs,Ma,js,Oa="データセット全体に前処理関数を適用するには、🤗 Datasets <code>map</code> 関数を使用します。 <code>num_proc</code> パラメータを使用してプロセスの数を増やすことで、<code>map</code> を高速化できます。 <code>remove_columns</code> メソッドを使用して、不要な列を削除します。",da,ys,ha,us,st="🤗 Transformers には ASR 用のデータ照合器がないため、<code>DataCollat​​orWithPadding</code> を調整してサンプルのバッチを作成する必要があります。また、テキストとラベルが (データセット全体ではなく) バッチ内の最も長い要素の長さに合わせて動的に埋め込まれ、均一な長さになります。 <code>padding=True</code> を設定すると、<code>tokenizer</code> 関数でテキストを埋め込むことができますが、動的な埋め込みの方が効率的です。",ja,fs,at="他のデータ照合器とは異なり、この特定のデータ照合器は、<code>input_values</code>と <code>labels</code>」に異なるパディング方法を適用する必要があります。",ya,gs,ua,Js,tt="次に、<code>DataCollat​​orForCTCWithPadding</code> をインスタンス化します。",fa,bs,ga,ws,Ja,Us,lt='トレーニング中にメトリクスを含めると、多くの場合、モデルのパフォーマンスを評価するのに役立ちます。 🤗 <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> ライブラリを使用して、評価メソッドをすばやくロードできます。このタスクでは、<a href="https://huggingface.co/spaces/evaluate-metric/wer" rel="nofollow">単語エラー率</a> (WER) メトリクスを読み込みます (🤗 Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">クイック ツアー</a> を参照して、メトリクスをロードして計算する方法の詳細を確認してください)。',ba,Ts,wa,$s,et="次に、予測とラベルを <code>compute</code> に渡して WER を計算する関数を作成します。",Ua,_s,Ta,Cs,nt="これで<code>compute_metrics</code>関数の準備が整いました。トレーニングをセットアップするときにこの関数に戻ります。",$a,Is,_a,V,Ca,H,Ia,vs,va,Rs,pt="モデルを微調整したので、それを推論に使用できるようになりました。",Ra,Zs,rt="推論を実行したい音声ファイルをロードします。必要に応じて、オーディオ ファイルのサンプリング レートをモデルのサンプリング レートと一致するようにリサンプリングすることを忘れないでください。",Za,ks,ka,Ws,ct='推論用に微調整されたモデルを試す最も簡単な方法は、それを <a href="/docs/transformers/main/ja/main_classes/pipelines#transformers.pipeline">pipeline()</a> で使用することです。モデルを使用して自動音声認識用の<code>pipeline</code>をインスタンス化し、オーディオ ファイルをそれに渡します。',Wa,xs,xa,Y,Ga,Gs,it="必要に応じて、「パイプライン」の結果を手動で複製することもできます。",Ba,N,Xa,Vs,Va;return b=new Bs({props:{title:"Automatic speech recognition",local:"automatic-speech-recognition",headingTag:"h1"}}),Z=new It({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/asr.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/asr.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/asr.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/asr.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/pytorch/asr.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ja/tensorflow/asr.ipynb"}]}}),v=new Ct({props:{id:"TksaY_FDgnk"}}),x=new Ha({props:{$$slots:{default:[vt]},$$scope:{ctx:I}}}),E=new U({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGUlMjBqaXdlcg==",highlighted:"pip install transformers datasets evaluate jiwer",wrap:!1}}),A=new U({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),F=new Bs({props:{title:"Load MInDS-14 dataset",local:"load-minds-14-dataset",headingTag:"h2"}}),S=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFtaW5kcyUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJQb2x5QUklMkZtaW5kczE0JTIyJTJDJTIwbmFtZSUzRCUyMmVuLVVTJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiU1QiUzQTEwMCU1RCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>minds = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>)`,wrap:!1}}),P=new U({props:{code:"bWluZHMlMjAlM0QlMjBtaW5kcy50cmFpbl90ZXN0X3NwbGl0KHRlc3Rfc2l6ZSUzRDAuMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),K=new U({props:{code:"bWluZHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>minds
DatasetDict({
    train: Dataset({
        features: [<span class="hljs-string">&#x27;path&#x27;</span>, <span class="hljs-string">&#x27;audio&#x27;</span>, <span class="hljs-string">&#x27;transcription&#x27;</span>, <span class="hljs-string">&#x27;english_transcription&#x27;</span>, <span class="hljs-string">&#x27;intent_class&#x27;</span>, <span class="hljs-string">&#x27;lang_id&#x27;</span>],
        num_rows: <span class="hljs-number">16</span>
    })
    test: Dataset({
        features: [<span class="hljs-string">&#x27;path&#x27;</span>, <span class="hljs-string">&#x27;audio&#x27;</span>, <span class="hljs-string">&#x27;transcription&#x27;</span>, <span class="hljs-string">&#x27;english_transcription&#x27;</span>, <span class="hljs-string">&#x27;intent_class&#x27;</span>, <span class="hljs-string">&#x27;lang_id&#x27;</span>],
        num_rows: <span class="hljs-number">4</span>
    })
})`,wrap:!1}}),ss=new U({props:{code:"bWluZHMlMjAlM0QlMjBtaW5kcy5yZW1vdmVfY29sdW1ucyglNUIlMjJlbmdsaXNoX3RyYW5zY3JpcHRpb24lMjIlMkMlMjAlMjJpbnRlbnRfY2xhc3MlMjIlMkMlMjAlMjJsYW5nX2lkJTIyJTVEKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.remove_columns([<span class="hljs-string">&quot;english_transcription&quot;</span>, <span class="hljs-string">&quot;intent_class&quot;</span>, <span class="hljs-string">&quot;lang_id&quot;</span>])',wrap:!1}}),ts=new U({props:{code:"bWluZHMlNUIlMjJ0cmFpbiUyMiU1RCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>minds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>: {<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">0.00024414</span>,  <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        , ...,  <span class="hljs-number">0.00024414</span>,
          <span class="hljs-number">0.00024414</span>,  <span class="hljs-number">0.00024414</span>], dtype=float32),
  <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav&#x27;</span>,
  <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">8000</span>},
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav&#x27;</span>,
 <span class="hljs-string">&#x27;transcription&#x27;</span>: <span class="hljs-string">&quot;hi I&#x27;m trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing&quot;</span>}`,wrap:!1}}),ns=new Bs({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),rs=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJmYWNlYm9vayUyRndhdjJ2ZWMyLWJhc2UlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`,wrap:!1}}),is=new U({props:{code:"bWluZHMlMjAlM0QlMjBtaW5kcy5jYXN0X2NvbHVtbiglMjJhdWRpbyUyMiUyQyUyMEF1ZGlvKHNhbXBsaW5nX3JhdGUlM0QxNl8wMDApKSUwQW1pbmRzJTVCJTIydHJhaW4lMjIlNUQlNUIwJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>minds[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;audio&#x27;</span>: {<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">2.38064706e-04</span>, -<span class="hljs-number">1.58618059e-04</span>, -<span class="hljs-number">5.43987835e-06</span>, ...,
          <span class="hljs-number">2.78103951e-04</span>,  <span class="hljs-number">2.38446111e-04</span>,  <span class="hljs-number">1.18740834e-04</span>], dtype=float32),
  <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav&#x27;</span>,
  <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>},
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~APP_ERROR/602ba9e2963e11ccd901cd4f.wav&#x27;</span>,
 <span class="hljs-string">&#x27;transcription&#x27;</span>: <span class="hljs-string">&quot;hi I&#x27;m trying to use the banking app on my phone and currently my checking and savings account balance is not refreshing&quot;</span>}`,wrap:!1}}),os=new U({props:{code:"ZGVmJTIwdXBwZXJjYXNlKGV4YW1wbGUpJTNBJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwJTdCJTIydHJhbnNjcmlwdGlvbiUyMiUzQSUyMGV4YW1wbGUlNUIlMjJ0cmFuc2NyaXB0aW9uJTIyJTVELnVwcGVyKCklN0QlMEElMEElMEFtaW5kcyUyMCUzRCUyMG1pbmRzLm1hcCh1cHBlcmNhc2Up",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">uppercase</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;transcription&quot;</span>: example[<span class="hljs-string">&quot;transcription&quot;</span>].upper()}


<span class="hljs-meta">&gt;&gt;&gt; </span>minds = minds.<span class="hljs-built_in">map</span>(uppercase)`,wrap:!1}}),hs=new U({props:{code:"ZGVmJTIwcHJlcGFyZV9kYXRhc2V0KGJhdGNoKSUzQSUwQSUyMCUyMCUyMCUyMGF1ZGlvJTIwJTNEJTIwYmF0Y2glNUIlMjJhdWRpbyUyMiU1RCUwQSUyMCUyMCUyMCUyMGJhdGNoJTIwJTNEJTIwcHJvY2Vzc29yKGF1ZGlvJTVCJTIyYXJyYXklMjIlNUQlMkMlMjBzYW1wbGluZ19yYXRlJTNEYXVkaW8lNUIlMjJzYW1wbGluZ19yYXRlJTIyJTVEJTJDJTIwdGV4dCUzRGJhdGNoJTVCJTIydHJhbnNjcmlwdGlvbiUyMiU1RCklMEElMjAlMjAlMjAlMjBiYXRjaCU1QiUyMmlucHV0X2xlbmd0aCUyMiU1RCUyMCUzRCUyMGxlbihiYXRjaCU1QiUyMmlucHV0X3ZhbHVlcyUyMiU1RCU1QjAlNUQpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwYmF0Y2g=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataset</span>(<span class="hljs-params">batch</span>):
<span class="hljs-meta">... </span>    audio = batch[<span class="hljs-string">&quot;audio&quot;</span>]
<span class="hljs-meta">... </span>    batch = processor(audio[<span class="hljs-string">&quot;array&quot;</span>], sampling_rate=audio[<span class="hljs-string">&quot;sampling_rate&quot;</span>], text=batch[<span class="hljs-string">&quot;transcription&quot;</span>])
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;input_length&quot;</span>] = <span class="hljs-built_in">len</span>(batch[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">0</span>])
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> batch`,wrap:!1}}),ys=new U({props:{code:"ZW5jb2RlZF9taW5kcyUyMCUzRCUyMG1pbmRzLm1hcChwcmVwYXJlX2RhdGFzZXQlMkMlMjByZW1vdmVfY29sdW1ucyUzRG1pbmRzLmNvbHVtbl9uYW1lcyU1QiUyMnRyYWluJTIyJTVEJTJDJTIwbnVtX3Byb2MlM0Q0KQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_minds = minds.<span class="hljs-built_in">map</span>(prepare_dataset, remove_columns=minds.column_names[<span class="hljs-string">&quot;train&quot;</span>], num_proc=<span class="hljs-number">4</span>)',wrap:!1}}),gs=new U({props:{code:"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",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass, field
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Any</span>, <span class="hljs-type">Dict</span>, <span class="hljs-type">List</span>, <span class="hljs-type">Optional</span>, <span class="hljs-type">Union</span>


<span class="hljs-meta">&gt;&gt;&gt; </span>@dataclass
<span class="hljs-meta">... </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataCollatorCTCWithPadding</span>:
<span class="hljs-meta">... </span>    processor: AutoProcessor
<span class="hljs-meta">... </span>    padding: <span class="hljs-type">Union</span>[<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">str</span>] = <span class="hljs-string">&quot;longest&quot;</span>

<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, features: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, <span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">int</span>], torch.Tensor]]]</span>) -&gt; <span class="hljs-type">Dict</span>[<span class="hljs-built_in">str</span>, torch.Tensor]:
<span class="hljs-meta">... </span>        <span class="hljs-comment"># split inputs and labels since they have to be of different lengths and need</span>
<span class="hljs-meta">... </span>        <span class="hljs-comment"># different padding methods</span>
<span class="hljs-meta">... </span>        input_features = [{<span class="hljs-string">&quot;input_values&quot;</span>: feature[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">0</span>]} <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features]
<span class="hljs-meta">... </span>        label_features = [{<span class="hljs-string">&quot;input_ids&quot;</span>: feature[<span class="hljs-string">&quot;labels&quot;</span>]} <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features]

<span class="hljs-meta">... </span>        batch = self.processor.pad(input_features, padding=self.padding, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-meta">... </span>        labels_batch = self.processor.pad(labels=label_features, padding=self.padding, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

<span class="hljs-meta">... </span>        <span class="hljs-comment"># replace padding with -100 to ignore loss correctly</span>
<span class="hljs-meta">... </span>        labels = labels_batch[<span class="hljs-string">&quot;input_ids&quot;</span>].masked_fill(labels_batch.attention_mask.ne(<span class="hljs-number">1</span>), -<span class="hljs-number">100</span>)

<span class="hljs-meta">... </span>        batch[<span class="hljs-string">&quot;labels&quot;</span>] = labels

<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> batch`,wrap:!1}}),bs=new U({props:{code:"ZGF0YV9jb2xsYXRvciUyMCUzRCUyMERhdGFDb2xsYXRvckNUQ1dpdGhQYWRkaW5nKHByb2Nlc3NvciUzRHByb2Nlc3NvciUyQyUyMHBhZGRpbmclM0QlMjJsb25nZXN0JTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorCTCWithPadding(processor=processor, padding=<span class="hljs-string">&quot;longest&quot;</span>)',wrap:!1}}),ws=new Bs({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),Ts=new U({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEF3ZXIlMjAlM0QlMjBldmFsdWF0ZS5sb2FkKCUyMndlciUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>wer = evaluate.load(<span class="hljs-string">&quot;wer&quot;</span>)`,wrap:!1}}),_s=new U({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKHByZWQpJTNBJTBBJTIwJTIwJTIwJTIwcHJlZF9sb2dpdHMlMjAlM0QlMjBwcmVkLnByZWRpY3Rpb25zJTBBJTIwJTIwJTIwJTIwcHJlZF9pZHMlMjAlM0QlMjBucC5hcmdtYXgocHJlZF9sb2dpdHMlMkMlMjBheGlzJTNELTEpJTBBJTBBJTIwJTIwJTIwJTIwcHJlZC5sYWJlbF9pZHMlNUJwcmVkLmxhYmVsX2lkcyUyMCUzRCUzRCUyMC0xMDAlNUQlMjAlM0QlMjBwcm9jZXNzb3IudG9rZW5pemVyLnBhZF90b2tlbl9pZCUwQSUwQSUyMCUyMCUyMCUyMHByZWRfc3RyJTIwJTNEJTIwcHJvY2Vzc29yLmJhdGNoX2RlY29kZShwcmVkX2lkcyklMEElMjAlMjAlMjAlMjBsYWJlbF9zdHIlMjAlM0QlMjBwcm9jZXNzb3IuYmF0Y2hfZGVjb2RlKHByZWQubGFiZWxfaWRzJTJDJTIwZ3JvdXBfdG9rZW5zJTNERmFsc2UpJTBBJTBBJTIwJTIwJTIwJTIwd2VyJTIwJTNEJTIwd2VyLmNvbXB1dGUocHJlZGljdGlvbnMlM0RwcmVkX3N0ciUyQyUyMHJlZmVyZW5jZXMlM0RsYWJlbF9zdHIpJTBBJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwJTdCJTIyd2VyJTIyJTNBJTIwd2VyJTdE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">pred</span>):
<span class="hljs-meta">... </span>    pred_logits = pred.predictions
<span class="hljs-meta">... </span>    pred_ids = np.argmax(pred_logits, axis=-<span class="hljs-number">1</span>)

<span class="hljs-meta">... </span>    pred.label_ids[pred.label_ids == -<span class="hljs-number">100</span>] = processor.tokenizer.pad_token_id

<span class="hljs-meta">... </span>    pred_str = processor.batch_decode(pred_ids)
<span class="hljs-meta">... </span>    label_str = processor.batch_decode(pred.label_ids, group_tokens=<span class="hljs-literal">False</span>)

<span class="hljs-meta">... </span>    wer = wer.compute(predictions=pred_str, references=label_str)

<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;wer&quot;</span>: wer}`,wrap:!1}}),Is=new Bs({props:{title:"Train",local:"train",headingTag:"h2"}}),V=new ut({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[kt]},$$scope:{ctx:I}}}),H=new Ha({props:{$$slots:{default:[Wt]},$$scope:{ctx:I}}}),vs=new Bs({props:{title:"Inference",local:"inference",headingTag:"h2"}}),ks=new U({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjAlMjJlbi1VUyUyMiUyQyUyMHNwbGl0JTNEJTIydHJhaW4lMjIpJTBBZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEMTYwMDApKSUwQXNhbXBsaW5nX3JhdGUlMjAlM0QlMjBkYXRhc2V0LmZlYXR1cmVzJTVCJTIyYXVkaW8lMjIlNUQuc2FtcGxpbmdfcmF0ZSUwQWF1ZGlvX2ZpbGUlMjAlM0QlMjBkYXRhc2V0JTVCMCU1RCU1QiUyMmF1ZGlvJTIyJTVEJTVCJTIycGF0aCUyMiU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, <span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16000</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>sampling_rate = dataset.features[<span class="hljs-string">&quot;audio&quot;</span>].sampling_rate
<span class="hljs-meta">&gt;&gt;&gt; </span>audio_file = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;path&quot;</span>]`,wrap:!1}}),xs=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBdHJhbnNjcmliZXIlMjAlM0QlMjBwaXBlbGluZSglMjJhdXRvbWF0aWMtc3BlZWNoLXJlY29nbml0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJzdGV2aGxpdSUyRm15X2F3ZXNvbWVfYXNyX21pbmRzX21vZGVsJTIyKSUwQXRyYW5zY3JpYmVyKGF1ZGlvX2ZpbGUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>transcriber = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;stevhliu/my_awesome_asr_minds_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>transcriber(audio_file)
{<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;I WOUD LIKE O SET UP JOINT ACOUNT WTH Y PARTNER&#x27;</span>}`,wrap:!1}}),Y=new Ha({props:{$$slots:{default:[xt]},$$scope:{ctx:I}}}),N=new ut({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[Bt]},$$scope:{ctx:I}}}),{c(){e=m("meta"),f=n(),r=m("p"),g=n(),M(b.$$.fragment),C=n(),M(Z.$$.fragment),R=n(),M(v.$$.fragment),k=n(),T=m("p"),T.textContent=X,W=n(),$=m("p"),$.textContent=G,i=n(),_=m("ol"),_.innerHTML=Q,B=n(),M(x.$$.fragment),c=n(),w=m("p"),w.textContent=Xs,Ys=n(),M(E.$$.fragment),Ns=n(),z=m("p"),z.textContent=Ya,Qs=n(),M(A.$$.fragment),Es=n(),M(F.$$.fragment),zs=n(),q=m("p"),q.innerHTML=Na,As=n(),M(S.$$.fragment),Fs=n(),L=m("p"),L.innerHTML=Qa,qs=n(),M(P.$$.fragment),Ss=n(),D=m("p"),D.textContent=Ea,Ls=n(),M(K.$$.fragment),Ps=n(),O=m("p"),O.innerHTML=za,Ds=n(),M(ss.$$.fragment),Ks=n(),as=m("p"),as.textContent=Aa,Os=n(),M(ts.$$.fragment),sa=n(),ls=m("p"),ls.textContent=Fa,aa=n(),es=m("ul"),es.innerHTML=qa,ta=n(),M(ns.$$.fragment),la=n(),ps=m("p"),ps.textContent=Sa,ea=n(),M(rs.$$.fragment),na=n(),cs=m("p"),cs.innerHTML=La,pa=n(),M(is.$$.fragment),ra=n(),ms=m("p"),ms.innerHTML=Pa,ca=n(),M(os.$$.fragment),ia=n(),Ms=m("p"),Ms.textContent=Da,ma=n(),ds=m("ol"),ds.innerHTML=Ka,oa=n(),M(hs.$$.fragment),Ma=n(),js=m("p"),js.innerHTML=Oa,da=n(),M(ys.$$.fragment),ha=n(),us=m("p"),us.innerHTML=st,ja=n(),fs=m("p"),fs.innerHTML=at,ya=n(),M(gs.$$.fragment),ua=n(),Js=m("p"),Js.innerHTML=tt,fa=n(),M(bs.$$.fragment),ga=n(),M(ws.$$.fragment),Ja=n(),Us=m("p"),Us.innerHTML=lt,ba=n(),M(Ts.$$.fragment),wa=n(),$s=m("p"),$s.innerHTML=et,Ua=n(),M(_s.$$.fragment),Ta=n(),Cs=m("p"),Cs.innerHTML=nt,$a=n(),M(Is.$$.fragment),_a=n(),M(V.$$.fragment),Ca=n(),M(H.$$.fragment),Ia=n(),M(vs.$$.fragment),va=n(),Rs=m("p"),Rs.textContent=pt,Ra=n(),Zs=m("p"),Zs.textContent=rt,Za=n(),M(ks.$$.fragment),ka=n(),Ws=m("p"),Ws.innerHTML=ct,Wa=n(),M(xs.$$.fragment),xa=n(),M(Y.$$.fragment),Ga=n(),Gs=m("p"),Gs.textContent=it,Ba=n(),M(N.$$.fragment),Xa=n(),Vs=m("p"),this.h()},l(s){const a=Ut("svelte-u9bgzb",document.head);e=o(a,"META",{name:!0,content:!0}),a.forEach(t),f=p(s),r=o(s,"P",{}),jt(r).forEach(t),g=p(s),d(b.$$.fragment,s),C=p(s),d(Z.$$.fragment,s),R=p(s),d(v.$$.fragment,s),k=p(s),T=o(s,"P",{"data-svelte-h":!0}),J(T)!=="svelte-1kxkciy"&&(T.textContent=X),W=p(s),$=o(s,"P",{"data-svelte-h":!0}),J($)!=="svelte-w5jzhi"&&($.textContent=G),i=p(s),_=o(s,"OL",{"data-svelte-h":!0}),J(_)!=="svelte-1a5eauk"&&(_.innerHTML=Q),B=p(s),d(x.$$.fragment,s),c=p(s),w=o(s,"P",{"data-svelte-h":!0}),J(w)!=="svelte-1lya3k8"&&(w.textContent=Xs),Ys=p(s),d(E.$$.fragment,s),Ns=p(s),z=o(s,"P",{"data-svelte-h":!0}),J(z)!=="svelte-193zy02"&&(z.textContent=Ya),Qs=p(s),d(A.$$.fragment,s),Es=p(s),d(F.$$.fragment,s),zs=p(s),q=o(s,"P",{"data-svelte-h":!0}),J(q)!=="svelte-hquw2w"&&(q.innerHTML=Na),As=p(s),d(S.$$.fragment,s),Fs=p(s),L=o(s,"P",{"data-svelte-h":!0}),J(L)!=="svelte-1lbdsew"&&(L.innerHTML=Qa),qs=p(s),d(P.$$.fragment,s),Ss=p(s),D=o(s,"P",{"data-svelte-h":!0}),J(D)!=="svelte-1px2i3t"&&(D.textContent=Ea),Ls=p(s),d(K.$$.fragment,s),Ps=p(s),O=o(s,"P",{"data-svelte-h":!0}),J(O)!=="svelte-1ao6613"&&(O.innerHTML=za),Ds=p(s),d(ss.$$.fragment,s),Ks=p(s),as=o(s,"P",{"data-svelte-h":!0}),J(as)!=="svelte-8i31kj"&&(as.textContent=Aa),Os=p(s),d(ts.$$.fragment,s),sa=p(s),ls=o(s,"P",{"data-svelte-h":!0}),J(ls)!=="svelte-gnvpca"&&(ls.textContent=Fa),aa=p(s),es=o(s,"UL",{"data-svelte-h":!0}),J(es)!=="svelte-1qypy57"&&(es.innerHTML=qa),ta=p(s),d(ns.$$.fragment,s),la=p(s),ps=o(s,"P",{"data-svelte-h":!0}),J(ps)!=="svelte-4nh2qr"&&(ps.textContent=Sa),ea=p(s),d(rs.$$.fragment,s),na=p(s),cs=o(s,"P",{"data-svelte-h":!0}),J(cs)!=="svelte-1bb93wu"&&(cs.innerHTML=La),pa=p(s),d(is.$$.fragment,s),ra=p(s),ms=o(s,"P",{"data-svelte-h":!0}),J(ms)!=="svelte-s6qe8n"&&(ms.innerHTML=Pa),ca=p(s),d(os.$$.fragment,s),ia=p(s),Ms=o(s,"P",{"data-svelte-h":!0}),J(Ms)!=="svelte-16wi3kv"&&(Ms.textContent=Da),ma=p(s),ds=o(s,"OL",{"data-svelte-h":!0}),J(ds)!=="svelte-1izpmn2"&&(ds.innerHTML=Ka),oa=p(s),d(hs.$$.fragment,s),Ma=p(s),js=o(s,"P",{"data-svelte-h":!0}),J(js)!=="svelte-1o2hu6u"&&(js.innerHTML=Oa),da=p(s),d(ys.$$.fragment,s),ha=p(s),us=o(s,"P",{"data-svelte-h":!0}),J(us)!=="svelte-1g3uhk"&&(us.innerHTML=st),ja=p(s),fs=o(s,"P",{"data-svelte-h":!0}),J(fs)!=="svelte-jse1bt"&&(fs.innerHTML=at),ya=p(s),d(gs.$$.fragment,s),ua=p(s),Js=o(s,"P",{"data-svelte-h":!0}),J(Js)!=="svelte-12ra8g5"&&(Js.innerHTML=tt),fa=p(s),d(bs.$$.fragment,s),ga=p(s),d(ws.$$.fragment,s),Ja=p(s),Us=o(s,"P",{"data-svelte-h":!0}),J(Us)!=="svelte-1is2ofz"&&(Us.innerHTML=lt),ba=p(s),d(Ts.$$.fragment,s),wa=p(s),$s=o(s,"P",{"data-svelte-h":!0}),J($s)!=="svelte-2t2nn0"&&($s.innerHTML=et),Ua=p(s),d(_s.$$.fragment,s),Ta=p(s),Cs=o(s,"P",{"data-svelte-h":!0}),J(Cs)!=="svelte-18cw5xr"&&(Cs.innerHTML=nt),$a=p(s),d(Is.$$.fragment,s),_a=p(s),d(V.$$.fragment,s),Ca=p(s),d(H.$$.fragment,s),Ia=p(s),d(vs.$$.fragment,s),va=p(s),Rs=o(s,"P",{"data-svelte-h":!0}),J(Rs)!=="svelte-cyrfc8"&&(Rs.textContent=pt),Ra=p(s),Zs=o(s,"P",{"data-svelte-h":!0}),J(Zs)!=="svelte-frlt8d"&&(Zs.textContent=rt),Za=p(s),d(ks.$$.fragment,s),ka=p(s),Ws=o(s,"P",{"data-svelte-h":!0}),J(Ws)!=="svelte-wp5lcq"&&(Ws.innerHTML=ct),Wa=p(s),d(xs.$$.fragment,s),xa=p(s),d(Y.$$.fragment,s),Ga=p(s),Gs=o(s,"P",{"data-svelte-h":!0}),J(Gs)!=="svelte-1pll7p2"&&(Gs.textContent=it),Ba=p(s),d(N.$$.fragment,s),Xa=p(s),Vs=o(s,"P",{}),jt(Vs).forEach(t),this.h()},h(){yt(e,"name","hf:doc:metadata"),yt(e,"content",Vt)},m(s,a){Tt(document.head,e),l(s,f,a),l(s,r,a),l(s,g,a),h(b,s,a),l(s,C,a),h(Z,s,a),l(s,R,a),h(v,s,a),l(s,k,a),l(s,T,a),l(s,W,a),l(s,$,a),l(s,i,a),l(s,_,a),l(s,B,a),h(x,s,a),l(s,c,a),l(s,w,a),l(s,Ys,a),h(E,s,a),l(s,Ns,a),l(s,z,a),l(s,Qs,a),h(A,s,a),l(s,Es,a),h(F,s,a),l(s,zs,a),l(s,q,a),l(s,As,a),h(S,s,a),l(s,Fs,a),l(s,L,a),l(s,qs,a),h(P,s,a),l(s,Ss,a),l(s,D,a),l(s,Ls,a),h(K,s,a),l(s,Ps,a),l(s,O,a),l(s,Ds,a),h(ss,s,a),l(s,Ks,a),l(s,as,a),l(s,Os,a),h(ts,s,a),l(s,sa,a),l(s,ls,a),l(s,aa,a),l(s,es,a),l(s,ta,a),h(ns,s,a),l(s,la,a),l(s,ps,a),l(s,ea,a),h(rs,s,a),l(s,na,a),l(s,cs,a),l(s,pa,a),h(is,s,a),l(s,ra,a),l(s,ms,a),l(s,ca,a),h(os,s,a),l(s,ia,a),l(s,Ms,a),l(s,ma,a),l(s,ds,a),l(s,oa,a),h(hs,s,a),l(s,Ma,a),l(s,js,a),l(s,da,a),h(ys,s,a),l(s,ha,a),l(s,us,a),l(s,ja,a),l(s,fs,a),l(s,ya,a),h(gs,s,a),l(s,ua,a),l(s,Js,a),l(s,fa,a),h(bs,s,a),l(s,ga,a),h(ws,s,a),l(s,Ja,a),l(s,Us,a),l(s,ba,a),h(Ts,s,a),l(s,wa,a),l(s,$s,a),l(s,Ua,a),h(_s,s,a),l(s,Ta,a),l(s,Cs,a),l(s,$a,a),h(Is,s,a),l(s,_a,a),h(V,s,a),l(s,Ca,a),h(H,s,a),l(s,Ia,a),h(vs,s,a),l(s,va,a),l(s,Rs,a),l(s,Ra,a),l(s,Zs,a),l(s,Za,a),h(ks,s,a),l(s,ka,a),l(s,Ws,a),l(s,Wa,a),h(xs,s,a),l(s,xa,a),h(Y,s,a),l(s,Ga,a),l(s,Gs,a),l(s,Ba,a),h(N,s,a),l(s,Xa,a),l(s,Vs,a),Va=!0},p(s,[a]){const mt={};a&2&&(mt.$$scope={dirty:a,ctx:s}),x.$set(mt);const ot={};a&2&&(ot.$$scope={dirty:a,ctx:s}),V.$set(ot);const Mt={};a&2&&(Mt.$$scope={dirty:a,ctx:s}),H.$set(Mt);const dt={};a&2&&(dt.$$scope={dirty:a,ctx:s}),Y.$set(dt);const ht={};a&2&&(ht.$$scope={dirty:a,ctx:s}),N.$set(ht)},i(s){Va||(j(b.$$.fragment,s),j(Z.$$.fragment,s),j(v.$$.fragment,s),j(x.$$.fragment,s),j(E.$$.fragment,s),j(A.$$.fragment,s),j(F.$$.fragment,s),j(S.$$.fragment,s),j(P.$$.fragment,s),j(K.$$.fragment,s),j(ss.$$.fragment,s),j(ts.$$.fragment,s),j(ns.$$.fragment,s),j(rs.$$.fragment,s),j(is.$$.fragment,s),j(os.$$.fragment,s),j(hs.$$.fragment,s),j(ys.$$.fragment,s),j(gs.$$.fragment,s),j(bs.$$.fragment,s),j(ws.$$.fragment,s),j(Ts.$$.fragment,s),j(_s.$$.fragment,s),j(Is.$$.fragment,s),j(V.$$.fragment,s),j(H.$$.fragment,s),j(vs.$$.fragment,s),j(ks.$$.fragment,s),j(xs.$$.fragment,s),j(Y.$$.fragment,s),j(N.$$.fragment,s),Va=!0)},o(s){y(b.$$.fragment,s),y(Z.$$.fragment,s),y(v.$$.fragment,s),y(x.$$.fragment,s),y(E.$$.fragment,s),y(A.$$.fragment,s),y(F.$$.fragment,s),y(S.$$.fragment,s),y(P.$$.fragment,s),y(K.$$.fragment,s),y(ss.$$.fragment,s),y(ts.$$.fragment,s),y(ns.$$.fragment,s),y(rs.$$.fragment,s),y(is.$$.fragment,s),y(os.$$.fragment,s),y(hs.$$.fragment,s),y(ys.$$.fragment,s),y(gs.$$.fragment,s),y(bs.$$.fragment,s),y(ws.$$.fragment,s),y(Ts.$$.fragment,s),y(_s.$$.fragment,s),y(Is.$$.fragment,s),y(V.$$.fragment,s),y(H.$$.fragment,s),y(vs.$$.fragment,s),y(ks.$$.fragment,s),y(xs.$$.fragment,s),y(Y.$$.fragment,s),y(N.$$.fragment,s),Va=!1},d(s){s&&(t(f),t(r),t(g),t(C),t(R),t(k),t(T),t(W),t($),t(i),t(_),t(B),t(c),t(w),t(Ys),t(Ns),t(z),t(Qs),t(Es),t(zs),t(q),t(As),t(Fs),t(L),t(qs),t(Ss),t(D),t(Ls),t(Ps),t(O),t(Ds),t(Ks),t(as),t(Os),t(sa),t(ls),t(aa),t(es),t(ta),t(la),t(ps),t(ea),t(na),t(cs),t(pa),t(ra),t(ms),t(ca),t(ia),t(Ms),t(ma),t(ds),t(oa),t(Ma),t(js),t(da),t(ha),t(us),t(ja),t(fs),t(ya),t(ua),t(Js),t(fa),t(ga),t(Ja),t(Us),t(ba),t(wa),t($s),t(Ua),t(Ta),t(Cs),t($a),t(_a),t(Ca),t(Ia),t(va),t(Rs),t(Ra),t(Zs),t(Za),t(ka),t(Ws),t(Wa),t(xa),t(Ga),t(Gs),t(Ba),t(Xa),t(Vs)),t(e),u(b,s),u(Z,s),u(v,s),u(x,s),u(E,s),u(A,s),u(F,s),u(S,s),u(P,s),u(K,s),u(ss,s),u(ts,s),u(ns,s),u(rs,s),u(is,s),u(os,s),u(hs,s),u(ys,s),u(gs,s),u(bs,s),u(ws,s),u(Ts,s),u(_s,s),u(Is,s),u(V,s),u(H,s),u(vs,s),u(ks,s),u(xs,s),u(Y,s),u(N,s)}}}const Vt='{"title":"Automatic speech recognition","local":"automatic-speech-recognition","sections":[{"title":"Load MInDS-14 dataset","local":"load-minds-14-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function Ht(I){return Jt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class St extends bt{constructor(e){super(),wt(this,e,Ht,Xt,gt,{})}}export{St as component};
