import{s as Ul,o as _l,n as Re}from"../chunks/scheduler.9bc65507.js";import{S as gl,i as jl,g as p,s as r,r as w,A as bl,h as o,f as l,c as s,j as Ve,u as J,x as c,k as dl,y as Ne,a,v as y,d as T,t as d,w as h}from"../chunks/index.707bf1b6.js";import{C as _}from"../chunks/CodeBlock.54a9f38d.js";import{F as hl,M as Ge}from"../chunks/Markdown.8ab98a13.js";import{H as j}from"../chunks/Heading.342b1fa6.js";function $l(g){let i,u='この例のスクリプトは、🤗 <a href="https://huggingface.co/docs/datasets/" rel="nofollow">Datasets</a> ライブラリからデータセットをダウンロードし、前処理を行います。次に、<a href="https://huggingface.co/docs/transformers/main_classes/trainer" rel="nofollow">Trainer</a> を使用して要約をサポートするアーキテクチャ上でデータセットをファインチューニングします。以下の例では、<a href="https://huggingface.co/datasets/cnn_dailymail" rel="nofollow">CNN/DailyMail</a> データセット上で <a href="https://huggingface.co/google-t5/t5-small" rel="nofollow">T5-small</a> をファインチューニングする方法が示されています。T5 モデルは、そのトレーニング方法に起因して追加の <code>source_prefix</code> 引数が必要です。このプロンプトにより、T5 はこれが要約タスクであることを知ることができます。',n,m,f;return m=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),{c(){i=p("p"),i.innerHTML=u,n=r(),w(m.$$.fragment)},l(M){i=o(M,"P",{"data-svelte-h":!0}),c(i)!=="svelte-dv1ww7"&&(i.innerHTML=u),n=s(M),J(m.$$.fragment,M)},m(M,U){a(M,i,U),a(M,n,U),y(m,M,U),f=!0},p:Re,i(M){f||(T(m.$$.fragment,M),f=!0)},o(M){d(m.$$.fragment,M),f=!1},d(M){M&&(l(i),l(n)),h(m,M)}}}function Cl(g){let i,u;return i=new Ge({props:{$$slots:{default:[$l]},$$scope:{ctx:g}}}),{c(){w(i.$$.fragment)},l(n){J(i.$$.fragment,n)},m(n,m){y(i,n,m),u=!0},p(n,m){const f={};m&2&&(f.$$scope={dirty:m,ctx:n}),i.$set(f)},i(n){u||(T(i.$$.fragment,n),u=!0)},o(n){d(i.$$.fragment,n),u=!1},d(n){h(i,n)}}}function Xl(g){let i,u='この例のスクリプトは、🤗 <a href="https://huggingface.co/docs/datasets/" rel="nofollow">Datasets</a> ライブラリからデータセットをダウンロードして前処理します。その後、スクリプトは要約をサポートするアーキテクチャ上で Keras を使用してデータセットをファインチューニングします。以下の例では、<a href="https://huggingface.co/google-t5/t5-small" rel="nofollow">T5-small</a> を <a href="https://huggingface.co/datasets/cnn_dailymail" rel="nofollow">CNN/DailyMail</a> データセットでファインチューニングする方法を示しています。T5 モデルは、そのトレーニング方法に起因して追加の <code>source_prefix</code> 引数が必要です。このプロンプトは、T5 にこれが要約タスクであることを知らせます。',n,m,f;return m=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZ0ZW5zb3JmbG93JTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9uYW1lJTIwY25uX2RhaWx5bWFpbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9jb25maWclMjAlMjIzLjAuMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlMjA4JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUyMDE2JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMyUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWw=",highlighted:`python examples/tensorflow/summarization/run_summarization.py  \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,wrap:!1}}),{c(){i=p("p"),i.innerHTML=u,n=r(),w(m.$$.fragment)},l(M){i=o(M,"P",{"data-svelte-h":!0}),c(i)!=="svelte-wmbem5"&&(i.innerHTML=u),n=s(M),J(m.$$.fragment,M)},m(M,U){a(M,i,U),a(M,n,U),y(m,M,U),f=!0},p:Re,i(M){f||(T(m.$$.fragment,M),f=!0)},o(M){d(m.$$.fragment,M),f=!1},d(M){M&&(l(i),l(n)),h(m,M)}}}function Il(g){let i,u;return i=new Ge({props:{$$slots:{default:[Xl]},$$scope:{ctx:g}}}),{c(){w(i.$$.fragment)},l(n){J(i.$$.fragment,n)},m(n,m){y(i,n,m),u=!0},p(n,m){const f={};m&2&&(f.$$scope={dirty:m,ctx:n}),i.$set(f)},i(n){u||(T(i.$$.fragment,n),u=!0)},o(n){d(i.$$.fragment,n),u=!1},d(n){h(i,n)}}}function Al(g){let i,u='Tensor Processing Units (TPUs)は、パフォーマンスを加速させるために特別に設計されています。PyTorchは、<a href="https://www.tensorflow.org/xla" rel="nofollow">XLA</a>ディープラーニングコンパイラを使用してTPUsをサポートしており、詳細については<a href="https://github.com/pytorch/xla/blob/master/README.md" rel="nofollow">こちら</a>をご覧ください。TPUを使用するには、<code>xla_spawn.py</code>スクリプトを起動し、<code>num_cores</code>引数を使用して使用するTPUコアの数を設定します。',n,m,f;return m=new _({props:{code:"cHl0aG9uJTIweGxhX3NwYXduLnB5JTIwLS1udW1fY29yZXMlMjA4JTIwJTVDJTBBJTIwJTIwJTIwJTIwc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python xla_spawn.py --num_cores 8 \\
    summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),{c(){i=p("p"),i.innerHTML=u,n=r(),w(m.$$.fragment)},l(M){i=o(M,"P",{"data-svelte-h":!0}),c(i)!=="svelte-19tulso"&&(i.innerHTML=u),n=s(M),J(m.$$.fragment,M)},m(M,U){a(M,i,U),a(M,n,U),y(m,M,U),f=!0},p:Re,i(M){f||(T(m.$$.fragment,M),f=!0)},o(M){d(m.$$.fragment,M),f=!1},d(M){M&&(l(i),l(n)),h(m,M)}}}function vl(g){let i,u;return i=new Ge({props:{$$slots:{default:[Al]},$$scope:{ctx:g}}}),{c(){w(i.$$.fragment)},l(n){J(i.$$.fragment,n)},m(n,m){y(i,n,m),u=!0},p(n,m){const f={};m&2&&(f.$$scope={dirty:m,ctx:n}),i.$set(f)},i(n){u||(T(i.$$.fragment,n),u=!0)},o(n){d(i.$$.fragment,n),u=!1},d(n){h(i,n)}}}function Wl(g){let i,u='もちろん、Tensor Processing Units（TPUs）は性能を高速化するために特別に設計されています。TensorFlowスクリプトは、TPUsでトレーニングするために<a href="https://www.tensorflow.org/guide/distributed_training#tpustrategy" rel="nofollow"><code>TPUStrategy</code></a>を利用します。TPUを使用するには、TPUリソースの名前を<code>tpu</code>引数に渡します。',n,m,f;return m=new _({props:{code:"cHl0aG9uJTIwcnVuX3N1bW1hcml6YXRpb24ucHklMjAlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRwdSUyMG5hbWVfb2ZfdHB1X3Jlc291cmNlJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9uYW1lJTIwY25uX2RhaWx5bWFpbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9jb25maWclMjAlMjIzLjAuMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlMjA4JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUyMDE2JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMyUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWw=",highlighted:`python run_summarization.py  \\
    --tpu name_of_tpu_resource \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,wrap:!1}}),{c(){i=p("p"),i.innerHTML=u,n=r(),w(m.$$.fragment)},l(M){i=o(M,"P",{"data-svelte-h":!0}),c(i)!=="svelte-fxym0v"&&(i.innerHTML=u),n=s(M),J(m.$$.fragment,M)},m(M,U){a(M,i,U),a(M,n,U),y(m,M,U),f=!0},p:Re,i(M){f||(T(m.$$.fragment,M),f=!0)},o(M){d(m.$$.fragment,M),f=!1},d(M){M&&(l(i),l(n)),h(m,M)}}}function Zl(g){let i,u;return i=new Ge({props:{$$slots:{default:[Wl]},$$scope:{ctx:g}}}),{c(){w(i.$$.fragment)},l(n){J(i.$$.fragment,n)},m(n,m){y(i,n,m),u=!0},p(n,m){const f={};m&2&&(f.$$scope={dirty:m,ctx:n}),i.$set(f)},i(n){u||(T(i.$$.fragment,n),u=!0)},o(n){d(i.$$.fragment,n),u=!1},d(n){h(i,n)}}}function xl(g){let i,u,n,m,f,M,U,Be='🤗 Transformersの<a href="./notebooks/README">notebooks</a>と一緒に、<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch" rel="nofollow">PyTorch</a>、<a href="https://github.com/huggingface/transformers/tree/main/examples/tensorflow" rel="nofollow">TensorFlow</a>、または<a href="https://github.com/huggingface/transformers/tree/main/examples/flax" rel="nofollow">JAX/Flax</a>を使用してモデルをトレーニングする方法を示すサンプルスクリプトもあります。',vt,X,Fe='また、私たちの<a href="https://github.com/huggingface/transformers/tree/main/examples/research_projects" rel="nofollow">研究プロジェクト</a>や<a href="https://github.com/huggingface/transformers/tree/main/examples/legacy" rel="nofollow">レガシーの例</a>で使用したスクリプトも見つかります。これらのスクリプトは現在メンテナンスされておらず、おそらく最新バージョンのライブラリと互換性がない特定の🤗 Transformersのバージョンが必要です。',Wt,I,Ye="サンプルスクリプトはすべての問題でそのまま動作することは期待されておらず、解決しようとしている問題にスクリプトを適応させる必要があるかもしれません。この点をサポートするために、ほとんどのスクリプトはデータがどのように前処理されているかを完全に公開し、必要に応じて編集できるようにしています。",Zt,A,ze='サンプルスクリプトで実装したい機能がある場合は、<a href="https://discuss.huggingface.co/" rel="nofollow">フォーラム</a>か<a href="https://github.com/huggingface/transformers/issues" rel="nofollow">イシュートラッカー</a>で議論してからプルリクエストを提出してください。バグ修正は歓迎しますが、読みやすさのコストで機能を追加するプルリクエストはほとんどマージされない可能性が高いです。',xt,v,Se='このガイドでは、<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization" rel="nofollow">PyTorch</a>と<a href="https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization" rel="nofollow">TensorFlow</a>で実行するサマリゼーショントレーニングスクリプトの実行方法を示します。すべての例は、明示的に指定されていない限り、両方のフレームワークともに動作することが期待されています。',Rt,W,Gt,Z,Ee="最新バージョンのサンプルスクリプトを正常に実行するには、新しい仮想環境に🤗 Transformersをソースからインストールする必要があります:",Lt,x,Vt,R,He="以前のスクリプトのバージョンについては、以下のトグルをクリックしてください：",Nt,G,ke='<summary>以前の🤗 Transformersのバージョンに関する例</summary> <ul><li><a href="https://github.com/huggingface/transformers/tree/v4.5.1/examples">v4.5.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.4.2/examples">v4.4.2</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.3.3/examples">v4.3.3</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.2.2/examples">v4.2.2</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.1.1/examples">v4.1.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.0.1/examples">v4.0.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.5.1/examples">v3.5.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.4.0/examples">v3.4.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.3.1/examples">v3.3.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.2.0/examples">v3.2.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.1.0/examples">v3.1.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.0.2/examples">v3.0.2</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.11.0/examples">v2.11.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.10.0/examples">v2.10.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.9.1/examples">v2.9.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.8.0/examples">v2.8.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.7.0/examples">v2.7.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.6.0/examples">v2.6.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.5.1/examples">v2.5.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.4.0/examples">v2.4.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.3.0/examples">v2.3.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.2.0/examples">v2.2.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.1.0/examples">v2.1.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.0.0/examples">v2.0.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v1.2.0/examples">v1.2.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v1.1.0/examples">v1.1.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v1.0.0/examples">v1.0.0</a></li></ul>',Bt,L,Qe="次に、現在の🤗 Transformersのクローンを特定のバージョンに切り替えてください。たとえば、v3.5.1などです。",Ft,V,Yt,N,De="適切なライブラリバージョンを設定したら、任意の例のフォルダに移動し、例固有の要件をインストールします：",zt,B,St,F,Et,b,Ht,Y,kt,z,Pe='<a href="https://huggingface.co/docs/transformers/main_classes/trainer" rel="nofollow">Trainer</a>は、分散トレーニングと混合精度をサポートしています。つまり、この機能をスクリプトで使用することができます。これらの機能を有効にするには、次の手順を実行します。',Qt,S,qe="<li><code>fp16</code>引数を追加して混合精度を有効にします。</li> <li><code>nproc_per_node</code>引数で使用するGPUの数を設定します。</li>",Dt,E,Oe="以下は提供されたBashコードです。このコードの日本語訳をMarkdown形式で記載します。",Pt,H,qt,k,Ke='TensorFlowスクリプトは、分散トレーニングに<a href="https://www.tensorflow.org/guide/distributed_training#mirroredstrategy" rel="nofollow"><code>MirroredStrategy</code></a>を使用し、トレーニングスクリプトに追加の引数を追加する必要はありません。TensorFlowスクリプトは、デフォルトで複数のGPUが利用可能な場合にそれらを使用します。',Ot,Q,Kt,$,te,D,ee,P,tl='🤗 <a href="https://huggingface.co/docs/accelerate" rel="nofollow">Accelerate</a>は、PyTorch専用のライブラリで、CPUのみ、複数のGPU、TPUなど、さまざまなセットアップでモデルをトレーニングするための統一された方法を提供します。PyTorchのトレーニングループを完全に可視化しながら実行できます。まだインストールしていない場合は、🤗 Accelerateをインストールしてください：',le,C,It,el="注意：Accelerateは急速に開発が進行しているため、スクリプトを実行するにはaccelerateのgitバージョンをインストールする必要があります",Le,q,ae,O,ll="代わりに、<code>run_summarization_no_trainer.py</code> スクリプトを使用する必要があります。 🤗 Accelerate がサポートするスクリプトには、フォルダ内に <code>task_no_trainer.py</code> ファイルが含まれています。まず、次のコマンドを実行して設定ファイルを作成し、保存します：",ie,K,ne,tt,al="テストを行い、設定が正しく構成されているか確認してください：",re,et,se,lt,il="Now you are ready to launch the training:",Me,at,me,it,pe,nt,nl="要約スクリプトは、CSVまたはJSON Lineファイルであれば、カスタムデータセットをサポートしています。独自のデータセットを使用する場合、いくつかの追加の引数を指定する必要があります。",oe,rt,rl="<li><code>train_file</code>および<code>validation_file</code>は、トレーニングとバリデーションのファイルへのパスを指定します。</li> <li><code>text_column</code>は要約するための入力テキストです。</li> <li><code>summary_column</code>は出力する対象テキストです。</li>",fe,st,sl="カスタムデータセットを使用した要約スクリプトは、以下のようになります：",ue,Mt,ce,mt,we,pt,Ml="すべてが予想通りに動作することを確認するために、データセット全体を処理する前に、データセットの一部の例でスクリプトを実行することは良いアイデアです。以下の引数を使用して、データセットを最大サンプル数に切り詰めます：",Je,ot,ml="<li><code>max_train_samples</code></li> <li><code>max_eval_samples</code></li> <li><code>max_predict_samples</code></li>",ye,ft,Te,ut,pl="一部の例のスクリプトは、<code>max_predict_samples</code>引数をサポートしていないことがあります。この引数がサポートされているかどうかがわからない場合は、<code>-h</code>引数を追加して確認してください。",de,ct,he,wt,Ue,Jt,ol="以前のチェックポイントからトレーニングを再開するための役立つオプションもあります。これにより、トレーニングが中断された場合でも、最初からやり直すことなく、中断したところから再開できます。チェックポイントからトレーニングを再開するための2つの方法があります。",_e,yt,fl="最初の方法は、<code>output_dir previous_output_dir</code> 引数を使用して、<code>output_dir</code> に保存された最新のチェックポイントからトレーニングを再開する方法です。この場合、<code>overwrite_output_dir</code> を削除する必要があります：",ge,Tt,je,dt,ul="2番目の方法では、<code>resume_from_checkpoint path_to_specific_checkpoint</code> 引数を使用して、特定のチェックポイントフォルダからトレーニングを再開します。",be,ht,$e,Ut,Ce,_t,cl='すべてのスクリプトは、最終的なモデルを <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a> にアップロードできます。開始する前に Hugging Face にログインしていることを確認してください。',Xe,gt,Ie,jt,wl="次に、スクリプトに <code>push_to_hub</code> 引数を追加します。この引数は、Hugging Face のユーザー名と <code>output_dir</code> で指定したフォルダ名でリポジトリを作成します。",Ae,bt,Jl="特定の名前をリポジトリに付けるには、<code>push_to_hub_model_id</code> 引数を使用して追加します。このリポジトリは自動的にあなたの名前空間の下にリストされます。",ve,$t,yl="以下の例は、特定のリポジトリ名でモデルをアップロードする方法を示しています:",We,Ct,Ze,At,xe;return f=new j({props:{title:"Train with a script",local:"train-with-a-script",headingTag:"h1"}}),W=new j({props:{title:"Setup",local:"setup",headingTag:"h2"}}),x=new _({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZodWdnaW5nZmFjZSUyRnRyYW5zZm9ybWVycyUwQWNkJTIwdHJhbnNmb3JtZXJzJTBBcGlwJTIwaW5zdGFsbCUyMC4=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers
<span class="hljs-built_in">cd</span> transformers
pip install .`,wrap:!1}}),V=new _({props:{code:"Z2l0JTIwY2hlY2tvdXQlMjB0YWdzJTJGdjMuNS4x",highlighted:"git checkout tags/v3.5.1",wrap:!1}}),B=new _({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1yJTIwcmVxdWlyZW1lbnRzLnR4dA==",highlighted:"pip install -r requirements.txt",wrap:!1}}),F=new j({props:{title:"Run a script",local:"run-a-script",headingTag:"h2"}}),b=new hl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Il],pytorch:[Cl]},$$scope:{ctx:g}}}),Y=new j({props:{title:"Distributed training and mixed precision",local:"distributed-training-and-mixed-precision",headingTag:"h2"}}),H=new _({props:{code:"dG9yY2hydW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLW5wcm9jX3Blcl9ub2RlJTIwOCUyMHB5dG9yY2glMkZzdW1tYXJpemF0aW9uJTJGcnVuX3N1bW1hcml6YXRpb24ucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLWZwMTYlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW1vZGVsX25hbWVfb3JfcGF0aCUyMGdvb2dsZS10NSUyRnQ1LXNtYWxsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kb190cmFpbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fZXZhbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9uYW1lJTIwY25uX2RhaWx5bWFpbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9jb25maWclMjAlMjIzLjAuMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tc291cmNlX3ByZWZpeCUyMCUyMnN1bW1hcml6ZSUzQSUyMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW92ZXJ3cml0ZV9vdXRwdXRfZGlyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wcmVkaWN0X3dpdGhfZ2VuZXJhdGU=",highlighted:`torchrun \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),Q=new j({props:{title:"Run a script on a TPU",local:"run-a-script-on-a-tpu",headingTag:"h2"}}),$=new hl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Zl],pytorch:[vl]},$$scope:{ctx:g}}}),D=new j({props:{title:"Run a script with 🤗 Accelerate",local:"run-a-script-with--accelerate",headingTag:"h2"}}),q=new _({props:{code:"cGlwJTIwaW5zdGFsbCUyMGdpdCUyQmh0dHBzJTNBJTJGJTJGZ2l0aHViLmNvbSUyRmh1Z2dpbmdmYWNlJTJGYWNjZWxlcmF0ZQ==",highlighted:"pip install git+https://github.com/huggingface/accelerate",wrap:!1}}),K=new _({props:{code:"YWNjZWxlcmF0ZSUyMGNvbmZpZw==",highlighted:"accelerate config",wrap:!1}}),et=new _({props:{code:"YWNjZWxlcmF0ZSUyMHRlc3Q=",highlighted:'accelerate <span class="hljs-built_in">test</span>',wrap:!1}}),at=new _({props:{code:"YWNjZWxlcmF0ZSUyMGxhdW5jaCUyMHJ1bl9zdW1tYXJpemF0aW9uX25vX3RyYWluZXIucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLW1vZGVsX25hbWVfb3JfcGF0aCUyMGdvb2dsZS10NSUyRnQ1LXNtYWxsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X25hbWUlMjBjbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X2NvbmZpZyUyMCUyMjMuMC4wJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwfiUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9u",highlighted:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir ~/tmp/tst-summarization`,wrap:!1}}),it=new j({props:{title:"Use a custom dataset",local:"use-a-custom-dataset",headingTag:"h2"}}),Mt=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRyYWluX2ZpbGUlMjBwYXRoX3RvX2Nzdl9vcl9qc29ubGluZXNfZmlsZSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tdmFsaWRhdGlvbl9maWxlJTIwcGF0aF90b19jc3Zfb3JfanNvbmxpbmVzX2ZpbGUlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRleHRfY29sdW1uJTIwdGV4dF9jb2x1bW5fbmFtZSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tc3VtbWFyeV9jb2x1bW4lMjBzdW1tYXJ5X2NvbHVtbl9uYW1lJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLW92ZXJ3cml0ZV9vdXRwdXRfZGlyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZQ==",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate`,wrap:!1}}),mt=new j({props:{title:"Test a script",local:"test-a-script",headingTag:"h2"}}),ft=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tbWF4X3RyYWluX3NhbXBsZXMlMjA1MCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tbWF4X2V2YWxfc2FtcGxlcyUyMDUwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tYXhfcHJlZGljdF9zYW1wbGVzJTIwNTAlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX3RyYWluJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kb19ldmFsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X25hbWUlMjBjbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X2NvbmZpZyUyMCUyMjMuMC4wJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3ZlcndyaXRlX291dHB1dF9kaXIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZQ==",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),ct=new _({props:{code:"ZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwLWg=",highlighted:"examples/pytorch/summarization/run_summarization.py -h",wrap:!1}}),wt=new j({props:{title:"Resume training from checkpoint",local:"resume-training-from-checkpoint",headingTag:"h2"}}),Tt=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwcHJldmlvdXNfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --output_dir previous_output_dir \\
    --predict_with_generate`,wrap:!1}}),ht=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcmVzdW1lX2Zyb21fY2hlY2twb2ludCUyMHBhdGhfdG9fc3BlY2lmaWNfY2hlY2twb2ludCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --resume_from_checkpoint path_to_specific_checkpoint \\
    --predict_with_generate`,wrap:!1}}),Ut=new j({props:{title:"Share your model",local:"share-your-model",headingTag:"h2"}}),gt=new _({props:{code:"aHVnZ2luZ2ZhY2UtY2xpJTIwbG9naW4=",highlighted:"huggingface-cli login",wrap:!1}}),Ct=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXB1c2hfdG9faHViJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wdXNoX3RvX2h1Yl9tb2RlbF9pZCUyMGZpbmV0dW5lZC10NS1jbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3ZlcndyaXRlX291dHB1dF9kaXIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZQ==",highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --push_to_hub \\
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),{c(){i=p("meta"),u=r(),n=p("p"),m=r(),w(f.$$.fragment),M=r(),U=p("p"),U.innerHTML=Be,vt=r(),X=p("p"),X.innerHTML=Fe,Wt=r(),I=p("p"),I.textContent=Ye,Zt=r(),A=p("p"),A.innerHTML=ze,xt=r(),v=p("p"),v.innerHTML=Se,Rt=r(),w(W.$$.fragment),Gt=r(),Z=p("p"),Z.textContent=Ee,Lt=r(),w(x.$$.fragment),Vt=r(),R=p("p"),R.textContent=He,Nt=r(),G=p("details"),G.innerHTML=ke,Bt=r(),L=p("p"),L.textContent=Qe,Ft=r(),w(V.$$.fragment),Yt=r(),N=p("p"),N.textContent=De,zt=r(),w(B.$$.fragment),St=r(),w(F.$$.fragment),Et=r(),w(b.$$.fragment),Ht=r(),w(Y.$$.fragment),kt=r(),z=p("p"),z.innerHTML=Pe,Qt=r(),S=p("ul"),S.innerHTML=qe,Dt=r(),E=p("p"),E.textContent=Oe,Pt=r(),w(H.$$.fragment),qt=r(),k=p("p"),k.innerHTML=Ke,Ot=r(),w(Q.$$.fragment),Kt=r(),w($.$$.fragment),te=r(),w(D.$$.fragment),ee=r(),P=p("p"),P.innerHTML=tl,le=r(),C=p("blockquote"),It=p("p"),It.textContent=el,Le=r(),w(q.$$.fragment),ae=r(),O=p("p"),O.innerHTML=ll,ie=r(),w(K.$$.fragment),ne=r(),tt=p("p"),tt.textContent=al,re=r(),w(et.$$.fragment),se=r(),lt=p("p"),lt.textContent=il,Me=r(),w(at.$$.fragment),me=r(),w(it.$$.fragment),pe=r(),nt=p("p"),nt.textContent=nl,oe=r(),rt=p("ul"),rt.innerHTML=rl,fe=r(),st=p("p"),st.textContent=sl,ue=r(),w(Mt.$$.fragment),ce=r(),w(mt.$$.fragment),we=r(),pt=p("p"),pt.textContent=Ml,Je=r(),ot=p("ul"),ot.innerHTML=ml,ye=r(),w(ft.$$.fragment),Te=r(),ut=p("p"),ut.innerHTML=pl,de=r(),w(ct.$$.fragment),he=r(),w(wt.$$.fragment),Ue=r(),Jt=p("p"),Jt.textContent=ol,_e=r(),yt=p("p"),yt.innerHTML=fl,ge=r(),w(Tt.$$.fragment),je=r(),dt=p("p"),dt.innerHTML=ul,be=r(),w(ht.$$.fragment),$e=r(),w(Ut.$$.fragment),Ce=r(),_t=p("p"),_t.innerHTML=cl,Xe=r(),w(gt.$$.fragment),Ie=r(),jt=p("p"),jt.innerHTML=wl,Ae=r(),bt=p("p"),bt.innerHTML=Jl,ve=r(),$t=p("p"),$t.textContent=yl,We=r(),w(Ct.$$.fragment),Ze=r(),At=p("p"),this.h()},l(t){const e=bl("svelte-u9bgzb",document.head);i=o(e,"META",{name:!0,content:!0}),e.forEach(l),u=s(t),n=o(t,"P",{}),Ve(n).forEach(l),m=s(t),J(f.$$.fragment,t),M=s(t),U=o(t,"P",{"data-svelte-h":!0}),c(U)!=="svelte-1306ylp"&&(U.innerHTML=Be),vt=s(t),X=o(t,"P",{"data-svelte-h":!0}),c(X)!=="svelte-syxjfu"&&(X.innerHTML=Fe),Wt=s(t),I=o(t,"P",{"data-svelte-h":!0}),c(I)!=="svelte-1lausv5"&&(I.textContent=Ye),Zt=s(t),A=o(t,"P",{"data-svelte-h":!0}),c(A)!=="svelte-27a3wx"&&(A.innerHTML=ze),xt=s(t),v=o(t,"P",{"data-svelte-h":!0}),c(v)!=="svelte-19fm544"&&(v.innerHTML=Se),Rt=s(t),J(W.$$.fragment,t),Gt=s(t),Z=o(t,"P",{"data-svelte-h":!0}),c(Z)!=="svelte-1n5u51u"&&(Z.textContent=Ee),Lt=s(t),J(x.$$.fragment,t),Vt=s(t),R=o(t,"P",{"data-svelte-h":!0}),c(R)!=="svelte-b8k59p"&&(R.textContent=He),Nt=s(t),G=o(t,"DETAILS",{"data-svelte-h":!0}),c(G)!=="svelte-1hlw0ln"&&(G.innerHTML=ke),Bt=s(t),L=o(t,"P",{"data-svelte-h":!0}),c(L)!=="svelte-5wcyhr"&&(L.textContent=Qe),Ft=s(t),J(V.$$.fragment,t),Yt=s(t),N=o(t,"P",{"data-svelte-h":!0}),c(N)!=="svelte-gflbb4"&&(N.textContent=De),zt=s(t),J(B.$$.fragment,t),St=s(t),J(F.$$.fragment,t),Et=s(t),J(b.$$.fragment,t),Ht=s(t),J(Y.$$.fragment,t),kt=s(t),z=o(t,"P",{"data-svelte-h":!0}),c(z)!=="svelte-5guxi7"&&(z.innerHTML=Pe),Qt=s(t),S=o(t,"UL",{"data-svelte-h":!0}),c(S)!=="svelte-1bvcrdb"&&(S.innerHTML=qe),Dt=s(t),E=o(t,"P",{"data-svelte-h":!0}),c(E)!=="svelte-1ai2r2d"&&(E.textContent=Oe),Pt=s(t),J(H.$$.fragment,t),qt=s(t),k=o(t,"P",{"data-svelte-h":!0}),c(k)!=="svelte-1qm19xe"&&(k.innerHTML=Ke),Ot=s(t),J(Q.$$.fragment,t),Kt=s(t),J($.$$.fragment,t),te=s(t),J(D.$$.fragment,t),ee=s(t),P=o(t,"P",{"data-svelte-h":!0}),c(P)!=="svelte-hzxcyx"&&(P.innerHTML=tl),le=s(t),C=o(t,"BLOCKQUOTE",{});var Xt=Ve(C);It=o(Xt,"P",{"data-svelte-h":!0}),c(It)!=="svelte-a2o98p"&&(It.textContent=el),Le=s(Xt),J(q.$$.fragment,Xt),Xt.forEach(l),ae=s(t),O=o(t,"P",{"data-svelte-h":!0}),c(O)!=="svelte-1rg63kt"&&(O.innerHTML=ll),ie=s(t),J(K.$$.fragment,t),ne=s(t),tt=o(t,"P",{"data-svelte-h":!0}),c(tt)!=="svelte-1ts1ezg"&&(tt.textContent=al),re=s(t),J(et.$$.fragment,t),se=s(t),lt=o(t,"P",{"data-svelte-h":!0}),c(lt)!=="svelte-15segnh"&&(lt.textContent=il),Me=s(t),J(at.$$.fragment,t),me=s(t),J(it.$$.fragment,t),pe=s(t),nt=o(t,"P",{"data-svelte-h":!0}),c(nt)!=="svelte-xnq3c6"&&(nt.textContent=nl),oe=s(t),rt=o(t,"UL",{"data-svelte-h":!0}),c(rt)!=="svelte-wpo5wn"&&(rt.innerHTML=rl),fe=s(t),st=o(t,"P",{"data-svelte-h":!0}),c(st)!=="svelte-7sp0p4"&&(st.textContent=sl),ue=s(t),J(Mt.$$.fragment,t),ce=s(t),J(mt.$$.fragment,t),we=s(t),pt=o(t,"P",{"data-svelte-h":!0}),c(pt)!=="svelte-yvv2tq"&&(pt.textContent=Ml),Je=s(t),ot=o(t,"UL",{"data-svelte-h":!0}),c(ot)!=="svelte-14g5f8g"&&(ot.innerHTML=ml),ye=s(t),J(ft.$$.fragment,t),Te=s(t),ut=o(t,"P",{"data-svelte-h":!0}),c(ut)!=="svelte-1ngexd8"&&(ut.innerHTML=pl),de=s(t),J(ct.$$.fragment,t),he=s(t),J(wt.$$.fragment,t),Ue=s(t),Jt=o(t,"P",{"data-svelte-h":!0}),c(Jt)!=="svelte-rk9vlj"&&(Jt.textContent=ol),_e=s(t),yt=o(t,"P",{"data-svelte-h":!0}),c(yt)!=="svelte-1voypz1"&&(yt.innerHTML=fl),ge=s(t),J(Tt.$$.fragment,t),je=s(t),dt=o(t,"P",{"data-svelte-h":!0}),c(dt)!=="svelte-vt284o"&&(dt.innerHTML=ul),be=s(t),J(ht.$$.fragment,t),$e=s(t),J(Ut.$$.fragment,t),Ce=s(t),_t=o(t,"P",{"data-svelte-h":!0}),c(_t)!=="svelte-jhy2j4"&&(_t.innerHTML=cl),Xe=s(t),J(gt.$$.fragment,t),Ie=s(t),jt=o(t,"P",{"data-svelte-h":!0}),c(jt)!=="svelte-jx8oo9"&&(jt.innerHTML=wl),Ae=s(t),bt=o(t,"P",{"data-svelte-h":!0}),c(bt)!=="svelte-1rlq1wj"&&(bt.innerHTML=Jl),ve=s(t),$t=o(t,"P",{"data-svelte-h":!0}),c($t)!=="svelte-e0p2jd"&&($t.textContent=yl),We=s(t),J(Ct.$$.fragment,t),Ze=s(t),At=o(t,"P",{}),Ve(At).forEach(l),this.h()},h(){dl(i,"name","hf:doc:metadata"),dl(i,"content",Rl)},m(t,e){Ne(document.head,i),a(t,u,e),a(t,n,e),a(t,m,e),y(f,t,e),a(t,M,e),a(t,U,e),a(t,vt,e),a(t,X,e),a(t,Wt,e),a(t,I,e),a(t,Zt,e),a(t,A,e),a(t,xt,e),a(t,v,e),a(t,Rt,e),y(W,t,e),a(t,Gt,e),a(t,Z,e),a(t,Lt,e),y(x,t,e),a(t,Vt,e),a(t,R,e),a(t,Nt,e),a(t,G,e),a(t,Bt,e),a(t,L,e),a(t,Ft,e),y(V,t,e),a(t,Yt,e),a(t,N,e),a(t,zt,e),y(B,t,e),a(t,St,e),y(F,t,e),a(t,Et,e),y(b,t,e),a(t,Ht,e),y(Y,t,e),a(t,kt,e),a(t,z,e),a(t,Qt,e),a(t,S,e),a(t,Dt,e),a(t,E,e),a(t,Pt,e),y(H,t,e),a(t,qt,e),a(t,k,e),a(t,Ot,e),y(Q,t,e),a(t,Kt,e),y($,t,e),a(t,te,e),y(D,t,e),a(t,ee,e),a(t,P,e),a(t,le,e),a(t,C,e),Ne(C,It),Ne(C,Le),y(q,C,null),a(t,ae,e),a(t,O,e),a(t,ie,e),y(K,t,e),a(t,ne,e),a(t,tt,e),a(t,re,e),y(et,t,e),a(t,se,e),a(t,lt,e),a(t,Me,e),y(at,t,e),a(t,me,e),y(it,t,e),a(t,pe,e),a(t,nt,e),a(t,oe,e),a(t,rt,e),a(t,fe,e),a(t,st,e),a(t,ue,e),y(Mt,t,e),a(t,ce,e),y(mt,t,e),a(t,we,e),a(t,pt,e),a(t,Je,e),a(t,ot,e),a(t,ye,e),y(ft,t,e),a(t,Te,e),a(t,ut,e),a(t,de,e),y(ct,t,e),a(t,he,e),y(wt,t,e),a(t,Ue,e),a(t,Jt,e),a(t,_e,e),a(t,yt,e),a(t,ge,e),y(Tt,t,e),a(t,je,e),a(t,dt,e),a(t,be,e),y(ht,t,e),a(t,$e,e),y(Ut,t,e),a(t,Ce,e),a(t,_t,e),a(t,Xe,e),y(gt,t,e),a(t,Ie,e),a(t,jt,e),a(t,Ae,e),a(t,bt,e),a(t,ve,e),a(t,$t,e),a(t,We,e),y(Ct,t,e),a(t,Ze,e),a(t,At,e),xe=!0},p(t,[e]){const Xt={};e&2&&(Xt.$$scope={dirty:e,ctx:t}),b.$set(Xt);const Tl={};e&2&&(Tl.$$scope={dirty:e,ctx:t}),$.$set(Tl)},i(t){xe||(T(f.$$.fragment,t),T(W.$$.fragment,t),T(x.$$.fragment,t),T(V.$$.fragment,t),T(B.$$.fragment,t),T(F.$$.fragment,t),T(b.$$.fragment,t),T(Y.$$.fragment,t),T(H.$$.fragment,t),T(Q.$$.fragment,t),T($.$$.fragment,t),T(D.$$.fragment,t),T(q.$$.fragment,t),T(K.$$.fragment,t),T(et.$$.fragment,t),T(at.$$.fragment,t),T(it.$$.fragment,t),T(Mt.$$.fragment,t),T(mt.$$.fragment,t),T(ft.$$.fragment,t),T(ct.$$.fragment,t),T(wt.$$.fragment,t),T(Tt.$$.fragment,t),T(ht.$$.fragment,t),T(Ut.$$.fragment,t),T(gt.$$.fragment,t),T(Ct.$$.fragment,t),xe=!0)},o(t){d(f.$$.fragment,t),d(W.$$.fragment,t),d(x.$$.fragment,t),d(V.$$.fragment,t),d(B.$$.fragment,t),d(F.$$.fragment,t),d(b.$$.fragment,t),d(Y.$$.fragment,t),d(H.$$.fragment,t),d(Q.$$.fragment,t),d($.$$.fragment,t),d(D.$$.fragment,t),d(q.$$.fragment,t),d(K.$$.fragment,t),d(et.$$.fragment,t),d(at.$$.fragment,t),d(it.$$.fragment,t),d(Mt.$$.fragment,t),d(mt.$$.fragment,t),d(ft.$$.fragment,t),d(ct.$$.fragment,t),d(wt.$$.fragment,t),d(Tt.$$.fragment,t),d(ht.$$.fragment,t),d(Ut.$$.fragment,t),d(gt.$$.fragment,t),d(Ct.$$.fragment,t),xe=!1},d(t){t&&(l(u),l(n),l(m),l(M),l(U),l(vt),l(X),l(Wt),l(I),l(Zt),l(A),l(xt),l(v),l(Rt),l(Gt),l(Z),l(Lt),l(Vt),l(R),l(Nt),l(G),l(Bt),l(L),l(Ft),l(Yt),l(N),l(zt),l(St),l(Et),l(Ht),l(kt),l(z),l(Qt),l(S),l(Dt),l(E),l(Pt),l(qt),l(k),l(Ot),l(Kt),l(te),l(ee),l(P),l(le),l(C),l(ae),l(O),l(ie),l(ne),l(tt),l(re),l(se),l(lt),l(Me),l(me),l(pe),l(nt),l(oe),l(rt),l(fe),l(st),l(ue),l(ce),l(we),l(pt),l(Je),l(ot),l(ye),l(Te),l(ut),l(de),l(he),l(Ue),l(Jt),l(_e),l(yt),l(ge),l(je),l(dt),l(be),l($e),l(Ce),l(_t),l(Xe),l(Ie),l(jt),l(Ae),l(bt),l(ve),l($t),l(We),l(Ze),l(At)),l(i),h(f,t),h(W,t),h(x,t),h(V,t),h(B,t),h(F,t),h(b,t),h(Y,t),h(H,t),h(Q,t),h($,t),h(D,t),h(q),h(K,t),h(et,t),h(at,t),h(it,t),h(Mt,t),h(mt,t),h(ft,t),h(ct,t),h(wt,t),h(Tt,t),h(ht,t),h(Ut,t),h(gt,t),h(Ct,t)}}}const Rl='{"title":"Train with a script","local":"train-with-a-script","sections":[{"title":"Setup","local":"setup","sections":[],"depth":2},{"title":"Run a script","local":"run-a-script","sections":[],"depth":2},{"title":"Distributed training and mixed precision","local":"distributed-training-and-mixed-precision","sections":[],"depth":2},{"title":"Run a script on a TPU","local":"run-a-script-on-a-tpu","sections":[],"depth":2},{"title":"Run a script with 🤗 Accelerate","local":"run-a-script-with--accelerate","sections":[],"depth":2},{"title":"Use a custom dataset","local":"use-a-custom-dataset","sections":[],"depth":2},{"title":"Test a script","local":"test-a-script","sections":[],"depth":2},{"title":"Resume training from checkpoint","local":"resume-training-from-checkpoint","sections":[],"depth":2},{"title":"Share your model","local":"share-your-model","sections":[],"depth":2}],"depth":1}';function Gl(g){return _l(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Yl extends gl{constructor(i){super(),jl(this,i,Gl,xl,Ul,{})}}export{Yl as component};
