import{s as $t,n as ot,o as Ct}from"../chunks/scheduler.9bc65507.js";import{S as xt,i as ct,g as f,s as i,r as y,A as vt,h as r,f as n,c as a,j as _t,u as L,x as p,k as Pt,y as Ut,a as l,v as H,d as M,t as A,w as S}from"../chunks/index.707bf1b6.js";import{H as E}from"../chunks/Heading.342b1fa6.js";function ht(tt){let s,I,w,j,m,q,u,et=`大規模なトランスフォーマーモデルのトレーニングおよび本番環境への展開はさまざまな課題を提起します。
トレーニング中には、モデルが利用可能なGPUメモリよりも多くを必要としたり、トレーニング速度が遅かったりする可能性があります。
デプロイフェーズでは、モデルが本番環境で必要なスループットを処理するのに苦労することがあります。`,z,_,nt=`このドキュメンテーションは、これらの課題を克服し、ユースケースに最適な設定を見つけるのに役立つことを目的としています。
ガイドはトレーニングと推論のセクションに分かれており、それぞれ異なる課題と解決策が存在します。
各セクション内には、トレーニング用のシングルGPU対マルチGPU、推論用のCPU対GPUなど、異なるハードウェア構成用の別々のガイドが用意されています。`,k,P,lt="このドキュメントを出発点として、シナリオに合った方法に進むための情報源としてご利用ください。",F,$,R,o,it=`大規模なトランスフォーマーモデルを効率的にトレーニングするには、GPUやTPUなどのアクセラレータが必要です。
最も一般的なケースは、シングルGPUがある場合です。シングルGPUでのトレーニング効率を最適化するための一般的なアプローチを学ぶには、以下を参照してください。`,X,C,at='<li><a href="perf_train_gpu_one">シングルGPUでの効率的なトレーニングのための方法とツール</a>: GPUメモリの効果的な利用、トレーニングの高速化などを支援する共通のアプローチを学ぶためにここから始めてください。</li> <li><a href="perf_train_gpu_many">マルチGPUトレーニングセクション</a>: マルチGPU環境に適用されるデータ、テンソル、パイプライン並列性など、さらなる最適化方法について詳細に学びます。</li> <li><a href="perf_train_cpu">CPUトレーニングセクション</a>: CPU上での混合精度トレーニングについて学びます。</li> <li><a href="perf_train_cpu_many">複数CPUでの効率的なトレーニング</a>: 分散CPUトレーニングについて学びます。</li> <li><a href="perf_train_tpu_tf">TensorFlowでTPUを使用したトレーニング</a>: TPUに慣れていない場合は、TPUでのトレーニングとXLAの使用についてのセクションを参照してください。</li> <li><a href="perf_hardware">トレーニングのためのカスタムハードウェア</a>: 独自のディープラーニング環境を構築する際のヒントやトリックを見つけます。</li> <li><a href="hpo_train">Trainer APIを使用したハイパーパラメーター検索</a></li>',B,x,D,c,ft=`本番環境で大規模なモデルを効率的に推論することは、それらをトレーニングすることと同じくらい難しいことがあります。
以下のセクションでは、CPUおよびシングル/マルチGPU環境で推論を実行する手順について説明します。`,J,v,rt='<li><a href="perf_infer_cpu">シングルCPUでの推論</a></li> <li><a href="perf_infer_gpu_one">シングルGPUでの推論</a></li> <li><a href="perf_infer_gpu_many">マルチGPU推論</a></li> <li><a href="tf_xla">TensorFlowモデルのXLA統合</a></li>',K,U,N,h,pt="モデルをトレーニングするか、それを使用して推論を実行するかに関係なく適用されるテクニック、ヒント、トリックがここにあります。",O,T,st='<li><a href="big_models">大規模モデルのインスタンス化</a></li> <li><a href="debugging">パフォーマンスの問題のトラブルシューティング</a></li>',Q,d,V,g,mt=`このドキュメントはまだ完全ではなく、さらに追加する必要がある項目がたくさんあります。
追加や訂正が必要な場合は、遠慮せずにPRをオープンするか、詳細を議論するためにIssueを開始してください。`,W,b,ut="AがBよりも優れているという貢献を行う際には、再現可能なベンチマークやその情報の出典へのリンクを含めてみてください（あなた自身の情報である場合を除く）。",Y,G,Z;return m=new E({props:{title:"Performance and Scalability",local:"performance-and-scalability",headingTag:"h1"}}),$=new E({props:{title:"Training",local:"training",headingTag:"h2"}}),x=new E({props:{title:"Inference",local:"inference",headingTag:"h2"}}),U=new E({props:{title:"Training and inference",local:"training-and-inference",headingTag:"h2"}}),d=new E({props:{title:"Contribute",local:"contribute",headingTag:"h2"}}),{c(){s=f("meta"),I=i(),w=f("p"),j=i(),y(m.$$.fragment),q=i(),u=f("p"),u.textContent=et,z=i(),_=f("p"),_.textContent=nt,k=i(),P=f("p"),P.textContent=lt,F=i(),y($.$$.fragment),R=i(),o=f("p"),o.textContent=it,X=i(),C=f("ul"),C.innerHTML=at,B=i(),y(x.$$.fragment),D=i(),c=f("p"),c.textContent=ft,J=i(),v=f("ul"),v.innerHTML=rt,K=i(),y(U.$$.fragment),N=i(),h=f("p"),h.textContent=pt,O=i(),T=f("ul"),T.innerHTML=st,Q=i(),y(d.$$.fragment),V=i(),g=f("p"),g.textContent=mt,W=i(),b=f("p"),b.textContent=ut,Y=i(),G=f("p"),this.h()},l(t){const e=vt("svelte-u9bgzb",document.head);s=r(e,"META",{name:!0,content:!0}),e.forEach(n),I=a(t),w=r(t,"P",{}),_t(w).forEach(n),j=a(t),L(m.$$.fragment,t),q=a(t),u=r(t,"P",{"data-svelte-h":!0}),p(u)!=="svelte-1ba1wy3"&&(u.textContent=et),z=a(t),_=r(t,"P",{"data-svelte-h":!0}),p(_)!=="svelte-1v7sbcj"&&(_.textContent=nt),k=a(t),P=r(t,"P",{"data-svelte-h":!0}),p(P)!=="svelte-11kz8me"&&(P.textContent=lt),F=a(t),L($.$$.fragment,t),R=a(t),o=r(t,"P",{"data-svelte-h":!0}),p(o)!=="svelte-l3gevf"&&(o.textContent=it),X=a(t),C=r(t,"UL",{"data-svelte-h":!0}),p(C)!=="svelte-1xio3b8"&&(C.innerHTML=at),B=a(t),L(x.$$.fragment,t),D=a(t),c=r(t,"P",{"data-svelte-h":!0}),p(c)!=="svelte-1s7en6c"&&(c.textContent=ft),J=a(t),v=r(t,"UL",{"data-svelte-h":!0}),p(v)!=="svelte-di2vlx"&&(v.innerHTML=rt),K=a(t),L(U.$$.fragment,t),N=a(t),h=r(t,"P",{"data-svelte-h":!0}),p(h)!=="svelte-bx4mq5"&&(h.textContent=pt),O=a(t),T=r(t,"UL",{"data-svelte-h":!0}),p(T)!=="svelte-14t6nld"&&(T.innerHTML=st),Q=a(t),L(d.$$.fragment,t),V=a(t),g=r(t,"P",{"data-svelte-h":!0}),p(g)!=="svelte-1672qac"&&(g.textContent=mt),W=a(t),b=r(t,"P",{"data-svelte-h":!0}),p(b)!=="svelte-jhia4z"&&(b.textContent=ut),Y=a(t),G=r(t,"P",{}),_t(G).forEach(n),this.h()},h(){Pt(s,"name","hf:doc:metadata"),Pt(s,"content",Tt)},m(t,e){Ut(document.head,s),l(t,I,e),l(t,w,e),l(t,j,e),H(m,t,e),l(t,q,e),l(t,u,e),l(t,z,e),l(t,_,e),l(t,k,e),l(t,P,e),l(t,F,e),H($,t,e),l(t,R,e),l(t,o,e),l(t,X,e),l(t,C,e),l(t,B,e),H(x,t,e),l(t,D,e),l(t,c,e),l(t,J,e),l(t,v,e),l(t,K,e),H(U,t,e),l(t,N,e),l(t,h,e),l(t,O,e),l(t,T,e),l(t,Q,e),H(d,t,e),l(t,V,e),l(t,g,e),l(t,W,e),l(t,b,e),l(t,Y,e),l(t,G,e),Z=!0},p:ot,i(t){Z||(M(m.$$.fragment,t),M($.$$.fragment,t),M(x.$$.fragment,t),M(U.$$.fragment,t),M(d.$$.fragment,t),Z=!0)},o(t){A(m.$$.fragment,t),A($.$$.fragment,t),A(x.$$.fragment,t),A(U.$$.fragment,t),A(d.$$.fragment,t),Z=!1},d(t){t&&(n(I),n(w),n(j),n(q),n(u),n(z),n(_),n(k),n(P),n(F),n(R),n(o),n(X),n(C),n(B),n(D),n(c),n(J),n(v),n(K),n(N),n(h),n(O),n(T),n(Q),n(V),n(g),n(W),n(b),n(Y),n(G)),n(s),S(m,t),S($,t),S(x,t),S(U,t),S(d,t)}}}const Tt='{"title":"Performance and Scalability","local":"performance-and-scalability","sections":[{"title":"Training","local":"training","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2},{"title":"Training and inference","local":"training-and-inference","sections":[],"depth":2},{"title":"Contribute","local":"contribute","sections":[],"depth":2}],"depth":1}';function dt(tt){return Ct(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gt extends xt{constructor(s){super(),ct(this,s,dt,ht,$t,{})}}export{Gt as component};
