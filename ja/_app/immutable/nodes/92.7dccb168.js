import{s as At,o as xt,n as Me}from"../chunks/scheduler.9bc65507.js";import{S as zt,i as jt,g as p,s as a,r as u,A as Pt,h as m,f as s,c as r,j as F,u as f,x as k,k as W,y as i,a as l,v as h,d as g,t as _,w as b}from"../chunks/index.707bf1b6.js";import{T as wt}from"../chunks/Tip.c2ecdbf4.js";import{D as R}from"../chunks/Docstring.17db21ae.js";import{C as dt}from"../chunks/CodeBlock.54a9f38d.js";import{E as lt}from"../chunks/ExampleCodeBlock.4f515aa9.js";import{H as ce}from"../chunks/Heading.342b1fa6.js";function Lt(A){let t,C="Example:",d,c,T;return c=new dt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMENwbUFudE1vZGVsJTJDJTIwQ3BtQW50Q29uZmlnJTBBJTBBJTIzJTIwSW5pdGlhbGl6aW5nJTIwYSUyMENQTUFudCUyMGNwbS1hbnQtMTBiJTIwc3R5bGUlMjBjb25maWd1cmF0aW9uJTBBY29uZmlndXJhdGlvbiUyMCUzRCUyMENwbUFudENvbmZpZygpJTBBJTBBJTIzJTIwSW5pdGlhbGl6aW5nJTIwYSUyMG1vZGVsJTIwZnJvbSUyMHRoZSUyMGNwbS1hbnQtMTBiJTIwc3R5bGUlMjBjb25maWd1cmF0aW9uJTBBbW9kZWwlMjAlM0QlMjBDcG1BbnRNb2RlbChjb25maWd1cmF0aW9uKSUwQSUwQSUyMyUyMEFjY2Vzc2luZyUyMHRoZSUyMG1vZGVsJTIwY29uZmlndXJhdGlvbiUwQWNvbmZpZ3VyYXRpb24lMjAlM0QlMjBtb2RlbC5jb25maWc=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> CpmAntModel, CpmAntConfig

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Initializing a CPMAnt cpm-ant-10b style configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>configuration = CpmAntConfig()

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Initializing a model from the cpm-ant-10b style configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model = CpmAntModel(configuration)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Accessing the model configuration</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>configuration = model.config`,wrap:!1}}),{c(){t=p("p"),t.textContent=C,d=a(),u(c.$$.fragment)},l(n){t=m(n,"P",{"data-svelte-h":!0}),k(t)!=="svelte-11lpom8"&&(t.textContent=C),d=r(n),f(c.$$.fragment,n)},m(n,v){l(n,t,v),l(n,d,v),h(c,n,v),T=!0},p:Me,i(n){T||(g(c.$$.fragment,n),T=!0)},o(n){_(c.$$.fragment,n),T=!1},d(n){n&&(s(t),s(d)),b(c,n)}}}function Jt(A){let t,C=`Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`;return{c(){t=p("p"),t.innerHTML=C},l(d){t=m(d,"P",{"data-svelte-h":!0}),k(t)!=="svelte-fincs2"&&(t.innerHTML=C)},m(d,c){l(d,t,c)},p:Me,d(d){d&&s(t)}}}function qt(A){let t,C="Example:",d,c,T;return c=new dt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBDcG1BbnRNb2RlbCUwQWltcG9ydCUyMHRvcmNoJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyb3BlbmJtYiUyRmNwbS1hbnQtMTBiJTIyKSUwQW1vZGVsJTIwJTNEJTIwQ3BtQW50TW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMm9wZW5ibWIlMkZjcG0tYW50LTEwYiUyMiklMEElMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoJTIySGVsbG8lMkMlMjBteSUyMGRvZyUyMGlzJTIwY3V0ZSUyMiUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKSUwQSUwQWxhc3RfaGlkZGVuX3N0YXRlcyUyMCUzRCUyMG91dHB1dHMubGFzdF9oaWRkZW5fc3RhdGU=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, CpmAntModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;openbmb/cpm-ant-10b&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = CpmAntModel.from_pretrained(<span class="hljs-string">&quot;openbmb/cpm-ant-10b&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)

<span class="hljs-meta">&gt;&gt;&gt; </span>last_hidden_states = outputs.last_hidden_state`,wrap:!1}}),{c(){t=p("p"),t.textContent=C,d=a(),u(c.$$.fragment)},l(n){t=m(n,"P",{"data-svelte-h":!0}),k(t)!=="svelte-11lpom8"&&(t.textContent=C),d=r(n),f(c.$$.fragment,n)},m(n,v){l(n,t,v),l(n,d,v),h(c,n,v),T=!0},p:Me,i(n){T||(g(c.$$.fragment,n),T=!0)},o(n){_(c.$$.fragment,n),T=!1},d(n){n&&(s(t),s(d)),b(c,n)}}}function Ft(A){let t,C=`Although the recipe for forward pass needs to be defined within this function, one should call the <code>Module</code>
instance afterwards instead of this since the former takes care of running the pre and post processing steps while
the latter silently ignores them.`;return{c(){t=p("p"),t.innerHTML=C},l(d){t=m(d,"P",{"data-svelte-h":!0}),k(t)!=="svelte-fincs2"&&(t.innerHTML=C)},m(d,c){l(d,t,c)},p:Me,d(d){d&&s(t)}}}function Wt(A){let t,C="Example:",d,c,T;return c=new dt({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b1Rva2VuaXplciUyQyUyMENwbUFudEZvckNhdXNhbExNJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyb3BlbmJtYiUyRmNwbS1hbnQtMTBiJTIyKSUwQW1vZGVsJTIwJTNEJTIwQ3BtQW50Rm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKCUyMm9wZW5ibWIlMkZjcG0tYW50LTEwYiUyMiklMEElMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoJTIySGVsbG8lMkMlMjBteSUyMGRvZyUyMGlzJTIwY3V0ZSUyMiUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzJTJDJTIwbGFiZWxzJTNEaW5wdXRzJTVCJTIyaW5wdXRfaWRzJTIyJTVEKSUwQWxvc3MlMjAlM0QlMjBvdXRwdXRzLmxvc3MlMEFsb2dpdHMlMjAlM0QlMjBvdXRwdXRzLmxvZ2l0cw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, CpmAntForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;openbmb/cpm-ant-10b&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = CpmAntForCausalLM.from_pretrained(<span class="hljs-string">&quot;openbmb/cpm-ant-10b&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Hello, my dog is cute&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs, labels=inputs[<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>loss = outputs.loss
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`,wrap:!1}}),{c(){t=p("p"),t.textContent=C,d=a(),u(c.$$.fragment)},l(n){t=m(n,"P",{"data-svelte-h":!0}),k(t)!=="svelte-11lpom8"&&(t.textContent=C),d=r(n),f(c.$$.fragment,n)},m(n,v){l(n,t,v),l(n,d,v),h(c,n,v),T=!0},p:Me,i(n){T||(g(c.$$.fragment,n),T=!0)},o(n){_(c.$$.fragment,n),T=!1},d(n){n&&(s(t),s(d)),b(c,n)}}}function It(A){let t,C,d,c,T,n,v,we,N,ct='CPM-Ant は、10B パラメータを備えたオープンソースの中国語の事前トレーニング済み言語モデル (PLM) です。これは、CPM-Live のライブ トレーニング プロセスの最初のマイルストーンでもあります。トレーニングプロセスは費用対効果が高く、環境に優しいものです。 CPM-Ant は、CUGE ベンチマークでのデルタ チューニングでも有望な結果を達成しています。フル モデルに加えて、さまざまなハードウェア構成の要件を満たすさまざまな圧縮バージョンも提供しています。 <a href="https://github.com/OpenBMB/CPM-Live/tree/cpm-ant/cpm-live" rel="nofollow">詳細を見る</a>',Ae,O,pt='このモデルは <a href="https://huggingface.co/openbmb" rel="nofollow">OpenBMB</a> によって提供されました。元のコードは <a href="https://github.com/OpenBMB/CPM-Live/tree/cpm-ant/cpm-live" rel="nofollow">ここ</a> にあります。',xe,S,ze,D,mt='<li><a href="https://github.com/OpenBMB/CPM-Live/tree/cpm-ant/cpm-live" rel="nofollow">CPM-Live</a> に関するチュートリアル。</li>',je,X,Pe,$,Y,He,pe,ut=`This is the configuration class to store the configuration of a <a href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntModel">CpmAntModel</a>. It is used to instantiate an
CPMAnt model according to the specified arguments, defining the model architecture. Instantiating a configuration
with the defaults will yield a similar configuration to that of the CPMAnt
<a href="https://huggingface.co/openbmb/cpm-ant-10b" rel="nofollow">openbmb/cpm-ant-10b</a> architecture.`,Ze,me,ft=`Configuration objects inherit from <a href="/docs/transformers/main/ja/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a> and can be used to control the model outputs. Read the
documentation from <a href="/docs/transformers/main/ja/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a> for more information.`,Ge,B,Le,K,Je,M,ee,Ee,ue,ht="Construct a CPMAnt tokenizer. Based on byte-level Byte-Pair-Encoding.",Ve,J,te,Qe,fe,gt=`Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
adding special tokens. A CPMAnt sequence has the following format:`,Re,he,_t="<li>single sequence: <code>[BOS] Sequence</code>.</li>",Ne,U,ne,Oe,ge,bt=`Retrieve sequence ids from a token list that has no special tokens added. This method is called when adding
special tokens using the tokenizer <code>prepare_for_model</code> method.`,qe,oe,Fe,w,se,Se,_e,Tt=`The bare CPMAnt Model outputting raw hidden-states without any specific head on top.
This model is a PyTorch <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow">torch.nn.Module</a> sub-class. Use
it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and
behavior.`,De,be,kt=`Parameters
config (<a href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntConfig">~CpmAntConfig</a>): Model configuration class with all the parameters of the
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,Xe,x,ae,Ye,Te,Ct='The <a href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntModel">CpmAntModel</a> forward method, overrides the <code>__call__</code> special method.',Ke,H,et,Z,We,re,Ie,y,ie,tt,ke,vt="The CPMAnt Model with a language modeling head on top (linear layer with weights tied to the input embeddings).",nt,Ce,yt=`This model is a PyTorch <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow">torch.nn.Module</a> sub-class. Use
it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to general usage and
behavior.`,ot,ve,$t=`Parameters
config (<a href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntConfig">~CpmAntConfig</a>): Model configuration class with all the parameters of the
Initializing with a config file does not load the weights associated with the model, only the
configuration. Check out the <a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a> method to load the model weights.`,st,z,le,at,ye,Mt='The <a href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntForCausalLM">CpmAntForCausalLM</a> forward method, overrides the <code>__call__</code> special method.',rt,G,it,E,Be,$e,Ue;return T=new ce({props:{title:"CPMAnt",local:"cpmant",headingTag:"h1"}}),v=new ce({props:{title:"Overview",local:"overview",headingTag:"h2"}}),S=new ce({props:{title:"Resources",local:"resources",headingTag:"h2"}}),X=new ce({props:{title:"CpmAntConfig",local:"transformers.CpmAntConfig",headingTag:"h2"}}),Y=new R({props:{name:"class transformers.CpmAntConfig",anchor:"transformers.CpmAntConfig",parameters:[{name:"vocab_size",val:": int = 30720"},{name:"hidden_size",val:": int = 4096"},{name:"num_attention_heads",val:": int = 32"},{name:"dim_head",val:": int = 128"},{name:"dim_ff",val:": int = 10240"},{name:"num_hidden_layers",val:": int = 48"},{name:"dropout_p",val:": int = 0.0"},{name:"position_bias_num_buckets",val:": int = 512"},{name:"position_bias_max_distance",val:": int = 2048"},{name:"eps",val:": int = 1e-06"},{name:"init_std",val:": float = 1.0"},{name:"prompt_types",val:": int = 32"},{name:"prompt_length",val:": int = 32"},{name:"segment_types",val:": int = 32"},{name:"use_cache",val:": bool = True"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.CpmAntConfig.vocab_size",description:`<strong>vocab_size</strong> (<code>int</code>, <em>optional</em>, defaults to 30720) &#x2014;
Vocabulary size of the CPMAnt model. Defines the number of different tokens that can be represented by the
<code>input</code> passed when calling <a href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntModel">CpmAntModel</a>.`,name:"vocab_size"},{anchor:"transformers.CpmAntConfig.hidden_size",description:`<strong>hidden_size</strong> (<code>int</code>, <em>optional</em>, defaults to 4096) &#x2014;
Dimension of the encoder layers.`,name:"hidden_size"},{anchor:"transformers.CpmAntConfig.num_attention_heads",description:`<strong>num_attention_heads</strong> (<code>int</code>, <em>optional</em>, defaults to 32) &#x2014;
Number of attention heads in the Transformer encoder.`,name:"num_attention_heads"},{anchor:"transformers.CpmAntConfig.dim_head",description:`<strong>dim_head</strong> (<code>int</code>, <em>optional</em>, defaults to 128) &#x2014;
Dimension of attention heads for each attention layer in the Transformer encoder.`,name:"dim_head"},{anchor:"transformers.CpmAntConfig.dim_ff",description:`<strong>dim_ff</strong> (<code>int</code>, <em>optional</em>, defaults to 10240) &#x2014;
Dimension of the &#x201C;intermediate&#x201D; (i.e., feed-forward) layer in the Transformer encoder.`,name:"dim_ff"},{anchor:"transformers.CpmAntConfig.num_hidden_layers",description:`<strong>num_hidden_layers</strong> (<code>int</code>, <em>optional</em>, defaults to 48) &#x2014;
Number of layers of the Transformer encoder.`,name:"num_hidden_layers"},{anchor:"transformers.CpmAntConfig.dropout_p",description:`<strong>dropout_p</strong> (<code>float</code>, <em>optional</em>, defaults to 0.0) &#x2014;
The dropout probability for all fully connected layers in the embeddings, encoder.`,name:"dropout_p"},{anchor:"transformers.CpmAntConfig.position_bias_num_buckets",description:`<strong>position_bias_num_buckets</strong> (<code>int</code>, <em>optional</em>, defaults to 512) &#x2014;
The number of position_bias buckets.`,name:"position_bias_num_buckets"},{anchor:"transformers.CpmAntConfig.position_bias_max_distance",description:`<strong>position_bias_max_distance</strong> (<code>int</code>, <em>optional</em>, defaults to 2048) &#x2014;
The maximum sequence length that this model might ever be used with. Typically set this to something large
just in case (e.g., 512 or 1024 or 2048).`,name:"position_bias_max_distance"},{anchor:"transformers.CpmAntConfig.eps",description:`<strong>eps</strong> (<code>float</code>, <em>optional</em>, defaults to 1e-06) &#x2014;
The epsilon used by the layer normalization layers.`,name:"eps"},{anchor:"transformers.CpmAntConfig.init_std",description:`<strong>init_std</strong> (<code>float</code>, <em>optional</em>, defaults to 1.0) &#x2014;
Initialize parameters with std = init_std.`,name:"init_std"},{anchor:"transformers.CpmAntConfig.prompt_types",description:`<strong>prompt_types</strong> (<code>int</code>, <em>optional</em>, defaults to 32) &#x2014;
The type of prompt.`,name:"prompt_types"},{anchor:"transformers.CpmAntConfig.prompt_length",description:`<strong>prompt_length</strong> (<code>int</code>, <em>optional</em>, defaults to 32) &#x2014;
The length of prompt.`,name:"prompt_length"},{anchor:"transformers.CpmAntConfig.segment_types",description:`<strong>segment_types</strong> (<code>int</code>, <em>optional</em>, defaults to 32) &#x2014;
The type of segment.`,name:"segment_types"},{anchor:"transformers.CpmAntConfig.use_cache",description:`<strong>use_cache</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether to use cache.`,name:"use_cache"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/configuration_cpmant.py#L29"}}),B=new lt({props:{anchor:"transformers.CpmAntConfig.example",$$slots:{default:[Lt]},$$scope:{ctx:A}}}),K=new ce({props:{title:"CpmAntTokenizer",local:"transformers.CpmAntTokenizer",headingTag:"h2"}}),ee=new R({props:{name:"class transformers.CpmAntTokenizer",anchor:"transformers.CpmAntTokenizer",parameters:[{name:"vocab_file",val:""},{name:"bod_token",val:" = '<d>'"},{name:"eod_token",val:" = '</d>'"},{name:"bos_token",val:" = '<s>'"},{name:"eos_token",val:" = '</s>'"},{name:"pad_token",val:" = '<pad>'"},{name:"unk_token",val:" = '<unk>'"},{name:"line_token",val:" = '</n>'"},{name:"space_token",val:" = '</_>'"},{name:"padding_side",val:" = 'left'"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.CpmAntTokenizer.vocab_file",description:`<strong>vocab_file</strong> (<code>str</code>) &#x2014;
Path to the vocabulary file.`,name:"vocab_file"},{anchor:"transformers.CpmAntTokenizer.bod_token",description:`<strong>bod_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;d&gt;&quot;</code>) &#x2014;
The beginning of document token.`,name:"bod_token"},{anchor:"transformers.CpmAntTokenizer.eod_token",description:`<strong>eod_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/d&gt;&quot;</code>) &#x2014;
The end of document token.`,name:"eod_token"},{anchor:"transformers.CpmAntTokenizer.bos_token",description:`<strong>bos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;s&gt;&quot;</code>) &#x2014;
The beginning of sequence token.`,name:"bos_token"},{anchor:"transformers.CpmAntTokenizer.eos_token",description:`<strong>eos_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/s&gt;&quot;</code>) &#x2014;
The end of sequence token.`,name:"eos_token"},{anchor:"transformers.CpmAntTokenizer.pad_token",description:`<strong>pad_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;pad&gt;&quot;</code>) &#x2014;
The token used for padding.`,name:"pad_token"},{anchor:"transformers.CpmAntTokenizer.unk_token",description:`<strong>unk_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;unk&gt;&quot;</code>) &#x2014;
The unknown token.`,name:"unk_token"},{anchor:"transformers.CpmAntTokenizer.line_token",description:`<strong>line_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/n&gt;&quot;</code>) &#x2014;
The line token.`,name:"line_token"},{anchor:"transformers.CpmAntTokenizer.space_token",description:`<strong>space_token</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&lt;/_&gt;&quot;</code>) &#x2014;
The space token.`,name:"space_token"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/tokenization_cpmant.py#L88"}}),te=new R({props:{name:"build_inputs_with_special_tokens",anchor:"transformers.CpmAntTokenizer.build_inputs_with_special_tokens",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": List = None"}],parametersDescription:[{anchor:"transformers.CpmAntTokenizer.build_inputs_with_special_tokens.token_ids_0",description:"<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014; The first tokenized sequence that special tokens will be added.",name:"token_ids_0"},{anchor:"transformers.CpmAntTokenizer.build_inputs_with_special_tokens.token_ids_1",description:"<strong>token_ids_1</strong> (<code>List[int]</code>) &#x2014; The optional second tokenized sequence that special tokens will be added.",name:"token_ids_1"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/tokenization_cpmant.py#L236",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The model input with special tokens.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),ne=new R({props:{name:"get_special_tokens_mask",anchor:"transformers.CpmAntTokenizer.get_special_tokens_mask",parameters:[{name:"token_ids_0",val:": List"},{name:"token_ids_1",val:": Optional = None"},{name:"already_has_special_tokens",val:": bool = False"}],parametersDescription:[{anchor:"transformers.CpmAntTokenizer.get_special_tokens_mask.token_ids_0",description:"<strong>token_ids_0</strong> (<code>List[int]</code>) &#x2014; List of IDs.",name:"token_ids_0"},{anchor:"transformers.CpmAntTokenizer.get_special_tokens_mask.token_ids_1",description:"<strong>token_ids_1</strong> (<code>List[int]</code>, <em>optional</em>) &#x2014; Optional second list of IDs for sequence pairs.",name:"token_ids_1"},{anchor:"transformers.CpmAntTokenizer.get_special_tokens_mask.already_has_special_tokens",description:`<strong>already_has_special_tokens</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the token list is already formatted with special tokens for the model.`,name:"already_has_special_tokens"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/tokenization_cpmant.py#L254",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),oe=new ce({props:{title:"CpmAntModel",local:"transformers.CpmAntModel",headingTag:"h2"}}),se=new R({props:{name:"class transformers.CpmAntModel",anchor:"transformers.CpmAntModel",parameters:[{name:"config",val:": CpmAntConfig"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/modeling_cpmant.py#L594"}}),ae=new R({props:{name:"forward",anchor:"transformers.CpmAntModel.forward",parameters:[{name:"input_ids",val:": Optional = None"},{name:"output_attentions",val:": Optional = None"},{name:"output_hidden_states",val:": Optional = None"},{name:"past_key_values",val:": Optional = None"},{name:"use_cache",val:": Optional = None"},{name:"return_dict",val:": Optional = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.CpmAntModel.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.Tensor</code> of shape <code>(batch_size, seq_len)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <code>CPMAntTokenizer</code>. See <a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.CpmAntModel.forward.past_key_values",description:`<strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) &#x2014;
Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
blocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.`,name:"past_key_values"},{anchor:"transformers.CpmAntModel.forward.use_cache",description:`<strong>use_cache</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
If set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding (see
<code>past_key_values</code>).`,name:"use_cache"},{anchor:"transformers.CpmAntModel.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers.`,name:"output_attentions"},{anchor:"transformers.CpmAntModel.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers.`,name:"output_hidden_states"},{anchor:"transformers.CpmAntModel.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/main/ja/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/modeling_cpmant.py#L636",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A <a
  href="/docs/transformers/main/ja/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPast"
>transformers.modeling_outputs.BaseModelOutputWithPast</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntConfig"
>CpmAntConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>last_hidden_state</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, hidden_size)</code>) — Sequence of hidden-states at the output of the last layer of the model.</p>
<p>If <code>past_key_values</code> is used only the last hidden-state of the sequences of shape <code>(batch_size, 1, hidden_size)</code> is output.</p>
</li>
<li>
<p><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) — Tuple of <code>tuple(torch.FloatTensor)</code> of length <code>config.n_layers</code>, with each tuple having 2 tensors of shape
<code>(batch_size, num_heads, sequence_length, embed_size_per_head)</code>) and optionally if
<code>config.is_encoder_decoder=True</code> 2 additional tensors of shape <code>(batch_size, num_heads, encoder_sequence_length, embed_size_per_head)</code>.</p>
<p>Contains pre-computed hidden-states (key and values in the self-attention blocks and optionally if
<code>config.is_encoder_decoder=True</code> in the cross-attention blocks) that can be used (see <code>past_key_values</code>
input) to speed up sequential decoding.</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><a
  href="/docs/transformers/main/ja/main_classes/output#transformers.modeling_outputs.BaseModelOutputWithPast"
>transformers.modeling_outputs.BaseModelOutputWithPast</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),H=new wt({props:{$$slots:{default:[Jt]},$$scope:{ctx:A}}}),Z=new lt({props:{anchor:"transformers.CpmAntModel.forward.example",$$slots:{default:[qt]},$$scope:{ctx:A}}}),re=new ce({props:{title:"CpmAntForCausalLM",local:"transformers.CpmAntForCausalLM",headingTag:"h2"}}),ie=new R({props:{name:"class transformers.CpmAntForCausalLM",anchor:"transformers.CpmAntForCausalLM",parameters:[{name:"config",val:": CpmAntConfig"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/modeling_cpmant.py#L739"}}),le=new R({props:{name:"forward",anchor:"transformers.CpmAntForCausalLM.forward",parameters:[{name:"input_ids",val:": Optional = None"},{name:"past_key_values",val:": Optional = None"},{name:"use_cache",val:": Optional = None"},{name:"output_attentions",val:": Optional = None"},{name:"output_hidden_states",val:": Optional = None"},{name:"labels",val:": Optional = None"},{name:"return_dict",val:": Optional = None"},{name:"attention_mask",val:": Optional = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.CpmAntForCausalLM.forward.input_ids",description:`<strong>input_ids</strong> (<code>torch.Tensor</code> of shape <code>(batch_size, seq_len)</code>) &#x2014;
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <code>CPMAntTokenizer</code>. See <a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>`,name:"input_ids"},{anchor:"transformers.CpmAntForCausalLM.forward.past_key_values",description:`<strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) &#x2014;
Contains pre-computed hidden-states (key and values in the self-attention blocks and in the cross-attention
blocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.`,name:"past_key_values"},{anchor:"transformers.CpmAntForCausalLM.forward.use_cache",description:`<strong>use_cache</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
If set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding (see
<code>past_key_values</code>).`,name:"use_cache"},{anchor:"transformers.CpmAntForCausalLM.forward.output_attentions",description:`<strong>output_attentions</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the attentions tensors of all attention layers.`,name:"output_attentions"},{anchor:"transformers.CpmAntForCausalLM.forward.output_hidden_states",description:`<strong>output_hidden_states</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return the hidden states of all layers.`,name:"output_hidden_states"},{anchor:"transformers.CpmAntForCausalLM.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not to return a <a href="/docs/transformers/main/ja/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.</p>
<p>Args &#x2014;
input_ids (<code>torch.Tensor</code> of shape <code>(batch_size, seq_len)</code>):
Indices of input sequence tokens in the vocabulary.</p>
<p>Indices can be obtained using <code>CPMAntTokenizer</code>. See <a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.encode">PreTrainedTokenizer.encode()</a> and
<a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizerFast.__call__">PreTrainedTokenizer.<strong>call</strong>()</a> for details.</p>
<p><a href="../glossary#input-ids">What are input IDs?</a>
past_key_values (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>):
Contains pre-computed hidden-states (key and values in the self-attention blocks and in the
cross-attention blocks) that can be used (see <code>past_key_values</code> input) to speed up sequential decoding.
use_cache (<code>bool</code>, <em>optional</em>):
If set to <code>True</code>, <code>past_key_values</code> key value states are returned and can be used to speed up decoding
(see <code>past_key_values</code>).
output_attentions (<code>bool</code>, <em>optional</em>):
Whether or not to return the attentions tensors of all attention layers.
output_hidden_states (<code>bool</code>, <em>optional</em>):
Whether or not to return the hidden states of all layers.
labels (<code>torch.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>):
Labels for computing the masked language modeling loss.
return_dict (<code>bool</code>, <em>optional</em>):
Whether or not to return a <a href="/docs/transformers/main/ja/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.
attention_mask (<code>torch.Tensor</code> of shape <code>(batch_size, sequence_length)</code>, <em>optional</em>):
CPMAnt will process attention mask automatically, this parameter is a dummy parameter for
text-generation pipeline.</p>
<p>Example &#x2014;`,name:"return_dict"},{anchor:"transformers.CpmAntForCausalLM.forward.Text",description:"<strong>Text</strong> Generation with CpmAntForCausalLM. &#x2014;",name:"Text"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/models/cpmant/modeling_cpmant.py#L758",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A <a
  href="/docs/transformers/main/ja/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithPast"
>transformers.modeling_outputs.CausalLMOutputWithPast</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<a
  href="/docs/transformers/main/ja/model_doc/cpmant#transformers.CpmAntConfig"
>CpmAntConfig</a>) and inputs.</p>
<ul>
<li>
<p><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned when <code>labels</code> is provided) — Language modeling loss (for next-token prediction).</p>
</li>
<li>
<p><strong>logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, sequence_length, config.vocab_size)</code>) — Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).</p>
</li>
<li>
<p><strong>past_key_values</strong> (<code>tuple(tuple(torch.FloatTensor))</code>, <em>optional</em>, returned when <code>use_cache=True</code> is passed or when <code>config.use_cache=True</code>) — Tuple of <code>tuple(torch.FloatTensor)</code> of length <code>config.n_layers</code>, with each tuple having 2 tensors of shape
<code>(batch_size, num_heads, sequence_length, embed_size_per_head)</code>)</p>
<p>Contains pre-computed hidden-states (key and values in the self-attention blocks) that can be used (see
<code>past_key_values</code> input) to speed up sequential decoding.</p>
</li>
<li>
<p><strong>hidden_states</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_hidden_states=True</code> is passed or when <code>config.output_hidden_states=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for the output of the embeddings, if the model has an embedding layer, +
one for the output of each layer) of shape <code>(batch_size, sequence_length, hidden_size)</code>.</p>
<p>Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.</p>
</li>
<li>
<p><strong>attentions</strong> (<code>tuple(torch.FloatTensor)</code>, <em>optional</em>, returned when <code>output_attentions=True</code> is passed or when <code>config.output_attentions=True</code>) — Tuple of <code>torch.FloatTensor</code> (one for each layer) of shape <code>(batch_size, num_heads, sequence_length, sequence_length)</code>.</p>
<p>Attentions weights after the attention softmax, used to compute the weighted average in the self-attention
heads.</p>
</li>
</ul>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><a
  href="/docs/transformers/main/ja/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithPast"
>transformers.modeling_outputs.CausalLMOutputWithPast</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),G=new wt({props:{$$slots:{default:[Ft]},$$scope:{ctx:A}}}),E=new lt({props:{anchor:"transformers.CpmAntForCausalLM.forward.example",$$slots:{default:[Wt]},$$scope:{ctx:A}}}),{c(){t=p("meta"),C=a(),d=p("p"),c=a(),u(T.$$.fragment),n=a(),u(v.$$.fragment),we=a(),N=p("p"),N.innerHTML=ct,Ae=a(),O=p("p"),O.innerHTML=pt,xe=a(),u(S.$$.fragment),ze=a(),D=p("ul"),D.innerHTML=mt,je=a(),u(X.$$.fragment),Pe=a(),$=p("div"),u(Y.$$.fragment),He=a(),pe=p("p"),pe.innerHTML=ut,Ze=a(),me=p("p"),me.innerHTML=ft,Ge=a(),u(B.$$.fragment),Le=a(),u(K.$$.fragment),Je=a(),M=p("div"),u(ee.$$.fragment),Ee=a(),ue=p("p"),ue.textContent=ht,Ve=a(),J=p("div"),u(te.$$.fragment),Qe=a(),fe=p("p"),fe.textContent=gt,Re=a(),he=p("ul"),he.innerHTML=_t,Ne=a(),U=p("div"),u(ne.$$.fragment),Oe=a(),ge=p("p"),ge.innerHTML=bt,qe=a(),u(oe.$$.fragment),Fe=a(),w=p("div"),u(se.$$.fragment),Se=a(),_e=p("p"),_e.innerHTML=Tt,De=a(),be=p("p"),be.innerHTML=kt,Xe=a(),x=p("div"),u(ae.$$.fragment),Ye=a(),Te=p("p"),Te.innerHTML=Ct,Ke=a(),u(H.$$.fragment),et=a(),u(Z.$$.fragment),We=a(),u(re.$$.fragment),Ie=a(),y=p("div"),u(ie.$$.fragment),tt=a(),ke=p("p"),ke.textContent=vt,nt=a(),Ce=p("p"),Ce.innerHTML=yt,ot=a(),ve=p("p"),ve.innerHTML=$t,st=a(),z=p("div"),u(le.$$.fragment),at=a(),ye=p("p"),ye.innerHTML=Mt,rt=a(),u(G.$$.fragment),it=a(),u(E.$$.fragment),Be=a(),$e=p("p"),this.h()},l(e){const o=Pt("svelte-u9bgzb",document.head);t=m(o,"META",{name:!0,content:!0}),o.forEach(s),C=r(e),d=m(e,"P",{}),F(d).forEach(s),c=r(e),f(T.$$.fragment,e),n=r(e),f(v.$$.fragment,e),we=r(e),N=m(e,"P",{"data-svelte-h":!0}),k(N)!=="svelte-1u8yeuk"&&(N.innerHTML=ct),Ae=r(e),O=m(e,"P",{"data-svelte-h":!0}),k(O)!=="svelte-56e9ul"&&(O.innerHTML=pt),xe=r(e),f(S.$$.fragment,e),ze=r(e),D=m(e,"UL",{"data-svelte-h":!0}),k(D)!=="svelte-zuce7s"&&(D.innerHTML=mt),je=r(e),f(X.$$.fragment,e),Pe=r(e),$=m(e,"DIV",{class:!0});var j=F($);f(Y.$$.fragment,j),He=r(j),pe=m(j,"P",{"data-svelte-h":!0}),k(pe)!=="svelte-f7p6ow"&&(pe.innerHTML=ut),Ze=r(j),me=m(j,"P",{"data-svelte-h":!0}),k(me)!=="svelte-1s6wgpv"&&(me.innerHTML=ft),Ge=r(j),f(B.$$.fragment,j),j.forEach(s),Le=r(e),f(K.$$.fragment,e),Je=r(e),M=m(e,"DIV",{class:!0});var P=F(M);f(ee.$$.fragment,P),Ee=r(P),ue=m(P,"P",{"data-svelte-h":!0}),k(ue)!=="svelte-16scib2"&&(ue.textContent=ht),Ve=r(P),J=m(P,"DIV",{class:!0});var I=F(J);f(te.$$.fragment,I),Qe=r(I),fe=m(I,"P",{"data-svelte-h":!0}),k(fe)!=="svelte-1noycua"&&(fe.textContent=gt),Re=r(I),he=m(I,"UL",{"data-svelte-h":!0}),k(he)!=="svelte-9q72go"&&(he.innerHTML=_t),I.forEach(s),Ne=r(P),U=m(P,"DIV",{class:!0});var de=F(U);f(ne.$$.fragment,de),Oe=r(de),ge=m(de,"P",{"data-svelte-h":!0}),k(ge)!=="svelte-1f4f5kp"&&(ge.innerHTML=bt),de.forEach(s),P.forEach(s),qe=r(e),f(oe.$$.fragment,e),Fe=r(e),w=m(e,"DIV",{class:!0});var L=F(w);f(se.$$.fragment,L),Se=r(L),_e=m(L,"P",{"data-svelte-h":!0}),k(_e)!=="svelte-vm2tc8"&&(_e.innerHTML=Tt),De=r(L),be=m(L,"P",{"data-svelte-h":!0}),k(be)!=="svelte-147dyyh"&&(be.innerHTML=kt),Xe=r(L),x=m(L,"DIV",{class:!0});var V=F(x);f(ae.$$.fragment,V),Ye=r(V),Te=m(V,"P",{"data-svelte-h":!0}),k(Te)!=="svelte-1sbwvmg"&&(Te.innerHTML=Ct),Ke=r(V),f(H.$$.fragment,V),et=r(V),f(Z.$$.fragment,V),V.forEach(s),L.forEach(s),We=r(e),f(re.$$.fragment,e),Ie=r(e),y=m(e,"DIV",{class:!0});var q=F(y);f(ie.$$.fragment,q),tt=r(q),ke=m(q,"P",{"data-svelte-h":!0}),k(ke)!=="svelte-12po86d"&&(ke.textContent=vt),nt=r(q),Ce=m(q,"P",{"data-svelte-h":!0}),k(Ce)!=="svelte-68lg8f"&&(Ce.innerHTML=yt),ot=r(q),ve=m(q,"P",{"data-svelte-h":!0}),k(ve)!=="svelte-147dyyh"&&(ve.innerHTML=$t),st=r(q),z=m(q,"DIV",{class:!0});var Q=F(z);f(le.$$.fragment,Q),at=r(Q),ye=m(Q,"P",{"data-svelte-h":!0}),k(ye)!=="svelte-1pkdfn4"&&(ye.innerHTML=Mt),rt=r(Q),f(G.$$.fragment,Q),it=r(Q),f(E.$$.fragment,Q),Q.forEach(s),q.forEach(s),Be=r(e),$e=m(e,"P",{}),F($e).forEach(s),this.h()},h(){W(t,"name","hf:doc:metadata"),W(t,"content",Bt),W($,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),W(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,o){i(document.head,t),l(e,C,o),l(e,d,o),l(e,c,o),h(T,e,o),l(e,n,o),h(v,e,o),l(e,we,o),l(e,N,o),l(e,Ae,o),l(e,O,o),l(e,xe,o),h(S,e,o),l(e,ze,o),l(e,D,o),l(e,je,o),h(X,e,o),l(e,Pe,o),l(e,$,o),h(Y,$,null),i($,He),i($,pe),i($,Ze),i($,me),i($,Ge),h(B,$,null),l(e,Le,o),h(K,e,o),l(e,Je,o),l(e,M,o),h(ee,M,null),i(M,Ee),i(M,ue),i(M,Ve),i(M,J),h(te,J,null),i(J,Qe),i(J,fe),i(J,Re),i(J,he),i(M,Ne),i(M,U),h(ne,U,null),i(U,Oe),i(U,ge),l(e,qe,o),h(oe,e,o),l(e,Fe,o),l(e,w,o),h(se,w,null),i(w,Se),i(w,_e),i(w,De),i(w,be),i(w,Xe),i(w,x),h(ae,x,null),i(x,Ye),i(x,Te),i(x,Ke),h(H,x,null),i(x,et),h(Z,x,null),l(e,We,o),h(re,e,o),l(e,Ie,o),l(e,y,o),h(ie,y,null),i(y,tt),i(y,ke),i(y,nt),i(y,Ce),i(y,ot),i(y,ve),i(y,st),i(y,z),h(le,z,null),i(z,at),i(z,ye),i(z,rt),h(G,z,null),i(z,it),h(E,z,null),l(e,Be,o),l(e,$e,o),Ue=!0},p(e,[o]){const j={};o&2&&(j.$$scope={dirty:o,ctx:e}),B.$set(j);const P={};o&2&&(P.$$scope={dirty:o,ctx:e}),H.$set(P);const I={};o&2&&(I.$$scope={dirty:o,ctx:e}),Z.$set(I);const de={};o&2&&(de.$$scope={dirty:o,ctx:e}),G.$set(de);const L={};o&2&&(L.$$scope={dirty:o,ctx:e}),E.$set(L)},i(e){Ue||(g(T.$$.fragment,e),g(v.$$.fragment,e),g(S.$$.fragment,e),g(X.$$.fragment,e),g(Y.$$.fragment,e),g(B.$$.fragment,e),g(K.$$.fragment,e),g(ee.$$.fragment,e),g(te.$$.fragment,e),g(ne.$$.fragment,e),g(oe.$$.fragment,e),g(se.$$.fragment,e),g(ae.$$.fragment,e),g(H.$$.fragment,e),g(Z.$$.fragment,e),g(re.$$.fragment,e),g(ie.$$.fragment,e),g(le.$$.fragment,e),g(G.$$.fragment,e),g(E.$$.fragment,e),Ue=!0)},o(e){_(T.$$.fragment,e),_(v.$$.fragment,e),_(S.$$.fragment,e),_(X.$$.fragment,e),_(Y.$$.fragment,e),_(B.$$.fragment,e),_(K.$$.fragment,e),_(ee.$$.fragment,e),_(te.$$.fragment,e),_(ne.$$.fragment,e),_(oe.$$.fragment,e),_(se.$$.fragment,e),_(ae.$$.fragment,e),_(H.$$.fragment,e),_(Z.$$.fragment,e),_(re.$$.fragment,e),_(ie.$$.fragment,e),_(le.$$.fragment,e),_(G.$$.fragment,e),_(E.$$.fragment,e),Ue=!1},d(e){e&&(s(C),s(d),s(c),s(n),s(we),s(N),s(Ae),s(O),s(xe),s(ze),s(D),s(je),s(Pe),s($),s(Le),s(Je),s(M),s(qe),s(Fe),s(w),s(We),s(Ie),s(y),s(Be),s($e)),s(t),b(T,e),b(v,e),b(S,e),b(X,e),b(Y),b(B),b(K,e),b(ee),b(te),b(ne),b(oe,e),b(se),b(ae),b(H),b(Z),b(re,e),b(ie),b(le),b(G),b(E)}}}const Bt='{"title":"CPMAnt","local":"cpmant","sections":[{"title":"Overview","local":"overview","sections":[],"depth":2},{"title":"Resources","local":"resources","sections":[],"depth":2},{"title":"CpmAntConfig","local":"transformers.CpmAntConfig","sections":[],"depth":2},{"title":"CpmAntTokenizer","local":"transformers.CpmAntTokenizer","sections":[],"depth":2},{"title":"CpmAntModel","local":"transformers.CpmAntModel","sections":[],"depth":2},{"title":"CpmAntForCausalLM","local":"transformers.CpmAntForCausalLM","sections":[],"depth":2}],"depth":1}';function Ut(A){return xt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Nt extends zt{constructor(t){super(),jt(this,t,Ut,It,At,{})}}export{Nt as component};
