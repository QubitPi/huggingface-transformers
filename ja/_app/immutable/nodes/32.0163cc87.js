import{s as Wo,c as Vo,u as Ro,g as Go,d as qo,o as Yo,n as Va}from"../chunks/scheduler.9bc65507.js";import{S as zo,i as Bo,r as f,u as g,v as h,d,t as p,w as u,g as s,m as No,s as r,h as o,j as v,n as Fo,f as n,c as a,k as $,a as c,y as t,o as Oo,A as Xo,x as i}from"../chunks/index.707bf1b6.js";import{T as Qo}from"../chunks/Tip.c2ecdbf4.js";import{D as C}from"../chunks/Docstring.17db21ae.js";import{C as Qa}from"../chunks/CodeBlock.54a9f38d.js";import{E as So}from"../chunks/ExampleCodeBlock.4f515aa9.js";import{H as Br}from"../chunks/Heading.342b1fa6.js";function Zo(j){let m,x,b,k,M;const _=j[1].default,y=Vo(_,j,j[2],null);return{c(){m=s("p"),x=No("Deprecated in "),b=No(j[0]),k=r(),y&&y.c(),this.h()},l(L){m=o(L,"P",{class:!0});var I=v(m);x=Fo(I,"Deprecated in "),b=Fo(I,j[0]),I.forEach(n),k=a(L),y&&y.l(L),this.h()},h(){$(m,"class","font-medium")},m(L,I){c(L,m,I),t(m,x),t(m,b),c(L,k,I),y&&y.m(L,I),M=!0},p(L,I){(!M||I&1)&&Oo(b,L[0]),y&&y.p&&(!M||I&4)&&Ro(y,_,L,L[2],M?qo(_,L[2],I,null):Go(L[2]),null)},i(L){M||(d(y,L),M=!0)},o(L){p(y,L),M=!1},d(L){L&&(n(m),n(k)),y&&y.d(L)}}}function Ko(j){let m,x;return m=new Qo({props:{warning:!0,$$slots:{default:[Zo]},$$scope:{ctx:j}}}),{c(){f(m.$$.fragment)},l(b){g(m.$$.fragment,b)},m(b,k){h(m,b,k),x=!0},p(b,[k]){const M={};k&5&&(M.$$scope={dirty:k,ctx:b}),m.$set(M)},i(b){x||(d(m.$$.fragment,b),x=!0)},o(b){p(m.$$.fragment,b),x=!1},d(b){u(m,b)}}}function el(j,m,x){let{$$slots:b={},$$scope:k}=m,{version:M}=m;return j.$$set=_=>{"version"in _&&x(0,M=_.version),"$$scope"in _&&x(2,k=_.$$scope)},[M,b,k]}class tl extends zo{constructor(m){super(),Bo(this,m,el,Ko,Wo,{version:0})}}function rl(j){let m,x="Setting <code>WANDB_LOG_MODEL</code> as <code>bool</code> will be deprecated in version 5 of 🤗 Transformers.";return{c(){m=s("p"),m.innerHTML=x},l(b){m=o(b,"P",{"data-svelte-h":!0}),i(m)!=="svelte-fxlq1n"&&(m.innerHTML=x)},m(b,k){c(b,m,k)},p:Va,d(b){b&&n(m)}}}function al(j){let m,x="Example:",b,k,M;return k=new Qa({props:{code:"JTIzJTIwTm90ZSUzQSUyMFRoaXMlMjBleGFtcGxlJTIwc2tpcHMlMjBvdmVyJTIwc29tZSUyMHNldHVwJTIwc3RlcHMlMjBmb3IlMjBicmV2aXR5LiUwQWZyb20lMjBmbHl0ZWtpdCUyMGltcG9ydCUyMGN1cnJlbnRfY29udGV4dCUyQyUyMHRhc2slMEElMEElMEElNDB0YXNrJTBBZGVmJTIwdHJhaW5faGZfdHJhbnNmb3JtZXIoKSUzQSUwQSUyMCUyMCUyMCUyMGNwJTIwJTNEJTIwY3VycmVudF9jb250ZXh0KCkuY2hlY2twb2ludCUwQSUyMCUyMCUyMCUyMHRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKC4uLiUyQyUyMGNhbGxiYWNrcyUzRCU1QkZseXRlQ2FsbGJhY2soKSU1RCklMEElMjAlMjAlMjAlMjBvdXRwdXQlMjAlM0QlMjB0cmFpbmVyLnRyYWluKHJlc3VtZV9mcm9tX2NoZWNrcG9pbnQlM0RjcC5yZXN0b3JlKCkp",highlighted:`<span class="hljs-comment"># Note: This example skips over some setup steps for brevity.</span>
<span class="hljs-keyword">from</span> flytekit <span class="hljs-keyword">import</span> current_context, task


<span class="hljs-meta">@task</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">train_hf_transformer</span>():
    cp = current_context().checkpoint
    trainer = Trainer(..., callbacks=[FlyteCallback()])
    output = trainer.train(resume_from_checkpoint=cp.restore())`,wrap:!1}}),{c(){m=s("p"),m.textContent=x,b=r(),f(k.$$.fragment)},l(_){m=o(_,"P",{"data-svelte-h":!0}),i(m)!=="svelte-11lpom8"&&(m.textContent=x),b=a(_),g(k.$$.fragment,_)},m(_,y){c(_,m,y),c(_,b,y),h(k,_,y),M=!0},p:Va,i(_){M||(d(k.$$.fragment,_),M=!0)},o(_){p(k.$$.fragment,_),M=!1},d(_){_&&(n(m),n(b)),u(k,_)}}}function nl(j){let m,x="Example:",b,k,M;return k=new Qa({props:{code:"Y2xhc3MlMjBQcmludGVyQ2FsbGJhY2soVHJhaW5lckNhbGxiYWNrKSUzQSUwQSUyMCUyMCUyMCUyMGRlZiUyMG9uX2xvZyhzZWxmJTJDJTIwYXJncyUyQyUyMHN0YXRlJTJDJTIwY29udHJvbCUyQyUyMGxvZ3MlM0ROb25lJTJDJTIwKiprd2FyZ3MpJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwXyUyMCUzRCUyMGxvZ3MucG9wKCUyMnRvdGFsX2Zsb3MlMjIlMkMlMjBOb25lKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGlmJTIwc3RhdGUuaXNfbG9jYWxfcHJvY2Vzc196ZXJvJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcHJpbnQobG9ncyk=",highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">PrinterCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_log</span>(<span class="hljs-params">self, args, state, control, logs=<span class="hljs-literal">None</span>, **kwargs</span>):
        _ = logs.pop(<span class="hljs-string">&quot;total_flos&quot;</span>, <span class="hljs-literal">None</span>)
        <span class="hljs-keyword">if</span> state.is_local_process_zero:
            <span class="hljs-built_in">print</span>(logs)`,wrap:!1}}),{c(){m=s("p"),m.textContent=x,b=r(),f(k.$$.fragment)},l(_){m=o(_,"P",{"data-svelte-h":!0}),i(m)!=="svelte-11lpom8"&&(m.textContent=x),b=a(_),g(k.$$.fragment,_)},m(_,y){c(_,m,y),c(_,b,y),h(k,_,y),M=!0},p:Va,i(_){M||(d(k.$$.fragment,_),M=!0)},o(_){p(k.$$.fragment,_),M=!1},d(_){_&&(n(m),n(b)),u(k,_)}}}function sl(j){let m,x=`In all this class, one step is to be understood as one update step. When using gradient accumulation, one update
step may require several forward and backward passes: if you use <code>gradient_accumulation_steps=n</code>, then one update
step requires going through <em>n</em> batches.`;return{c(){m=s("p"),m.innerHTML=x},l(b){m=o(b,"P",{"data-svelte-h":!0}),i(m)!=="svelte-rhwh6p"&&(m.innerHTML=x)},m(b,k){c(b,m,k)},p:Va,d(b){b&&n(m)}}}function ol(j){let m,x,b,k,M,_,y,L=`コールバックは、PyTorch のトレーニング ループの動作をカスタマイズできるオブジェクトです。
トレーニング ループを検査できる <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> (この機能は TensorFlow にはまだ実装されていません)
状態を確認し (進捗レポート、TensorBoard または他の ML プラットフォームへのログ記録など)、決定を下します (初期段階など)。
停止中）。`,I,je,ks=`コールバックは、返される <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerControl">TrainerControl</a> オブジェクトを除けば、「読み取り専用」のコード部分です。
トレーニング ループ内では何も変更できません。トレーニング ループの変更が必要なカスタマイズの場合は、次のことを行う必要があります。
<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> をサブクラス化し、必要なメソッドをオーバーライドします (例については、<a href="trainer">trainer</a> を参照してください)。`,Qr,Ie,ws='デフォルトでは、<code>TrainingArguments.report_to</code> は <code>&quot;all&quot;</code> に設定されているため、<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> は次のコールバックを使用します。',Vr,Ee,Ms=`<li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.DefaultFlowCallback">DefaultFlowCallback</a> は、ログ記録、保存、評価のデフォルトの動作を処理します。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.PrinterCallback">PrinterCallback</a> または <a href="/docs/transformers/main/ja/main_classes/callback#transformers.ProgressCallback">ProgressCallback</a> で進行状況を表示し、
ログ (最初のログは、<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> を通じて tqdm を非アクティブ化する場合に使用され、そうでない場合に使用されます)
2番目です)。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.TensorBoardCallback">TensorBoardCallback</a> (PyTorch &gt;= 1.4 を介して) tensorboard にアクセスできる場合
またはテンソルボードX）。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.WandbCallback">WandbCallback</a> <a href="https://www.wandb.com/" rel="nofollow">wandb</a> がインストールされている場合。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.CometCallback">CometCallback</a> <a href="https://www.comet.ml/site/" rel="nofollow">comet_ml</a> がインストールされている場合。</li> <li><a href="https://www.mlflow.org/" rel="nofollow">mlflow</a> がインストールされている場合は <a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.MLflowCallback">MLflowCallback</a>。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.NeptuneCallback">NeptuneCallback</a> <a href="https://neptune.ai/" rel="nofollow">neptune</a> がインストールされている場合。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.AzureMLCallback">AzureMLCallback</a> <a href="https://pypi.org/project/azureml-sdk/" rel="nofollow">azureml-sdk</a> の場合
インストールされています。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.CodeCarbonCallback">CodeCarbonCallback</a> <a href="https://pypi.org/project/codecarbon/" rel="nofollow">codecarbon</a> の場合
インストールされています。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.ClearMLCallback">ClearMLCallback</a> <a href="https://github.com/allegroai/clearml" rel="nofollow">clearml</a> がインストールされている場合。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.DagsHubCallback">DagsHubCallback</a> <a href="https://dagshub.com/" rel="nofollow">dagshub</a> がインストールされている場合。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.FlyteCallback">FlyteCallback</a> <a href="https://flyte.org/" rel="nofollow">flyte</a> がインストールされている場合。</li> <li><a href="/docs/transformers/main/ja/main_classes/callback#transformers.integrations.DVCLiveCallback">DVCLiveCallback</a> <a href="https://www.dvc.org/doc/dvclive" rel="nofollow">dvclive</a> がインストールされている場合。</li>`,Rr,He,ys="パッケージがインストールされているが、付随する統合を使用したくない場合は、<code>TrainingArguments.report_to</code> を、使用したい統合のみのリストに変更できます (例: <code>[&quot;azure_ml&quot;, &quot;wandb&quot;]</code>) 。",Gr,Pe,xs=`コールバックを実装するメインクラスは <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> です。それは、
<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> は <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> をインスタンス化するために使用され、それにアクセスできます。
<a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerState">TrainerState</a> を介してトレーナーの内部状態を取得し、トレーニング ループ上でいくつかのアクションを実行できます。
<a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerControl">TrainerControl</a>。`,qr,Je,Yr,De,Ls='ライブラリで利用可能な <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> のリストは次のとおりです。',Or,S,Ue,Ra,It,js='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.comet.ml/site/" rel="nofollow">Comet ML</a>.',Ga,H,Ae,qa,Et,Is="Setup the optional Comet.ml integration.",Ya,Ht,Es="Environment:",Oa,Pt,Hs=`<li><strong>COMET_MODE</strong> (<code>str</code>, <em>optional</em>, defaults to <code>ONLINE</code>):
Whether to create an online, offline experiment or disable Comet logging. Can be <code>OFFLINE</code>, <code>ONLINE</code>, or
<code>DISABLED</code>.</li> <li><strong>COMET_PROJECT_NAME</strong> (<code>str</code>, <em>optional</em>):
Comet project name for experiments.</li> <li><strong>COMET_OFFLINE_DIRECTORY</strong> (<code>str</code>, <em>optional</em>):
Folder to use for saving offline experiments when <code>COMET_MODE</code> is <code>OFFLINE</code>.</li> <li><strong>COMET_LOG_ASSETS</strong> (<code>str</code>, <em>optional</em>, defaults to <code>TRUE</code>):
Whether or not to log training assets (tf event logs, checkpoints, etc), to Comet. Can be <code>TRUE</code>, or
<code>FALSE</code>.</li>`,Xa,Jt,Ps=`For a number of configurable items in the environment, see
<a href="https://www.comet.ml/docs/python-sdk/advanced/#comet-configuration-variables" rel="nofollow">here</a>.`,Xr,O,Ne,Za,Dt,Js='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that handles the default flow of the training loop for logs, evaluation and checkpoints.',Zr,X,Fe,Ka,Ut,Ds='A bare <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that just prints the logs.',Kr,Z,Se,en,At,Us='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that displays the progress of training or evaluation.',ea,W,We,tn,Nt,As='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that handles early stopping.',rn,Ft,Ns=`This callback depends on <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> argument <em>load_best_model_at_end</em> functionality to set best_metric
in <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerState">TrainerState</a>. Note that if the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> argument <em>save_steps</em> differs from <em>eval_steps</em>, the
early stopping will not occur until the next save step.`,ta,K,ze,an,St,Fs='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.tensorflow.org/tensorboard" rel="nofollow">TensorBoard</a>.',ra,z,Be,nn,Wt,Ss='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs metrics, media, model checkpoints to <a href="https://www.wandb.com/" rel="nofollow">Weight and Biases</a>.',sn,P,Qe,on,zt,Ws="Setup the optional Weights &amp; Biases (<em>wandb</em>) integration.",ln,Bt,zs=`One can subclass and override this method to customize the setup if needed. Find more information
<a href="https://docs.wandb.ai/guides/integrations/huggingface" rel="nofollow">here</a>. You can also override the following environment
variables:`,cn,Qt,Bs="Environment:",mn,B,Ve,Vt,Qs=`<strong>WANDB_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;false&quot;</code>):
Whether to log model and checkpoints during training. Can be <code>&quot;end&quot;</code>, <code>&quot;checkpoint&quot;</code> or <code>&quot;false&quot;</code>. If set
to <code>&quot;end&quot;</code>, the model will be uploaded at the end of training. If set to <code>&quot;checkpoint&quot;</code>, the checkpoint
will be uploaded every <code>args.save_steps</code> . If set to <code>&quot;false&quot;</code>, the model will not be uploaded. Use along
with <code>load_best_model_at_end()</code> to upload best model.`,dn,ne,pn,Rt,Vs=`<p><strong>WANDB_WATCH</strong> (<code>str</code>, <em>optional</em> defaults to <code>&quot;false&quot;</code>):
Can be <code>&quot;gradients&quot;</code>, <code>&quot;all&quot;</code>, <code>&quot;parameters&quot;</code>, or <code>&quot;false&quot;</code>. Set to <code>&quot;all&quot;</code> to log gradients and
parameters.</p>`,fn,Gt,Rs=`<p><strong>WANDB_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;huggingface&quot;</code>):
Set this to a custom string to store results in a different project.</p>`,gn,qt,Gs=`<p><strong>WANDB_DISABLED</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to disable wandb entirely. Set <code>WANDB_DISABLED=true</code> to disable.</p>`,aa,Q,Re,hn,Yt,qs=`A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.mlflow.org/" rel="nofollow">MLflow</a>. Can be disabled by setting
environment variable <code>DISABLE_MLFLOW_INTEGRATION = TRUE</code>.`,un,A,Ge,bn,Ot,Ys="Setup the optional MLflow integration.",_n,Xt,Os="Environment:",vn,Zt,Xs=`<li><strong>HF_MLFLOW_LOG_ARTIFACTS</strong> (<code>str</code>, <em>optional</em>):
Whether to use MLflow <code>.log_artifact()</code> facility to log artifacts. This only makes sense if logging to a
remote server, e.g. s3 or GCS. If set to <code>True</code> or <em>1</em>, will copy each saved checkpoint on each save in
<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>’s <code>output_dir</code> to the local or remote artifact storage. Using it without a remote
storage will just copy the files to your artifact location.</li> <li><strong>MLFLOW_TRACKING_URI</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&quot;</code>):
Whether to store runs at a specific path or remote server. Default to an empty string which will store runs
at <code>./mlruns</code> locally.</li> <li><strong>MLFLOW_EXPERIMENT_NAME</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
Whether to use an MLflow experiment_name under which to launch the run. Default to <code>None</code> which will point
to the <code>Default</code> experiment in MLflow. Otherwise, it is a case sensitive name of the experiment to be
activated. If an experiment with this name does not exist, a new experiment with this name is created.</li> <li><strong>MLFLOW_TAGS</strong> (<code>str</code>, <em>optional</em>):
A string dump of a dictionary of key/value pair to be added to the MLflow run as tags. Example:
<code>os.environ[&#39;MLFLOW_TAGS&#39;]=&#39;{&quot;release.candidate&quot;: &quot;RC1&quot;, &quot;release.version&quot;: &quot;2.2.0&quot;}&#39;</code>.</li> <li><strong>MLFLOW_NESTED_RUN</strong> (<code>str</code>, <em>optional</em>):
Whether to use MLflow nested runs. If set to <code>True</code> or <em>1</em>, will create a nested run inside the current
run.</li> <li><strong>MLFLOW_RUN_ID</strong> (<code>str</code>, <em>optional</em>):
Allow to reattach to an existing run which can be usefull when resuming training from a checkpoint. When
<code>MLFLOW_RUN_ID</code> environment variable is set, <code>start_run</code> attempts to resume a run with the specified run ID
and other parameters are ignored.</li> <li><strong>MLFLOW_FLATTEN_PARAMS</strong> (<code>str</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to flatten the parameters dictionary before logging.</li>`,na,ee,qe,Tn,Kt,Zs='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://pypi.org/project/azureml-sdk/" rel="nofollow">AzureML</a>.',sa,te,Ye,$n,er,Ks='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that tracks the CO2 emission of training.',oa,V,Oe,Cn,tr,eo='TrainerCallback that sends the logs to <a href="https://app.neptune.ai" rel="nofollow">Neptune</a>.',kn,rr,to=`For instructions and examples, see the <a href="https://docs.neptune.ai/integrations/transformers" rel="nofollow">Transformers integration
guide</a> in the Neptune documentation.`,la,J,Xe,wn,ar,ro='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://clear.ml/" rel="nofollow">ClearML</a>.',Mn,nr,ao="Environment:",yn,sr,no=`<li><strong>CLEARML_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>HuggingFace Transformers</code>):
ClearML project name.</li> <li><strong>CLEARML_TASK</strong> (<code>str</code>, <em>optional</em>, defaults to <code>Trainer</code>):
ClearML task name.</li> <li><strong>CLEARML_LOG_MODEL</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to log models as artifacts during training.</li>`,ia,R,Ze,xn,or,so='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs to <a href="https://dagshub.com/" rel="nofollow">DagsHub</a>. Extends <code>MLflowCallback</code>',Ln,N,Ke,jn,lr,oo="Setup the DagsHub’s Logging integration.",In,ir,lo="Environment:",En,cr,io=`<li><strong>HF_DAGSHUB_LOG_ARTIFACTS</strong> (<code>str</code>, <em>optional</em>):
Whether to save the data and model artifacts for the experiment. Default to <code>False</code>.</li>`,ca,G,et,Hn,mr,co=`A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://flyte.org/" rel="nofollow">Flyte</a>.
NOTE: This callback only works within a Flyte task.`,Pn,se,ma,D,tt,Jn,dr,mo='A <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.dvc.org/doc/dvclive" rel="nofollow">DVCLive</a>.',Dn,pr,po=`Use the environment variables below in <code>setup</code> to configure the integration. To customize this callback beyond
those environment variables, see <a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface" rel="nofollow">here</a>.`,Un,F,rt,An,fr,fo=`Setup the optional DVCLive integration. To customize this callback beyond the environment variables below, see
<a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface" rel="nofollow">here</a>.`,Nn,gr,go="Environment:",Fn,hr,ho=`<li><strong>HF_DVCLIVE_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>):
Whether to use <code>dvclive.Live.log_artifact()</code> to log checkpoints created by <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>. If set to <code>True</code> or
<em>1</em>, the final checkpoint is logged at the end of training. If set to <code>all</code>, the entire
<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>’s <code>output_dir</code> is logged at each checkpoint.</li>`,da,at,pa,T,nt,Sn,ur,uo=`A class for objects that will inspect the state of the training loop at some events and take some decisions. At
each of those events the following arguments are available:`,Wn,br,bo=`The <code>control</code> object is the only one that can be changed by the callback, in which case the event that changes it
should return the modified version.`,zn,_r,_o=`The argument <code>args</code>, <code>state</code> and <code>control</code> are positionals for all events, all the others are grouped in <code>kwargs</code>.
You can unpack the ones you need in the signature of the event using them. As an example, see the code of the
simple <a href="/docs/transformers/main/ja/main_classes/callback#transformers.PrinterCallback">PrinterCallback</a>.`,Bn,oe,Qn,le,st,Vn,vr,vo="Event called at the beginning of an epoch.",Rn,ie,ot,Gn,Tr,To="Event called at the end of an epoch.",qn,ce,lt,Yn,$r,$o="Event called after an evaluation phase.",On,me,it,Xn,Cr,Co='Event called at the end of the initialization of the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>.',Zn,de,ct,Kn,kr,ko="Event called after logging the last logs.",es,pe,mt,ts,wr,wo="Event called after a successful prediction.",rs,fe,dt,as,Mr,Mo="Event called after a prediction step.",ns,ge,pt,ss,yr,yo="Event called after a checkpoint save.",os,he,ft,ls,xr,xo=`Event called at the beginning of a training step. If using gradient accumulation, one training step might take
several inputs.`,is,ue,gt,cs,Lr,Lo=`Event called at the end of a training step. If using gradient accumulation, one training step might take
several inputs.`,ms,be,ht,ds,jr,jo="Event called at the end of an substep during gradient accumulation.",ps,_e,ut,fs,Ir,Io="Event called at the beginning of training.",gs,ve,bt,hs,Er,Eo="Event called at the end of training.",fa,_t,Ho='以下は、カスタム コールバックを PyTorch <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> に登録する方法の例です。',ga,vt,ha,Tt,Po="コールバックを登録する別の方法は、次のように <code>trainer.add_callback()</code> を呼び出すことです。",ua,$t,ba,Ct,_a,E,kt,us,Hr,Jo=`A class containing the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> inner state that will be saved along the model and optimizer when checkpointing
and passed to the <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a>.`,bs,Te,_s,$e,wt,vs,Pr,Do="Create an instance from the content of <code>json_path</code>.",Ts,Ce,Mt,$s,Jr,Uo="Save the content of this instance in JSON format inside <code>json_path</code>.",va,yt,Ta,re,xt,Cs,Dr,Ao=`A class that handles the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> control flow. This class is used by the <a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> to activate some
switches in the training loop.`,$a,zr,Ca;return M=new Br({props:{title:"コールバック数",local:"コールバック数",headingTag:"h1"}}),Je=new Br({props:{title:"利用可能なコールバック",local:"transformers.integrations.CometCallback",headingTag:"h2"}}),Ue=new C({props:{name:"class transformers.integrations.CometCallback",anchor:"transformers.integrations.CometCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L833"}}),Ae=new C({props:{name:"setup",anchor:"transformers.integrations.CometCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L844"}}),Ne=new C({props:{name:"class transformers.DefaultFlowCallback",anchor:"transformers.DefaultFlowCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L432"}}),Fe=new C({props:{name:"class transformers.PrinterCallback",anchor:"transformers.PrinterCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L532"}}),Se=new C({props:{name:"class transformers.ProgressCallback",anchor:"transformers.ProgressCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L482"}}),We=new C({props:{name:"class transformers.EarlyStoppingCallback",anchor:"transformers.EarlyStoppingCallback",parameters:[{name:"early_stopping_patience",val:": int = 1"},{name:"early_stopping_threshold",val:": Optional = 0.0"}],parametersDescription:[{anchor:"transformers.EarlyStoppingCallback.early_stopping_patience",description:`<strong>early_stopping_patience</strong> (<code>int</code>) &#x2014;
Use with <code>metric_for_best_model</code> to stop training when the specified metric worsens for
<code>early_stopping_patience</code> evaluation calls.`,name:"early_stopping_patience"},{anchor:"transformers.EarlyStoppingCallback.early_stopping_threshold(float,",description:`<strong>early_stopping_threshold(<code>float</code>,</strong> <em>optional</em>) &#x2014;
Use with TrainingArguments <code>metric_for_best_model</code> and <code>early_stopping_patience</code> to denote how much the
specified metric must improve to satisfy early stopping conditions. \``,name:"early_stopping_threshold(float,"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L543"}}),ze=new C({props:{name:"class transformers.integrations.TensorBoardCallback",anchor:"transformers.integrations.TensorBoardCallback",parameters:[{name:"tb_writer",val:" = None"}],parametersDescription:[{anchor:"transformers.integrations.TensorBoardCallback.tb_writer",description:`<strong>tb_writer</strong> (<code>SummaryWriter</code>, <em>optional</em>) &#x2014;
The writer to use. Will instantiate one if not set.`,name:"tb_writer"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L579"}}),Be=new C({props:{name:"class transformers.integrations.WandbCallback",anchor:"transformers.integrations.WandbCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L665"}}),Qe=new C({props:{name:"setup",anchor:"transformers.integrations.WandbCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L690"}}),ne=new tl({props:{version:"5.0",$$slots:{default:[rl]},$$scope:{ctx:j}}}),Re=new C({props:{name:"class transformers.integrations.MLflowCallback",anchor:"transformers.integrations.MLflowCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L933"}}),Ge=new C({props:{name:"setup",anchor:"transformers.integrations.MLflowCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L952"}}),qe=new C({props:{name:"class transformers.integrations.AzureMLCallback",anchor:"transformers.integrations.AzureMLCallback",parameters:[{name:"azureml_run",val:" = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L910"}}),Ye=new C({props:{name:"class transformers.integrations.CodeCarbonCallback",anchor:"transformers.integrations.CodeCarbonCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1410"}}),Oe=new C({props:{name:"class transformers.integrations.NeptuneCallback",anchor:"transformers.integrations.NeptuneCallback",parameters:[{name:"api_token",val:": Optional = None"},{name:"project",val:": Optional = None"},{name:"name",val:": Optional = None"},{name:"base_namespace",val:": str = 'finetuning'"},{name:"run",val:" = None"},{name:"log_parameters",val:": bool = True"},{name:"log_checkpoints",val:": Optional = None"},{name:"**neptune_run_kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.NeptuneCallback.api_token",description:`<strong>api_token</strong> (<code>str</code>, <em>optional</em>) &#x2014; Neptune API token obtained upon registration.
You can leave this argument out if you have saved your token to the <code>NEPTUNE_API_TOKEN</code> environment
variable (strongly recommended). See full setup instructions in the
<a href="https://docs.neptune.ai/setup/installation" rel="nofollow">docs</a>.`,name:"api_token"},{anchor:"transformers.integrations.NeptuneCallback.project",description:`<strong>project</strong> (<code>str</code>, <em>optional</em>) &#x2014; Name of an existing Neptune project, in the form &#x201C;workspace-name/project-name&#x201D;.
You can find and copy the name in Neptune from the project settings -&gt; Properties. If None (default), the
value of the <code>NEPTUNE_PROJECT</code> environment variable is used.`,name:"project"},{anchor:"transformers.integrations.NeptuneCallback.name",description:"<strong>name</strong> (<code>str</code>, <em>optional</em>) &#x2014; Custom name for the run.",name:"name"},{anchor:"transformers.integrations.NeptuneCallback.base_namespace",description:`<strong>base_namespace</strong> (<code>str</code>, optional, defaults to &#x201C;finetuning&#x201D;) &#x2014; In the Neptune run, the root namespace
that will contain all of the metadata logged by the callback.`,name:"base_namespace"},{anchor:"transformers.integrations.NeptuneCallback.log_parameters",description:`<strong>log_parameters</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
If True, logs all Trainer arguments and model parameters provided by the Trainer.`,name:"log_parameters"},{anchor:"transformers.integrations.NeptuneCallback.log_checkpoints",description:`<strong>log_checkpoints</strong> (<code>str</code>, <em>optional</em>) &#x2014; If &#x201C;same&#x201D;, uploads checkpoints whenever they are saved by the Trainer.
If &#x201C;last&#x201D;, uploads only the most recently saved checkpoint. If &#x201C;best&#x201D;, uploads the best checkpoint (among
the ones saved by the Trainer). If <code>None</code>, does not upload checkpoints.`,name:"log_checkpoints"},{anchor:"transformers.integrations.NeptuneCallback.run",description:`<strong>run</strong> (<code>Run</code>, <em>optional</em>) &#x2014; Pass a Neptune run object if you want to continue logging to an existing run.
Read more about resuming runs in the <a href="https://docs.neptune.ai/logging/to_existing_object" rel="nofollow">docs</a>.`,name:"run"},{anchor:"transformers.integrations.NeptuneCallback.*neptune_run_kwargs",description:`*<strong>*neptune_run_kwargs</strong> (<em>optional</em>) &#x2014;
Additional keyword arguments to be passed directly to the
<a href="https://docs.neptune.ai/api/neptune#init_run" rel="nofollow"><code>neptune.init_run()</code></a> function when a new run is created.`,name:"*neptune_run_kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1139"}}),Xe=new C({props:{name:"class transformers.integrations.ClearMLCallback",anchor:"transformers.integrations.ClearMLCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1439"}}),Ze=new C({props:{name:"class transformers.integrations.DagsHubCallback",anchor:"transformers.integrations.DagsHubCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1079"}}),Ke=new C({props:{name:"setup",anchor:"transformers.integrations.DagsHubCallback.setup",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1093"}}),et=new C({props:{name:"class transformers.integrations.FlyteCallback",anchor:"transformers.integrations.FlyteCallback",parameters:[{name:"save_log_history",val:": bool = True"},{name:"sync_checkpoints",val:": bool = True"}],parametersDescription:[{anchor:"transformers.integrations.FlyteCallback.save_log_history",description:`<strong>save_log_history</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to True, the training logs are saved as a Flyte Deck.`,name:"save_log_history"},{anchor:"transformers.integrations.FlyteCallback.sync_checkpoints",description:`<strong>sync_checkpoints</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to True, checkpoints are synced with Flyte and can be used to resume training in the case of an
interruption.`,name:"sync_checkpoints"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1692"}}),se=new So({props:{anchor:"transformers.integrations.FlyteCallback.example",$$slots:{default:[al]},$$scope:{ctx:j}}}),tt=new C({props:{name:"class transformers.integrations.DVCLiveCallback",anchor:"transformers.integrations.DVCLiveCallback",parameters:[{name:"live",val:": Optional = None"},{name:"log_model",val:": Union = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.DVCLiveCallback.live",description:`<strong>live</strong> (<code>dvclive.Live</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
Optional Live instance. If None, a new instance will be created using **kwargs.`,name:"live"},{anchor:"transformers.integrations.DVCLiveCallback.log_model",description:`<strong>log_model</strong> (Union[Literal[&#x201C;all&#x201D;], bool], <em>optional</em>, defaults to <code>None</code>) &#x2014;
Whether to use <code>dvclive.Live.log_artifact()</code> to log checkpoints created by <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>. If set to <code>True</code>,
the final checkpoint is logged at the end of training. If set to <code>&quot;all&quot;</code>, the entire
<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>&#x2019;s <code>output_dir</code> is logged at each checkpoint.`,name:"log_model"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1755"}}),rt=new C({props:{name:"setup",anchor:"transformers.integrations.DVCLiveCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1796"}}),at=new Br({props:{title:"TrainerCallback",local:"transformers.TrainerCallback",headingTag:"h2"}}),nt=new C({props:{name:"class transformers.TrainerCallback",anchor:"transformers.TrainerCallback",parameters:[],parametersDescription:[{anchor:"transformers.TrainerCallback.args",description:`<strong>args</strong> (<a href="/docs/transformers/main/ja/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>) &#x2014;
The training arguments used to instantiate the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>.`,name:"args"},{anchor:"transformers.TrainerCallback.state",description:`<strong>state</strong> (<a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerState">TrainerState</a>) &#x2014;
The current state of the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a>.`,name:"state"},{anchor:"transformers.TrainerCallback.control",description:`<strong>control</strong> (<a href="/docs/transformers/main/ja/main_classes/callback#transformers.TrainerControl">TrainerControl</a>) &#x2014;
The object that is returned to the <a href="/docs/transformers/main/ja/main_classes/trainer#transformers.Trainer">Trainer</a> and can be used to make some decisions.`,name:"control"},{anchor:"transformers.TrainerCallback.model",description:`<strong>model</strong> (<a href="/docs/transformers/main/ja/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a> or <code>torch.nn.Module</code>) &#x2014;
The model being trained.`,name:"model"},{anchor:"transformers.TrainerCallback.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/ja/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.TrainerCallback.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.Optimizer</code>) &#x2014;
The optimizer used for the training steps.`,name:"optimizer"},{anchor:"transformers.TrainerCallback.lr_scheduler",description:`<strong>lr_scheduler</strong> (<code>torch.optim.lr_scheduler.LambdaLR</code>) &#x2014;
The scheduler used for setting the learning rate.`,name:"lr_scheduler"},{anchor:"transformers.TrainerCallback.train_dataloader",description:`<strong>train_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"train_dataloader"},{anchor:"transformers.TrainerCallback.eval_dataloader",description:`<strong>eval_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"eval_dataloader"},{anchor:"transformers.TrainerCallback.metrics",description:`<strong>metrics</strong> (<code>Dict[str, float]</code>) &#x2014;
The metrics computed by the last evaluation phase.</p>
<p>Those are only accessible in the event <code>on_evaluate</code>.`,name:"metrics"},{anchor:"transformers.TrainerCallback.logs",description:`<strong>logs</strong>  (<code>Dict[str, float]</code>) &#x2014;
The values to log.</p>
<p>Those are only accessible in the event <code>on_log</code>.`,name:"logs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L175"}}),oe=new So({props:{anchor:"transformers.TrainerCallback.example",$$slots:{default:[nl]},$$scope:{ctx:j}}}),st=new C({props:{name:"on_epoch_begin",anchor:"transformers.TrainerCallback.on_epoch_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L244"}}),ot=new C({props:{name:"on_epoch_end",anchor:"transformers.TrainerCallback.on_epoch_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L250"}}),lt=new C({props:{name:"on_evaluate",anchor:"transformers.TrainerCallback.on_evaluate",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L276"}}),it=new C({props:{name:"on_init_end",anchor:"transformers.TrainerCallback.on_init_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L226"}}),ct=new C({props:{name:"on_log",anchor:"transformers.TrainerCallback.on_log",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L294"}}),mt=new C({props:{name:"on_predict",anchor:"transformers.TrainerCallback.on_predict",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"metrics",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L282"}}),dt=new C({props:{name:"on_prediction_step",anchor:"transformers.TrainerCallback.on_prediction_step",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L300"}}),pt=new C({props:{name:"on_save",anchor:"transformers.TrainerCallback.on_save",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L288"}}),ft=new C({props:{name:"on_step_begin",anchor:"transformers.TrainerCallback.on_step_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L256"}}),gt=new C({props:{name:"on_step_end",anchor:"transformers.TrainerCallback.on_step_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L269"}}),ht=new C({props:{name:"on_substep_end",anchor:"transformers.TrainerCallback.on_substep_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L263"}}),ut=new C({props:{name:"on_train_begin",anchor:"transformers.TrainerCallback.on_train_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L232"}}),bt=new C({props:{name:"on_train_end",anchor:"transformers.TrainerCallback.on_train_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L238"}}),vt=new Qa({props:{code:"Y2xhc3MlMjBNeUNhbGxiYWNrKFRyYWluZXJDYWxsYmFjayklM0ElMEElMjAlMjAlMjAlMjAlMjJBJTIwY2FsbGJhY2slMjB0aGF0JTIwcHJpbnRzJTIwYSUyMG1lc3NhZ2UlMjBhdCUyMHRoZSUyMGJlZ2lubmluZyUyMG9mJTIwdHJhaW5pbmclMjIlMEElMEElMjAlMjAlMjAlMjBkZWYlMjBvbl90cmFpbl9iZWdpbihzZWxmJTJDJTIwYXJncyUyQyUyMHN0YXRlJTJDJTIwY29udHJvbCUyQyUyMCoqa3dhcmdzKSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHByaW50KCUyMlN0YXJ0aW5nJTIwdHJhaW5pbmclMjIpJTBBJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHRyYWluX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0RldmFsX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBjYWxsYmFja3MlM0QlNUJNeUNhbGxiYWNrJTVEJTJDJTIwJTIwJTIzJTIwV2UlMjBjYW4lMjBlaXRoZXIlMjBwYXNzJTIwdGhlJTIwY2FsbGJhY2slMjBjbGFzcyUyMHRoaXMlMjB3YXklMjBvciUyMGFuJTIwaW5zdGFuY2UlMjBvZiUyMGl0JTIwKE15Q2FsbGJhY2soKSklMEEp",highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-string">&quot;A callback that prints a message at the beginning of training&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_train_begin</span>(<span class="hljs-params">self, args, state, control, **kwargs</span>):
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training&quot;</span>)


trainer = Trainer(
    model,
    args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    callbacks=[MyCallback],  <span class="hljs-comment"># We can either pass the callback class this way or an instance of it (MyCallback())</span>
)`,wrap:!1}}),$t=new Qa({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIoLi4uKSUwQXRyYWluZXIuYWRkX2NhbGxiYWNrKE15Q2FsbGJhY2spJTBBJTIzJTIwQWx0ZXJuYXRpdmVseSUyQyUyMHdlJTIwY2FuJTIwcGFzcyUyMGFuJTIwaW5zdGFuY2UlMjBvZiUyMHRoZSUyMGNhbGxiYWNrJTIwY2xhc3MlMEF0cmFpbmVyLmFkZF9jYWxsYmFjayhNeUNhbGxiYWNrKCkp",highlighted:`trainer = Trainer(...)
trainer.add_callback(MyCallback)
<span class="hljs-comment"># Alternatively, we can pass an instance of the callback class</span>
trainer.add_callback(MyCallback())`,wrap:!1}}),Ct=new Br({props:{title:"TrainerState",local:"transformers.TrainerState",headingTag:"h2"}}),kt=new C({props:{name:"class transformers.TrainerState",anchor:"transformers.TrainerState",parameters:[{name:"epoch",val:": Optional = None"},{name:"global_step",val:": int = 0"},{name:"max_steps",val:": int = 0"},{name:"logging_steps",val:": int = 500"},{name:"eval_steps",val:": int = 500"},{name:"save_steps",val:": int = 500"},{name:"train_batch_size",val:": int = None"},{name:"num_train_epochs",val:": int = 0"},{name:"num_input_tokens_seen",val:": int = 0"},{name:"total_flos",val:": float = 0"},{name:"log_history",val:": List = None"},{name:"best_metric",val:": Optional = None"},{name:"best_model_checkpoint",val:": Optional = None"},{name:"is_local_process_zero",val:": bool = True"},{name:"is_world_process_zero",val:": bool = True"},{name:"is_hyper_param_search",val:": bool = False"},{name:"trial_name",val:": str = None"},{name:"trial_params",val:": Dict = None"}],parametersDescription:[{anchor:"transformers.TrainerState.epoch",description:`<strong>epoch</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Only set during training, will represent the epoch the training is at (the decimal part being the
percentage of the current epoch completed).`,name:"epoch"},{anchor:"transformers.TrainerState.global_step",description:`<strong>global_step</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
During training, represents the number of update steps completed.`,name:"global_step"},{anchor:"transformers.TrainerState.max_steps",description:`<strong>max_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The number of update steps to do during the current training.`,name:"max_steps"},{anchor:"transformers.TrainerState.logging_steps",description:`<strong>logging_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 500) &#x2014;
Log every X updates steps`,name:"logging_steps"},{anchor:"transformers.TrainerState.eval_steps",description:`<strong>eval_steps</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Run an evaluation every X steps.`,name:"eval_steps"},{anchor:"transformers.TrainerState.save_steps",description:`<strong>save_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 500) &#x2014;
Save checkpoint every X updates steps.`,name:"save_steps"},{anchor:"transformers.TrainerState.train_batch_size",description:`<strong>train_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The batch size for the training dataloader. Only needed when
<code>auto_find_batch_size</code> has been used.`,name:"train_batch_size"},{anchor:"transformers.TrainerState.num_input_tokens_seen",description:`<strong>num_input_tokens_seen</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The number of tokens seen during training (number of input tokens, not the number of prediction tokens).`,name:"num_input_tokens_seen"},{anchor:"transformers.TrainerState.total_flos",description:`<strong>total_flos</strong> (<code>float</code>, <em>optional</em>, defaults to 0) &#x2014;
The total number of floating operations done by the model since the beginning of training (stored as floats
to avoid overflow).`,name:"total_flos"},{anchor:"transformers.TrainerState.log_history",description:`<strong>log_history</strong> (<code>List[Dict[str, float]]</code>, <em>optional</em>) &#x2014;
The list of logs done since the beginning of training.`,name:"log_history"},{anchor:"transformers.TrainerState.best_metric",description:`<strong>best_metric</strong> (<code>float</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the best metric encountered so far.`,name:"best_metric"},{anchor:"transformers.TrainerState.best_model_checkpoint",description:`<strong>best_model_checkpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the name of the checkpoint for the best model encountered so
far.`,name:"best_model_checkpoint"},{anchor:"transformers.TrainerState.is_local_process_zero",description:`<strong>is_local_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on
several machines) main process.`,name:"is_local_process_zero"},{anchor:"transformers.TrainerState.is_world_process_zero",description:`<strong>is_world_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the global main process (when training in a distributed fashion on several
machines, this is only going to be <code>True</code> for one process).`,name:"is_world_process_zero"},{anchor:"transformers.TrainerState.is_hyper_param_search",description:`<strong>is_hyper_param_search</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether we are in the process of a hyper parameter search using Trainer.hyperparameter_search. This will
impact the way data will be logged in TensorBoard.`,name:"is_hyper_param_search"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L34"}}),Te=new Qo({props:{$$slots:{default:[sl]},$$scope:{ctx:j}}}),wt=new C({props:{name:"load_from_json",anchor:"transformers.TrainerState.load_from_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L117"}}),Mt=new C({props:{name:"save_to_json",anchor:"transformers.TrainerState.save_to_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L111"}}),yt=new Br({props:{title:"TrainerControl",local:"transformers.TrainerControl",headingTag:"h2"}}),xt=new C({props:{name:"class transformers.TrainerControl",anchor:"transformers.TrainerControl",parameters:[{name:"should_training_stop",val:": bool = False"},{name:"should_epoch_stop",val:": bool = False"},{name:"should_save",val:": bool = False"},{name:"should_evaluate",val:": bool = False"},{name:"should_log",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TrainerControl.should_training_stop",description:`<strong>should_training_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the training should be interrupted.</p>
<p>If <code>True</code>, this variable will not be set back to <code>False</code>. The training will just stop.`,name:"should_training_stop"},{anchor:"transformers.TrainerControl.should_epoch_stop",description:`<strong>should_epoch_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the current epoch should be interrupted.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next epoch.`,name:"should_epoch_stop"},{anchor:"transformers.TrainerControl.should_save",description:`<strong>should_save</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be saved at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_save"},{anchor:"transformers.TrainerControl.should_evaluate",description:`<strong>should_evaluate</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be evaluated at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_evaluate"},{anchor:"transformers.TrainerControl.should_log",description:`<strong>should_log</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the logs should be reported at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_log"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L125"}}),{c(){m=s("meta"),x=r(),b=s("p"),k=r(),f(M.$$.fragment),_=r(),y=s("p"),y.innerHTML=L,I=r(),je=s("p"),je.innerHTML=ks,Qr=r(),Ie=s("p"),Ie.innerHTML=ws,Vr=r(),Ee=s("ul"),Ee.innerHTML=Ms,Rr=r(),He=s("p"),He.innerHTML=ys,Gr=r(),Pe=s("p"),Pe.innerHTML=xs,qr=r(),f(Je.$$.fragment),Yr=r(),De=s("p"),De.innerHTML=Ls,Or=r(),S=s("div"),f(Ue.$$.fragment),Ra=r(),It=s("p"),It.innerHTML=js,Ga=r(),H=s("div"),f(Ae.$$.fragment),qa=r(),Et=s("p"),Et.textContent=Is,Ya=r(),Ht=s("p"),Ht.textContent=Es,Oa=r(),Pt=s("ul"),Pt.innerHTML=Hs,Xa=r(),Jt=s("p"),Jt.innerHTML=Ps,Xr=r(),O=s("div"),f(Ne.$$.fragment),Za=r(),Dt=s("p"),Dt.innerHTML=Js,Zr=r(),X=s("div"),f(Fe.$$.fragment),Ka=r(),Ut=s("p"),Ut.innerHTML=Ds,Kr=r(),Z=s("div"),f(Se.$$.fragment),en=r(),At=s("p"),At.innerHTML=Us,ea=r(),W=s("div"),f(We.$$.fragment),tn=r(),Nt=s("p"),Nt.innerHTML=As,rn=r(),Ft=s("p"),Ft.innerHTML=Ns,ta=r(),K=s("div"),f(ze.$$.fragment),an=r(),St=s("p"),St.innerHTML=Fs,ra=r(),z=s("div"),f(Be.$$.fragment),nn=r(),Wt=s("p"),Wt.innerHTML=Ss,sn=r(),P=s("div"),f(Qe.$$.fragment),on=r(),zt=s("p"),zt.innerHTML=Ws,ln=r(),Bt=s("p"),Bt.innerHTML=zs,cn=r(),Qt=s("p"),Qt.textContent=Bs,mn=r(),B=s("ul"),Ve=s("li"),Vt=s("p"),Vt.innerHTML=Qs,dn=r(),f(ne.$$.fragment),pn=r(),Rt=s("li"),Rt.innerHTML=Vs,fn=r(),Gt=s("li"),Gt.innerHTML=Rs,gn=r(),qt=s("li"),qt.innerHTML=Gs,aa=r(),Q=s("div"),f(Re.$$.fragment),hn=r(),Yt=s("p"),Yt.innerHTML=qs,un=r(),A=s("div"),f(Ge.$$.fragment),bn=r(),Ot=s("p"),Ot.textContent=Ys,_n=r(),Xt=s("p"),Xt.textContent=Os,vn=r(),Zt=s("ul"),Zt.innerHTML=Xs,na=r(),ee=s("div"),f(qe.$$.fragment),Tn=r(),Kt=s("p"),Kt.innerHTML=Zs,sa=r(),te=s("div"),f(Ye.$$.fragment),$n=r(),er=s("p"),er.innerHTML=Ks,oa=r(),V=s("div"),f(Oe.$$.fragment),Cn=r(),tr=s("p"),tr.innerHTML=eo,kn=r(),rr=s("p"),rr.innerHTML=to,la=r(),J=s("div"),f(Xe.$$.fragment),wn=r(),ar=s("p"),ar.innerHTML=ro,Mn=r(),nr=s("p"),nr.textContent=ao,yn=r(),sr=s("ul"),sr.innerHTML=no,ia=r(),R=s("div"),f(Ze.$$.fragment),xn=r(),or=s("p"),or.innerHTML=so,Ln=r(),N=s("div"),f(Ke.$$.fragment),jn=r(),lr=s("p"),lr.textContent=oo,In=r(),ir=s("p"),ir.textContent=lo,En=r(),cr=s("ul"),cr.innerHTML=io,ca=r(),G=s("div"),f(et.$$.fragment),Hn=r(),mr=s("p"),mr.innerHTML=co,Pn=r(),f(se.$$.fragment),ma=r(),D=s("div"),f(tt.$$.fragment),Jn=r(),dr=s("p"),dr.innerHTML=mo,Dn=r(),pr=s("p"),pr.innerHTML=po,Un=r(),F=s("div"),f(rt.$$.fragment),An=r(),fr=s("p"),fr.innerHTML=fo,Nn=r(),gr=s("p"),gr.textContent=go,Fn=r(),hr=s("ul"),hr.innerHTML=ho,da=r(),f(at.$$.fragment),pa=r(),T=s("div"),f(nt.$$.fragment),Sn=r(),ur=s("p"),ur.textContent=uo,Wn=r(),br=s("p"),br.innerHTML=bo,zn=r(),_r=s("p"),_r.innerHTML=_o,Bn=r(),f(oe.$$.fragment),Qn=r(),le=s("div"),f(st.$$.fragment),Vn=r(),vr=s("p"),vr.textContent=vo,Rn=r(),ie=s("div"),f(ot.$$.fragment),Gn=r(),Tr=s("p"),Tr.textContent=To,qn=r(),ce=s("div"),f(lt.$$.fragment),Yn=r(),$r=s("p"),$r.textContent=$o,On=r(),me=s("div"),f(it.$$.fragment),Xn=r(),Cr=s("p"),Cr.innerHTML=Co,Zn=r(),de=s("div"),f(ct.$$.fragment),Kn=r(),kr=s("p"),kr.textContent=ko,es=r(),pe=s("div"),f(mt.$$.fragment),ts=r(),wr=s("p"),wr.textContent=wo,rs=r(),fe=s("div"),f(dt.$$.fragment),as=r(),Mr=s("p"),Mr.textContent=Mo,ns=r(),ge=s("div"),f(pt.$$.fragment),ss=r(),yr=s("p"),yr.textContent=yo,os=r(),he=s("div"),f(ft.$$.fragment),ls=r(),xr=s("p"),xr.textContent=xo,is=r(),ue=s("div"),f(gt.$$.fragment),cs=r(),Lr=s("p"),Lr.textContent=Lo,ms=r(),be=s("div"),f(ht.$$.fragment),ds=r(),jr=s("p"),jr.textContent=jo,ps=r(),_e=s("div"),f(ut.$$.fragment),fs=r(),Ir=s("p"),Ir.textContent=Io,gs=r(),ve=s("div"),f(bt.$$.fragment),hs=r(),Er=s("p"),Er.textContent=Eo,fa=r(),_t=s("p"),_t.innerHTML=Ho,ga=r(),f(vt.$$.fragment),ha=r(),Tt=s("p"),Tt.innerHTML=Po,ua=r(),f($t.$$.fragment),ba=r(),f(Ct.$$.fragment),_a=r(),E=s("div"),f(kt.$$.fragment),us=r(),Hr=s("p"),Hr.innerHTML=Jo,bs=r(),f(Te.$$.fragment),_s=r(),$e=s("div"),f(wt.$$.fragment),vs=r(),Pr=s("p"),Pr.innerHTML=Do,Ts=r(),Ce=s("div"),f(Mt.$$.fragment),$s=r(),Jr=s("p"),Jr.innerHTML=Uo,va=r(),f(yt.$$.fragment),Ta=r(),re=s("div"),f(xt.$$.fragment),Cs=r(),Dr=s("p"),Dr.innerHTML=Ao,$a=r(),zr=s("p"),this.h()},l(e){const l=Xo("svelte-u9bgzb",document.head);m=o(l,"META",{name:!0,content:!0}),l.forEach(n),x=a(e),b=o(e,"P",{}),v(b).forEach(n),k=a(e),g(M.$$.fragment,e),_=a(e),y=o(e,"P",{"data-svelte-h":!0}),i(y)!=="svelte-1vobzxg"&&(y.innerHTML=L),I=a(e),je=o(e,"P",{"data-svelte-h":!0}),i(je)!=="svelte-1cfup3n"&&(je.innerHTML=ks),Qr=a(e),Ie=o(e,"P",{"data-svelte-h":!0}),i(Ie)!=="svelte-d50wob"&&(Ie.innerHTML=ws),Vr=a(e),Ee=o(e,"UL",{"data-svelte-h":!0}),i(Ee)!=="svelte-fyjiy4"&&(Ee.innerHTML=Ms),Rr=a(e),He=o(e,"P",{"data-svelte-h":!0}),i(He)!=="svelte-1b834xs"&&(He.innerHTML=ys),Gr=a(e),Pe=o(e,"P",{"data-svelte-h":!0}),i(Pe)!=="svelte-1ecg6pf"&&(Pe.innerHTML=xs),qr=a(e),g(Je.$$.fragment,e),Yr=a(e),De=o(e,"P",{"data-svelte-h":!0}),i(De)!=="svelte-k1ad7d"&&(De.innerHTML=Ls),Or=a(e),S=o(e,"DIV",{class:!0});var ae=v(S);g(Ue.$$.fragment,ae),Ra=a(ae),It=o(ae,"P",{"data-svelte-h":!0}),i(It)!=="svelte-1l2y3b6"&&(It.innerHTML=js),Ga=a(ae),H=o(ae,"DIV",{class:!0});var U=v(H);g(Ae.$$.fragment,U),qa=a(U),Et=o(U,"P",{"data-svelte-h":!0}),i(Et)!=="svelte-1bfkm9x"&&(Et.textContent=Is),Ya=a(U),Ht=o(U,"P",{"data-svelte-h":!0}),i(Ht)!=="svelte-1fkshtn"&&(Ht.textContent=Es),Oa=a(U),Pt=o(U,"UL",{"data-svelte-h":!0}),i(Pt)!=="svelte-12drq5x"&&(Pt.innerHTML=Hs),Xa=a(U),Jt=o(U,"P",{"data-svelte-h":!0}),i(Jt)!=="svelte-1faq0a7"&&(Jt.innerHTML=Ps),U.forEach(n),ae.forEach(n),Xr=a(e),O=o(e,"DIV",{class:!0});var Lt=v(O);g(Ne.$$.fragment,Lt),Za=a(Lt),Dt=o(Lt,"P",{"data-svelte-h":!0}),i(Dt)!=="svelte-6svysx"&&(Dt.innerHTML=Js),Lt.forEach(n),Zr=a(e),X=o(e,"DIV",{class:!0});var jt=v(X);g(Fe.$$.fragment,jt),Ka=a(jt),Ut=o(jt,"P",{"data-svelte-h":!0}),i(Ut)!=="svelte-e6fxs2"&&(Ut.innerHTML=Ds),jt.forEach(n),Kr=a(e),Z=o(e,"DIV",{class:!0});var ka=v(Z);g(Se.$$.fragment,ka),en=a(ka),At=o(ka,"P",{"data-svelte-h":!0}),i(At)!=="svelte-w3u5vn"&&(At.innerHTML=Us),ka.forEach(n),ea=a(e),W=o(e,"DIV",{class:!0});var Ur=v(W);g(We.$$.fragment,Ur),tn=a(Ur),Nt=o(Ur,"P",{"data-svelte-h":!0}),i(Nt)!=="svelte-1u5pbjw"&&(Nt.innerHTML=As),rn=a(Ur),Ft=o(Ur,"P",{"data-svelte-h":!0}),i(Ft)!=="svelte-1cmgnu4"&&(Ft.innerHTML=Ns),Ur.forEach(n),ta=a(e),K=o(e,"DIV",{class:!0});var wa=v(K);g(ze.$$.fragment,wa),an=a(wa),St=o(wa,"P",{"data-svelte-h":!0}),i(St)!=="svelte-1hfmggn"&&(St.innerHTML=Fs),wa.forEach(n),ra=a(e),z=o(e,"DIV",{class:!0});var Ar=v(z);g(Be.$$.fragment,Ar),nn=a(Ar),Wt=o(Ar,"P",{"data-svelte-h":!0}),i(Wt)!=="svelte-12eqks8"&&(Wt.innerHTML=Ss),sn=a(Ar),P=o(Ar,"DIV",{class:!0});var q=v(P);g(Qe.$$.fragment,q),on=a(q),zt=o(q,"P",{"data-svelte-h":!0}),i(zt)!=="svelte-op70zs"&&(zt.innerHTML=Ws),ln=a(q),Bt=o(q,"P",{"data-svelte-h":!0}),i(Bt)!=="svelte-m2rt7w"&&(Bt.innerHTML=zs),cn=a(q),Qt=o(q,"P",{"data-svelte-h":!0}),i(Qt)!=="svelte-1fkshtn"&&(Qt.textContent=Bs),mn=a(q),B=o(q,"UL",{});var ke=v(B);Ve=o(ke,"LI",{});var Ma=v(Ve);Vt=o(Ma,"P",{"data-svelte-h":!0}),i(Vt)!=="svelte-py3r3s"&&(Vt.innerHTML=Qs),dn=a(Ma),g(ne.$$.fragment,Ma),Ma.forEach(n),pn=a(ke),Rt=o(ke,"LI",{"data-svelte-h":!0}),i(Rt)!=="svelte-dx3m30"&&(Rt.innerHTML=Vs),fn=a(ke),Gt=o(ke,"LI",{"data-svelte-h":!0}),i(Gt)!=="svelte-n1uh6c"&&(Gt.innerHTML=Rs),gn=a(ke),qt=o(ke,"LI",{"data-svelte-h":!0}),i(qt)!=="svelte-ybo66z"&&(qt.innerHTML=Gs),ke.forEach(n),q.forEach(n),Ar.forEach(n),aa=a(e),Q=o(e,"DIV",{class:!0});var Nr=v(Q);g(Re.$$.fragment,Nr),hn=a(Nr),Yt=o(Nr,"P",{"data-svelte-h":!0}),i(Yt)!=="svelte-lcj2so"&&(Yt.innerHTML=qs),un=a(Nr),A=o(Nr,"DIV",{class:!0});var we=v(A);g(Ge.$$.fragment,we),bn=a(we),Ot=o(we,"P",{"data-svelte-h":!0}),i(Ot)!=="svelte-nmg16f"&&(Ot.textContent=Ys),_n=a(we),Xt=o(we,"P",{"data-svelte-h":!0}),i(Xt)!=="svelte-1fkshtn"&&(Xt.textContent=Os),vn=a(we),Zt=o(we,"UL",{"data-svelte-h":!0}),i(Zt)!=="svelte-1kyhd99"&&(Zt.innerHTML=Xs),we.forEach(n),Nr.forEach(n),na=a(e),ee=o(e,"DIV",{class:!0});var ya=v(ee);g(qe.$$.fragment,ya),Tn=a(ya),Kt=o(ya,"P",{"data-svelte-h":!0}),i(Kt)!=="svelte-4clse7"&&(Kt.innerHTML=Zs),ya.forEach(n),sa=a(e),te=o(e,"DIV",{class:!0});var xa=v(te);g(Ye.$$.fragment,xa),$n=a(xa),er=o(xa,"P",{"data-svelte-h":!0}),i(er)!=="svelte-1daiwkb"&&(er.innerHTML=Ks),xa.forEach(n),oa=a(e),V=o(e,"DIV",{class:!0});var Fr=v(V);g(Oe.$$.fragment,Fr),Cn=a(Fr),tr=o(Fr,"P",{"data-svelte-h":!0}),i(tr)!=="svelte-4ag9j6"&&(tr.innerHTML=eo),kn=a(Fr),rr=o(Fr,"P",{"data-svelte-h":!0}),i(rr)!=="svelte-1mhjcx0"&&(rr.innerHTML=to),Fr.forEach(n),la=a(e),J=o(e,"DIV",{class:!0});var Me=v(J);g(Xe.$$.fragment,Me),wn=a(Me),ar=o(Me,"P",{"data-svelte-h":!0}),i(ar)!=="svelte-mdwcvt"&&(ar.innerHTML=ro),Mn=a(Me),nr=o(Me,"P",{"data-svelte-h":!0}),i(nr)!=="svelte-1fkshtn"&&(nr.textContent=ao),yn=a(Me),sr=o(Me,"UL",{"data-svelte-h":!0}),i(sr)!=="svelte-15svthu"&&(sr.innerHTML=no),Me.forEach(n),ia=a(e),R=o(e,"DIV",{class:!0});var Sr=v(R);g(Ze.$$.fragment,Sr),xn=a(Sr),or=o(Sr,"P",{"data-svelte-h":!0}),i(or)!=="svelte-140pgpo"&&(or.innerHTML=so),Ln=a(Sr),N=o(Sr,"DIV",{class:!0});var ye=v(N);g(Ke.$$.fragment,ye),jn=a(ye),lr=o(ye,"P",{"data-svelte-h":!0}),i(lr)!=="svelte-1wbmj3"&&(lr.textContent=oo),In=a(ye),ir=o(ye,"P",{"data-svelte-h":!0}),i(ir)!=="svelte-1fkshtn"&&(ir.textContent=lo),En=a(ye),cr=o(ye,"UL",{"data-svelte-h":!0}),i(cr)!=="svelte-dna85o"&&(cr.innerHTML=io),ye.forEach(n),Sr.forEach(n),ca=a(e),G=o(e,"DIV",{class:!0});var Wr=v(G);g(et.$$.fragment,Wr),Hn=a(Wr),mr=o(Wr,"P",{"data-svelte-h":!0}),i(mr)!=="svelte-1ooma4z"&&(mr.innerHTML=co),Pn=a(Wr),g(se.$$.fragment,Wr),Wr.forEach(n),ma=a(e),D=o(e,"DIV",{class:!0});var xe=v(D);g(tt.$$.fragment,xe),Jn=a(xe),dr=o(xe,"P",{"data-svelte-h":!0}),i(dr)!=="svelte-1hfp9o6"&&(dr.innerHTML=mo),Dn=a(xe),pr=o(xe,"P",{"data-svelte-h":!0}),i(pr)!=="svelte-eu3kj7"&&(pr.innerHTML=po),Un=a(xe),F=o(xe,"DIV",{class:!0});var Le=v(F);g(rt.$$.fragment,Le),An=a(Le),fr=o(Le,"P",{"data-svelte-h":!0}),i(fr)!=="svelte-jjkenj"&&(fr.innerHTML=fo),Nn=a(Le),gr=o(Le,"P",{"data-svelte-h":!0}),i(gr)!=="svelte-1fkshtn"&&(gr.textContent=go),Fn=a(Le),hr=o(Le,"UL",{"data-svelte-h":!0}),i(hr)!=="svelte-rvk2oa"&&(hr.innerHTML=ho),Le.forEach(n),xe.forEach(n),da=a(e),g(at.$$.fragment,e),pa=a(e),T=o(e,"DIV",{class:!0});var w=v(T);g(nt.$$.fragment,w),Sn=a(w),ur=o(w,"P",{"data-svelte-h":!0}),i(ur)!=="svelte-14xg00o"&&(ur.textContent=uo),Wn=a(w),br=o(w,"P",{"data-svelte-h":!0}),i(br)!=="svelte-1xprdvt"&&(br.innerHTML=bo),zn=a(w),_r=o(w,"P",{"data-svelte-h":!0}),i(_r)!=="svelte-8ufiwj"&&(_r.innerHTML=_o),Bn=a(w),g(oe.$$.fragment,w),Qn=a(w),le=o(w,"DIV",{class:!0});var La=v(le);g(st.$$.fragment,La),Vn=a(La),vr=o(La,"P",{"data-svelte-h":!0}),i(vr)!=="svelte-106889p"&&(vr.textContent=vo),La.forEach(n),Rn=a(w),ie=o(w,"DIV",{class:!0});var ja=v(ie);g(ot.$$.fragment,ja),Gn=a(ja),Tr=o(ja,"P",{"data-svelte-h":!0}),i(Tr)!=="svelte-oshcpj"&&(Tr.textContent=To),ja.forEach(n),qn=a(w),ce=o(w,"DIV",{class:!0});var Ia=v(ce);g(lt.$$.fragment,Ia),Yn=a(Ia),$r=o(Ia,"P",{"data-svelte-h":!0}),i($r)!=="svelte-1o0xh73"&&($r.textContent=$o),Ia.forEach(n),On=a(w),me=o(w,"DIV",{class:!0});var Ea=v(me);g(it.$$.fragment,Ea),Xn=a(Ea),Cr=o(Ea,"P",{"data-svelte-h":!0}),i(Cr)!=="svelte-jt4n1g"&&(Cr.innerHTML=Co),Ea.forEach(n),Zn=a(w),de=o(w,"DIV",{class:!0});var Ha=v(de);g(ct.$$.fragment,Ha),Kn=a(Ha),kr=o(Ha,"P",{"data-svelte-h":!0}),i(kr)!=="svelte-10eiwg0"&&(kr.textContent=ko),Ha.forEach(n),es=a(w),pe=o(w,"DIV",{class:!0});var Pa=v(pe);g(mt.$$.fragment,Pa),ts=a(Pa),wr=o(Pa,"P",{"data-svelte-h":!0}),i(wr)!=="svelte-1df7x4n"&&(wr.textContent=wo),Pa.forEach(n),rs=a(w),fe=o(w,"DIV",{class:!0});var Ja=v(fe);g(dt.$$.fragment,Ja),as=a(Ja),Mr=o(Ja,"P",{"data-svelte-h":!0}),i(Mr)!=="svelte-18swygp"&&(Mr.textContent=Mo),Ja.forEach(n),ns=a(w),ge=o(w,"DIV",{class:!0});var Da=v(ge);g(pt.$$.fragment,Da),ss=a(Da),yr=o(Da,"P",{"data-svelte-h":!0}),i(yr)!=="svelte-19xp05v"&&(yr.textContent=yo),Da.forEach(n),os=a(w),he=o(w,"DIV",{class:!0});var Ua=v(he);g(ft.$$.fragment,Ua),ls=a(Ua),xr=o(Ua,"P",{"data-svelte-h":!0}),i(xr)!=="svelte-7af61p"&&(xr.textContent=xo),Ua.forEach(n),is=a(w),ue=o(w,"DIV",{class:!0});var Aa=v(ue);g(gt.$$.fragment,Aa),cs=a(Aa),Lr=o(Aa,"P",{"data-svelte-h":!0}),i(Lr)!=="svelte-8cdxjr"&&(Lr.textContent=Lo),Aa.forEach(n),ms=a(w),be=o(w,"DIV",{class:!0});var Na=v(be);g(ht.$$.fragment,Na),ds=a(Na),jr=o(Na,"P",{"data-svelte-h":!0}),i(jr)!=="svelte-sluvs0"&&(jr.textContent=jo),Na.forEach(n),ps=a(w),_e=o(w,"DIV",{class:!0});var Fa=v(_e);g(ut.$$.fragment,Fa),fs=a(Fa),Ir=o(Fa,"P",{"data-svelte-h":!0}),i(Ir)!=="svelte-6bvy6d"&&(Ir.textContent=Io),Fa.forEach(n),gs=a(w),ve=o(w,"DIV",{class:!0});var Sa=v(ve);g(bt.$$.fragment,Sa),hs=a(Sa),Er=o(Sa,"P",{"data-svelte-h":!0}),i(Er)!=="svelte-zzwxsv"&&(Er.textContent=Eo),Sa.forEach(n),w.forEach(n),fa=a(e),_t=o(e,"P",{"data-svelte-h":!0}),i(_t)!=="svelte-wu4ft3"&&(_t.innerHTML=Ho),ga=a(e),g(vt.$$.fragment,e),ha=a(e),Tt=o(e,"P",{"data-svelte-h":!0}),i(Tt)!=="svelte-183oh1l"&&(Tt.innerHTML=Po),ua=a(e),g($t.$$.fragment,e),ba=a(e),g(Ct.$$.fragment,e),_a=a(e),E=o(e,"DIV",{class:!0});var Y=v(E);g(kt.$$.fragment,Y),us=a(Y),Hr=o(Y,"P",{"data-svelte-h":!0}),i(Hr)!=="svelte-1o3q9xe"&&(Hr.innerHTML=Jo),bs=a(Y),g(Te.$$.fragment,Y),_s=a(Y),$e=o(Y,"DIV",{class:!0});var Wa=v($e);g(wt.$$.fragment,Wa),vs=a(Wa),Pr=o(Wa,"P",{"data-svelte-h":!0}),i(Pr)!=="svelte-hbs6ga"&&(Pr.innerHTML=Do),Wa.forEach(n),Ts=a(Y),Ce=o(Y,"DIV",{class:!0});var za=v(Ce);g(Mt.$$.fragment,za),$s=a(za),Jr=o(za,"P",{"data-svelte-h":!0}),i(Jr)!=="svelte-dkslae"&&(Jr.innerHTML=Uo),za.forEach(n),Y.forEach(n),va=a(e),g(yt.$$.fragment,e),Ta=a(e),re=o(e,"DIV",{class:!0});var Ba=v(re);g(xt.$$.fragment,Ba),Cs=a(Ba),Dr=o(Ba,"P",{"data-svelte-h":!0}),i(Dr)!=="svelte-t17a5m"&&(Dr.innerHTML=Ao),Ba.forEach(n),$a=a(e),zr=o(e,"P",{}),v(zr).forEach(n),this.h()},h(){$(m,"name","hf:doc:metadata"),$(m,"content",ll),$(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(de,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(he,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,l){t(document.head,m),c(e,x,l),c(e,b,l),c(e,k,l),h(M,e,l),c(e,_,l),c(e,y,l),c(e,I,l),c(e,je,l),c(e,Qr,l),c(e,Ie,l),c(e,Vr,l),c(e,Ee,l),c(e,Rr,l),c(e,He,l),c(e,Gr,l),c(e,Pe,l),c(e,qr,l),h(Je,e,l),c(e,Yr,l),c(e,De,l),c(e,Or,l),c(e,S,l),h(Ue,S,null),t(S,Ra),t(S,It),t(S,Ga),t(S,H),h(Ae,H,null),t(H,qa),t(H,Et),t(H,Ya),t(H,Ht),t(H,Oa),t(H,Pt),t(H,Xa),t(H,Jt),c(e,Xr,l),c(e,O,l),h(Ne,O,null),t(O,Za),t(O,Dt),c(e,Zr,l),c(e,X,l),h(Fe,X,null),t(X,Ka),t(X,Ut),c(e,Kr,l),c(e,Z,l),h(Se,Z,null),t(Z,en),t(Z,At),c(e,ea,l),c(e,W,l),h(We,W,null),t(W,tn),t(W,Nt),t(W,rn),t(W,Ft),c(e,ta,l),c(e,K,l),h(ze,K,null),t(K,an),t(K,St),c(e,ra,l),c(e,z,l),h(Be,z,null),t(z,nn),t(z,Wt),t(z,sn),t(z,P),h(Qe,P,null),t(P,on),t(P,zt),t(P,ln),t(P,Bt),t(P,cn),t(P,Qt),t(P,mn),t(P,B),t(B,Ve),t(Ve,Vt),t(Ve,dn),h(ne,Ve,null),t(B,pn),t(B,Rt),t(B,fn),t(B,Gt),t(B,gn),t(B,qt),c(e,aa,l),c(e,Q,l),h(Re,Q,null),t(Q,hn),t(Q,Yt),t(Q,un),t(Q,A),h(Ge,A,null),t(A,bn),t(A,Ot),t(A,_n),t(A,Xt),t(A,vn),t(A,Zt),c(e,na,l),c(e,ee,l),h(qe,ee,null),t(ee,Tn),t(ee,Kt),c(e,sa,l),c(e,te,l),h(Ye,te,null),t(te,$n),t(te,er),c(e,oa,l),c(e,V,l),h(Oe,V,null),t(V,Cn),t(V,tr),t(V,kn),t(V,rr),c(e,la,l),c(e,J,l),h(Xe,J,null),t(J,wn),t(J,ar),t(J,Mn),t(J,nr),t(J,yn),t(J,sr),c(e,ia,l),c(e,R,l),h(Ze,R,null),t(R,xn),t(R,or),t(R,Ln),t(R,N),h(Ke,N,null),t(N,jn),t(N,lr),t(N,In),t(N,ir),t(N,En),t(N,cr),c(e,ca,l),c(e,G,l),h(et,G,null),t(G,Hn),t(G,mr),t(G,Pn),h(se,G,null),c(e,ma,l),c(e,D,l),h(tt,D,null),t(D,Jn),t(D,dr),t(D,Dn),t(D,pr),t(D,Un),t(D,F),h(rt,F,null),t(F,An),t(F,fr),t(F,Nn),t(F,gr),t(F,Fn),t(F,hr),c(e,da,l),h(at,e,l),c(e,pa,l),c(e,T,l),h(nt,T,null),t(T,Sn),t(T,ur),t(T,Wn),t(T,br),t(T,zn),t(T,_r),t(T,Bn),h(oe,T,null),t(T,Qn),t(T,le),h(st,le,null),t(le,Vn),t(le,vr),t(T,Rn),t(T,ie),h(ot,ie,null),t(ie,Gn),t(ie,Tr),t(T,qn),t(T,ce),h(lt,ce,null),t(ce,Yn),t(ce,$r),t(T,On),t(T,me),h(it,me,null),t(me,Xn),t(me,Cr),t(T,Zn),t(T,de),h(ct,de,null),t(de,Kn),t(de,kr),t(T,es),t(T,pe),h(mt,pe,null),t(pe,ts),t(pe,wr),t(T,rs),t(T,fe),h(dt,fe,null),t(fe,as),t(fe,Mr),t(T,ns),t(T,ge),h(pt,ge,null),t(ge,ss),t(ge,yr),t(T,os),t(T,he),h(ft,he,null),t(he,ls),t(he,xr),t(T,is),t(T,ue),h(gt,ue,null),t(ue,cs),t(ue,Lr),t(T,ms),t(T,be),h(ht,be,null),t(be,ds),t(be,jr),t(T,ps),t(T,_e),h(ut,_e,null),t(_e,fs),t(_e,Ir),t(T,gs),t(T,ve),h(bt,ve,null),t(ve,hs),t(ve,Er),c(e,fa,l),c(e,_t,l),c(e,ga,l),h(vt,e,l),c(e,ha,l),c(e,Tt,l),c(e,ua,l),h($t,e,l),c(e,ba,l),h(Ct,e,l),c(e,_a,l),c(e,E,l),h(kt,E,null),t(E,us),t(E,Hr),t(E,bs),h(Te,E,null),t(E,_s),t(E,$e),h(wt,$e,null),t($e,vs),t($e,Pr),t(E,Ts),t(E,Ce),h(Mt,Ce,null),t(Ce,$s),t(Ce,Jr),c(e,va,l),h(yt,e,l),c(e,Ta,l),c(e,re,l),h(xt,re,null),t(re,Cs),t(re,Dr),c(e,$a,l),c(e,zr,l),Ca=!0},p(e,[l]){const ae={};l&2&&(ae.$$scope={dirty:l,ctx:e}),ne.$set(ae);const U={};l&2&&(U.$$scope={dirty:l,ctx:e}),se.$set(U);const Lt={};l&2&&(Lt.$$scope={dirty:l,ctx:e}),oe.$set(Lt);const jt={};l&2&&(jt.$$scope={dirty:l,ctx:e}),Te.$set(jt)},i(e){Ca||(d(M.$$.fragment,e),d(Je.$$.fragment,e),d(Ue.$$.fragment,e),d(Ae.$$.fragment,e),d(Ne.$$.fragment,e),d(Fe.$$.fragment,e),d(Se.$$.fragment,e),d(We.$$.fragment,e),d(ze.$$.fragment,e),d(Be.$$.fragment,e),d(Qe.$$.fragment,e),d(ne.$$.fragment,e),d(Re.$$.fragment,e),d(Ge.$$.fragment,e),d(qe.$$.fragment,e),d(Ye.$$.fragment,e),d(Oe.$$.fragment,e),d(Xe.$$.fragment,e),d(Ze.$$.fragment,e),d(Ke.$$.fragment,e),d(et.$$.fragment,e),d(se.$$.fragment,e),d(tt.$$.fragment,e),d(rt.$$.fragment,e),d(at.$$.fragment,e),d(nt.$$.fragment,e),d(oe.$$.fragment,e),d(st.$$.fragment,e),d(ot.$$.fragment,e),d(lt.$$.fragment,e),d(it.$$.fragment,e),d(ct.$$.fragment,e),d(mt.$$.fragment,e),d(dt.$$.fragment,e),d(pt.$$.fragment,e),d(ft.$$.fragment,e),d(gt.$$.fragment,e),d(ht.$$.fragment,e),d(ut.$$.fragment,e),d(bt.$$.fragment,e),d(vt.$$.fragment,e),d($t.$$.fragment,e),d(Ct.$$.fragment,e),d(kt.$$.fragment,e),d(Te.$$.fragment,e),d(wt.$$.fragment,e),d(Mt.$$.fragment,e),d(yt.$$.fragment,e),d(xt.$$.fragment,e),Ca=!0)},o(e){p(M.$$.fragment,e),p(Je.$$.fragment,e),p(Ue.$$.fragment,e),p(Ae.$$.fragment,e),p(Ne.$$.fragment,e),p(Fe.$$.fragment,e),p(Se.$$.fragment,e),p(We.$$.fragment,e),p(ze.$$.fragment,e),p(Be.$$.fragment,e),p(Qe.$$.fragment,e),p(ne.$$.fragment,e),p(Re.$$.fragment,e),p(Ge.$$.fragment,e),p(qe.$$.fragment,e),p(Ye.$$.fragment,e),p(Oe.$$.fragment,e),p(Xe.$$.fragment,e),p(Ze.$$.fragment,e),p(Ke.$$.fragment,e),p(et.$$.fragment,e),p(se.$$.fragment,e),p(tt.$$.fragment,e),p(rt.$$.fragment,e),p(at.$$.fragment,e),p(nt.$$.fragment,e),p(oe.$$.fragment,e),p(st.$$.fragment,e),p(ot.$$.fragment,e),p(lt.$$.fragment,e),p(it.$$.fragment,e),p(ct.$$.fragment,e),p(mt.$$.fragment,e),p(dt.$$.fragment,e),p(pt.$$.fragment,e),p(ft.$$.fragment,e),p(gt.$$.fragment,e),p(ht.$$.fragment,e),p(ut.$$.fragment,e),p(bt.$$.fragment,e),p(vt.$$.fragment,e),p($t.$$.fragment,e),p(Ct.$$.fragment,e),p(kt.$$.fragment,e),p(Te.$$.fragment,e),p(wt.$$.fragment,e),p(Mt.$$.fragment,e),p(yt.$$.fragment,e),p(xt.$$.fragment,e),Ca=!1},d(e){e&&(n(x),n(b),n(k),n(_),n(y),n(I),n(je),n(Qr),n(Ie),n(Vr),n(Ee),n(Rr),n(He),n(Gr),n(Pe),n(qr),n(Yr),n(De),n(Or),n(S),n(Xr),n(O),n(Zr),n(X),n(Kr),n(Z),n(ea),n(W),n(ta),n(K),n(ra),n(z),n(aa),n(Q),n(na),n(ee),n(sa),n(te),n(oa),n(V),n(la),n(J),n(ia),n(R),n(ca),n(G),n(ma),n(D),n(da),n(pa),n(T),n(fa),n(_t),n(ga),n(ha),n(Tt),n(ua),n(ba),n(_a),n(E),n(va),n(Ta),n(re),n($a),n(zr)),n(m),u(M,e),u(Je,e),u(Ue),u(Ae),u(Ne),u(Fe),u(Se),u(We),u(ze),u(Be),u(Qe),u(ne),u(Re),u(Ge),u(qe),u(Ye),u(Oe),u(Xe),u(Ze),u(Ke),u(et),u(se),u(tt),u(rt),u(at,e),u(nt),u(oe),u(st),u(ot),u(lt),u(it),u(ct),u(mt),u(dt),u(pt),u(ft),u(gt),u(ht),u(ut),u(bt),u(vt,e),u($t,e),u(Ct,e),u(kt),u(Te),u(wt),u(Mt),u(yt,e),u(xt)}}}const ll='{"title":"コールバック数","local":"コールバック数","sections":[{"title":"利用可能なコールバック","local":"transformers.integrations.CometCallback","sections":[],"depth":2},{"title":"TrainerCallback","local":"transformers.TrainerCallback","sections":[],"depth":2},{"title":"TrainerState","local":"transformers.TrainerState","sections":[],"depth":2},{"title":"TrainerControl","local":"transformers.TrainerControl","sections":[],"depth":2}],"depth":1}';function il(j){return Yo(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ul extends zo{constructor(m){super(),Bo(this,m,il,ol,Wo,{})}}export{ul as component};
