import{s as Fe,o as Ae,n as qe}from"../chunks/scheduler.9991993c.js";import{S as Qe,i as Ye,g as p,s as a,r as c,A as Ne,h as i,f as s,c as n,j as Ve,u as o,x as r,k as ze,y as Ke,a as l,v as d,d as h,t as f,w as y}from"../chunks/index.7fc9a5e7.js";import{T as De}from"../chunks/Tip.9de92fc6.js";import{C as w}from"../chunks/CodeBlock.e11cba92.js";import{H as Ue}from"../chunks/Heading.e3de321f.js";function Oe(Y){let m,_="请注意，随机创建的模型使用“空”张量进行初始化，这些张量占用内存空间但不填充它（因此随机值是给定时间内该内存块中的任何内容）。在第3步之后，对未初始化的权重执行适合模型/参数种类的随机初始化（例如正态分布），以尽可能提高速度！";return{c(){m=p("p"),m.textContent=_},l(M){m=i(M,"P",{"data-svelte-h":!0}),r(m)!=="svelte-1s8s2m3"&&(m.textContent=_)},m(M,q){l(M,m,q)},p:qe,d(M){M&&s(m)}}}function et(Y){let m,_,M,q,$,N,g,xe="当你想使用一个非常大的预训练模型时，一个挑战是尽量减少对内存的使用。通常从PyTorch开始的工作流程如下：",K,u,ke="<li>用随机权重创建你的模型。</li> <li>加载你的预训练权重。</li> <li>将这些预训练权重放入你的随机模型中。</li>",D,T,Ce="步骤1和2都需要完整版本的模型在内存中，这在大多数情况下不是问题，但如果你的模型开始达到几个GB的大小，这两个副本可能会让你超出内存的限制。更糟糕的是，如果你使用<code>torch.distributed</code>来启动分布式训练，每个进程都会加载预训练模型并将这两个副本存储在内存中。",O,j,ee,b,ve="在本指南中，我们将探讨 Transformers 提供的解决方案来处理这个问题。请注意，这是一个积极开发的领域，因此这里解释的API在将来可能会略有变化。",te,U,se,x,Je="自4.18.0版本起，占用空间超过10GB的模型检查点将自动分成较小的片段。在使用<code>model.save_pretrained(save_dir)</code>时，您最终会得到几个部分<code>checkpoints</code>（每个的大小都小于10GB）以及一个索引，该索引将参数名称映射到存储它们的文件。",le,k,Be="您可以使用<code>max_shard_size</code>参数来控制分片之前的最大大小。为了示例的目的，我们将使用具有较小分片大小的普通大小的模型：让我们以传统的BERT模型为例。",ae,C,ne,v,Ze='如果您使用 <a href="%E6%A8%A1%E5%9E%8B%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BF%9D%E5%AD%98"><code>PreTrainedModel.save_pretrained</code></a> 进行保存，您将得到一个新的文件夹，其中包含两个文件：模型的配置和权重：',pe,J,ie,B,Ge="现在让我们使用最大分片大小为200MB：",me,Z,re,G,Re='在模型配置文件最上方，我们可以看到三个不同的权重文件，以及一个<code>index.json</code>索引文件。这样的<code>checkpoint</code>可以使用<a href="/docs/transformers/main/zh/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>方法完全重新加载：',ce,R,oe,X,Xe="对于大型模型来说，这样做的主要优点是在上述工作流程的步骤2中，每个<code>checkpoint</code>的分片在前一个分片之后加载，从而将内存中的内存使用限制在模型大小加上最大分片的大小。",de,H,He="在后台，索引文件用于确定<code>checkpoint</code>中包含哪些键以及相应的权重存储在哪里。我们可以像加载任何json一样加载该索引，并获得一个字典：",he,I,fe,W,Ie="目前元数据仅包括模型的总大小。我们计划在将来添加其他信息：",ye,L,Me,S,We="权重映射是该索引的主要部分，它将每个参数的名称（通常在PyTorch模型的<code>state_dict</code>中找到）映射到存储该参数的文件：",je,E,we,P,Le='如果您想直接在模型内部加载这样的分片<code>checkpoint</code>，而不使用 [<code>PreTrainedModel.from_pretrained</code>](就像您会为完整<code>checkpoint</code>执行 <code>model.load_state_dict()</code> 一样)，您应该使用 <a href="/docs/transformers/main/zh/main_classes/model#transformers.modeling_utils.load_sharded_checkpoint">modeling_utils.load_sharded_checkpoint()</a>：',_e,V,$e,z,ge,F,Se="分片<code>checkpoints</code>在上述工作流的第2步中降低了内存使用，但为了在低内存环境中使用该模型，我们建议使用基于 Accelerate 库的工具。",ue,A,Ee='请阅读以下指南以获取更多信息：<a href="./main_classes/model#large-model-loading">使用 Accelerate 进行大模型加载</a>',Te,Q,be;return $=new Ue({props:{title:"实例化大型模型",local:"实例化大型模型",headingTag:"h1"}}),j=new De({props:{$$slots:{default:[Oe]},$$scope:{ctx:Y}}}),U=new Ue({props:{title:"分片checkpoints",local:"分片checkpoints",headingTag:"h2"}}),C=new w({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS1jYXNlZCUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

model = AutoModel.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)`,wrap:!1}}),J=new w({props:{code:"aW1wb3J0JTIwb3MlMEFpbXBvcnQlMjB0ZW1wZmlsZSUwQSUwQXdpdGglMjB0ZW1wZmlsZS5UZW1wb3JhcnlEaXJlY3RvcnkoKSUyMGFzJTIwdG1wX2RpciUzQSUwQSUyMCUyMCUyMCUyMG1vZGVsLnNhdmVfcHJldHJhaW5lZCh0bXBfZGlyKSUwQSUyMCUyMCUyMCUyMHByaW50KHNvcnRlZChvcy5saXN0ZGlyKHRtcF9kaXIpKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tempfile

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir)
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(os.listdir(tmp_dir)))
[<span class="hljs-string">&#x27;config.json&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model.bin&#x27;</span>]`,wrap:!1}}),Z=new w({props:{code:"d2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjIwME1CJTIyKSUwQSUyMCUyMCUyMCUyMHByaW50KHNvcnRlZChvcy5saXN0ZGlyKHRtcF9kaXIpKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-built_in">sorted</span>(os.listdir(tmp_dir)))
[<span class="hljs-string">&#x27;config.json&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model-00001-of-00003.bin&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model-00002-of-00003.bin&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model-00003-of-00003.bin&#x27;</span>, <span class="hljs-string">&#x27;pytorch_model.bin.index.json&#x27;</span>]`,wrap:!1}}),R=new w({props:{code:"d2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjIwME1CJTIyKSUwQSUyMCUyMCUyMCUyMG5ld19tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbC5mcm9tX3ByZXRyYWluZWQodG1wX2Rpcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    new_model = AutoModel.from_pretrained(tmp_dir)`,wrap:!1}}),I=new w({props:{code:"aW1wb3J0JTIwanNvbiUwQSUwQXdpdGglMjB0ZW1wZmlsZS5UZW1wb3JhcnlEaXJlY3RvcnkoKSUyMGFzJTIwdG1wX2RpciUzQSUwQSUyMCUyMCUyMCUyMG1vZGVsLnNhdmVfcHJldHJhaW5lZCh0bXBfZGlyJTJDJTIwbWF4X3NoYXJkX3NpemUlM0QlMjIyMDBNQiUyMiklMEElMjAlMjAlMjAlMjB3aXRoJTIwb3Blbihvcy5wYXRoLmpvaW4odG1wX2RpciUyQyUyMCUyMnB5dG9yY2hfbW9kZWwuYmluLmluZGV4Lmpzb24lMjIpJTJDJTIwJTIyciUyMiklMjBhcyUyMGYlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBpbmRleCUyMCUzRCUyMGpzb24ubG9hZChmKSUwQSUwQXByaW50KGluZGV4LmtleXMoKSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> json

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(os.path.join(tmp_dir, <span class="hljs-string">&quot;pytorch_model.bin.index.json&quot;</span>), <span class="hljs-string">&quot;r&quot;</span>) <span class="hljs-keyword">as</span> f:
<span class="hljs-meta">... </span>        index = json.load(f)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(index.keys())
dict_keys([<span class="hljs-string">&#x27;metadata&#x27;</span>, <span class="hljs-string">&#x27;weight_map&#x27;</span>])`,wrap:!1}}),L=new w({props:{code:"aW5kZXglNUIlMjJtZXRhZGF0YSUyMiU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>index[<span class="hljs-string">&quot;metadata&quot;</span>]
{<span class="hljs-string">&#x27;total_size&#x27;</span>: <span class="hljs-number">433245184</span>}`,wrap:!1}}),E=new w({props:{code:"aW5kZXglNUIlMjJ3ZWlnaHRfbWFwJTIyJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>index[<span class="hljs-string">&quot;weight_map&quot;</span>]
{<span class="hljs-string">&#x27;embeddings.LayerNorm.bias&#x27;</span>: <span class="hljs-string">&#x27;pytorch_model-00001-of-00003.bin&#x27;</span>,
 <span class="hljs-string">&#x27;embeddings.LayerNorm.weight&#x27;</span>: <span class="hljs-string">&#x27;pytorch_model-00001-of-00003.bin&#x27;</span>,
 ...`,wrap:!1}}),V=new w({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbGluZ191dGlscyUyMGltcG9ydCUyMGxvYWRfc2hhcmRlZF9jaGVja3BvaW50JTBBJTBBd2l0aCUyMHRlbXBmaWxlLlRlbXBvcmFyeURpcmVjdG9yeSgpJTIwYXMlMjB0bXBfZGlyJTNBJTBBJTIwJTIwJTIwJTIwbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHRtcF9kaXIlMkMlMjBtYXhfc2hhcmRfc2l6ZSUzRCUyMjIwME1CJTIyKSUwQSUyMCUyMCUyMCUyMGxvYWRfc2hhcmRlZF9jaGVja3BvaW50KG1vZGVsJTJDJTIwdG1wX2Rpcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.modeling_utils <span class="hljs-keyword">import</span> load_sharded_checkpoint

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> tempfile.TemporaryDirectory() <span class="hljs-keyword">as</span> tmp_dir:
<span class="hljs-meta">... </span>    model.save_pretrained(tmp_dir, max_shard_size=<span class="hljs-string">&quot;200MB&quot;</span>)
<span class="hljs-meta">... </span>    load_sharded_checkpoint(model, tmp_dir)`,wrap:!1}}),z=new Ue({props:{title:"低内存加载",local:"低内存加载",headingTag:"h2"}}),{c(){m=p("meta"),_=a(),M=p("p"),q=a(),c($.$$.fragment),N=a(),g=p("p"),g.textContent=xe,K=a(),u=p("ol"),u.innerHTML=ke,D=a(),T=p("p"),T.innerHTML=Ce,O=a(),c(j.$$.fragment),ee=a(),b=p("p"),b.textContent=ve,te=a(),c(U.$$.fragment),se=a(),x=p("p"),x.innerHTML=Je,le=a(),k=p("p"),k.innerHTML=Be,ae=a(),c(C.$$.fragment),ne=a(),v=p("p"),v.innerHTML=Ze,pe=a(),c(J.$$.fragment),ie=a(),B=p("p"),B.textContent=Ge,me=a(),c(Z.$$.fragment),re=a(),G=p("p"),G.innerHTML=Re,ce=a(),c(R.$$.fragment),oe=a(),X=p("p"),X.innerHTML=Xe,de=a(),H=p("p"),H.innerHTML=He,he=a(),c(I.$$.fragment),fe=a(),W=p("p"),W.textContent=Ie,ye=a(),c(L.$$.fragment),Me=a(),S=p("p"),S.innerHTML=We,je=a(),c(E.$$.fragment),we=a(),P=p("p"),P.innerHTML=Le,_e=a(),c(V.$$.fragment),$e=a(),c(z.$$.fragment),ge=a(),F=p("p"),F.innerHTML=Se,ue=a(),A=p("p"),A.innerHTML=Ee,Te=a(),Q=p("p"),this.h()},l(e){const t=Ne("svelte-u9bgzb",document.head);m=i(t,"META",{name:!0,content:!0}),t.forEach(s),_=n(e),M=i(e,"P",{}),Ve(M).forEach(s),q=n(e),o($.$$.fragment,e),N=n(e),g=i(e,"P",{"data-svelte-h":!0}),r(g)!=="svelte-f980nr"&&(g.textContent=xe),K=n(e),u=i(e,"OL",{"data-svelte-h":!0}),r(u)!=="svelte-qi8gup"&&(u.innerHTML=ke),D=n(e),T=i(e,"P",{"data-svelte-h":!0}),r(T)!=="svelte-3m51fj"&&(T.innerHTML=Ce),O=n(e),o(j.$$.fragment,e),ee=n(e),b=i(e,"P",{"data-svelte-h":!0}),r(b)!=="svelte-1fsody1"&&(b.textContent=ve),te=n(e),o(U.$$.fragment,e),se=n(e),x=i(e,"P",{"data-svelte-h":!0}),r(x)!=="svelte-p12rar"&&(x.innerHTML=Je),le=n(e),k=i(e,"P",{"data-svelte-h":!0}),r(k)!=="svelte-fnq70n"&&(k.innerHTML=Be),ae=n(e),o(C.$$.fragment,e),ne=n(e),v=i(e,"P",{"data-svelte-h":!0}),r(v)!=="svelte-1vlh5wl"&&(v.innerHTML=Ze),pe=n(e),o(J.$$.fragment,e),ie=n(e),B=i(e,"P",{"data-svelte-h":!0}),r(B)!=="svelte-15702pw"&&(B.textContent=Ge),me=n(e),o(Z.$$.fragment,e),re=n(e),G=i(e,"P",{"data-svelte-h":!0}),r(G)!=="svelte-yzeurb"&&(G.innerHTML=Re),ce=n(e),o(R.$$.fragment,e),oe=n(e),X=i(e,"P",{"data-svelte-h":!0}),r(X)!=="svelte-bnpz0s"&&(X.innerHTML=Xe),de=n(e),H=i(e,"P",{"data-svelte-h":!0}),r(H)!=="svelte-18it1xo"&&(H.innerHTML=He),he=n(e),o(I.$$.fragment,e),fe=n(e),W=i(e,"P",{"data-svelte-h":!0}),r(W)!=="svelte-26dikn"&&(W.textContent=Ie),ye=n(e),o(L.$$.fragment,e),Me=n(e),S=i(e,"P",{"data-svelte-h":!0}),r(S)!=="svelte-1lig6ro"&&(S.innerHTML=We),je=n(e),o(E.$$.fragment,e),we=n(e),P=i(e,"P",{"data-svelte-h":!0}),r(P)!=="svelte-8dbmah"&&(P.innerHTML=Le),_e=n(e),o(V.$$.fragment,e),$e=n(e),o(z.$$.fragment,e),ge=n(e),F=i(e,"P",{"data-svelte-h":!0}),r(F)!=="svelte-1qqd7tm"&&(F.innerHTML=Se),ue=n(e),A=i(e,"P",{"data-svelte-h":!0}),r(A)!=="svelte-kz6dhx"&&(A.innerHTML=Ee),Te=n(e),Q=i(e,"P",{}),Ve(Q).forEach(s),this.h()},h(){ze(m,"name","hf:doc:metadata"),ze(m,"content",tt)},m(e,t){Ke(document.head,m),l(e,_,t),l(e,M,t),l(e,q,t),d($,e,t),l(e,N,t),l(e,g,t),l(e,K,t),l(e,u,t),l(e,D,t),l(e,T,t),l(e,O,t),d(j,e,t),l(e,ee,t),l(e,b,t),l(e,te,t),d(U,e,t),l(e,se,t),l(e,x,t),l(e,le,t),l(e,k,t),l(e,ae,t),d(C,e,t),l(e,ne,t),l(e,v,t),l(e,pe,t),d(J,e,t),l(e,ie,t),l(e,B,t),l(e,me,t),d(Z,e,t),l(e,re,t),l(e,G,t),l(e,ce,t),d(R,e,t),l(e,oe,t),l(e,X,t),l(e,de,t),l(e,H,t),l(e,he,t),d(I,e,t),l(e,fe,t),l(e,W,t),l(e,ye,t),d(L,e,t),l(e,Me,t),l(e,S,t),l(e,je,t),d(E,e,t),l(e,we,t),l(e,P,t),l(e,_e,t),d(V,e,t),l(e,$e,t),d(z,e,t),l(e,ge,t),l(e,F,t),l(e,ue,t),l(e,A,t),l(e,Te,t),l(e,Q,t),be=!0},p(e,[t]){const Pe={};t&2&&(Pe.$$scope={dirty:t,ctx:e}),j.$set(Pe)},i(e){be||(h($.$$.fragment,e),h(j.$$.fragment,e),h(U.$$.fragment,e),h(C.$$.fragment,e),h(J.$$.fragment,e),h(Z.$$.fragment,e),h(R.$$.fragment,e),h(I.$$.fragment,e),h(L.$$.fragment,e),h(E.$$.fragment,e),h(V.$$.fragment,e),h(z.$$.fragment,e),be=!0)},o(e){f($.$$.fragment,e),f(j.$$.fragment,e),f(U.$$.fragment,e),f(C.$$.fragment,e),f(J.$$.fragment,e),f(Z.$$.fragment,e),f(R.$$.fragment,e),f(I.$$.fragment,e),f(L.$$.fragment,e),f(E.$$.fragment,e),f(V.$$.fragment,e),f(z.$$.fragment,e),be=!1},d(e){e&&(s(_),s(M),s(q),s(N),s(g),s(K),s(u),s(D),s(T),s(O),s(ee),s(b),s(te),s(se),s(x),s(le),s(k),s(ae),s(ne),s(v),s(pe),s(ie),s(B),s(me),s(re),s(G),s(ce),s(oe),s(X),s(de),s(H),s(he),s(fe),s(W),s(ye),s(Me),s(S),s(je),s(we),s(P),s(_e),s($e),s(ge),s(F),s(ue),s(A),s(Te),s(Q)),s(m),y($,e),y(j,e),y(U,e),y(C,e),y(J,e),y(Z,e),y(R,e),y(I,e),y(L,e),y(E,e),y(V,e),y(z,e)}}}const tt='{"title":"实例化大型模型","local":"实例化大型模型","sections":[{"title":"分片checkpoints","local":"分片checkpoints","sections":[],"depth":2},{"title":"低内存加载","local":"低内存加载","sections":[],"depth":2}],"depth":1}';function st(Y){return Ae(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class mt extends Qe{constructor(m){super(),Ye(this,m,st,et,Fe,{})}}export{mt as component};
