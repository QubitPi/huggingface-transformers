import{s as Qt,o as Lt,n as Et}from"../chunks/scheduler.9991993c.js";import{S as zt,i as It,g as n,s,r,A as Nt,h as o,f as l,c as p,j as Xt,u as m,x as u,k as $e,y as Pt,a,v as d,d as f,t as M,w as b}from"../chunks/index.7fc9a5e7.js";import{T as xt}from"../chunks/Tip.9de92fc6.js";import{C as $}from"../chunks/CodeBlock.e11cba92.js";import{D as Yt}from"../chunks/DocNotebookDropdown.a0cb4c0f.js";import{H as _}from"../chunks/Heading.e3de321f.js";function At(ue){let i,y="你可以使用<code>AutoModelFor</code>类或基础模型类（如<code>OPTForCausalLM</code>或<code>LlamaForCausalLM</code>）来加载一个PEFT adapter。";return{c(){i=n("p"),i.innerHTML=y},l(c){i=o(c,"P",{"data-svelte-h":!0}),u(i)!=="svelte-ttdt4u"&&(i.innerHTML=y)},m(c,T){a(c,i,T)},p:Et,d(c){c&&l(i)}}}function qt(ue){let i,y='如果你不熟悉如何使用<code>Trainer</code>微调模型，请查看<a href="training">微调预训练模型</a>教程。';return{c(){i=n("p"),i.innerHTML=y},l(c){i=o(c,"P",{"data-svelte-h":!0}),u(i)!=="svelte-f6p6ap"&&(i.innerHTML=y)},m(c,T){a(c,i,T)},p:Et,d(c){c&&l(i)}}}function St(ue){let i,y,c,T,Z,ye,U,Te,k,Mt='<a href="https://huggingface.co/blog/peft" rel="nofollow">参数高效微调（PEFT）方法</a>在微调过程中冻结预训练模型的参数，并在其顶部添加少量可训练参数（adapters）。adapters被训练以学习特定任务的信息。这种方法已被证明非常节省内存，同时具有较低的计算使用量，同时产生与完全微调模型相当的结果。',he,v,bt="使用PEFT训练的adapters通常比完整模型小一个数量级，使其方便共享、存储和加载。",we,h,ut='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/PEFT-hub-screenshot.png"/> <figcaption class="text-center">与完整尺寸的模型权重（约为700MB）相比，存储在Hub上的OPTForCausalLM模型的adapter权重仅为~6MB。</figcaption>',ge,F,ct='如果您对学习更多关于🤗 PEFT库感兴趣，请查看<a href="https://huggingface.co/docs/peft/index" rel="nofollow">文档</a>。',Je,W,Ce,j,$t="首先安装 🤗 PEFT：",_e,B,Ze,R,yt="如果你想尝试全新的特性，你可能会有兴趣从源代码安装这个库：",Ue,V,ke,G,ve,H,Tt="Transformers原生支持一些PEFT方法，这意味着你可以加载本地存储或在Hub上的adapter权重，并使用几行代码轻松运行或训练它们。以下是受支持的方法：",Fe,X,ht='<li><a href="https://huggingface.co/docs/peft/conceptual_guides/lora" rel="nofollow">Low Rank Adapters</a></li> <li><a href="https://huggingface.co/docs/peft/conceptual_guides/ia3" rel="nofollow">IA3</a></li> <li><a href="https://arxiv.org/abs/2303.10512" rel="nofollow">AdaLoRA</a></li>',We,x,wt='如果你想使用其他PEFT方法，例如提示学习或提示微调，或者关于通用的 🤗 PEFT库，请参阅<a href="https://huggingface.co/docs/peft/index" rel="nofollow">文档</a>。',je,E,Be,Q,gt="要从huggingface的Transformers库中加载并使用PEFTadapter模型，请确保Hub仓库或本地目录包含一个<code>adapter_config.json</code>文件和adapter权重，如上例所示。然后，您可以使用<code>AutoModelFor</code>类加载PEFT adapter模型。例如，要为因果语言建模加载一个PEFT adapter模型：",Re,L,Jt="<li>指定PEFT模型id</li> <li>将其传递给<code>AutoModelForCausalLM</code>类</li>",Ve,z,Ge,w,He,I,Ct="您也可以通过<code>load_adapter</code>方法来加载 PEFT adapter。",Xe,N,xe,P,Ee,Y,_t='<code>bitsandbytes</code>集成支持8bit和4bit精度数据类型，这对于加载大模型非常有用，因为它可以节省内存（请参阅<code>bitsandbytes</code><a href="./quantization#bitsandbytes-integration">指南</a>以了解更多信息）。要有效地将模型分配到您的硬件，请在<a href="/docs/transformers/main/zh/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>中添加<code>load_in_8bit</code>或<code>load_in_4bit</code>参数，并将<code>device_map=&quot;auto&quot;</code>设置为：',Qe,A,Le,q,ze,S,Zt="你可以使用<code>~peft.PeftModel.add_adapter</code>方法为一个已有adapter的模型添加一个新的adapter，只要新adapter的类型与当前adapter相同即可。例如，如果你有一个附加到模型上的LoRA adapter：",Ie,K,Ne,D,Ut="添加一个新的adapter：",Pe,O,Ye,ee,kt="现在您可以使用<code>~peft.PeftModel.set_adapter</code>来设置要使用的adapter。",Ae,te,qe,le,Se,ae,vt="一旦您将adapter添加到模型中，您可以启用或禁用adapter模块。要启用adapter模块：",Ke,se,De,pe,Ft="要禁用adapter模块：",Oe,ne,et,oe,tt,ie,Wt="PEFT适配器受<code>Trainer</code>类支持，因此您可以为您的特定用例训练适配器。它只需要添加几行代码即可。例如，要训练一个LoRA adapter：",lt,g,at,re,jt="<li>使用任务类型和超参数定义adapter配置（参见<code>~peft.LoraConfig</code>以了解超参数的详细信息）。</li>",st,me,pt,J,Bt="<li>将adapter添加到模型中。</li>",nt,de,ot,C,Rt="<li>现在可以将模型传递给<code>Trainer</code>了！</li>",it,fe,rt,Me,Vt="要保存训练好的adapter并重新加载它：",mt,be,dt,ce,ft;return Z=new _({props:{title:"使用 🤗 PEFT 加载adapters",local:"使用--peft-加载adapters",headingTag:"h1"}}),U=new Yt({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/zh/peft.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/zh/pytorch/peft.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/zh/tensorflow/peft.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/zh/peft.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/zh/pytorch/peft.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/zh/tensorflow/peft.ipynb"}]}}),W=new _({props:{title:"设置",local:"设置",headingTag:"h2"}}),B=new $({props:{code:"cGlwJTIwaW5zdGFsbCUyMHBlZnQ=",highlighted:"pip install peft",wrap:!1}}),V=new $({props:{code:"cGlwJTIwaW5zdGFsbCUyMGdpdCUyQmh0dHBzJTNBJTJGJTJGZ2l0aHViLmNvbSUyRmh1Z2dpbmdmYWNlJTJGcGVmdC5naXQ=",highlighted:"pip install git+https://github.com/huggingface/peft.git",wrap:!1}}),G=new _({props:{title:"支持的 PEFT 模型",local:"支持的-peft-模型",headingTag:"h2"}}),E=new _({props:{title:"加载 PEFT adapter",local:"加载-peft-adapter",headingTag:"h2"}}),z=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQXBlZnRfbW9kZWxfaWQlMjAlM0QlMjAlMjJ5YmVsa2FkYSUyRm9wdC0zNTBtLWxvcmElMjIlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChwZWZ0X21vZGVsX2lkKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

peft_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>
model = AutoModelForCausalLM.from_pretrained(peft_model_id)`,wrap:!1}}),w=new xt({props:{$$slots:{default:[At]},$$scope:{ctx:ue}}}),N=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQW1vZGVsX2lkJTIwJTNEJTIwJTIyZmFjZWJvb2slMkZvcHQtMzUwbSUyMiUwQXBlZnRfbW9kZWxfaWQlMjAlM0QlMjAlMjJ5YmVsa2FkYSUyRm9wdC0zNTBtLWxvcmElMjIlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChtb2RlbF9pZCklMEFtb2RlbC5sb2FkX2FkYXB0ZXIocGVmdF9tb2RlbF9pZCk=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

model_id = <span class="hljs-string">&quot;facebook/opt-350m&quot;</span>
peft_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>

model = AutoModelForCausalLM.from_pretrained(model_id)
model.load_adapter(peft_model_id)`,wrap:!1}}),P=new _({props:{title:"基于8bit或4bit进行加载",local:"基于8bit或4bit进行加载",headingTag:"h2"}}),A=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwQXV0b1Rva2VuaXplciUwQSUwQXBlZnRfbW9kZWxfaWQlMjAlM0QlMjAlMjJ5YmVsa2FkYSUyRm9wdC0zNTBtLWxvcmElMjIlMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChwZWZ0X21vZGVsX2lkJTJDJTIwZGV2aWNlX21hcCUzRCUyMmF1dG8lMjIlMkMlMjBsb2FkX2luXzhiaXQlM0RUcnVlKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer

peft_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>
model = AutoModelForCausalLM.from_pretrained(peft_model_id, device_map=<span class="hljs-string">&quot;auto&quot;</span>, load_in_8bit=<span class="hljs-literal">True</span>)`,wrap:!1}}),q=new _({props:{title:"添加新的adapter",local:"添加新的adapter",headingTag:"h2"}}),K=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwT1BURm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTBBZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBQZWZ0Q29uZmlnJTBBJTBBbW9kZWxfaWQlMjAlM0QlMjAlMjJmYWNlYm9vayUyRm9wdC0zNTBtJTIyJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQobW9kZWxfaWQpJTBBJTBBbG9yYV9jb25maWclMjAlM0QlMjBMb3JhQ29uZmlnKCUwQSUyMCUyMCUyMCUyMHRhcmdldF9tb2R1bGVzJTNEJTVCJTIycV9wcm9qJTIyJTJDJTIwJTIya19wcm9qJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwaW5pdF9sb3JhX3dlaWdodHMlM0RGYWxzZSUwQSklMEElMEFtb2RlbC5hZGRfYWRhcHRlcihsb3JhX2NvbmZpZyUyQyUyMGFkYXB0ZXJfbmFtZSUzRCUyMmFkYXB0ZXJfMSUyMik=",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer
<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftConfig

model_id = <span class="hljs-string">&quot;facebook/opt-350m&quot;</span>
model = AutoModelForCausalLM.from_pretrained(model_id)

lora_config = LoraConfig(
    target_modules=[<span class="hljs-string">&quot;q_proj&quot;</span>, <span class="hljs-string">&quot;k_proj&quot;</span>],
    init_lora_weights=<span class="hljs-literal">False</span>
)

model.add_adapter(lora_config, adapter_name=<span class="hljs-string">&quot;adapter_1&quot;</span>)`,wrap:!1}}),O=new $({props:{code:"JTIzJTIwYXR0YWNoJTIwbmV3JTIwYWRhcHRlciUyMHdpdGglMjBzYW1lJTIwY29uZmlnJTBBbW9kZWwuYWRkX2FkYXB0ZXIobG9yYV9jb25maWclMkMlMjBhZGFwdGVyX25hbWUlM0QlMjJhZGFwdGVyXzIlMjIp",highlighted:`<span class="hljs-comment"># attach new adapter with same config</span>
model.add_adapter(lora_config, adapter_name=<span class="hljs-string">&quot;adapter_2&quot;</span>)`,wrap:!1}}),te=new $({props:{code:"JTIzJTIwdXNlJTIwYWRhcHRlcl8xJTBBbW9kZWwuc2V0X2FkYXB0ZXIoJTIyYWRhcHRlcl8xJTIyKSUwQW91dHB1dCUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqaW5wdXRzKSUwQXByaW50KHRva2VuaXplci5kZWNvZGUob3V0cHV0X2Rpc2FibGVkJTVCMCU1RCUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSklMEElMEElMjMlMjB1c2UlMjBhZGFwdGVyXzIlMEFtb2RlbC5zZXRfYWRhcHRlciglMjJhZGFwdGVyXzIlMjIpJTBBb3V0cHV0X2VuYWJsZWQlMjAlM0QlMjBtb2RlbC5nZW5lcmF0ZSgqKmlucHV0cyklMEFwcmludCh0b2tlbml6ZXIuZGVjb2RlKG91dHB1dF9lbmFibGVkJTVCMCU1RCUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKSk=",highlighted:`<span class="hljs-comment"># use adapter_1</span>
model.set_adapter(<span class="hljs-string">&quot;adapter_1&quot;</span>)
output = model.generate(**inputs)
<span class="hljs-built_in">print</span>(tokenizer.decode(output_disabled[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))

<span class="hljs-comment"># use adapter_2</span>
model.set_adapter(<span class="hljs-string">&quot;adapter_2&quot;</span>)
output_enabled = model.generate(**inputs)
<span class="hljs-built_in">print</span>(tokenizer.decode(output_enabled[<span class="hljs-number">0</span>], skip_special_tokens=<span class="hljs-literal">True</span>))`,wrap:!1}}),le=new _({props:{title:"启用和禁用adapters",local:"启用和禁用adapters",headingTag:"h2"}}),se=new $({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwT1BURm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTBBZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBQZWZ0Q29uZmlnJTBBJTBBbW9kZWxfaWQlMjAlM0QlMjAlMjJmYWNlYm9vayUyRm9wdC0zNTBtJTIyJTBBYWRhcHRlcl9tb2RlbF9pZCUyMCUzRCUyMCUyMnliZWxrYWRhJTJGb3B0LTM1MG0tbG9yYSUyMiUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2lkKSUwQXRleHQlMjAlM0QlMjAlMjJIZWxsbyUyMiUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcih0ZXh0JTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNLmZyb21fcHJldHJhaW5lZChtb2RlbF9pZCklMEFwZWZ0X2NvbmZpZyUyMCUzRCUyMFBlZnRDb25maWcuZnJvbV9wcmV0cmFpbmVkKGFkYXB0ZXJfbW9kZWxfaWQpJTBBJTBBJTIzJTIwdG8lMjBpbml0aWF0ZSUyMHdpdGglMjByYW5kb20lMjB3ZWlnaHRzJTBBcGVmdF9jb25maWcuaW5pdF9sb3JhX3dlaWdodHMlMjAlM0QlMjBGYWxzZSUwQSUwQW1vZGVsLmFkZF9hZGFwdGVyKHBlZnRfY29uZmlnKSUwQW1vZGVsLmVuYWJsZV9hZGFwdGVycygpJTBBb3V0cHV0JTIwJTNEJTIwbW9kZWwuZ2VuZXJhdGUoKippbnB1dHMp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, OPTForCausalLM, AutoTokenizer
<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> PeftConfig

model_id = <span class="hljs-string">&quot;facebook/opt-350m&quot;</span>
adapter_model_id = <span class="hljs-string">&quot;ybelkada/opt-350m-lora&quot;</span>
tokenizer = AutoTokenizer.from_pretrained(model_id)
text = <span class="hljs-string">&quot;Hello&quot;</span>
inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)

model = AutoModelForCausalLM.from_pretrained(model_id)
peft_config = PeftConfig.from_pretrained(adapter_model_id)

<span class="hljs-comment"># to initiate with random weights</span>
peft_config.init_lora_weights = <span class="hljs-literal">False</span>

model.add_adapter(peft_config)
model.enable_adapters()
output = model.generate(**inputs)`,wrap:!1}}),ne=new $({props:{code:"bW9kZWwuZGlzYWJsZV9hZGFwdGVycygpJTBBb3V0cHV0JTIwJTNEJTIwbW9kZWwuZ2VuZXJhdGUoKippbnB1dHMp",highlighted:`model.disable_adapters()
output = model.generate(**inputs)`,wrap:!1}}),oe=new _({props:{title:"训练一个 PEFT adapter",local:"训练一个-peft-adapter",headingTag:"h2"}}),g=new xt({props:{$$slots:{default:[qt]},$$scope:{ctx:ue}}}),me=new $({props:{code:"ZnJvbSUyMHBlZnQlMjBpbXBvcnQlMjBMb3JhQ29uZmlnJTBBJTBBcGVmdF9jb25maWclMjAlM0QlMjBMb3JhQ29uZmlnKCUwQSUyMCUyMCUyMCUyMGxvcmFfYWxwaGElM0QxNiUyQyUwQSUyMCUyMCUyMCUyMGxvcmFfZHJvcG91dCUzRDAuMSUyQyUwQSUyMCUyMCUyMCUyMHIlM0Q2NCUyQyUwQSUyMCUyMCUyMCUyMGJpYXMlM0QlMjJub25lJTIyJTJDJTBBJTIwJTIwJTIwJTIwdGFza190eXBlJTNEJTIyQ0FVU0FMX0xNJTIyJTJDJTBBKQ==",highlighted:`<span class="hljs-keyword">from</span> peft <span class="hljs-keyword">import</span> LoraConfig

peft_config = LoraConfig(
    lora_alpha=<span class="hljs-number">16</span>,
    lora_dropout=<span class="hljs-number">0.1</span>,
    r=<span class="hljs-number">64</span>,
    bias=<span class="hljs-string">&quot;none&quot;</span>,
    task_type=<span class="hljs-string">&quot;CAUSAL_LM&quot;</span>,
)`,wrap:!1}}),de=new $({props:{code:"bW9kZWwuYWRkX2FkYXB0ZXIocGVmdF9jb25maWcp",highlighted:"model.add_adapter(peft_config)",wrap:!1}}),fe=new $({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIobW9kZWwlM0Rtb2RlbCUyQyUyMC4uLiklMEF0cmFpbmVyLnRyYWluKCk=",highlighted:`trainer = Trainer(model=model, ...)
trainer.train()`,wrap:!1}}),be=new $({props:{code:"bW9kZWwuc2F2ZV9wcmV0cmFpbmVkKHNhdmVfZGlyKSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKHNhdmVfZGlyKQ==",highlighted:`model.save_pretrained(save_dir)
model = AutoModelForCausalLM.from_pretrained(save_dir)`,wrap:!1}}),{c(){i=n("meta"),y=s(),c=n("p"),T=s(),r(Z.$$.fragment),ye=s(),r(U.$$.fragment),Te=s(),k=n("p"),k.innerHTML=Mt,he=s(),v=n("p"),v.textContent=bt,we=s(),h=n("div"),h.innerHTML=ut,ge=s(),F=n("p"),F.innerHTML=ct,Je=s(),r(W.$$.fragment),Ce=s(),j=n("p"),j.textContent=$t,_e=s(),r(B.$$.fragment),Ze=s(),R=n("p"),R.textContent=yt,Ue=s(),r(V.$$.fragment),ke=s(),r(G.$$.fragment),ve=s(),H=n("p"),H.textContent=Tt,Fe=s(),X=n("ul"),X.innerHTML=ht,We=s(),x=n("p"),x.innerHTML=wt,je=s(),r(E.$$.fragment),Be=s(),Q=n("p"),Q.innerHTML=gt,Re=s(),L=n("ol"),L.innerHTML=Jt,Ve=s(),r(z.$$.fragment),Ge=s(),r(w.$$.fragment),He=s(),I=n("p"),I.innerHTML=Ct,Xe=s(),r(N.$$.fragment),xe=s(),r(P.$$.fragment),Ee=s(),Y=n("p"),Y.innerHTML=_t,Qe=s(),r(A.$$.fragment),Le=s(),r(q.$$.fragment),ze=s(),S=n("p"),S.innerHTML=Zt,Ie=s(),r(K.$$.fragment),Ne=s(),D=n("p"),D.textContent=Ut,Pe=s(),r(O.$$.fragment),Ye=s(),ee=n("p"),ee.innerHTML=kt,Ae=s(),r(te.$$.fragment),qe=s(),r(le.$$.fragment),Se=s(),ae=n("p"),ae.textContent=vt,Ke=s(),r(se.$$.fragment),De=s(),pe=n("p"),pe.textContent=Ft,Oe=s(),r(ne.$$.fragment),et=s(),r(oe.$$.fragment),tt=s(),ie=n("p"),ie.innerHTML=Wt,lt=s(),r(g.$$.fragment),at=s(),re=n("ol"),re.innerHTML=jt,st=s(),r(me.$$.fragment),pt=s(),J=n("ol"),J.innerHTML=Bt,nt=s(),r(de.$$.fragment),ot=s(),C=n("ol"),C.innerHTML=Rt,it=s(),r(fe.$$.fragment),rt=s(),Me=n("p"),Me.textContent=Vt,mt=s(),r(be.$$.fragment),dt=s(),ce=n("p"),this.h()},l(e){const t=Nt("svelte-u9bgzb",document.head);i=o(t,"META",{name:!0,content:!0}),t.forEach(l),y=p(e),c=o(e,"P",{}),Xt(c).forEach(l),T=p(e),m(Z.$$.fragment,e),ye=p(e),m(U.$$.fragment,e),Te=p(e),k=o(e,"P",{"data-svelte-h":!0}),u(k)!=="svelte-12hf5s4"&&(k.innerHTML=Mt),he=p(e),v=o(e,"P",{"data-svelte-h":!0}),u(v)!=="svelte-qlvep8"&&(v.textContent=bt),we=p(e),h=o(e,"DIV",{class:!0,"data-svelte-h":!0}),u(h)!=="svelte-132vjgz"&&(h.innerHTML=ut),ge=p(e),F=o(e,"P",{"data-svelte-h":!0}),u(F)!=="svelte-11ekk53"&&(F.innerHTML=ct),Je=p(e),m(W.$$.fragment,e),Ce=p(e),j=o(e,"P",{"data-svelte-h":!0}),u(j)!=="svelte-1nacabe"&&(j.textContent=$t),_e=p(e),m(B.$$.fragment,e),Ze=p(e),R=o(e,"P",{"data-svelte-h":!0}),u(R)!=="svelte-15fz30p"&&(R.textContent=yt),Ue=p(e),m(V.$$.fragment,e),ke=p(e),m(G.$$.fragment,e),ve=p(e),H=o(e,"P",{"data-svelte-h":!0}),u(H)!=="svelte-yd0lot"&&(H.textContent=Tt),Fe=p(e),X=o(e,"UL",{"data-svelte-h":!0}),u(X)!=="svelte-1ulyaf4"&&(X.innerHTML=ht),We=p(e),x=o(e,"P",{"data-svelte-h":!0}),u(x)!=="svelte-1afbjhn"&&(x.innerHTML=wt),je=p(e),m(E.$$.fragment,e),Be=p(e),Q=o(e,"P",{"data-svelte-h":!0}),u(Q)!=="svelte-1w0h7uv"&&(Q.innerHTML=gt),Re=p(e),L=o(e,"OL",{"data-svelte-h":!0}),u(L)!=="svelte-1teyl3"&&(L.innerHTML=Jt),Ve=p(e),m(z.$$.fragment,e),Ge=p(e),m(w.$$.fragment,e),He=p(e),I=o(e,"P",{"data-svelte-h":!0}),u(I)!=="svelte-sklh8l"&&(I.innerHTML=Ct),Xe=p(e),m(N.$$.fragment,e),xe=p(e),m(P.$$.fragment,e),Ee=p(e),Y=o(e,"P",{"data-svelte-h":!0}),u(Y)!=="svelte-1uvi8jr"&&(Y.innerHTML=_t),Qe=p(e),m(A.$$.fragment,e),Le=p(e),m(q.$$.fragment,e),ze=p(e),S=o(e,"P",{"data-svelte-h":!0}),u(S)!=="svelte-1ru1fss"&&(S.innerHTML=Zt),Ie=p(e),m(K.$$.fragment,e),Ne=p(e),D=o(e,"P",{"data-svelte-h":!0}),u(D)!=="svelte-1ncxqeu"&&(D.textContent=Ut),Pe=p(e),m(O.$$.fragment,e),Ye=p(e),ee=o(e,"P",{"data-svelte-h":!0}),u(ee)!=="svelte-rz0rsf"&&(ee.innerHTML=kt),Ae=p(e),m(te.$$.fragment,e),qe=p(e),m(le.$$.fragment,e),Se=p(e),ae=o(e,"P",{"data-svelte-h":!0}),u(ae)!=="svelte-1bhurej"&&(ae.textContent=vt),Ke=p(e),m(se.$$.fragment,e),De=p(e),pe=o(e,"P",{"data-svelte-h":!0}),u(pe)!=="svelte-3in7n1"&&(pe.textContent=Ft),Oe=p(e),m(ne.$$.fragment,e),et=p(e),m(oe.$$.fragment,e),tt=p(e),ie=o(e,"P",{"data-svelte-h":!0}),u(ie)!=="svelte-icxw9d"&&(ie.innerHTML=Wt),lt=p(e),m(g.$$.fragment,e),at=p(e),re=o(e,"OL",{"data-svelte-h":!0}),u(re)!=="svelte-5hhrit"&&(re.innerHTML=jt),st=p(e),m(me.$$.fragment,e),pt=p(e),J=o(e,"OL",{start:!0,"data-svelte-h":!0}),u(J)!=="svelte-1ah7cux"&&(J.innerHTML=Bt),nt=p(e),m(de.$$.fragment,e),ot=p(e),C=o(e,"OL",{start:!0,"data-svelte-h":!0}),u(C)!=="svelte-1t5e9c7"&&(C.innerHTML=Rt),it=p(e),m(fe.$$.fragment,e),rt=p(e),Me=o(e,"P",{"data-svelte-h":!0}),u(Me)!=="svelte-rh8m8z"&&(Me.textContent=Vt),mt=p(e),m(be.$$.fragment,e),dt=p(e),ce=o(e,"P",{}),Xt(ce).forEach(l),this.h()},h(){$e(i,"name","hf:doc:metadata"),$e(i,"content",Kt),$e(h,"class","flex flex-col justify-center"),$e(J,"start","2"),$e(C,"start","3")},m(e,t){Pt(document.head,i),a(e,y,t),a(e,c,t),a(e,T,t),d(Z,e,t),a(e,ye,t),d(U,e,t),a(e,Te,t),a(e,k,t),a(e,he,t),a(e,v,t),a(e,we,t),a(e,h,t),a(e,ge,t),a(e,F,t),a(e,Je,t),d(W,e,t),a(e,Ce,t),a(e,j,t),a(e,_e,t),d(B,e,t),a(e,Ze,t),a(e,R,t),a(e,Ue,t),d(V,e,t),a(e,ke,t),d(G,e,t),a(e,ve,t),a(e,H,t),a(e,Fe,t),a(e,X,t),a(e,We,t),a(e,x,t),a(e,je,t),d(E,e,t),a(e,Be,t),a(e,Q,t),a(e,Re,t),a(e,L,t),a(e,Ve,t),d(z,e,t),a(e,Ge,t),d(w,e,t),a(e,He,t),a(e,I,t),a(e,Xe,t),d(N,e,t),a(e,xe,t),d(P,e,t),a(e,Ee,t),a(e,Y,t),a(e,Qe,t),d(A,e,t),a(e,Le,t),d(q,e,t),a(e,ze,t),a(e,S,t),a(e,Ie,t),d(K,e,t),a(e,Ne,t),a(e,D,t),a(e,Pe,t),d(O,e,t),a(e,Ye,t),a(e,ee,t),a(e,Ae,t),d(te,e,t),a(e,qe,t),d(le,e,t),a(e,Se,t),a(e,ae,t),a(e,Ke,t),d(se,e,t),a(e,De,t),a(e,pe,t),a(e,Oe,t),d(ne,e,t),a(e,et,t),d(oe,e,t),a(e,tt,t),a(e,ie,t),a(e,lt,t),d(g,e,t),a(e,at,t),a(e,re,t),a(e,st,t),d(me,e,t),a(e,pt,t),a(e,J,t),a(e,nt,t),d(de,e,t),a(e,ot,t),a(e,C,t),a(e,it,t),d(fe,e,t),a(e,rt,t),a(e,Me,t),a(e,mt,t),d(be,e,t),a(e,dt,t),a(e,ce,t),ft=!0},p(e,[t]){const Gt={};t&2&&(Gt.$$scope={dirty:t,ctx:e}),w.$set(Gt);const Ht={};t&2&&(Ht.$$scope={dirty:t,ctx:e}),g.$set(Ht)},i(e){ft||(f(Z.$$.fragment,e),f(U.$$.fragment,e),f(W.$$.fragment,e),f(B.$$.fragment,e),f(V.$$.fragment,e),f(G.$$.fragment,e),f(E.$$.fragment,e),f(z.$$.fragment,e),f(w.$$.fragment,e),f(N.$$.fragment,e),f(P.$$.fragment,e),f(A.$$.fragment,e),f(q.$$.fragment,e),f(K.$$.fragment,e),f(O.$$.fragment,e),f(te.$$.fragment,e),f(le.$$.fragment,e),f(se.$$.fragment,e),f(ne.$$.fragment,e),f(oe.$$.fragment,e),f(g.$$.fragment,e),f(me.$$.fragment,e),f(de.$$.fragment,e),f(fe.$$.fragment,e),f(be.$$.fragment,e),ft=!0)},o(e){M(Z.$$.fragment,e),M(U.$$.fragment,e),M(W.$$.fragment,e),M(B.$$.fragment,e),M(V.$$.fragment,e),M(G.$$.fragment,e),M(E.$$.fragment,e),M(z.$$.fragment,e),M(w.$$.fragment,e),M(N.$$.fragment,e),M(P.$$.fragment,e),M(A.$$.fragment,e),M(q.$$.fragment,e),M(K.$$.fragment,e),M(O.$$.fragment,e),M(te.$$.fragment,e),M(le.$$.fragment,e),M(se.$$.fragment,e),M(ne.$$.fragment,e),M(oe.$$.fragment,e),M(g.$$.fragment,e),M(me.$$.fragment,e),M(de.$$.fragment,e),M(fe.$$.fragment,e),M(be.$$.fragment,e),ft=!1},d(e){e&&(l(y),l(c),l(T),l(ye),l(Te),l(k),l(he),l(v),l(we),l(h),l(ge),l(F),l(Je),l(Ce),l(j),l(_e),l(Ze),l(R),l(Ue),l(ke),l(ve),l(H),l(Fe),l(X),l(We),l(x),l(je),l(Be),l(Q),l(Re),l(L),l(Ve),l(Ge),l(He),l(I),l(Xe),l(xe),l(Ee),l(Y),l(Qe),l(Le),l(ze),l(S),l(Ie),l(Ne),l(D),l(Pe),l(Ye),l(ee),l(Ae),l(qe),l(Se),l(ae),l(Ke),l(De),l(pe),l(Oe),l(et),l(tt),l(ie),l(lt),l(at),l(re),l(st),l(pt),l(J),l(nt),l(ot),l(C),l(it),l(rt),l(Me),l(mt),l(dt),l(ce)),l(i),b(Z,e),b(U,e),b(W,e),b(B,e),b(V,e),b(G,e),b(E,e),b(z,e),b(w,e),b(N,e),b(P,e),b(A,e),b(q,e),b(K,e),b(O,e),b(te,e),b(le,e),b(se,e),b(ne,e),b(oe,e),b(g,e),b(me,e),b(de,e),b(fe,e),b(be,e)}}}const Kt='{"title":"使用 🤗 PEFT 加载adapters","local":"使用--peft-加载adapters","sections":[{"title":"设置","local":"设置","sections":[],"depth":2},{"title":"支持的 PEFT 模型","local":"支持的-peft-模型","sections":[],"depth":2},{"title":"加载 PEFT adapter","local":"加载-peft-adapter","sections":[],"depth":2},{"title":"基于8bit或4bit进行加载","local":"基于8bit或4bit进行加载","sections":[],"depth":2},{"title":"添加新的adapter","local":"添加新的adapter","sections":[],"depth":2},{"title":"启用和禁用adapters","local":"启用和禁用adapters","sections":[],"depth":2},{"title":"训练一个 PEFT adapter","local":"训练一个-peft-adapter","sections":[],"depth":2}],"depth":1}';function Dt(ue){return Lt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class pl extends zt{constructor(i){super(),It(this,i,Dt,St,Qt,{})}}export{pl as component};
