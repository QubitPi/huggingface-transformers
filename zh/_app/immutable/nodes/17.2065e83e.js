import{s as Yo,o as er,n as It}from"../chunks/scheduler.9991993c.js";import{S as tr,i as nr,g as a,s as r,r as c,A as or,h as i,f as t,c as s,j as b,u as m,x as _,k as $,y as o,a as d,v as p,d as f,t as u,w as g}from"../chunks/index.7fc9a5e7.js";import{T as Ht}from"../chunks/Tip.9de92fc6.js";import{D as v}from"../chunks/Docstring.8180f571.js";import{C as rr}from"../chunks/CodeBlock.e11cba92.js";import{E as sr}from"../chunks/ExampleCodeBlock.a03fccd6.js";import{H as At}from"../chunks/Heading.e3de321f.js";function ar(w){let l,x=`One of <code>start_states</code> or <code>start_positions</code> should be not <code>None</code>. If both are set, <code>start_positions</code> overrides
<code>start_states</code>.`;return{c(){l=a("p"),l.innerHTML=x},l(h){l=i(h,"P",{"data-svelte-h":!0}),_(l)!=="svelte-1oii8ff"&&(l.innerHTML=x)},m(h,y){d(h,l,y)},p:It,d(h){h&&t(l)}}}function ir(w){let l,x=`One of <code>start_states</code> or <code>start_positions</code> should be not <code>None</code>. If both are set, <code>start_positions</code> overrides
<code>start_states</code>.`;return{c(){l=a("p"),l.innerHTML=x},l(h){l=i(h,"P",{"data-svelte-h":!0}),_(l)!=="svelte-1oii8ff"&&(l.innerHTML=x)},m(h,y){d(h,l,y)},p:It,d(h){h&&t(l)}}}function dr(w){let l,x="Examples:",h,y,P;return y=new rr({props:{code:"JTIzJTIwcmVuYW1lJTIwdGhlJTIwdXN1YWwlMjBmb3J3YXJkKCklMjBmbiUyMHRvJTIwZm9yd2FyZF9jaHVuaygpJTBBZGVmJTIwZm9yd2FyZF9jaHVuayhzZWxmJTJDJTIwaGlkZGVuX3N0YXRlcyklM0ElMEElMjAlMjAlMjAlMjBoaWRkZW5fc3RhdGVzJTIwJTNEJTIwc2VsZi5kZWNvZGVyKGhpZGRlbl9zdGF0ZXMpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaGlkZGVuX3N0YXRlcyUwQSUwQSUwQSUyMyUyMGltcGxlbWVudCUyMGElMjBjaHVua2VkJTIwZm9yd2FyZCUyMGZ1bmN0aW9uJTBBZGVmJTIwZm9yd2FyZChzZWxmJTJDJTIwaGlkZGVuX3N0YXRlcyklM0ElMEElMjAlMjAlMjAlMjByZXR1cm4lMjBhcHBseV9jaHVua2luZ190b19mb3J3YXJkKHNlbGYuZm9yd2FyZF9jaHVuayUyQyUyMHNlbGYuY2h1bmtfc2l6ZV9sbV9oZWFkJTJDJTIwc2VsZi5zZXFfbGVuX2RpbSUyQyUyMGhpZGRlbl9zdGF0ZXMp",highlighted:`<span class="hljs-comment"># rename the usual forward() fn to forward_chunk()</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">forward_chunk</span>(<span class="hljs-params">self, hidden_states</span>):
    hidden_states = self.decoder(hidden_states)
    <span class="hljs-keyword">return</span> hidden_states


<span class="hljs-comment"># implement a chunked forward function</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, hidden_states</span>):
    <span class="hljs-keyword">return</span> apply_chunking_to_forward(self.forward_chunk, self.chunk_size_lm_head, self.seq_len_dim, hidden_states)`,wrap:!1}}),{c(){l=a("p"),l.textContent=x,h=r(),c(y.$$.fragment)},l(T){l=i(T,"P",{"data-svelte-h":!0}),_(l)!=="svelte-kvfsh7"&&(l.textContent=x),h=s(T),m(y.$$.fragment,T)},m(T,L){d(T,l,L),d(T,h,L),p(y,T,L),P=!0},p:It,i(T){P||(f(y.$$.fragment,T),P=!0)},o(T){u(y.$$.fragment,T),P=!1},d(T){T&&(t(l),t(h)),g(y,T)}}}function lr(w){let l,x="Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.";return{c(){l=a("p"),l.textContent=x},l(h){l=i(h,"P",{"data-svelte-h":!0}),_(l)!=="svelte-14hlsz0"&&(l.textContent=x)},m(h,y){d(h,l,y)},p:It,d(h){h&&t(l)}}}function cr(w){let l,x="Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.";return{c(){l=a("p"),l.textContent=x},l(h){l=i(h,"P",{"data-svelte-h":!0}),_(l)!=="svelte-14hlsz0"&&(l.textContent=x)},m(h,y){d(h,l,y)},p:It,d(h){h&&t(l)}}}function mr(w){let l,x="Any label of -100 will be ignored (along with the corresponding logits) in the loss computation.";return{c(){l=a("p"),l.textContent=x},l(h){l=i(h,"P",{"data-svelte-h":!0}),_(l)!=="svelte-14hlsz0"&&(l.textContent=x)},m(h,y){d(h,l,y)},p:It,d(h){h&&t(l)}}}function pr(w){let l,x,h,y,P,T,L,bo="此页面列出了库使用的所有自定义层，以及它为模型提供的实用函数。",Vt,me,$o="其中大多数只有在您研究库中模型的代码时才有用。",jt,pe,Ot,D,fe,Ln,Ze,vo="1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).",Dn,Be,xo="Basically works like a linear layer but the weights are transposed.",Nt,z,ue,zn,Ue,yo="Compute SQuAD start logits from sequence hidden states.",qn,Xe,ge,Jt,q,he,Sn,Re,To="Compute SQuAD end logits from sequence hidden states.",Fn,ee,_e,Mn,te,Gt,S,be,An,We,wo="Compute SQuAD 2.0 answer class from classification and start tokens hidden states.",In,ne,$e,En,oe,Zt,O,ve,Qn,Ke,Co='Base class for outputs of question answering models using a <a href="/docs/transformers/main/zh/internal/modeling_utils#transformers.modeling_utils.SQuADHead">SQuADHead</a>.',Bt,F,xe,Hn,Ye,ko="A SQuAD head inspired by XLNet.",Vn,et,ye,Ut,M,Te,jn,tt,Po="Compute a single vector summary of a sequence hidden states.",On,re,we,Nn,nt,Lo="Compute a single vector summary of a sequence hidden states.",Xt,Ce,Rt,C,ke,Jn,ot,Do=`This function chunks the <code>input_tensors</code> into smaller input tensor parts of size <code>chunk_size</code> over the dimension
<code>chunk_dim</code>. It then applies a layer <code>forward_fn</code> to each chunk independently to save memory.`,Gn,rt,zo=`If the <code>forward_fn</code> is independent across the <code>chunk_dim</code> this function will yield the same result as directly
applying <code>forward_fn</code> to <code>input_tensors</code>.`,Zn,se,Wt,N,Pe,Bn,st,qo="Finds the heads and their indices taking <code>already_pruned_heads</code> into account.",Kt,A,Le,Un,at,So="Prune a Conv1D or linear layer to keep only entries in index.",Xn,it,Fo="Used to remove heads.",Yt,I,De,Rn,dt,Mo=`Prune a Conv1D layer to keep only entries in index. A Conv1D work as a Linear layer (see e.g. BERT) but the weights
are transposed.`,Wn,lt,Ao="Used to remove heads.",en,E,ze,Kn,ct,Io="Prune a linear layer to keep only entries in index.",Yn,mt,Eo="Used to remove heads.",tn,qe,nn,Q,Se,eo,pt,Qo="1D-convolutional layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2).",to,ft,Ho="Basically works like a linear layer but the weights are transposed.",on,J,Fe,no,ut,Vo="Compute a single vector summary of a sequence hidden states.",rn,Me,sn,H,Ae,oo,gt,jo="Loss function suitable for causal language modeling (CLM), that is, the task of guessing the next token.",ro,ae,an,V,Ie,so,ht,Oo="Loss function suitable for masked language modeling (MLM), that is, the task of guessing the masked tokens.",ao,ie,dn,G,Ee,io,_t,No="Loss function suitable for multiple choice tasks.",ln,Z,Qe,lo,bt,Jo="Loss function suitable for question answering.",cn,B,He,co,$t,Go="Loss function suitable for sequence classification.",mn,j,Ve,mo,vt,Zo="Loss function suitable for token classification.",po,de,pn,je,fn,U,Oe,fo,xt,Bo="Creates a <code>keras.initializers.TruncatedNormal</code> with the given range.",un,k,Ne,uo,yt,Uo="Decorate a Keras Layer class to support Keras serialization.",go,Tt,Xo="This is done by:",ho,wt,Ro=`<li>Adding a <code>transformers_config</code> dict to the Keras config dictionary in <code>get_config</code> (called by Keras at
serialization time.</li> <li>Wrapping <code>__init__</code> to accept that <code>transformers_config</code> dict (passed by Keras at deserialization time) and
convert it to a config object for the actual layer initializer.</li> <li>Registering the class as a custom object in Keras (if the Tensorflow version supports this), so that it does not
need to be supplied in <code>custom_objects</code> in the call to <code>keras.models.load_model</code>.</li>`,gn,X,Je,_o,Ct,Wo="Deal with dynamic shape in tensorflow cleanly.",hn,Et,_n;return P=new At({props:{title:"自定义层和工具",local:"自定义层和工具",headingTag:"h1"}}),pe=new At({props:{title:"Pytorch自定义模块",local:"transformers.Conv1D",headingTag:"h2"}}),fe=new v({props:{name:"class transformers.Conv1D",anchor:"transformers.Conv1D",parameters:[{name:"nf",val:""},{name:"nx",val:""}],parametersDescription:[{anchor:"transformers.Conv1D.nf",description:"<strong>nf</strong> (<code>int</code>) &#x2014; The number of output features.",name:"nf"},{anchor:"transformers.Conv1D.nx",description:"<strong>nx</strong> (<code>int</code>) &#x2014; The number of input features.",name:"nx"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/pytorch_utils.py#L83"}}),ue=new v({props:{name:"class transformers.modeling_utils.PoolerStartLogits",anchor:"transformers.modeling_utils.PoolerStartLogits",parameters:[{name:"config",val:": PretrainedConfig"}],parametersDescription:[{anchor:"transformers.modeling_utils.PoolerStartLogits.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/zh/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The config used by the model, will be used to grab the <code>hidden_size</code> of the model.`,name:"config"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4211"}}),ge=new v({props:{name:"forward",anchor:"transformers.modeling_utils.PoolerStartLogits.forward",parameters:[{name:"hidden_states",val:": FloatTensor"},{name:"p_mask",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.modeling_utils.PoolerStartLogits.forward.hidden_states",description:`<strong>hidden_states</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len, hidden_size)</code>) &#x2014;
The final hidden states of the model.`,name:"hidden_states"},{anchor:"transformers.modeling_utils.PoolerStartLogits.forward.p_mask",description:`<strong>p_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len)</code>, <em>optional</em>) &#x2014;
Mask for tokens at invalid position, such as query and special symbols (PAD, SEP, CLS). 1.0 means token
should be masked.`,name:"p_mask"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4224",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The start logits for SQuAD.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.FloatTensor</code></p>
`}}),he=new v({props:{name:"class transformers.modeling_utils.PoolerEndLogits",anchor:"transformers.modeling_utils.PoolerEndLogits",parameters:[{name:"config",val:": PretrainedConfig"}],parametersDescription:[{anchor:"transformers.modeling_utils.PoolerEndLogits.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/zh/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The config used by the model, will be used to grab the <code>hidden_size</code> of the model and the <code>layer_norm_eps</code>
to use.`,name:"config"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4249"}}),_e=new v({props:{name:"forward",anchor:"transformers.modeling_utils.PoolerEndLogits.forward",parameters:[{name:"hidden_states",val:": FloatTensor"},{name:"start_states",val:": Optional = None"},{name:"start_positions",val:": Optional = None"},{name:"p_mask",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.modeling_utils.PoolerEndLogits.forward.hidden_states",description:`<strong>hidden_states</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len, hidden_size)</code>) &#x2014;
The final hidden states of the model.`,name:"hidden_states"},{anchor:"transformers.modeling_utils.PoolerEndLogits.forward.start_states",description:`<strong>start_states</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len, hidden_size)</code>, <em>optional</em>) &#x2014;
The hidden states of the first tokens for the labeled span.`,name:"start_states"},{anchor:"transformers.modeling_utils.PoolerEndLogits.forward.start_positions",description:`<strong>start_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
The position of the first token for the labeled span.`,name:"start_positions"},{anchor:"transformers.modeling_utils.PoolerEndLogits.forward.p_mask",description:`<strong>p_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len)</code>, <em>optional</em>) &#x2014;
Mask for tokens at invalid position, such as query and special symbols (PAD, SEP, CLS). 1.0 means token
should be masked.`,name:"p_mask"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4266",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The end logits for SQuAD.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.FloatTensor</code></p>
`}}),te=new Ht({props:{$$slots:{default:[ar]},$$scope:{ctx:w}}}),be=new v({props:{name:"class transformers.modeling_utils.PoolerAnswerClass",anchor:"transformers.modeling_utils.PoolerAnswerClass",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.modeling_utils.PoolerAnswerClass.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/zh/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The config used by the model, will be used to grab the <code>hidden_size</code> of the model.`,name:"config"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4318"}}),$e=new v({props:{name:"forward",anchor:"transformers.modeling_utils.PoolerAnswerClass.forward",parameters:[{name:"hidden_states",val:": FloatTensor"},{name:"start_states",val:": Optional = None"},{name:"start_positions",val:": Optional = None"},{name:"cls_index",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.modeling_utils.PoolerAnswerClass.forward.hidden_states",description:`<strong>hidden_states</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len, hidden_size)</code>) &#x2014;
The final hidden states of the model.`,name:"hidden_states"},{anchor:"transformers.modeling_utils.PoolerAnswerClass.forward.start_states",description:`<strong>start_states</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len, hidden_size)</code>, <em>optional</em>) &#x2014;
The hidden states of the first tokens for the labeled span.`,name:"start_states"},{anchor:"transformers.modeling_utils.PoolerAnswerClass.forward.start_positions",description:`<strong>start_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
The position of the first token for the labeled span.`,name:"start_positions"},{anchor:"transformers.modeling_utils.PoolerAnswerClass.forward.cls_index",description:`<strong>cls_index</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Position of the CLS token for each sentence in the batch. If <code>None</code>, takes the last token.`,name:"cls_index"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4333",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The SQuAD 2.0 answer class.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.FloatTensor</code></p>
`}}),oe=new Ht({props:{$$slots:{default:[ir]},$$scope:{ctx:w}}}),ve=new v({props:{name:"class transformers.modeling_utils.SquadHeadOutput",anchor:"transformers.modeling_utils.SquadHeadOutput",parameters:[{name:"loss",val:": Optional = None"},{name:"start_top_log_probs",val:": Optional = None"},{name:"start_top_index",val:": Optional = None"},{name:"end_top_log_probs",val:": Optional = None"},{name:"end_top_index",val:": Optional = None"},{name:"cls_logits",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.modeling_utils.SquadHeadOutput.loss",description:`<strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned if both <code>start_positions</code> and <code>end_positions</code> are provided) &#x2014;
Classification loss as the sum of start token, end token (and is_impossible if provided) classification
losses.`,name:"loss"},{anchor:"transformers.modeling_utils.SquadHeadOutput.start_top_log_probs",description:`<strong>start_top_log_probs</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.start_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) &#x2014;
Log probabilities for the top config.start_n_top start token possibilities (beam-search).`,name:"start_top_log_probs"},{anchor:"transformers.modeling_utils.SquadHeadOutput.start_top_index",description:`<strong>start_top_index</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, config.start_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) &#x2014;
Indices for the top config.start_n_top start token possibilities (beam-search).`,name:"start_top_index"},{anchor:"transformers.modeling_utils.SquadHeadOutput.end_top_log_probs",description:`<strong>end_top_log_probs</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.start_n_top * config.end_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) &#x2014;
Log probabilities for the top <code>config.start_n_top * config.end_n_top</code> end token possibilities
(beam-search).`,name:"end_top_log_probs"},{anchor:"transformers.modeling_utils.SquadHeadOutput.end_top_index",description:`<strong>end_top_index</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, config.start_n_top * config.end_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) &#x2014;
Indices for the top <code>config.start_n_top * config.end_n_top</code> end token possibilities (beam-search).`,name:"end_top_index"},{anchor:"transformers.modeling_utils.SquadHeadOutput.cls_logits",description:`<strong>cls_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) &#x2014;
Log probabilities for the <code>is_impossible</code> label of the answers.`,name:"cls_logits"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4383"}}),xe=new v({props:{name:"class transformers.modeling_utils.SQuADHead",anchor:"transformers.modeling_utils.SQuADHead",parameters:[{name:"config",val:""}],parametersDescription:[{anchor:"transformers.modeling_utils.SQuADHead.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/zh/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The config used by the model, will be used to grab the <code>hidden_size</code> of the model and the <code>layer_norm_eps</code>
to use.`,name:"config"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4414"}}),ye=new v({props:{name:"forward",anchor:"transformers.modeling_utils.SQuADHead.forward",parameters:[{name:"hidden_states",val:": FloatTensor"},{name:"start_positions",val:": Optional = None"},{name:"end_positions",val:": Optional = None"},{name:"cls_index",val:": Optional = None"},{name:"is_impossible",val:": Optional = None"},{name:"p_mask",val:": Optional = None"},{name:"return_dict",val:": bool = False"}],parametersDescription:[{anchor:"transformers.modeling_utils.SQuADHead.forward.hidden_states",description:`<strong>hidden_states</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len, hidden_size)</code>) &#x2014;
Final hidden states of the model on the sequence tokens.`,name:"hidden_states"},{anchor:"transformers.modeling_utils.SQuADHead.forward.start_positions",description:`<strong>start_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Positions of the first token for the labeled span.`,name:"start_positions"},{anchor:"transformers.modeling_utils.SQuADHead.forward.end_positions",description:`<strong>end_positions</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Positions of the last token for the labeled span.`,name:"end_positions"},{anchor:"transformers.modeling_utils.SQuADHead.forward.cls_index",description:`<strong>cls_index</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Position of the CLS token for each sentence in the batch. If <code>None</code>, takes the last token.`,name:"cls_index"},{anchor:"transformers.modeling_utils.SQuADHead.forward.is_impossible",description:`<strong>is_impossible</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>) &#x2014;
Whether the question has a possible answer in the paragraph or not.`,name:"is_impossible"},{anchor:"transformers.modeling_utils.SQuADHead.forward.p_mask",description:`<strong>p_mask</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, seq_len)</code>, <em>optional</em>) &#x2014;
Mask for tokens at invalid position, such as query and special symbols (PAD, SEP, CLS). 1.0 means token
should be masked.`,name:"p_mask"},{anchor:"transformers.modeling_utils.SQuADHead.forward.return_dict",description:`<strong>return_dict</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to return a <a href="/docs/transformers/main/zh/main_classes/output#transformers.utils.ModelOutput">ModelOutput</a> instead of a plain tuple.`,name:"return_dict"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4433",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A <a
  href="/docs/transformers/main/zh/internal/modeling_utils#transformers.modeling_utils.SquadHeadOutput"
>transformers.modeling_utils.SquadHeadOutput</a> or a tuple of
<code>torch.FloatTensor</code> (if <code>return_dict=False</code> is passed or when <code>config.return_dict=False</code>) comprising various
elements depending on the configuration (<code>&lt;class 'transformers.configuration_utils.PretrainedConfig'&gt;</code>) and inputs.</p>
<ul>
<li><strong>loss</strong> (<code>torch.FloatTensor</code> of shape <code>(1,)</code>, <em>optional</em>, returned if both <code>start_positions</code> and <code>end_positions</code> are provided) — Classification loss as the sum of start token, end token (and is_impossible if provided) classification
losses.</li>
<li><strong>start_top_log_probs</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.start_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) — Log probabilities for the top config.start_n_top start token possibilities (beam-search).</li>
<li><strong>start_top_index</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, config.start_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) — Indices for the top config.start_n_top start token possibilities (beam-search).</li>
<li><strong>end_top_log_probs</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size, config.start_n_top * config.end_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) — Log probabilities for the top <code>config.start_n_top * config.end_n_top</code> end token possibilities
(beam-search).</li>
<li><strong>end_top_index</strong> (<code>torch.LongTensor</code> of shape <code>(batch_size, config.start_n_top * config.end_n_top)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) — Indices for the top <code>config.start_n_top * config.end_n_top</code> end token possibilities (beam-search).</li>
<li><strong>cls_logits</strong> (<code>torch.FloatTensor</code> of shape <code>(batch_size,)</code>, <em>optional</em>, returned if <code>start_positions</code> or <code>end_positions</code> is not provided) — Log probabilities for the <code>is_impossible</code> label of the answers.</li>
</ul>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><a
  href="/docs/transformers/main/zh/internal/modeling_utils#transformers.modeling_utils.SquadHeadOutput"
>transformers.modeling_utils.SquadHeadOutput</a> or <code>tuple(torch.FloatTensor)</code></p>
`}}),Te=new v({props:{name:"class transformers.modeling_utils.SequenceSummary",anchor:"transformers.modeling_utils.SequenceSummary",parameters:[{name:"config",val:": PretrainedConfig"}],parametersDescription:[{anchor:"transformers.modeling_utils.SequenceSummary.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/zh/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The config used by the model. Relevant arguments in the config class of the model are (refer to the actual
config class of your model for the default values it uses):</p>
<ul>
<li>
<p><strong>summary_type</strong> (<code>str</code>) &#x2014; The method to use to make this summary. Accepted values are:</p>
<ul>
<li><code>&quot;last&quot;</code> &#x2014; Take the last token hidden state (like XLNet)</li>
<li><code>&quot;first&quot;</code> &#x2014; Take the first token hidden state (like Bert)</li>
<li><code>&quot;mean&quot;</code> &#x2014; Take the mean of all tokens hidden states</li>
<li><code>&quot;cls_index&quot;</code> &#x2014; Supply a Tensor of classification token position (GPT/GPT-2)</li>
<li><code>&quot;attn&quot;</code> &#x2014; Not implemented now, use multi-head attention</li>
</ul>
</li>
<li>
<p><strong>summary_use_proj</strong> (<code>bool</code>) &#x2014; Add a projection after the vector extraction.</p>
</li>
<li>
<p><strong>summary_proj_to_labels</strong> (<code>bool</code>) &#x2014; If <code>True</code>, the projection outputs to <code>config.num_labels</code> classes
(otherwise to <code>config.hidden_size</code>).</p>
</li>
<li>
<p><strong>summary_activation</strong> (<code>Optional[str]</code>) &#x2014; Set to <code>&quot;tanh&quot;</code> to add a tanh activation to the output,
another string or <code>None</code> will add no activation.</p>
</li>
<li>
<p><strong>summary_first_dropout</strong> (<code>float</code>) &#x2014; Optional dropout probability before the projection and activation.</p>
</li>
<li>
<p><strong>summary_last_dropout</strong> (<code>float</code>)&#x2014; Optional dropout probability after the projection and activation.</p>
</li>
</ul>`,name:"config"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4531"}}),we=new v({props:{name:"forward",anchor:"transformers.modeling_utils.SequenceSummary.forward",parameters:[{name:"hidden_states",val:": FloatTensor"},{name:"cls_index",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.modeling_utils.SequenceSummary.forward.hidden_states",description:`<strong>hidden_states</strong> (<code>torch.FloatTensor</code> of shape <code>[batch_size, seq_len, hidden_size]</code>) &#x2014;
The hidden states of the last layer.`,name:"hidden_states"},{anchor:"transformers.modeling_utils.SequenceSummary.forward.cls_index",description:`<strong>cls_index</strong> (<code>torch.LongTensor</code> of shape <code>[batch_size]</code> or <code>[batch_size, ...]</code> where &#x2026; are optional leading dimensions of <code>hidden_states</code>, <em>optional</em>) &#x2014;
Used if <code>summary_type == &quot;cls_index&quot;</code> and takes the last token of the sequence as classification token.`,name:"cls_index"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_utils.py#L4586",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The summary of the sequence hidden states.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.FloatTensor</code></p>
`}}),Ce=new At({props:{title:"PyTorch帮助函数",local:"transformers.apply_chunking_to_forward",headingTag:"h2"}}),ke=new v({props:{name:"transformers.apply_chunking_to_forward",anchor:"transformers.apply_chunking_to_forward",parameters:[{name:"forward_fn",val:": Callable"},{name:"chunk_size",val:": int"},{name:"chunk_dim",val:": int"},{name:"*input_tensors",val:""}],parametersDescription:[{anchor:"transformers.apply_chunking_to_forward.forward_fn",description:`<strong>forward_fn</strong> (<code>Callable[..., torch.Tensor]</code>) &#x2014;
The forward function of the model.`,name:"forward_fn"},{anchor:"transformers.apply_chunking_to_forward.chunk_size",description:`<strong>chunk_size</strong> (<code>int</code>) &#x2014;
The chunk size of a chunked tensor: <code>num_chunks = len(input_tensors[0]) / chunk_size</code>.`,name:"chunk_size"},{anchor:"transformers.apply_chunking_to_forward.chunk_dim",description:`<strong>chunk_dim</strong> (<code>int</code>) &#x2014;
The dimension over which the <code>input_tensors</code> should be chunked.`,name:"chunk_dim"},{anchor:"transformers.apply_chunking_to_forward.input_tensors",description:`<strong>input_tensors</strong> (<code>Tuple[torch.Tensor]</code>) &#x2014;
The input tensors of <code>forward_fn</code> which will be chunked`,name:"input_tensors"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/pytorch_utils.py#L165",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A tensor with the same shape as the <code>forward_fn</code> would have given if applied\`.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.Tensor</code></p>
`}}),se=new sr({props:{anchor:"transformers.apply_chunking_to_forward.example",$$slots:{default:[dr]},$$scope:{ctx:w}}}),Pe=new v({props:{name:"transformers.pytorch_utils.find_pruneable_heads_and_indices",anchor:"transformers.pytorch_utils.find_pruneable_heads_and_indices",parameters:[{name:"heads",val:": List"},{name:"n_heads",val:": int"},{name:"head_size",val:": int"},{name:"already_pruned_heads",val:": Set"}],parametersDescription:[{anchor:"transformers.pytorch_utils.find_pruneable_heads_and_indices.heads",description:"<strong>heads</strong> (<code>List[int]</code>) &#x2014; List of the indices of heads to prune.",name:"heads"},{anchor:"transformers.pytorch_utils.find_pruneable_heads_and_indices.n_heads",description:"<strong>n_heads</strong> (<code>int</code>) &#x2014; The number of heads in the model.",name:"n_heads"},{anchor:"transformers.pytorch_utils.find_pruneable_heads_and_indices.head_size",description:"<strong>head_size</strong> (<code>int</code>) &#x2014; The size of each head.",name:"head_size"},{anchor:"transformers.pytorch_utils.find_pruneable_heads_and_indices.already_pruned_heads",description:"<strong>already_pruned_heads</strong> (<code>Set[int]</code>) &#x2014; A set of already pruned heads.",name:"already_pruned_heads"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/pytorch_utils.py#L240",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>A tuple with the indices of heads to prune taking <code>already_pruned_heads</code>
into account and the indices of rows/columns to keep in the layer weight.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>Tuple[Set[int], torch.LongTensor]</code></p>
`}}),Le=new v({props:{name:"transformers.prune_layer",anchor:"transformers.prune_layer",parameters:[{name:"layer",val:": Union"},{name:"index",val:": LongTensor"},{name:"dim",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.prune_layer.layer",description:"<strong>layer</strong> (<code>Union[torch.nn.Linear, Conv1D]</code>) &#x2014; The layer to prune.",name:"layer"},{anchor:"transformers.prune_layer.index",description:"<strong>index</strong> (<code>torch.LongTensor</code>) &#x2014; The indices to keep in the layer.",name:"index"},{anchor:"transformers.prune_layer.dim",description:"<strong>dim</strong> (<code>int</code>, <em>optional</em>) &#x2014; The dimension on which to keep the indices.",name:"dim"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/pytorch_utils.py#L141",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The pruned layer as a new layer with <code>requires_grad=True</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.nn.Linear</code> or <a
  href="/docs/transformers/main/zh/internal/modeling_utils#transformers.Conv1D"
>Conv1D</a></p>
`}}),De=new v({props:{name:"transformers.pytorch_utils.prune_conv1d_layer",anchor:"transformers.pytorch_utils.prune_conv1d_layer",parameters:[{name:"layer",val:": Conv1D"},{name:"index",val:": LongTensor"},{name:"dim",val:": int = 1"}],parametersDescription:[{anchor:"transformers.pytorch_utils.prune_conv1d_layer.layer",description:'<strong>layer</strong> (<a href="/docs/transformers/main/zh/internal/modeling_utils#transformers.Conv1D">Conv1D</a>) &#x2014; The layer to prune.',name:"layer"},{anchor:"transformers.pytorch_utils.prune_conv1d_layer.index",description:"<strong>index</strong> (<code>torch.LongTensor</code>) &#x2014; The indices to keep in the layer.",name:"index"},{anchor:"transformers.pytorch_utils.prune_conv1d_layer.dim",description:"<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 1) &#x2014; The dimension on which to keep the indices.",name:"dim"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/pytorch_utils.py#L108",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The pruned layer as a new layer with <code>requires_grad=True</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><a
  href="/docs/transformers/main/zh/internal/modeling_utils#transformers.Conv1D"
>Conv1D</a></p>
`}}),ze=new v({props:{name:"transformers.pytorch_utils.prune_linear_layer",anchor:"transformers.pytorch_utils.prune_linear_layer",parameters:[{name:"layer",val:": Linear"},{name:"index",val:": LongTensor"},{name:"dim",val:": int = 0"}],parametersDescription:[{anchor:"transformers.pytorch_utils.prune_linear_layer.layer",description:"<strong>layer</strong> (<code>torch.nn.Linear</code>) &#x2014; The layer to prune.",name:"layer"},{anchor:"transformers.pytorch_utils.prune_linear_layer.index",description:"<strong>index</strong> (<code>torch.LongTensor</code>) &#x2014; The indices to keep in the layer.",name:"index"},{anchor:"transformers.pytorch_utils.prune_linear_layer.dim",description:"<strong>dim</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014; The dimension on which to keep the indices.",name:"dim"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/pytorch_utils.py#L49",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The pruned layer as a new layer with <code>requires_grad=True</code>.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>torch.nn.Linear</code></p>
`}}),qe=new At({props:{title:"TensorFlow自定义层",local:"transformers.modeling_tf_utils.TFConv1D",headingTag:"h2"}}),Se=new v({props:{name:"class transformers.modeling_tf_utils.TFConv1D",anchor:"transformers.modeling_tf_utils.TFConv1D",parameters:[{name:"nf",val:""},{name:"nx",val:""},{name:"initializer_range",val:" = 0.02"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.modeling_tf_utils.TFConv1D.nf",description:`<strong>nf</strong> (<code>int</code>) &#x2014;
The number of output features.`,name:"nf"},{anchor:"transformers.modeling_tf_utils.TFConv1D.nx",description:`<strong>nx</strong> (<code>int</code>) &#x2014;
The number of input features.`,name:"nx"},{anchor:"transformers.modeling_tf_utils.TFConv1D.initializer_range",description:`<strong>initializer_range</strong> (<code>float</code>, <em>optional</em>, defaults to 0.02) &#x2014;
The standard deviation to use to initialize the weights.`,name:"initializer_range"},{anchor:"transformers.modeling_tf_utils.TFConv1D.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
Additional keyword arguments passed along to the <code>__init__</code> of <code>keras.layers.Layer</code>.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L3169"}}),Fe=new v({props:{name:"class transformers.TFSequenceSummary",anchor:"transformers.TFSequenceSummary",parameters:[{name:"config",val:": PretrainedConfig"},{name:"initializer_range",val:": float = 0.02"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.TFSequenceSummary.config",description:`<strong>config</strong> (<a href="/docs/transformers/main/zh/main_classes/configuration#transformers.PretrainedConfig">PretrainedConfig</a>) &#x2014;
The config used by the model. Relevant arguments in the config class of the model are (refer to the actual
config class of your model for the default values it uses):</p>
<ul>
<li>
<p><strong>summary_type</strong> (<code>str</code>) &#x2014; The method to use to make this summary. Accepted values are:</p>
<ul>
<li><code>&quot;last&quot;</code> &#x2014; Take the last token hidden state (like XLNet)</li>
<li><code>&quot;first&quot;</code> &#x2014; Take the first token hidden state (like Bert)</li>
<li><code>&quot;mean&quot;</code> &#x2014; Take the mean of all tokens hidden states</li>
<li><code>&quot;cls_index&quot;</code> &#x2014; Supply a Tensor of classification token position (GPT/GPT-2)</li>
<li><code>&quot;attn&quot;</code> &#x2014; Not implemented now, use multi-head attention</li>
</ul>
</li>
<li>
<p><strong>summary_use_proj</strong> (<code>bool</code>) &#x2014; Add a projection after the vector extraction.</p>
</li>
<li>
<p><strong>summary_proj_to_labels</strong> (<code>bool</code>) &#x2014; If <code>True</code>, the projection outputs to <code>config.num_labels</code> classes
(otherwise to <code>config.hidden_size</code>).</p>
</li>
<li>
<p><strong>summary_activation</strong> (<code>Optional[str]</code>) &#x2014; Set to <code>&quot;tanh&quot;</code> to add a tanh activation to the output,
another string or <code>None</code> will add no activation.</p>
</li>
<li>
<p><strong>summary_first_dropout</strong> (<code>float</code>) &#x2014; Optional dropout probability before the projection and activation.</p>
</li>
<li>
<p><strong>summary_last_dropout</strong> (<code>float</code>)&#x2014; Optional dropout probability after the projection and activation.</p>
</li>
</ul>`,name:"config"},{anchor:"transformers.TFSequenceSummary.initializer_range",description:"<strong>initializer_range</strong> (<code>float</code>, defaults to 0.02) &#x2014; The standard deviation to use to initialize the weights.",name:"initializer_range"},{anchor:"transformers.TFSequenceSummary.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
Additional keyword arguments passed along to the <code>__init__</code> of <code>keras.layers.Layer</code>.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L3316"}}),Me=new At({props:{title:"TensorFlow loss 函数",local:"transformers.modeling_tf_utils.TFCausalLanguageModelingLoss",headingTag:"h2"}}),Ae=new v({props:{name:"class transformers.modeling_tf_utils.TFCausalLanguageModelingLoss",anchor:"transformers.modeling_tf_utils.TFCausalLanguageModelingLoss",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L204"}}),ae=new Ht({props:{$$slots:{default:[lr]},$$scope:{ctx:w}}}),Ie=new v({props:{name:"class transformers.modeling_tf_utils.TFMaskedLanguageModelingLoss",anchor:"transformers.modeling_tf_utils.TFMaskedLanguageModelingLoss",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L315"}}),ie=new Ht({props:{$$slots:{default:[cr]},$$scope:{ctx:w}}}),Ee=new v({props:{name:"class transformers.modeling_tf_utils.TFMultipleChoiceLoss",anchor:"transformers.modeling_tf_utils.TFMultipleChoiceLoss",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L307"}}),Qe=new v({props:{name:"class transformers.modeling_tf_utils.TFQuestionAnsweringLoss",anchor:"transformers.modeling_tf_utils.TFQuestionAnsweringLoss",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L233"}}),He=new v({props:{name:"class transformers.modeling_tf_utils.TFSequenceClassificationLoss",anchor:"transformers.modeling_tf_utils.TFSequenceClassificationLoss",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L288"}}),Ve=new v({props:{name:"class transformers.modeling_tf_utils.TFTokenClassificationLoss",anchor:"transformers.modeling_tf_utils.TFTokenClassificationLoss",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L246"}}),de=new Ht({props:{$$slots:{default:[mr]},$$scope:{ctx:w}}}),je=new At({props:{title:"TensorFlow帮助函数",local:"transformers.modeling_tf_utils.get_initializer",headingTag:"h2"}}),Oe=new v({props:{name:"transformers.modeling_tf_utils.get_initializer",anchor:"transformers.modeling_tf_utils.get_initializer",parameters:[{name:"initializer_range",val:": float = 0.02"}],parametersDescription:[{anchor:"transformers.modeling_tf_utils.get_initializer.initializer_range",description:"<strong>initializer_range</strong> (<em>float</em>, defaults to 0.02) &#x2014; Standard deviation of the initializer range.",name:"initializer_range"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L3441",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The truncated normal initializer.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>keras.initializers.TruncatedNormal</code></p>
`}}),Ne=new v({props:{name:"transformers.modeling_tf_utils.keras_serializable",anchor:"transformers.modeling_tf_utils.keras_serializable",parameters:[],parametersDescription:[{anchor:"transformers.modeling_tf_utils.keras_serializable.cls",description:`<strong>cls</strong> (a <code>keras.layers.Layers subclass</code>) &#x2014;
Typically a <code>TF.MainLayer</code> class in this project, in general must accept a <code>config</code> argument to its
initializer.`,name:"cls"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/modeling_tf_utils.py#L139",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The same class object, with modifications for Keras deserialization.</p>
`}}),Je=new v({props:{name:"transformers.shape_list",anchor:"transformers.shape_list",parameters:[{name:"tensor",val:": Union"}],parametersDescription:[{anchor:"transformers.shape_list.tensor",description:"<strong>tensor</strong> (<code>tf.Tensor</code> or <code>np.ndarray</code>) &#x2014; The tensor we want the shape of.",name:"tensor"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tf_utils.py#L28",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The shape of the tensor as a list.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>List[int]</code></p>
`}}),{c(){l=a("meta"),x=r(),h=a("p"),y=r(),c(P.$$.fragment),T=r(),L=a("p"),L.textContent=bo,Vt=r(),me=a("p"),me.textContent=$o,jt=r(),c(pe.$$.fragment),Ot=r(),D=a("div"),c(fe.$$.fragment),Ln=r(),Ze=a("p"),Ze.textContent=vo,Dn=r(),Be=a("p"),Be.textContent=xo,Nt=r(),z=a("div"),c(ue.$$.fragment),zn=r(),Ue=a("p"),Ue.textContent=yo,qn=r(),Xe=a("div"),c(ge.$$.fragment),Jt=r(),q=a("div"),c(he.$$.fragment),Sn=r(),Re=a("p"),Re.textContent=To,Fn=r(),ee=a("div"),c(_e.$$.fragment),Mn=r(),c(te.$$.fragment),Gt=r(),S=a("div"),c(be.$$.fragment),An=r(),We=a("p"),We.textContent=wo,In=r(),ne=a("div"),c($e.$$.fragment),En=r(),c(oe.$$.fragment),Zt=r(),O=a("div"),c(ve.$$.fragment),Qn=r(),Ke=a("p"),Ke.innerHTML=Co,Bt=r(),F=a("div"),c(xe.$$.fragment),Hn=r(),Ye=a("p"),Ye.textContent=ko,Vn=r(),et=a("div"),c(ye.$$.fragment),Ut=r(),M=a("div"),c(Te.$$.fragment),jn=r(),tt=a("p"),tt.textContent=Po,On=r(),re=a("div"),c(we.$$.fragment),Nn=r(),nt=a("p"),nt.textContent=Lo,Xt=r(),c(Ce.$$.fragment),Rt=r(),C=a("div"),c(ke.$$.fragment),Jn=r(),ot=a("p"),ot.innerHTML=Do,Gn=r(),rt=a("p"),rt.innerHTML=zo,Zn=r(),c(se.$$.fragment),Wt=r(),N=a("div"),c(Pe.$$.fragment),Bn=r(),st=a("p"),st.innerHTML=qo,Kt=r(),A=a("div"),c(Le.$$.fragment),Un=r(),at=a("p"),at.textContent=So,Xn=r(),it=a("p"),it.textContent=Fo,Yt=r(),I=a("div"),c(De.$$.fragment),Rn=r(),dt=a("p"),dt.textContent=Mo,Wn=r(),lt=a("p"),lt.textContent=Ao,en=r(),E=a("div"),c(ze.$$.fragment),Kn=r(),ct=a("p"),ct.textContent=Io,Yn=r(),mt=a("p"),mt.textContent=Eo,tn=r(),c(qe.$$.fragment),nn=r(),Q=a("div"),c(Se.$$.fragment),eo=r(),pt=a("p"),pt.textContent=Qo,to=r(),ft=a("p"),ft.textContent=Ho,on=r(),J=a("div"),c(Fe.$$.fragment),no=r(),ut=a("p"),ut.textContent=Vo,rn=r(),c(Me.$$.fragment),sn=r(),H=a("div"),c(Ae.$$.fragment),oo=r(),gt=a("p"),gt.textContent=jo,ro=r(),c(ae.$$.fragment),an=r(),V=a("div"),c(Ie.$$.fragment),so=r(),ht=a("p"),ht.textContent=Oo,ao=r(),c(ie.$$.fragment),dn=r(),G=a("div"),c(Ee.$$.fragment),io=r(),_t=a("p"),_t.textContent=No,ln=r(),Z=a("div"),c(Qe.$$.fragment),lo=r(),bt=a("p"),bt.textContent=Jo,cn=r(),B=a("div"),c(He.$$.fragment),co=r(),$t=a("p"),$t.textContent=Go,mn=r(),j=a("div"),c(Ve.$$.fragment),mo=r(),vt=a("p"),vt.textContent=Zo,po=r(),c(de.$$.fragment),pn=r(),c(je.$$.fragment),fn=r(),U=a("div"),c(Oe.$$.fragment),fo=r(),xt=a("p"),xt.innerHTML=Bo,un=r(),k=a("div"),c(Ne.$$.fragment),uo=r(),yt=a("p"),yt.textContent=Uo,go=r(),Tt=a("p"),Tt.textContent=Xo,ho=r(),wt=a("ol"),wt.innerHTML=Ro,gn=r(),X=a("div"),c(Je.$$.fragment),_o=r(),Ct=a("p"),Ct.textContent=Wo,hn=r(),Et=a("p"),this.h()},l(e){const n=or("svelte-u9bgzb",document.head);l=i(n,"META",{name:!0,content:!0}),n.forEach(t),x=s(e),h=i(e,"P",{}),b(h).forEach(t),y=s(e),m(P.$$.fragment,e),T=s(e),L=i(e,"P",{"data-svelte-h":!0}),_(L)!=="svelte-q5pi06"&&(L.textContent=bo),Vt=s(e),me=i(e,"P",{"data-svelte-h":!0}),_(me)!=="svelte-1k2ylrx"&&(me.textContent=$o),jt=s(e),m(pe.$$.fragment,e),Ot=s(e),D=i(e,"DIV",{class:!0});var R=b(D);m(fe.$$.fragment,R),Ln=s(R),Ze=i(R,"P",{"data-svelte-h":!0}),_(Ze)!=="svelte-1lta4gb"&&(Ze.textContent=vo),Dn=s(R),Be=i(R,"P",{"data-svelte-h":!0}),_(Be)!=="svelte-6u0wx8"&&(Be.textContent=xo),R.forEach(t),Nt=s(e),z=i(e,"DIV",{class:!0});var W=b(z);m(ue.$$.fragment,W),zn=s(W),Ue=i(W,"P",{"data-svelte-h":!0}),_(Ue)!=="svelte-nykzs4"&&(Ue.textContent=yo),qn=s(W),Xe=i(W,"DIV",{class:!0});var Qt=b(Xe);m(ge.$$.fragment,Qt),Qt.forEach(t),W.forEach(t),Jt=s(e),q=i(e,"DIV",{class:!0});var K=b(q);m(he.$$.fragment,K),Sn=s(K),Re=i(K,"P",{"data-svelte-h":!0}),_(Re)!=="svelte-1xgtkjp"&&(Re.textContent=To),Fn=s(K),ee=i(K,"DIV",{class:!0});var Ge=b(ee);m(_e.$$.fragment,Ge),Mn=s(Ge),m(te.$$.fragment,Ge),Ge.forEach(t),K.forEach(t),Gt=s(e),S=i(e,"DIV",{class:!0});var Y=b(S);m(be.$$.fragment,Y),An=s(Y),We=i(Y,"P",{"data-svelte-h":!0}),_(We)!=="svelte-i1ac0w"&&(We.textContent=wo),In=s(Y),ne=i(Y,"DIV",{class:!0});var bn=b(ne);m($e.$$.fragment,bn),En=s(bn),m(oe.$$.fragment,bn),bn.forEach(t),Y.forEach(t),Zt=s(e),O=i(e,"DIV",{class:!0});var $n=b(O);m(ve.$$.fragment,$n),Qn=s($n),Ke=i($n,"P",{"data-svelte-h":!0}),_(Ke)!=="svelte-1q47p2v"&&(Ke.innerHTML=Co),$n.forEach(t),Bt=s(e),F=i(e,"DIV",{class:!0});var kt=b(F);m(xe.$$.fragment,kt),Hn=s(kt),Ye=i(kt,"P",{"data-svelte-h":!0}),_(Ye)!=="svelte-vm79b9"&&(Ye.textContent=ko),Vn=s(kt),et=i(kt,"DIV",{class:!0});var Ko=b(et);m(ye.$$.fragment,Ko),Ko.forEach(t),kt.forEach(t),Ut=s(e),M=i(e,"DIV",{class:!0});var Pt=b(M);m(Te.$$.fragment,Pt),jn=s(Pt),tt=i(Pt,"P",{"data-svelte-h":!0}),_(tt)!=="svelte-1cor2i2"&&(tt.textContent=Po),On=s(Pt),re=i(Pt,"DIV",{class:!0});var vn=b(re);m(we.$$.fragment,vn),Nn=s(vn),nt=i(vn,"P",{"data-svelte-h":!0}),_(nt)!=="svelte-1cor2i2"&&(nt.textContent=Lo),vn.forEach(t),Pt.forEach(t),Xt=s(e),m(Ce.$$.fragment,e),Rt=s(e),C=i(e,"DIV",{class:!0});var le=b(C);m(ke.$$.fragment,le),Jn=s(le),ot=i(le,"P",{"data-svelte-h":!0}),_(ot)!=="svelte-16kfis2"&&(ot.innerHTML=Do),Gn=s(le),rt=i(le,"P",{"data-svelte-h":!0}),_(rt)!=="svelte-1ufp6tv"&&(rt.innerHTML=zo),Zn=s(le),m(se.$$.fragment,le),le.forEach(t),Wt=s(e),N=i(e,"DIV",{class:!0});var xn=b(N);m(Pe.$$.fragment,xn),Bn=s(xn),st=i(xn,"P",{"data-svelte-h":!0}),_(st)!=="svelte-o28a6l"&&(st.innerHTML=qo),xn.forEach(t),Kt=s(e),A=i(e,"DIV",{class:!0});var Lt=b(A);m(Le.$$.fragment,Lt),Un=s(Lt),at=i(Lt,"P",{"data-svelte-h":!0}),_(at)!=="svelte-by2rhc"&&(at.textContent=So),Xn=s(Lt),it=i(Lt,"P",{"data-svelte-h":!0}),_(it)!=="svelte-14zrzk1"&&(it.textContent=Fo),Lt.forEach(t),Yt=s(e),I=i(e,"DIV",{class:!0});var Dt=b(I);m(De.$$.fragment,Dt),Rn=s(Dt),dt=i(Dt,"P",{"data-svelte-h":!0}),_(dt)!=="svelte-1xogpwx"&&(dt.textContent=Mo),Wn=s(Dt),lt=i(Dt,"P",{"data-svelte-h":!0}),_(lt)!=="svelte-14zrzk1"&&(lt.textContent=Ao),Dt.forEach(t),en=s(e),E=i(e,"DIV",{class:!0});var zt=b(E);m(ze.$$.fragment,zt),Kn=s(zt),ct=i(zt,"P",{"data-svelte-h":!0}),_(ct)!=="svelte-1edz4x0"&&(ct.textContent=Io),Yn=s(zt),mt=i(zt,"P",{"data-svelte-h":!0}),_(mt)!=="svelte-14zrzk1"&&(mt.textContent=Eo),zt.forEach(t),tn=s(e),m(qe.$$.fragment,e),nn=s(e),Q=i(e,"DIV",{class:!0});var qt=b(Q);m(Se.$$.fragment,qt),eo=s(qt),pt=i(qt,"P",{"data-svelte-h":!0}),_(pt)!=="svelte-1lta4gb"&&(pt.textContent=Qo),to=s(qt),ft=i(qt,"P",{"data-svelte-h":!0}),_(ft)!=="svelte-6u0wx8"&&(ft.textContent=Ho),qt.forEach(t),on=s(e),J=i(e,"DIV",{class:!0});var yn=b(J);m(Fe.$$.fragment,yn),no=s(yn),ut=i(yn,"P",{"data-svelte-h":!0}),_(ut)!=="svelte-1cor2i2"&&(ut.textContent=Vo),yn.forEach(t),rn=s(e),m(Me.$$.fragment,e),sn=s(e),H=i(e,"DIV",{class:!0});var St=b(H);m(Ae.$$.fragment,St),oo=s(St),gt=i(St,"P",{"data-svelte-h":!0}),_(gt)!=="svelte-1obn9c"&&(gt.textContent=jo),ro=s(St),m(ae.$$.fragment,St),St.forEach(t),an=s(e),V=i(e,"DIV",{class:!0});var Ft=b(V);m(Ie.$$.fragment,Ft),so=s(Ft),ht=i(Ft,"P",{"data-svelte-h":!0}),_(ht)!=="svelte-16f7wip"&&(ht.textContent=Oo),ao=s(Ft),m(ie.$$.fragment,Ft),Ft.forEach(t),dn=s(e),G=i(e,"DIV",{class:!0});var Tn=b(G);m(Ee.$$.fragment,Tn),io=s(Tn),_t=i(Tn,"P",{"data-svelte-h":!0}),_(_t)!=="svelte-yqule2"&&(_t.textContent=No),Tn.forEach(t),ln=s(e),Z=i(e,"DIV",{class:!0});var wn=b(Z);m(Qe.$$.fragment,wn),lo=s(wn),bt=i(wn,"P",{"data-svelte-h":!0}),_(bt)!=="svelte-1mrk13b"&&(bt.textContent=Jo),wn.forEach(t),cn=s(e),B=i(e,"DIV",{class:!0});var Cn=b(B);m(He.$$.fragment,Cn),co=s(Cn),$t=i(Cn,"P",{"data-svelte-h":!0}),_($t)!=="svelte-13vmm2k"&&($t.textContent=Go),Cn.forEach(t),mn=s(e),j=i(e,"DIV",{class:!0});var Mt=b(j);m(Ve.$$.fragment,Mt),mo=s(Mt),vt=i(Mt,"P",{"data-svelte-h":!0}),_(vt)!=="svelte-biydvq"&&(vt.textContent=Zo),po=s(Mt),m(de.$$.fragment,Mt),Mt.forEach(t),pn=s(e),m(je.$$.fragment,e),fn=s(e),U=i(e,"DIV",{class:!0});var kn=b(U);m(Oe.$$.fragment,kn),fo=s(kn),xt=i(kn,"P",{"data-svelte-h":!0}),_(xt)!=="svelte-xpqleu"&&(xt.innerHTML=Bo),kn.forEach(t),un=s(e),k=i(e,"DIV",{class:!0});var ce=b(k);m(Ne.$$.fragment,ce),uo=s(ce),yt=i(ce,"P",{"data-svelte-h":!0}),_(yt)!=="svelte-5ynxmr"&&(yt.textContent=Uo),go=s(ce),Tt=i(ce,"P",{"data-svelte-h":!0}),_(Tt)!=="svelte-19x4elj"&&(Tt.textContent=Xo),ho=s(ce),wt=i(ce,"OL",{"data-svelte-h":!0}),_(wt)!=="svelte-16g9ved"&&(wt.innerHTML=Ro),ce.forEach(t),gn=s(e),X=i(e,"DIV",{class:!0});var Pn=b(X);m(Je.$$.fragment,Pn),_o=s(Pn),Ct=i(Pn,"P",{"data-svelte-h":!0}),_(Ct)!=="svelte-pubhri"&&(Ct.textContent=Wo),Pn.forEach(t),hn=s(e),Et=i(e,"P",{}),b(Et).forEach(t),this.h()},h(){$(l,"name","hf:doc:metadata"),$(l,"content",fr),$(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ne,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(et,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(G,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,n){o(document.head,l),d(e,x,n),d(e,h,n),d(e,y,n),p(P,e,n),d(e,T,n),d(e,L,n),d(e,Vt,n),d(e,me,n),d(e,jt,n),p(pe,e,n),d(e,Ot,n),d(e,D,n),p(fe,D,null),o(D,Ln),o(D,Ze),o(D,Dn),o(D,Be),d(e,Nt,n),d(e,z,n),p(ue,z,null),o(z,zn),o(z,Ue),o(z,qn),o(z,Xe),p(ge,Xe,null),d(e,Jt,n),d(e,q,n),p(he,q,null),o(q,Sn),o(q,Re),o(q,Fn),o(q,ee),p(_e,ee,null),o(ee,Mn),p(te,ee,null),d(e,Gt,n),d(e,S,n),p(be,S,null),o(S,An),o(S,We),o(S,In),o(S,ne),p($e,ne,null),o(ne,En),p(oe,ne,null),d(e,Zt,n),d(e,O,n),p(ve,O,null),o(O,Qn),o(O,Ke),d(e,Bt,n),d(e,F,n),p(xe,F,null),o(F,Hn),o(F,Ye),o(F,Vn),o(F,et),p(ye,et,null),d(e,Ut,n),d(e,M,n),p(Te,M,null),o(M,jn),o(M,tt),o(M,On),o(M,re),p(we,re,null),o(re,Nn),o(re,nt),d(e,Xt,n),p(Ce,e,n),d(e,Rt,n),d(e,C,n),p(ke,C,null),o(C,Jn),o(C,ot),o(C,Gn),o(C,rt),o(C,Zn),p(se,C,null),d(e,Wt,n),d(e,N,n),p(Pe,N,null),o(N,Bn),o(N,st),d(e,Kt,n),d(e,A,n),p(Le,A,null),o(A,Un),o(A,at),o(A,Xn),o(A,it),d(e,Yt,n),d(e,I,n),p(De,I,null),o(I,Rn),o(I,dt),o(I,Wn),o(I,lt),d(e,en,n),d(e,E,n),p(ze,E,null),o(E,Kn),o(E,ct),o(E,Yn),o(E,mt),d(e,tn,n),p(qe,e,n),d(e,nn,n),d(e,Q,n),p(Se,Q,null),o(Q,eo),o(Q,pt),o(Q,to),o(Q,ft),d(e,on,n),d(e,J,n),p(Fe,J,null),o(J,no),o(J,ut),d(e,rn,n),p(Me,e,n),d(e,sn,n),d(e,H,n),p(Ae,H,null),o(H,oo),o(H,gt),o(H,ro),p(ae,H,null),d(e,an,n),d(e,V,n),p(Ie,V,null),o(V,so),o(V,ht),o(V,ao),p(ie,V,null),d(e,dn,n),d(e,G,n),p(Ee,G,null),o(G,io),o(G,_t),d(e,ln,n),d(e,Z,n),p(Qe,Z,null),o(Z,lo),o(Z,bt),d(e,cn,n),d(e,B,n),p(He,B,null),o(B,co),o(B,$t),d(e,mn,n),d(e,j,n),p(Ve,j,null),o(j,mo),o(j,vt),o(j,po),p(de,j,null),d(e,pn,n),p(je,e,n),d(e,fn,n),d(e,U,n),p(Oe,U,null),o(U,fo),o(U,xt),d(e,un,n),d(e,k,n),p(Ne,k,null),o(k,uo),o(k,yt),o(k,go),o(k,Tt),o(k,ho),o(k,wt),d(e,gn,n),d(e,X,n),p(Je,X,null),o(X,_o),o(X,Ct),d(e,hn,n),d(e,Et,n),_n=!0},p(e,[n]){const R={};n&2&&(R.$$scope={dirty:n,ctx:e}),te.$set(R);const W={};n&2&&(W.$$scope={dirty:n,ctx:e}),oe.$set(W);const Qt={};n&2&&(Qt.$$scope={dirty:n,ctx:e}),se.$set(Qt);const K={};n&2&&(K.$$scope={dirty:n,ctx:e}),ae.$set(K);const Ge={};n&2&&(Ge.$$scope={dirty:n,ctx:e}),ie.$set(Ge);const Y={};n&2&&(Y.$$scope={dirty:n,ctx:e}),de.$set(Y)},i(e){_n||(f(P.$$.fragment,e),f(pe.$$.fragment,e),f(fe.$$.fragment,e),f(ue.$$.fragment,e),f(ge.$$.fragment,e),f(he.$$.fragment,e),f(_e.$$.fragment,e),f(te.$$.fragment,e),f(be.$$.fragment,e),f($e.$$.fragment,e),f(oe.$$.fragment,e),f(ve.$$.fragment,e),f(xe.$$.fragment,e),f(ye.$$.fragment,e),f(Te.$$.fragment,e),f(we.$$.fragment,e),f(Ce.$$.fragment,e),f(ke.$$.fragment,e),f(se.$$.fragment,e),f(Pe.$$.fragment,e),f(Le.$$.fragment,e),f(De.$$.fragment,e),f(ze.$$.fragment,e),f(qe.$$.fragment,e),f(Se.$$.fragment,e),f(Fe.$$.fragment,e),f(Me.$$.fragment,e),f(Ae.$$.fragment,e),f(ae.$$.fragment,e),f(Ie.$$.fragment,e),f(ie.$$.fragment,e),f(Ee.$$.fragment,e),f(Qe.$$.fragment,e),f(He.$$.fragment,e),f(Ve.$$.fragment,e),f(de.$$.fragment,e),f(je.$$.fragment,e),f(Oe.$$.fragment,e),f(Ne.$$.fragment,e),f(Je.$$.fragment,e),_n=!0)},o(e){u(P.$$.fragment,e),u(pe.$$.fragment,e),u(fe.$$.fragment,e),u(ue.$$.fragment,e),u(ge.$$.fragment,e),u(he.$$.fragment,e),u(_e.$$.fragment,e),u(te.$$.fragment,e),u(be.$$.fragment,e),u($e.$$.fragment,e),u(oe.$$.fragment,e),u(ve.$$.fragment,e),u(xe.$$.fragment,e),u(ye.$$.fragment,e),u(Te.$$.fragment,e),u(we.$$.fragment,e),u(Ce.$$.fragment,e),u(ke.$$.fragment,e),u(se.$$.fragment,e),u(Pe.$$.fragment,e),u(Le.$$.fragment,e),u(De.$$.fragment,e),u(ze.$$.fragment,e),u(qe.$$.fragment,e),u(Se.$$.fragment,e),u(Fe.$$.fragment,e),u(Me.$$.fragment,e),u(Ae.$$.fragment,e),u(ae.$$.fragment,e),u(Ie.$$.fragment,e),u(ie.$$.fragment,e),u(Ee.$$.fragment,e),u(Qe.$$.fragment,e),u(He.$$.fragment,e),u(Ve.$$.fragment,e),u(de.$$.fragment,e),u(je.$$.fragment,e),u(Oe.$$.fragment,e),u(Ne.$$.fragment,e),u(Je.$$.fragment,e),_n=!1},d(e){e&&(t(x),t(h),t(y),t(T),t(L),t(Vt),t(me),t(jt),t(Ot),t(D),t(Nt),t(z),t(Jt),t(q),t(Gt),t(S),t(Zt),t(O),t(Bt),t(F),t(Ut),t(M),t(Xt),t(Rt),t(C),t(Wt),t(N),t(Kt),t(A),t(Yt),t(I),t(en),t(E),t(tn),t(nn),t(Q),t(on),t(J),t(rn),t(sn),t(H),t(an),t(V),t(dn),t(G),t(ln),t(Z),t(cn),t(B),t(mn),t(j),t(pn),t(fn),t(U),t(un),t(k),t(gn),t(X),t(hn),t(Et)),t(l),g(P,e),g(pe,e),g(fe),g(ue),g(ge),g(he),g(_e),g(te),g(be),g($e),g(oe),g(ve),g(xe),g(ye),g(Te),g(we),g(Ce,e),g(ke),g(se),g(Pe),g(Le),g(De),g(ze),g(qe,e),g(Se),g(Fe),g(Me,e),g(Ae),g(ae),g(Ie),g(ie),g(Ee),g(Qe),g(He),g(Ve),g(de),g(je,e),g(Oe),g(Ne),g(Je)}}}const fr='{"title":"自定义层和工具","local":"自定义层和工具","sections":[{"title":"Pytorch自定义模块","local":"transformers.Conv1D","sections":[],"depth":2},{"title":"PyTorch帮助函数","local":"transformers.apply_chunking_to_forward","sections":[],"depth":2},{"title":"TensorFlow自定义层","local":"transformers.modeling_tf_utils.TFConv1D","sections":[],"depth":2},{"title":"TensorFlow loss 函数","local":"transformers.modeling_tf_utils.TFCausalLanguageModelingLoss","sections":[],"depth":2},{"title":"TensorFlow帮助函数","local":"transformers.modeling_tf_utils.get_initializer","sections":[],"depth":2}],"depth":1}';function ur(w){return er(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class yr extends tr{constructor(l){super(),nr(this,l,ur,pr,Yo,{})}}export{yr as component};
