import{s as Qs,c as Gs,u as Ys,g as Os,d as Xs,o as Zs,n as qa}from"../chunks/scheduler.9991993c.js";import{S as Vs,i as Rs,r as f,u as g,v as h,d,t as p,w as u,g as o,m as Ss,s as r,h as s,j as _,n as Ws,f as n,c as a,k as $,a as i,y as t,o as Ks,A as el,x as c}from"../chunks/index.7fc9a5e7.js";import{T as qs}from"../chunks/Tip.9de92fc6.js";import{D as C}from"../chunks/Docstring.8180f571.js";import{C as Ra}from"../chunks/CodeBlock.e11cba92.js";import{E as Bs}from"../chunks/ExampleCodeBlock.a03fccd6.js";import{H as Qr}from"../chunks/Heading.e3de321f.js";function tl(I){let m,x,b,k,M;const v=I[1].default,y=Gs(v,I,I[2],null);return{c(){m=o("p"),x=Ss("Deprecated in "),b=Ss(I[0]),k=r(),y&&y.c(),this.h()},l(L){m=s(L,"P",{class:!0});var E=_(m);x=Ws(E,"Deprecated in "),b=Ws(E,I[0]),E.forEach(n),k=a(L),y&&y.l(L),this.h()},h(){$(m,"class","font-medium")},m(L,E){i(L,m,E),t(m,x),t(m,b),i(L,k,E),y&&y.m(L,E),M=!0},p(L,E){(!M||E&1)&&Ks(b,L[0]),y&&y.p&&(!M||E&4)&&Ys(y,v,L,L[2],M?Xs(v,L[2],E,null):Os(L[2]),null)},i(L){M||(d(y,L),M=!0)},o(L){p(y,L),M=!1},d(L){L&&(n(m),n(k)),y&&y.d(L)}}}function rl(I){let m,x;return m=new qs({props:{warning:!0,$$slots:{default:[tl]},$$scope:{ctx:I}}}),{c(){f(m.$$.fragment)},l(b){g(m.$$.fragment,b)},m(b,k){h(m,b,k),x=!0},p(b,[k]){const M={};k&5&&(M.$$scope={dirty:k,ctx:b}),m.$set(M)},i(b){x||(d(m.$$.fragment,b),x=!0)},o(b){p(m.$$.fragment,b),x=!1},d(b){u(m,b)}}}function al(I,m,x){let{$$slots:b={},$$scope:k}=m,{version:M}=m;return I.$$set=v=>{"version"in v&&x(0,M=v.version),"$$scope"in v&&x(2,k=v.$$scope)},[M,b,k]}class nl extends Vs{constructor(m){super(),Rs(this,m,al,rl,Qs,{version:0})}}function ol(I){let m,x="Setting <code>WANDB_LOG_MODEL</code> as <code>bool</code> will be deprecated in version 5 of 🤗 Transformers.";return{c(){m=o("p"),m.innerHTML=x},l(b){m=s(b,"P",{"data-svelte-h":!0}),c(m)!=="svelte-fxlq1n"&&(m.innerHTML=x)},m(b,k){i(b,m,k)},p:qa,d(b){b&&n(m)}}}function sl(I){let m,x="Example:",b,k,M;return k=new Ra({props:{code:"JTIzJTIwTm90ZSUzQSUyMFRoaXMlMjBleGFtcGxlJTIwc2tpcHMlMjBvdmVyJTIwc29tZSUyMHNldHVwJTIwc3RlcHMlMjBmb3IlMjBicmV2aXR5LiUwQWZyb20lMjBmbHl0ZWtpdCUyMGltcG9ydCUyMGN1cnJlbnRfY29udGV4dCUyQyUyMHRhc2slMEElMEElMEElNDB0YXNrJTBBZGVmJTIwdHJhaW5faGZfdHJhbnNmb3JtZXIoKSUzQSUwQSUyMCUyMCUyMCUyMGNwJTIwJTNEJTIwY3VycmVudF9jb250ZXh0KCkuY2hlY2twb2ludCUwQSUyMCUyMCUyMCUyMHRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKC4uLiUyQyUyMGNhbGxiYWNrcyUzRCU1QkZseXRlQ2FsbGJhY2soKSU1RCklMEElMjAlMjAlMjAlMjBvdXRwdXQlMjAlM0QlMjB0cmFpbmVyLnRyYWluKHJlc3VtZV9mcm9tX2NoZWNrcG9pbnQlM0RjcC5yZXN0b3JlKCkp",highlighted:`<span class="hljs-comment"># Note: This example skips over some setup steps for brevity.</span>
<span class="hljs-keyword">from</span> flytekit <span class="hljs-keyword">import</span> current_context, task


<span class="hljs-meta">@task</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">train_hf_transformer</span>():
    cp = current_context().checkpoint
    trainer = Trainer(..., callbacks=[FlyteCallback()])
    output = trainer.train(resume_from_checkpoint=cp.restore())`,wrap:!1}}),{c(){m=o("p"),m.textContent=x,b=r(),f(k.$$.fragment)},l(v){m=s(v,"P",{"data-svelte-h":!0}),c(m)!=="svelte-11lpom8"&&(m.textContent=x),b=a(v),g(k.$$.fragment,v)},m(v,y){i(v,m,y),i(v,b,y),h(k,v,y),M=!0},p:qa,i(v){M||(d(k.$$.fragment,v),M=!0)},o(v){p(k.$$.fragment,v),M=!1},d(v){v&&(n(m),n(b)),u(k,v)}}}function ll(I){let m,x="Example:",b,k,M;return k=new Ra({props:{code:"Y2xhc3MlMjBQcmludGVyQ2FsbGJhY2soVHJhaW5lckNhbGxiYWNrKSUzQSUwQSUyMCUyMCUyMCUyMGRlZiUyMG9uX2xvZyhzZWxmJTJDJTIwYXJncyUyQyUyMHN0YXRlJTJDJTIwY29udHJvbCUyQyUyMGxvZ3MlM0ROb25lJTJDJTIwKiprd2FyZ3MpJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwXyUyMCUzRCUyMGxvZ3MucG9wKCUyMnRvdGFsX2Zsb3MlMjIlMkMlMjBOb25lKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGlmJTIwc3RhdGUuaXNfbG9jYWxfcHJvY2Vzc196ZXJvJTNBJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcHJpbnQobG9ncyk=",highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">PrinterCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_log</span>(<span class="hljs-params">self, args, state, control, logs=<span class="hljs-literal">None</span>, **kwargs</span>):
        _ = logs.pop(<span class="hljs-string">&quot;total_flos&quot;</span>, <span class="hljs-literal">None</span>)
        <span class="hljs-keyword">if</span> state.is_local_process_zero:
            <span class="hljs-built_in">print</span>(logs)`,wrap:!1}}),{c(){m=o("p"),m.textContent=x,b=r(),f(k.$$.fragment)},l(v){m=s(v,"P",{"data-svelte-h":!0}),c(m)!=="svelte-11lpom8"&&(m.textContent=x),b=a(v),g(k.$$.fragment,v)},m(v,y){i(v,m,y),i(v,b,y),h(k,v,y),M=!0},p:qa,i(v){M||(d(k.$$.fragment,v),M=!0)},o(v){p(k.$$.fragment,v),M=!1},d(v){v&&(n(m),n(b)),u(k,v)}}}function il(I){let m,x=`In all this class, one step is to be understood as one update step. When using gradient accumulation, one update
step may require several forward and backward passes: if you use <code>gradient_accumulation_steps=n</code>, then one update
step requires going through <em>n</em> batches.`;return{c(){m=o("p"),m.innerHTML=x},l(b){m=s(b,"P",{"data-svelte-h":!0}),c(m)!=="svelte-rhwh6p"&&(m.innerHTML=x)},m(b,k){i(b,m,k)},p:qa,d(b){b&&n(m)}}}function cl(I){let m,x,b,k,M,v,y,L="Callbacks可以用来自定义PyTorch [Trainer]中训练循环行为的对象（此功能尚未在TensorFlow中实现），该对象可以检查训练循环状态（用于进度报告、在TensorBoard或其他ML平台上记录日志等），并做出决策（例如提前停止）。",E,Ie,yo='Callbacks是“只读”的代码片段，除了它们返回的[TrainerControl]对象外，它们不能更改训练循环中的任何内容。对于需要更改训练循环的自定义，您应该继承[Trainer]并重载您需要的方法（有关示例，请参见<a href="trainer">trainer</a>）。',Vr,Ee,xo="默认情况下，<code>TrainingArguments.report_to</code> 设置为”all”，然后[Trainer]将使用以下callbacks。",Rr,He,Lo='<li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.DefaultFlowCallback">DefaultFlowCallback</a>，它处理默认的日志记录、保存和评估行为</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.PrinterCallback">PrinterCallback</a> 或 <a href="/docs/transformers/main/zh/main_classes/callback#transformers.ProgressCallback">ProgressCallback</a>，用于显示进度和打印日志（如果通过<code>TrainingArguments</code>停用tqdm，则使用第一个函数；否则使用第二个）。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.TensorBoardCallback">TensorBoardCallback</a>，如果TensorBoard可访问（通过PyTorch版本 &gt;= 1.4 或者 tensorboardX）。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.WandbCallback">WandbCallback</a>，如果安装了<a href="https://www.wandb.com/" rel="nofollow">wandb</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.CometCallback">CometCallback</a>，如果安装了<a href="https://www.comet.ml/site/" rel="nofollow">comet_ml</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.MLflowCallback">MLflowCallback</a>，如果安装了<a href="https://www.mlflow.org/" rel="nofollow">mlflow</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.NeptuneCallback">NeptuneCallback</a>，如果安装了<a href="https://neptune.ai/" rel="nofollow">neptune</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.AzureMLCallback">AzureMLCallback</a>，如果安装了<a href="https://pypi.org/project/azureml-sdk/" rel="nofollow">azureml-sdk</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.CodeCarbonCallback">CodeCarbonCallback</a>，如果安装了<a href="https://pypi.org/project/codecarbon/" rel="nofollow">codecarbon</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.ClearMLCallback">ClearMLCallback</a>，如果安装了<a href="https://github.com/allegroai/clearml" rel="nofollow">clearml</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.DagsHubCallback">DagsHubCallback</a>，如果安装了<a href="https://dagshub.com/" rel="nofollow">dagshub</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.FlyteCallback">FlyteCallback</a>，如果安装了<a href="https://flyte.org/" rel="nofollow">flyte</a>。</li> <li><a href="/docs/transformers/main/zh/main_classes/callback#transformers.integrations.DVCLiveCallback">DVCLiveCallback</a>，如果安装了<a href="https://dvc.org/doc/dvclive" rel="nofollow">dvclive</a>。</li>',qr,Pe,Io="如果安装了一个软件包，但您不希望使用相关的集成，您可以将 <code>TrainingArguments.report_to</code> 更改为仅包含您想要使用的集成的列表（例如 <code>[&quot;azure_ml&quot;, &quot;wandb&quot;]</code>）。",Gr,je,Eo='实现callbacks的主要类是<a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a>。它获取用于实例化<code>Trainer</code>的<code>TrainingArguments</code>，可以通过<a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerState">TrainerState</a>访问该Trainer的内部状态，并可以通过<a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerControl">TrainerControl</a>对训练循环执行一些操作。',Yr,Je,Or,De,Ho='这里是库里可用<a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a>的列表：',Xr,F,ze,Ga,Ht,Po='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.comet.ml/site/" rel="nofollow">Comet ML</a>.',Ya,P,Ue,Oa,Pt,jo="Setup the optional Comet.ml integration.",Xa,jt,Jo="Environment:",Za,Jt,Do=`<li><strong>COMET_MODE</strong> (<code>str</code>, <em>optional</em>, defaults to <code>ONLINE</code>):
Whether to create an online, offline experiment or disable Comet logging. Can be <code>OFFLINE</code>, <code>ONLINE</code>, or
<code>DISABLED</code>.</li> <li><strong>COMET_PROJECT_NAME</strong> (<code>str</code>, <em>optional</em>):
Comet project name for experiments.</li> <li><strong>COMET_OFFLINE_DIRECTORY</strong> (<code>str</code>, <em>optional</em>):
Folder to use for saving offline experiments when <code>COMET_MODE</code> is <code>OFFLINE</code>.</li> <li><strong>COMET_LOG_ASSETS</strong> (<code>str</code>, <em>optional</em>, defaults to <code>TRUE</code>):
Whether or not to log training assets (tf event logs, checkpoints, etc), to Comet. Can be <code>TRUE</code>, or
<code>FALSE</code>.</li>`,Ka,Dt,zo=`For a number of configurable items in the environment, see
<a href="https://www.comet.ml/docs/python-sdk/advanced/#comet-configuration-variables" rel="nofollow">here</a>.`,Zr,O,Ne,en,zt,Uo='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that handles the default flow of the training loop for logs, evaluation and checkpoints.',Kr,X,Ae,tn,Ut,No='A bare <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that just prints the logs.',ea,Z,Fe,rn,Nt,Ao='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that displays the progress of training or evaluation.',ta,S,Se,an,At,Fo='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that handles early stopping.',nn,Ft,So=`This callback depends on <code>TrainingArguments</code> argument <em>load_best_model_at_end</em> functionality to set best_metric
in <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerState">TrainerState</a>. Note that if the <code>TrainingArguments</code> argument <em>save_steps</em> differs from <em>eval_steps</em>, the
early stopping will not occur until the next save step.`,ra,K,We,on,St,Wo='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.tensorflow.org/tensorboard" rel="nofollow">TensorBoard</a>.',aa,W,Be,sn,Wt,Bo='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs metrics, media, model checkpoints to <a href="https://www.wandb.com/" rel="nofollow">Weight and Biases</a>.',ln,j,Qe,cn,Bt,Qo="Setup the optional Weights &amp; Biases (<em>wandb</em>) integration.",mn,Qt,Vo=`One can subclass and override this method to customize the setup if needed. Find more information
<a href="https://docs.wandb.ai/guides/integrations/huggingface" rel="nofollow">here</a>. You can also override the following environment
variables:`,dn,Vt,Ro="Environment:",pn,B,Ve,Rt,qo=`<strong>WANDB_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;false&quot;</code>):
Whether to log model and checkpoints during training. Can be <code>&quot;end&quot;</code>, <code>&quot;checkpoint&quot;</code> or <code>&quot;false&quot;</code>. If set
to <code>&quot;end&quot;</code>, the model will be uploaded at the end of training. If set to <code>&quot;checkpoint&quot;</code>, the checkpoint
will be uploaded every <code>args.save_steps</code> . If set to <code>&quot;false&quot;</code>, the model will not be uploaded. Use along
with <code>load_best_model_at_end()</code> to upload best model.`,fn,ne,gn,qt,Go=`<p><strong>WANDB_WATCH</strong> (<code>str</code>, <em>optional</em> defaults to <code>&quot;false&quot;</code>):
Can be <code>&quot;gradients&quot;</code>, <code>&quot;all&quot;</code>, <code>&quot;parameters&quot;</code>, or <code>&quot;false&quot;</code>. Set to <code>&quot;all&quot;</code> to log gradients and
parameters.</p>`,hn,Gt,Yo=`<p><strong>WANDB_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;huggingface&quot;</code>):
Set this to a custom string to store results in a different project.</p>`,un,Yt,Oo=`<p><strong>WANDB_DISABLED</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to disable wandb entirely. Set <code>WANDB_DISABLED=true</code> to disable.</p>`,na,Q,Re,bn,Ot,Xo=`A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.mlflow.org/" rel="nofollow">MLflow</a>. Can be disabled by setting
environment variable <code>DISABLE_MLFLOW_INTEGRATION = TRUE</code>.`,vn,U,qe,_n,Xt,Zo="Setup the optional MLflow integration.",Tn,Zt,Ko="Environment:",$n,Kt,es=`<li><strong>HF_MLFLOW_LOG_ARTIFACTS</strong> (<code>str</code>, <em>optional</em>):
Whether to use MLflow <code>.log_artifact()</code> facility to log artifacts. This only makes sense if logging to a
remote server, e.g. s3 or GCS. If set to <code>True</code> or <em>1</em>, will copy each saved checkpoint on each save in
<code>TrainingArguments</code>’s <code>output_dir</code> to the local or remote artifact storage. Using it without a remote
storage will just copy the files to your artifact location.</li> <li><strong>MLFLOW_TRACKING_URI</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;&quot;</code>):
Whether to store runs at a specific path or remote server. Default to an empty string which will store runs
at <code>./mlruns</code> locally.</li> <li><strong>MLFLOW_EXPERIMENT_NAME</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>):
Whether to use an MLflow experiment_name under which to launch the run. Default to <code>None</code> which will point
to the <code>Default</code> experiment in MLflow. Otherwise, it is a case sensitive name of the experiment to be
activated. If an experiment with this name does not exist, a new experiment with this name is created.</li> <li><strong>MLFLOW_TAGS</strong> (<code>str</code>, <em>optional</em>):
A string dump of a dictionary of key/value pair to be added to the MLflow run as tags. Example:
<code>os.environ[&#39;MLFLOW_TAGS&#39;]=&#39;{&quot;release.candidate&quot;: &quot;RC1&quot;, &quot;release.version&quot;: &quot;2.2.0&quot;}&#39;</code>.</li> <li><strong>MLFLOW_NESTED_RUN</strong> (<code>str</code>, <em>optional</em>):
Whether to use MLflow nested runs. If set to <code>True</code> or <em>1</em>, will create a nested run inside the current
run.</li> <li><strong>MLFLOW_RUN_ID</strong> (<code>str</code>, <em>optional</em>):
Allow to reattach to an existing run which can be usefull when resuming training from a checkpoint. When
<code>MLFLOW_RUN_ID</code> environment variable is set, <code>start_run</code> attempts to resume a run with the specified run ID
and other parameters are ignored.</li> <li><strong>MLFLOW_FLATTEN_PARAMS</strong> (<code>str</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to flatten the parameters dictionary before logging.</li>`,oa,ee,Ge,Cn,er,ts='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://pypi.org/project/azureml-sdk/" rel="nofollow">AzureML</a>.',sa,te,Ye,kn,tr,rs='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that tracks the CO2 emission of training.',la,V,Oe,wn,rr,as='TrainerCallback that sends the logs to <a href="https://app.neptune.ai" rel="nofollow">Neptune</a>.',Mn,ar,ns=`For instructions and examples, see the <a href="https://docs.neptune.ai/integrations/transformers" rel="nofollow">Transformers integration
guide</a> in the Neptune documentation.`,ia,J,Xe,yn,nr,os='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://clear.ml/" rel="nofollow">ClearML</a>.',xn,or,ss="Environment:",Ln,sr,ls=`<li><strong>CLEARML_PROJECT</strong> (<code>str</code>, <em>optional</em>, defaults to <code>HuggingFace Transformers</code>):
ClearML project name.</li> <li><strong>CLEARML_TASK</strong> (<code>str</code>, <em>optional</em>, defaults to <code>Trainer</code>):
ClearML task name.</li> <li><strong>CLEARML_LOG_MODEL</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>):
Whether to log models as artifacts during training.</li>`,ca,R,Ze,In,lr,is='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that logs to <a href="https://dagshub.com/" rel="nofollow">DagsHub</a>. Extends <code>MLflowCallback</code>',En,N,Ke,Hn,ir,cs="Setup the DagsHub’s Logging integration.",Pn,cr,ms="Environment:",jn,mr,ds=`<li><strong>HF_DAGSHUB_LOG_ARTIFACTS</strong> (<code>str</code>, <em>optional</em>):
Whether to save the data and model artifacts for the experiment. Default to <code>False</code>.</li>`,ma,q,et,Jn,dr,ps=`A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://flyte.org/" rel="nofollow">Flyte</a>.
NOTE: This callback only works within a Flyte task.`,Dn,oe,da,D,tt,zn,pr,fs='A <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> that sends the logs to <a href="https://www.dvc.org/doc/dvclive" rel="nofollow">DVCLive</a>.',Un,fr,gs=`Use the environment variables below in <code>setup</code> to configure the integration. To customize this callback beyond
those environment variables, see <a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface" rel="nofollow">here</a>.`,Nn,A,rt,An,gr,hs=`Setup the optional DVCLive integration. To customize this callback beyond the environment variables below, see
<a href="https://dvc.org/doc/dvclive/ml-frameworks/huggingface" rel="nofollow">here</a>.`,Fn,hr,us="Environment:",Sn,ur,bs=`<li><strong>HF_DVCLIVE_LOG_MODEL</strong> (<code>str</code>, <em>optional</em>):
Whether to use <code>dvclive.Live.log_artifact()</code> to log checkpoints created by <code>Trainer</code>. If set to <code>True</code> or
<em>1</em>, the final checkpoint is logged at the end of training. If set to <code>all</code>, the entire
<code>TrainingArguments</code>’s <code>output_dir</code> is logged at each checkpoint.</li>`,pa,at,fa,T,nt,Wn,br,vs=`A class for objects that will inspect the state of the training loop at some events and take some decisions. At
each of those events the following arguments are available:`,Bn,vr,_s=`The <code>control</code> object is the only one that can be changed by the callback, in which case the event that changes it
should return the modified version.`,Qn,_r,Ts=`The argument <code>args</code>, <code>state</code> and <code>control</code> are positionals for all events, all the others are grouped in <code>kwargs</code>.
You can unpack the ones you need in the signature of the event using them. As an example, see the code of the
simple <a href="/docs/transformers/main/zh/main_classes/callback#transformers.PrinterCallback">PrinterCallback</a>.`,Vn,se,Rn,le,ot,qn,Tr,$s="Event called at the beginning of an epoch.",Gn,ie,st,Yn,$r,Cs="Event called at the end of an epoch.",On,ce,lt,Xn,Cr,ks="Event called after an evaluation phase.",Zn,me,it,Kn,kr,ws="Event called at the end of the initialization of the <code>Trainer</code>.",eo,de,ct,to,wr,Ms="Event called after logging the last logs.",ro,pe,mt,ao,Mr,ys="Event called after a successful prediction.",no,fe,dt,oo,yr,xs="Event called after a prediction step.",so,ge,pt,lo,xr,Ls="Event called after a checkpoint save.",io,he,ft,co,Lr,Is=`Event called at the beginning of a training step. If using gradient accumulation, one training step might take
several inputs.`,mo,ue,gt,po,Ir,Es=`Event called at the end of a training step. If using gradient accumulation, one training step might take
several inputs.`,fo,be,ht,go,Er,Hs="Event called at the end of an substep during gradient accumulation.",ho,ve,ut,uo,Hr,Ps="Event called at the beginning of training.",bo,_e,bt,vo,Pr,js="Event called at the end of training.",ga,vt,Js="以下是如何使用PyTorch注册自定义callback的示例：",ha,_t,Ds="<code>Trainer</code>:",ua,Tt,ba,$t,zs="注册callback的另一种方式是调用 <code>trainer.add_callback()</code>，如下所示：",va,Ct,_a,kt,Ta,H,wt,_o,jr,Us=`A class containing the <code>Trainer</code> inner state that will be saved along the model and optimizer when checkpointing
and passed to the <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a>.`,To,Te,$o,$e,Mt,Co,Jr,Ns="Create an instance from the content of <code>json_path</code>.",ko,Ce,yt,wo,Dr,As="Save the content of this instance in JSON format inside <code>json_path</code>.",$a,xt,Ca,re,Lt,Mo,zr,Fs=`A class that handles the <code>Trainer</code> control flow. This class is used by the <a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerCallback">TrainerCallback</a> to activate some
switches in the training loop.`,ka,Br,wa;return M=new Qr({props:{title:"Callbacks",local:"callbacks",headingTag:"h1"}}),Je=new Qr({props:{title:"可用的Callbacks",local:"transformers.integrations.CometCallback",headingTag:"h2"}}),ze=new C({props:{name:"class transformers.integrations.CometCallback",anchor:"transformers.integrations.CometCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L833"}}),Ue=new C({props:{name:"setup",anchor:"transformers.integrations.CometCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L844"}}),Ne=new C({props:{name:"class transformers.DefaultFlowCallback",anchor:"transformers.DefaultFlowCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L432"}}),Ae=new C({props:{name:"class transformers.PrinterCallback",anchor:"transformers.PrinterCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L532"}}),Fe=new C({props:{name:"class transformers.ProgressCallback",anchor:"transformers.ProgressCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L482"}}),Se=new C({props:{name:"class transformers.EarlyStoppingCallback",anchor:"transformers.EarlyStoppingCallback",parameters:[{name:"early_stopping_patience",val:": int = 1"},{name:"early_stopping_threshold",val:": Optional = 0.0"}],parametersDescription:[{anchor:"transformers.EarlyStoppingCallback.early_stopping_patience",description:`<strong>early_stopping_patience</strong> (<code>int</code>) &#x2014;
Use with <code>metric_for_best_model</code> to stop training when the specified metric worsens for
<code>early_stopping_patience</code> evaluation calls.`,name:"early_stopping_patience"},{anchor:"transformers.EarlyStoppingCallback.early_stopping_threshold(float,",description:`<strong>early_stopping_threshold(<code>float</code>,</strong> <em>optional</em>) &#x2014;
Use with TrainingArguments <code>metric_for_best_model</code> and <code>early_stopping_patience</code> to denote how much the
specified metric must improve to satisfy early stopping conditions. \``,name:"early_stopping_threshold(float,"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L543"}}),We=new C({props:{name:"class transformers.integrations.TensorBoardCallback",anchor:"transformers.integrations.TensorBoardCallback",parameters:[{name:"tb_writer",val:" = None"}],parametersDescription:[{anchor:"transformers.integrations.TensorBoardCallback.tb_writer",description:`<strong>tb_writer</strong> (<code>SummaryWriter</code>, <em>optional</em>) &#x2014;
The writer to use. Will instantiate one if not set.`,name:"tb_writer"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L579"}}),Be=new C({props:{name:"class transformers.integrations.WandbCallback",anchor:"transformers.integrations.WandbCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L665"}}),Qe=new C({props:{name:"setup",anchor:"transformers.integrations.WandbCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L690"}}),ne=new nl({props:{version:"5.0",$$slots:{default:[ol]},$$scope:{ctx:I}}}),Re=new C({props:{name:"class transformers.integrations.MLflowCallback",anchor:"transformers.integrations.MLflowCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L933"}}),qe=new C({props:{name:"setup",anchor:"transformers.integrations.MLflowCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L952"}}),Ge=new C({props:{name:"class transformers.integrations.AzureMLCallback",anchor:"transformers.integrations.AzureMLCallback",parameters:[{name:"azureml_run",val:" = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L910"}}),Ye=new C({props:{name:"class transformers.integrations.CodeCarbonCallback",anchor:"transformers.integrations.CodeCarbonCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1410"}}),Oe=new C({props:{name:"class transformers.integrations.NeptuneCallback",anchor:"transformers.integrations.NeptuneCallback",parameters:[{name:"api_token",val:": Optional = None"},{name:"project",val:": Optional = None"},{name:"name",val:": Optional = None"},{name:"base_namespace",val:": str = 'finetuning'"},{name:"run",val:" = None"},{name:"log_parameters",val:": bool = True"},{name:"log_checkpoints",val:": Optional = None"},{name:"**neptune_run_kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.NeptuneCallback.api_token",description:`<strong>api_token</strong> (<code>str</code>, <em>optional</em>) &#x2014; Neptune API token obtained upon registration.
You can leave this argument out if you have saved your token to the <code>NEPTUNE_API_TOKEN</code> environment
variable (strongly recommended). See full setup instructions in the
<a href="https://docs.neptune.ai/setup/installation" rel="nofollow">docs</a>.`,name:"api_token"},{anchor:"transformers.integrations.NeptuneCallback.project",description:`<strong>project</strong> (<code>str</code>, <em>optional</em>) &#x2014; Name of an existing Neptune project, in the form &#x201C;workspace-name/project-name&#x201D;.
You can find and copy the name in Neptune from the project settings -&gt; Properties. If None (default), the
value of the <code>NEPTUNE_PROJECT</code> environment variable is used.`,name:"project"},{anchor:"transformers.integrations.NeptuneCallback.name",description:"<strong>name</strong> (<code>str</code>, <em>optional</em>) &#x2014; Custom name for the run.",name:"name"},{anchor:"transformers.integrations.NeptuneCallback.base_namespace",description:`<strong>base_namespace</strong> (<code>str</code>, optional, defaults to &#x201C;finetuning&#x201D;) &#x2014; In the Neptune run, the root namespace
that will contain all of the metadata logged by the callback.`,name:"base_namespace"},{anchor:"transformers.integrations.NeptuneCallback.log_parameters",description:`<strong>log_parameters</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
If True, logs all Trainer arguments and model parameters provided by the Trainer.`,name:"log_parameters"},{anchor:"transformers.integrations.NeptuneCallback.log_checkpoints",description:`<strong>log_checkpoints</strong> (<code>str</code>, <em>optional</em>) &#x2014; If &#x201C;same&#x201D;, uploads checkpoints whenever they are saved by the Trainer.
If &#x201C;last&#x201D;, uploads only the most recently saved checkpoint. If &#x201C;best&#x201D;, uploads the best checkpoint (among
the ones saved by the Trainer). If <code>None</code>, does not upload checkpoints.`,name:"log_checkpoints"},{anchor:"transformers.integrations.NeptuneCallback.run",description:`<strong>run</strong> (<code>Run</code>, <em>optional</em>) &#x2014; Pass a Neptune run object if you want to continue logging to an existing run.
Read more about resuming runs in the <a href="https://docs.neptune.ai/logging/to_existing_object" rel="nofollow">docs</a>.`,name:"run"},{anchor:"transformers.integrations.NeptuneCallback.*neptune_run_kwargs",description:`*<strong>*neptune_run_kwargs</strong> (<em>optional</em>) &#x2014;
Additional keyword arguments to be passed directly to the
<a href="https://docs.neptune.ai/api/neptune#init_run" rel="nofollow"><code>neptune.init_run()</code></a> function when a new run is created.`,name:"*neptune_run_kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1139"}}),Xe=new C({props:{name:"class transformers.integrations.ClearMLCallback",anchor:"transformers.integrations.ClearMLCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1439"}}),Ze=new C({props:{name:"class transformers.integrations.DagsHubCallback",anchor:"transformers.integrations.DagsHubCallback",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1079"}}),Ke=new C({props:{name:"setup",anchor:"transformers.integrations.DagsHubCallback.setup",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1093"}}),et=new C({props:{name:"class transformers.integrations.FlyteCallback",anchor:"transformers.integrations.FlyteCallback",parameters:[{name:"save_log_history",val:": bool = True"},{name:"sync_checkpoints",val:": bool = True"}],parametersDescription:[{anchor:"transformers.integrations.FlyteCallback.save_log_history",description:`<strong>save_log_history</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to True, the training logs are saved as a Flyte Deck.`,name:"save_log_history"},{anchor:"transformers.integrations.FlyteCallback.sync_checkpoints",description:`<strong>sync_checkpoints</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
When set to True, checkpoints are synced with Flyte and can be used to resume training in the case of an
interruption.`,name:"sync_checkpoints"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1692"}}),oe=new Bs({props:{anchor:"transformers.integrations.FlyteCallback.example",$$slots:{default:[sl]},$$scope:{ctx:I}}}),tt=new C({props:{name:"class transformers.integrations.DVCLiveCallback",anchor:"transformers.integrations.DVCLiveCallback",parameters:[{name:"live",val:": Optional = None"},{name:"log_model",val:": Union = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.integrations.DVCLiveCallback.live",description:`<strong>live</strong> (<code>dvclive.Live</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
Optional Live instance. If None, a new instance will be created using **kwargs.`,name:"live"},{anchor:"transformers.integrations.DVCLiveCallback.log_model",description:`<strong>log_model</strong> (Union[Literal[&#x201C;all&#x201D;], bool], <em>optional</em>, defaults to <code>None</code>) &#x2014;
Whether to use <code>dvclive.Live.log_artifact()</code> to log checkpoints created by <code>Trainer</code>. If set to <code>True</code>,
the final checkpoint is logged at the end of training. If set to <code>&quot;all&quot;</code>, the entire
<code>TrainingArguments</code>&#x2019;s <code>output_dir</code> is logged at each checkpoint.`,name:"log_model"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1755"}}),rt=new C({props:{name:"setup",anchor:"transformers.integrations.DVCLiveCallback.setup",parameters:[{name:"args",val:""},{name:"state",val:""},{name:"model",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/integrations/integration_utils.py#L1796"}}),at=new Qr({props:{title:"TrainerCallback",local:"transformers.TrainerCallback",headingTag:"h2"}}),nt=new C({props:{name:"class transformers.TrainerCallback",anchor:"transformers.TrainerCallback",parameters:[],parametersDescription:[{anchor:"transformers.TrainerCallback.args",description:`<strong>args</strong> (<code>TrainingArguments</code>) &#x2014;
The training arguments used to instantiate the <code>Trainer</code>.`,name:"args"},{anchor:"transformers.TrainerCallback.state",description:`<strong>state</strong> (<a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerState">TrainerState</a>) &#x2014;
The current state of the <code>Trainer</code>.`,name:"state"},{anchor:"transformers.TrainerCallback.control",description:`<strong>control</strong> (<a href="/docs/transformers/main/zh/main_classes/callback#transformers.TrainerControl">TrainerControl</a>) &#x2014;
The object that is returned to the <code>Trainer</code> and can be used to make some decisions.`,name:"control"},{anchor:"transformers.TrainerCallback.model",description:`<strong>model</strong> (<a href="/docs/transformers/main/zh/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a> or <code>torch.nn.Module</code>) &#x2014;
The model being trained.`,name:"model"},{anchor:"transformers.TrainerCallback.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.TrainerCallback.optimizer",description:`<strong>optimizer</strong> (<code>torch.optim.Optimizer</code>) &#x2014;
The optimizer used for the training steps.`,name:"optimizer"},{anchor:"transformers.TrainerCallback.lr_scheduler",description:`<strong>lr_scheduler</strong> (<code>torch.optim.lr_scheduler.LambdaLR</code>) &#x2014;
The scheduler used for setting the learning rate.`,name:"lr_scheduler"},{anchor:"transformers.TrainerCallback.train_dataloader",description:`<strong>train_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"train_dataloader"},{anchor:"transformers.TrainerCallback.eval_dataloader",description:`<strong>eval_dataloader</strong> (<code>torch.utils.data.DataLoader</code>, <em>optional</em>) &#x2014;
The current dataloader used for training.`,name:"eval_dataloader"},{anchor:"transformers.TrainerCallback.metrics",description:`<strong>metrics</strong> (<code>Dict[str, float]</code>) &#x2014;
The metrics computed by the last evaluation phase.</p>
<p>Those are only accessible in the event <code>on_evaluate</code>.`,name:"metrics"},{anchor:"transformers.TrainerCallback.logs",description:`<strong>logs</strong>  (<code>Dict[str, float]</code>) &#x2014;
The values to log.</p>
<p>Those are only accessible in the event <code>on_log</code>.`,name:"logs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L175"}}),se=new Bs({props:{anchor:"transformers.TrainerCallback.example",$$slots:{default:[ll]},$$scope:{ctx:I}}}),ot=new C({props:{name:"on_epoch_begin",anchor:"transformers.TrainerCallback.on_epoch_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L244"}}),st=new C({props:{name:"on_epoch_end",anchor:"transformers.TrainerCallback.on_epoch_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L250"}}),lt=new C({props:{name:"on_evaluate",anchor:"transformers.TrainerCallback.on_evaluate",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L276"}}),it=new C({props:{name:"on_init_end",anchor:"transformers.TrainerCallback.on_init_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L226"}}),ct=new C({props:{name:"on_log",anchor:"transformers.TrainerCallback.on_log",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L294"}}),mt=new C({props:{name:"on_predict",anchor:"transformers.TrainerCallback.on_predict",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"metrics",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L282"}}),dt=new C({props:{name:"on_prediction_step",anchor:"transformers.TrainerCallback.on_prediction_step",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L300"}}),pt=new C({props:{name:"on_save",anchor:"transformers.TrainerCallback.on_save",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L288"}}),ft=new C({props:{name:"on_step_begin",anchor:"transformers.TrainerCallback.on_step_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L256"}}),gt=new C({props:{name:"on_step_end",anchor:"transformers.TrainerCallback.on_step_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L269"}}),ht=new C({props:{name:"on_substep_end",anchor:"transformers.TrainerCallback.on_substep_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L263"}}),ut=new C({props:{name:"on_train_begin",anchor:"transformers.TrainerCallback.on_train_begin",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L232"}}),bt=new C({props:{name:"on_train_end",anchor:"transformers.TrainerCallback.on_train_end",parameters:[{name:"args",val:": TrainingArguments"},{name:"state",val:": TrainerState"},{name:"control",val:": TrainerControl"},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L238"}}),Tt=new Ra({props:{code:"Y2xhc3MlMjBNeUNhbGxiYWNrKFRyYWluZXJDYWxsYmFjayklM0ElMEElMjAlMjAlMjAlMjAlMjJBJTIwY2FsbGJhY2slMjB0aGF0JTIwcHJpbnRzJTIwYSUyMG1lc3NhZ2UlMjBhdCUyMHRoZSUyMGJlZ2lubmluZyUyMG9mJTIwdHJhaW5pbmclMjIlMEElMEElMjAlMjAlMjAlMjBkZWYlMjBvbl90cmFpbl9iZWdpbihzZWxmJTJDJTIwYXJncyUyQyUyMHN0YXRlJTJDJTIwY29udHJvbCUyQyUyMCoqa3dhcmdzKSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHByaW50KCUyMlN0YXJ0aW5nJTIwdHJhaW5pbmclMjIpJTBBJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHRyYWluX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0RldmFsX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBjYWxsYmFja3MlM0QlNUJNeUNhbGxiYWNrJTVEJTJDJTIwJTIwJTIzJTIwV2UlMjBjYW4lMjBlaXRoZXIlMjBwYXNzJTIwdGhlJTIwY2FsbGJhY2slMjBjbGFzcyUyMHRoaXMlMjB3YXklMjBvciUyMGFuJTIwaW5zdGFuY2UlMjBvZiUyMGl0JTIwKE15Q2FsbGJhY2soKSklMEEp",highlighted:`<span class="hljs-keyword">class</span> <span class="hljs-title class_">MyCallback</span>(<span class="hljs-title class_ inherited__">TrainerCallback</span>):
    <span class="hljs-string">&quot;A callback that prints a message at the beginning of training&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_train_begin</span>(<span class="hljs-params">self, args, state, control, **kwargs</span>):
        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Starting training&quot;</span>)


trainer = Trainer(
    model,
    args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset,
    callbacks=[MyCallback],  <span class="hljs-comment"># We can either pass the callback class this way or an instance of it (MyCallback())</span>
)`,wrap:!1}}),Ct=new Ra({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIoLi4uKSUwQXRyYWluZXIuYWRkX2NhbGxiYWNrKE15Q2FsbGJhY2spJTBBJTIzJTIwQWx0ZXJuYXRpdmVseSUyQyUyMHdlJTIwY2FuJTIwcGFzcyUyMGFuJTIwaW5zdGFuY2UlMjBvZiUyMHRoZSUyMGNhbGxiYWNrJTIwY2xhc3MlMEF0cmFpbmVyLmFkZF9jYWxsYmFjayhNeUNhbGxiYWNrKCkp",highlighted:`trainer = Trainer(...)
trainer.add_callback(MyCallback)
<span class="hljs-comment"># Alternatively, we can pass an instance of the callback class</span>
trainer.add_callback(MyCallback())`,wrap:!1}}),kt=new Qr({props:{title:"TrainerState",local:"transformers.TrainerState",headingTag:"h2"}}),wt=new C({props:{name:"class transformers.TrainerState",anchor:"transformers.TrainerState",parameters:[{name:"epoch",val:": Optional = None"},{name:"global_step",val:": int = 0"},{name:"max_steps",val:": int = 0"},{name:"logging_steps",val:": int = 500"},{name:"eval_steps",val:": int = 500"},{name:"save_steps",val:": int = 500"},{name:"train_batch_size",val:": int = None"},{name:"num_train_epochs",val:": int = 0"},{name:"num_input_tokens_seen",val:": int = 0"},{name:"total_flos",val:": float = 0"},{name:"log_history",val:": List = None"},{name:"best_metric",val:": Optional = None"},{name:"best_model_checkpoint",val:": Optional = None"},{name:"is_local_process_zero",val:": bool = True"},{name:"is_world_process_zero",val:": bool = True"},{name:"is_hyper_param_search",val:": bool = False"},{name:"trial_name",val:": str = None"},{name:"trial_params",val:": Dict = None"}],parametersDescription:[{anchor:"transformers.TrainerState.epoch",description:`<strong>epoch</strong> (<code>float</code>, <em>optional</em>) &#x2014;
Only set during training, will represent the epoch the training is at (the decimal part being the
percentage of the current epoch completed).`,name:"epoch"},{anchor:"transformers.TrainerState.global_step",description:`<strong>global_step</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
During training, represents the number of update steps completed.`,name:"global_step"},{anchor:"transformers.TrainerState.max_steps",description:`<strong>max_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The number of update steps to do during the current training.`,name:"max_steps"},{anchor:"transformers.TrainerState.logging_steps",description:`<strong>logging_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 500) &#x2014;
Log every X updates steps`,name:"logging_steps"},{anchor:"transformers.TrainerState.eval_steps",description:`<strong>eval_steps</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Run an evaluation every X steps.`,name:"eval_steps"},{anchor:"transformers.TrainerState.save_steps",description:`<strong>save_steps</strong> (<code>int</code>, <em>optional</em>, defaults to 500) &#x2014;
Save checkpoint every X updates steps.`,name:"save_steps"},{anchor:"transformers.TrainerState.train_batch_size",description:`<strong>train_batch_size</strong> (<code>int</code>, <em>optional</em>) &#x2014;
The batch size for the training dataloader. Only needed when
<code>auto_find_batch_size</code> has been used.`,name:"train_batch_size"},{anchor:"transformers.TrainerState.num_input_tokens_seen",description:`<strong>num_input_tokens_seen</strong> (<code>int</code>, <em>optional</em>, defaults to 0) &#x2014;
The number of tokens seen during training (number of input tokens, not the number of prediction tokens).`,name:"num_input_tokens_seen"},{anchor:"transformers.TrainerState.total_flos",description:`<strong>total_flos</strong> (<code>float</code>, <em>optional</em>, defaults to 0) &#x2014;
The total number of floating operations done by the model since the beginning of training (stored as floats
to avoid overflow).`,name:"total_flos"},{anchor:"transformers.TrainerState.log_history",description:`<strong>log_history</strong> (<code>List[Dict[str, float]]</code>, <em>optional</em>) &#x2014;
The list of logs done since the beginning of training.`,name:"log_history"},{anchor:"transformers.TrainerState.best_metric",description:`<strong>best_metric</strong> (<code>float</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the best metric encountered so far.`,name:"best_metric"},{anchor:"transformers.TrainerState.best_model_checkpoint",description:`<strong>best_model_checkpoint</strong> (<code>str</code>, <em>optional</em>) &#x2014;
When tracking the best model, the value of the name of the checkpoint for the best model encountered so
far.`,name:"best_model_checkpoint"},{anchor:"transformers.TrainerState.is_local_process_zero",description:`<strong>is_local_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on
several machines) main process.`,name:"is_local_process_zero"},{anchor:"transformers.TrainerState.is_world_process_zero",description:`<strong>is_world_process_zero</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not this process is the global main process (when training in a distributed fashion on several
machines, this is only going to be <code>True</code> for one process).`,name:"is_world_process_zero"},{anchor:"transformers.TrainerState.is_hyper_param_search",description:`<strong>is_hyper_param_search</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether we are in the process of a hyper parameter search using Trainer.hyperparameter_search. This will
impact the way data will be logged in TensorBoard.`,name:"is_hyper_param_search"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L34"}}),Te=new qs({props:{$$slots:{default:[il]},$$scope:{ctx:I}}}),Mt=new C({props:{name:"load_from_json",anchor:"transformers.TrainerState.load_from_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L117"}}),yt=new C({props:{name:"save_to_json",anchor:"transformers.TrainerState.save_to_json",parameters:[{name:"json_path",val:": str"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L111"}}),xt=new Qr({props:{title:"TrainerControl",local:"transformers.TrainerControl",headingTag:"h2"}}),Lt=new C({props:{name:"class transformers.TrainerControl",anchor:"transformers.TrainerControl",parameters:[{name:"should_training_stop",val:": bool = False"},{name:"should_epoch_stop",val:": bool = False"},{name:"should_save",val:": bool = False"},{name:"should_evaluate",val:": bool = False"},{name:"should_log",val:": bool = False"}],parametersDescription:[{anchor:"transformers.TrainerControl.should_training_stop",description:`<strong>should_training_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the training should be interrupted.</p>
<p>If <code>True</code>, this variable will not be set back to <code>False</code>. The training will just stop.`,name:"should_training_stop"},{anchor:"transformers.TrainerControl.should_epoch_stop",description:`<strong>should_epoch_stop</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the current epoch should be interrupted.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next epoch.`,name:"should_epoch_stop"},{anchor:"transformers.TrainerControl.should_save",description:`<strong>should_save</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be saved at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_save"},{anchor:"transformers.TrainerControl.should_evaluate",description:`<strong>should_evaluate</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the model should be evaluated at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_evaluate"},{anchor:"transformers.TrainerControl.should_log",description:`<strong>should_log</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not the logs should be reported at this step.</p>
<p>If <code>True</code>, this variable will be set back to <code>False</code> at the beginning of the next step.`,name:"should_log"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/trainer_callback.py#L125"}}),{c(){m=o("meta"),x=r(),b=o("p"),k=r(),f(M.$$.fragment),v=r(),y=o("p"),y.textContent=L,E=r(),Ie=o("p"),Ie.innerHTML=yo,Vr=r(),Ee=o("p"),Ee.innerHTML=xo,Rr=r(),He=o("ul"),He.innerHTML=Lo,qr=r(),Pe=o("p"),Pe.innerHTML=Io,Gr=r(),je=o("p"),je.innerHTML=Eo,Yr=r(),f(Je.$$.fragment),Or=r(),De=o("p"),De.innerHTML=Ho,Xr=r(),F=o("div"),f(ze.$$.fragment),Ga=r(),Ht=o("p"),Ht.innerHTML=Po,Ya=r(),P=o("div"),f(Ue.$$.fragment),Oa=r(),Pt=o("p"),Pt.textContent=jo,Xa=r(),jt=o("p"),jt.textContent=Jo,Za=r(),Jt=o("ul"),Jt.innerHTML=Do,Ka=r(),Dt=o("p"),Dt.innerHTML=zo,Zr=r(),O=o("div"),f(Ne.$$.fragment),en=r(),zt=o("p"),zt.innerHTML=Uo,Kr=r(),X=o("div"),f(Ae.$$.fragment),tn=r(),Ut=o("p"),Ut.innerHTML=No,ea=r(),Z=o("div"),f(Fe.$$.fragment),rn=r(),Nt=o("p"),Nt.innerHTML=Ao,ta=r(),S=o("div"),f(Se.$$.fragment),an=r(),At=o("p"),At.innerHTML=Fo,nn=r(),Ft=o("p"),Ft.innerHTML=So,ra=r(),K=o("div"),f(We.$$.fragment),on=r(),St=o("p"),St.innerHTML=Wo,aa=r(),W=o("div"),f(Be.$$.fragment),sn=r(),Wt=o("p"),Wt.innerHTML=Bo,ln=r(),j=o("div"),f(Qe.$$.fragment),cn=r(),Bt=o("p"),Bt.innerHTML=Qo,mn=r(),Qt=o("p"),Qt.innerHTML=Vo,dn=r(),Vt=o("p"),Vt.textContent=Ro,pn=r(),B=o("ul"),Ve=o("li"),Rt=o("p"),Rt.innerHTML=qo,fn=r(),f(ne.$$.fragment),gn=r(),qt=o("li"),qt.innerHTML=Go,hn=r(),Gt=o("li"),Gt.innerHTML=Yo,un=r(),Yt=o("li"),Yt.innerHTML=Oo,na=r(),Q=o("div"),f(Re.$$.fragment),bn=r(),Ot=o("p"),Ot.innerHTML=Xo,vn=r(),U=o("div"),f(qe.$$.fragment),_n=r(),Xt=o("p"),Xt.textContent=Zo,Tn=r(),Zt=o("p"),Zt.textContent=Ko,$n=r(),Kt=o("ul"),Kt.innerHTML=es,oa=r(),ee=o("div"),f(Ge.$$.fragment),Cn=r(),er=o("p"),er.innerHTML=ts,sa=r(),te=o("div"),f(Ye.$$.fragment),kn=r(),tr=o("p"),tr.innerHTML=rs,la=r(),V=o("div"),f(Oe.$$.fragment),wn=r(),rr=o("p"),rr.innerHTML=as,Mn=r(),ar=o("p"),ar.innerHTML=ns,ia=r(),J=o("div"),f(Xe.$$.fragment),yn=r(),nr=o("p"),nr.innerHTML=os,xn=r(),or=o("p"),or.textContent=ss,Ln=r(),sr=o("ul"),sr.innerHTML=ls,ca=r(),R=o("div"),f(Ze.$$.fragment),In=r(),lr=o("p"),lr.innerHTML=is,En=r(),N=o("div"),f(Ke.$$.fragment),Hn=r(),ir=o("p"),ir.textContent=cs,Pn=r(),cr=o("p"),cr.textContent=ms,jn=r(),mr=o("ul"),mr.innerHTML=ds,ma=r(),q=o("div"),f(et.$$.fragment),Jn=r(),dr=o("p"),dr.innerHTML=ps,Dn=r(),f(oe.$$.fragment),da=r(),D=o("div"),f(tt.$$.fragment),zn=r(),pr=o("p"),pr.innerHTML=fs,Un=r(),fr=o("p"),fr.innerHTML=gs,Nn=r(),A=o("div"),f(rt.$$.fragment),An=r(),gr=o("p"),gr.innerHTML=hs,Fn=r(),hr=o("p"),hr.textContent=us,Sn=r(),ur=o("ul"),ur.innerHTML=bs,pa=r(),f(at.$$.fragment),fa=r(),T=o("div"),f(nt.$$.fragment),Wn=r(),br=o("p"),br.textContent=vs,Bn=r(),vr=o("p"),vr.innerHTML=_s,Qn=r(),_r=o("p"),_r.innerHTML=Ts,Vn=r(),f(se.$$.fragment),Rn=r(),le=o("div"),f(ot.$$.fragment),qn=r(),Tr=o("p"),Tr.textContent=$s,Gn=r(),ie=o("div"),f(st.$$.fragment),Yn=r(),$r=o("p"),$r.textContent=Cs,On=r(),ce=o("div"),f(lt.$$.fragment),Xn=r(),Cr=o("p"),Cr.textContent=ks,Zn=r(),me=o("div"),f(it.$$.fragment),Kn=r(),kr=o("p"),kr.innerHTML=ws,eo=r(),de=o("div"),f(ct.$$.fragment),to=r(),wr=o("p"),wr.textContent=Ms,ro=r(),pe=o("div"),f(mt.$$.fragment),ao=r(),Mr=o("p"),Mr.textContent=ys,no=r(),fe=o("div"),f(dt.$$.fragment),oo=r(),yr=o("p"),yr.textContent=xs,so=r(),ge=o("div"),f(pt.$$.fragment),lo=r(),xr=o("p"),xr.textContent=Ls,io=r(),he=o("div"),f(ft.$$.fragment),co=r(),Lr=o("p"),Lr.textContent=Is,mo=r(),ue=o("div"),f(gt.$$.fragment),po=r(),Ir=o("p"),Ir.textContent=Es,fo=r(),be=o("div"),f(ht.$$.fragment),go=r(),Er=o("p"),Er.textContent=Hs,ho=r(),ve=o("div"),f(ut.$$.fragment),uo=r(),Hr=o("p"),Hr.textContent=Ps,bo=r(),_e=o("div"),f(bt.$$.fragment),vo=r(),Pr=o("p"),Pr.textContent=js,ga=r(),vt=o("p"),vt.textContent=Js,ha=r(),_t=o("p"),_t.innerHTML=Ds,ua=r(),f(Tt.$$.fragment),ba=r(),$t=o("p"),$t.innerHTML=zs,va=r(),f(Ct.$$.fragment),_a=r(),f(kt.$$.fragment),Ta=r(),H=o("div"),f(wt.$$.fragment),_o=r(),jr=o("p"),jr.innerHTML=Us,To=r(),f(Te.$$.fragment),$o=r(),$e=o("div"),f(Mt.$$.fragment),Co=r(),Jr=o("p"),Jr.innerHTML=Ns,ko=r(),Ce=o("div"),f(yt.$$.fragment),wo=r(),Dr=o("p"),Dr.innerHTML=As,$a=r(),f(xt.$$.fragment),Ca=r(),re=o("div"),f(Lt.$$.fragment),Mo=r(),zr=o("p"),zr.innerHTML=Fs,ka=r(),Br=o("p"),this.h()},l(e){const l=el("svelte-u9bgzb",document.head);m=s(l,"META",{name:!0,content:!0}),l.forEach(n),x=a(e),b=s(e,"P",{}),_(b).forEach(n),k=a(e),g(M.$$.fragment,e),v=a(e),y=s(e,"P",{"data-svelte-h":!0}),c(y)!=="svelte-ixc7mw"&&(y.textContent=L),E=a(e),Ie=s(e,"P",{"data-svelte-h":!0}),c(Ie)!=="svelte-1o90q5b"&&(Ie.innerHTML=yo),Vr=a(e),Ee=s(e,"P",{"data-svelte-h":!0}),c(Ee)!=="svelte-w2h063"&&(Ee.innerHTML=xo),Rr=a(e),He=s(e,"UL",{"data-svelte-h":!0}),c(He)!=="svelte-3zyy36"&&(He.innerHTML=Lo),qr=a(e),Pe=s(e,"P",{"data-svelte-h":!0}),c(Pe)!=="svelte-cfm0j7"&&(Pe.innerHTML=Io),Gr=a(e),je=s(e,"P",{"data-svelte-h":!0}),c(je)!=="svelte-16d2yxx"&&(je.innerHTML=Eo),Yr=a(e),g(Je.$$.fragment,e),Or=a(e),De=s(e,"P",{"data-svelte-h":!0}),c(De)!=="svelte-1qkta70"&&(De.innerHTML=Ho),Xr=a(e),F=s(e,"DIV",{class:!0});var ae=_(F);g(ze.$$.fragment,ae),Ga=a(ae),Ht=s(ae,"P",{"data-svelte-h":!0}),c(Ht)!=="svelte-hx3bnd"&&(Ht.innerHTML=Po),Ya=a(ae),P=s(ae,"DIV",{class:!0});var z=_(P);g(Ue.$$.fragment,z),Oa=a(z),Pt=s(z,"P",{"data-svelte-h":!0}),c(Pt)!=="svelte-1bfkm9x"&&(Pt.textContent=jo),Xa=a(z),jt=s(z,"P",{"data-svelte-h":!0}),c(jt)!=="svelte-1fkshtn"&&(jt.textContent=Jo),Za=a(z),Jt=s(z,"UL",{"data-svelte-h":!0}),c(Jt)!=="svelte-12drq5x"&&(Jt.innerHTML=Do),Ka=a(z),Dt=s(z,"P",{"data-svelte-h":!0}),c(Dt)!=="svelte-1faq0a7"&&(Dt.innerHTML=zo),z.forEach(n),ae.forEach(n),Zr=a(e),O=s(e,"DIV",{class:!0});var It=_(O);g(Ne.$$.fragment,It),en=a(It),zt=s(It,"P",{"data-svelte-h":!0}),c(zt)!=="svelte-gp0ssq"&&(zt.innerHTML=Uo),It.forEach(n),Kr=a(e),X=s(e,"DIV",{class:!0});var Et=_(X);g(Ae.$$.fragment,Et),tn=a(Et),Ut=s(Et,"P",{"data-svelte-h":!0}),c(Ut)!=="svelte-uq878j"&&(Ut.innerHTML=No),Et.forEach(n),ea=a(e),Z=s(e,"DIV",{class:!0});var Ma=_(Z);g(Fe.$$.fragment,Ma),rn=a(Ma),Nt=s(Ma,"P",{"data-svelte-h":!0}),c(Nt)!=="svelte-1f4frtw"&&(Nt.innerHTML=Ao),Ma.forEach(n),ta=a(e),S=s(e,"DIV",{class:!0});var Ur=_(S);g(Se.$$.fragment,Ur),an=a(Ur),At=s(Ur,"P",{"data-svelte-h":!0}),c(At)!=="svelte-bqp5vv"&&(At.innerHTML=Fo),nn=a(Ur),Ft=s(Ur,"P",{"data-svelte-h":!0}),c(Ft)!=="svelte-13ureob"&&(Ft.innerHTML=So),Ur.forEach(n),ra=a(e),K=s(e,"DIV",{class:!0});var ya=_(K);g(We.$$.fragment,ya),on=a(ya),St=s(ya,"P",{"data-svelte-h":!0}),c(St)!=="svelte-wkcw14"&&(St.innerHTML=Wo),ya.forEach(n),aa=a(e),W=s(e,"DIV",{class:!0});var Nr=_(W);g(Be.$$.fragment,Nr),sn=a(Nr),Wt=s(Nr,"P",{"data-svelte-h":!0}),c(Wt)!=="svelte-vfsdjb"&&(Wt.innerHTML=Bo),ln=a(Nr),j=s(Nr,"DIV",{class:!0});var G=_(j);g(Qe.$$.fragment,G),cn=a(G),Bt=s(G,"P",{"data-svelte-h":!0}),c(Bt)!=="svelte-op70zs"&&(Bt.innerHTML=Qo),mn=a(G),Qt=s(G,"P",{"data-svelte-h":!0}),c(Qt)!=="svelte-m2rt7w"&&(Qt.innerHTML=Vo),dn=a(G),Vt=s(G,"P",{"data-svelte-h":!0}),c(Vt)!=="svelte-1fkshtn"&&(Vt.textContent=Ro),pn=a(G),B=s(G,"UL",{});var ke=_(B);Ve=s(ke,"LI",{});var xa=_(Ve);Rt=s(xa,"P",{"data-svelte-h":!0}),c(Rt)!=="svelte-py3r3s"&&(Rt.innerHTML=qo),fn=a(xa),g(ne.$$.fragment,xa),xa.forEach(n),gn=a(ke),qt=s(ke,"LI",{"data-svelte-h":!0}),c(qt)!=="svelte-dx3m30"&&(qt.innerHTML=Go),hn=a(ke),Gt=s(ke,"LI",{"data-svelte-h":!0}),c(Gt)!=="svelte-n1uh6c"&&(Gt.innerHTML=Yo),un=a(ke),Yt=s(ke,"LI",{"data-svelte-h":!0}),c(Yt)!=="svelte-ybo66z"&&(Yt.innerHTML=Oo),ke.forEach(n),G.forEach(n),Nr.forEach(n),na=a(e),Q=s(e,"DIV",{class:!0});var Ar=_(Q);g(Re.$$.fragment,Ar),bn=a(Ar),Ot=s(Ar,"P",{"data-svelte-h":!0}),c(Ot)!=="svelte-1g77vdj"&&(Ot.innerHTML=Xo),vn=a(Ar),U=s(Ar,"DIV",{class:!0});var we=_(U);g(qe.$$.fragment,we),_n=a(we),Xt=s(we,"P",{"data-svelte-h":!0}),c(Xt)!=="svelte-nmg16f"&&(Xt.textContent=Zo),Tn=a(we),Zt=s(we,"P",{"data-svelte-h":!0}),c(Zt)!=="svelte-1fkshtn"&&(Zt.textContent=Ko),$n=a(we),Kt=s(we,"UL",{"data-svelte-h":!0}),c(Kt)!=="svelte-la246o"&&(Kt.innerHTML=es),we.forEach(n),Ar.forEach(n),oa=a(e),ee=s(e,"DIV",{class:!0});var La=_(ee);g(Ge.$$.fragment,La),Cn=a(La),er=s(La,"P",{"data-svelte-h":!0}),c(er)!=="svelte-8m42bk"&&(er.innerHTML=ts),La.forEach(n),sa=a(e),te=s(e,"DIV",{class:!0});var Ia=_(te);g(Ye.$$.fragment,Ia),kn=a(Ia),tr=s(Ia,"P",{"data-svelte-h":!0}),c(tr)!=="svelte-xfsfl8"&&(tr.innerHTML=rs),Ia.forEach(n),la=a(e),V=s(e,"DIV",{class:!0});var Fr=_(V);g(Oe.$$.fragment,Fr),wn=a(Fr),rr=s(Fr,"P",{"data-svelte-h":!0}),c(rr)!=="svelte-4ag9j6"&&(rr.innerHTML=as),Mn=a(Fr),ar=s(Fr,"P",{"data-svelte-h":!0}),c(ar)!=="svelte-1mhjcx0"&&(ar.innerHTML=ns),Fr.forEach(n),ia=a(e),J=s(e,"DIV",{class:!0});var Me=_(J);g(Xe.$$.fragment,Me),yn=a(Me),nr=s(Me,"P",{"data-svelte-h":!0}),c(nr)!=="svelte-1pjr4jm"&&(nr.innerHTML=os),xn=a(Me),or=s(Me,"P",{"data-svelte-h":!0}),c(or)!=="svelte-1fkshtn"&&(or.textContent=ss),Ln=a(Me),sr=s(Me,"UL",{"data-svelte-h":!0}),c(sr)!=="svelte-15svthu"&&(sr.innerHTML=ls),Me.forEach(n),ca=a(e),R=s(e,"DIV",{class:!0});var Sr=_(R);g(Ze.$$.fragment,Sr),In=a(Sr),lr=s(Sr,"P",{"data-svelte-h":!0}),c(lr)!=="svelte-1guxmsr"&&(lr.innerHTML=is),En=a(Sr),N=s(Sr,"DIV",{class:!0});var ye=_(N);g(Ke.$$.fragment,ye),Hn=a(ye),ir=s(ye,"P",{"data-svelte-h":!0}),c(ir)!=="svelte-1wbmj3"&&(ir.textContent=cs),Pn=a(ye),cr=s(ye,"P",{"data-svelte-h":!0}),c(cr)!=="svelte-1fkshtn"&&(cr.textContent=ms),jn=a(ye),mr=s(ye,"UL",{"data-svelte-h":!0}),c(mr)!=="svelte-dna85o"&&(mr.innerHTML=ds),ye.forEach(n),Sr.forEach(n),ma=a(e),q=s(e,"DIV",{class:!0});var Wr=_(q);g(et.$$.fragment,Wr),Jn=a(Wr),dr=s(Wr,"P",{"data-svelte-h":!0}),c(dr)!=="svelte-1ee0i6s"&&(dr.innerHTML=ps),Dn=a(Wr),g(oe.$$.fragment,Wr),Wr.forEach(n),da=a(e),D=s(e,"DIV",{class:!0});var xe=_(D);g(tt.$$.fragment,xe),zn=a(xe),pr=s(xe,"P",{"data-svelte-h":!0}),c(pr)!=="svelte-1nahj0d"&&(pr.innerHTML=fs),Un=a(xe),fr=s(xe,"P",{"data-svelte-h":!0}),c(fr)!=="svelte-eu3kj7"&&(fr.innerHTML=gs),Nn=a(xe),A=s(xe,"DIV",{class:!0});var Le=_(A);g(rt.$$.fragment,Le),An=a(Le),gr=s(Le,"P",{"data-svelte-h":!0}),c(gr)!=="svelte-jjkenj"&&(gr.innerHTML=hs),Fn=a(Le),hr=s(Le,"P",{"data-svelte-h":!0}),c(hr)!=="svelte-1fkshtn"&&(hr.textContent=us),Sn=a(Le),ur=s(Le,"UL",{"data-svelte-h":!0}),c(ur)!=="svelte-crnavn"&&(ur.innerHTML=bs),Le.forEach(n),xe.forEach(n),pa=a(e),g(at.$$.fragment,e),fa=a(e),T=s(e,"DIV",{class:!0});var w=_(T);g(nt.$$.fragment,w),Wn=a(w),br=s(w,"P",{"data-svelte-h":!0}),c(br)!=="svelte-14xg00o"&&(br.textContent=vs),Bn=a(w),vr=s(w,"P",{"data-svelte-h":!0}),c(vr)!=="svelte-1xprdvt"&&(vr.innerHTML=_s),Qn=a(w),_r=s(w,"P",{"data-svelte-h":!0}),c(_r)!=="svelte-wuj1xo"&&(_r.innerHTML=Ts),Vn=a(w),g(se.$$.fragment,w),Rn=a(w),le=s(w,"DIV",{class:!0});var Ea=_(le);g(ot.$$.fragment,Ea),qn=a(Ea),Tr=s(Ea,"P",{"data-svelte-h":!0}),c(Tr)!=="svelte-106889p"&&(Tr.textContent=$s),Ea.forEach(n),Gn=a(w),ie=s(w,"DIV",{class:!0});var Ha=_(ie);g(st.$$.fragment,Ha),Yn=a(Ha),$r=s(Ha,"P",{"data-svelte-h":!0}),c($r)!=="svelte-oshcpj"&&($r.textContent=Cs),Ha.forEach(n),On=a(w),ce=s(w,"DIV",{class:!0});var Pa=_(ce);g(lt.$$.fragment,Pa),Xn=a(Pa),Cr=s(Pa,"P",{"data-svelte-h":!0}),c(Cr)!=="svelte-1o0xh73"&&(Cr.textContent=ks),Pa.forEach(n),Zn=a(w),me=s(w,"DIV",{class:!0});var ja=_(me);g(it.$$.fragment,ja),Kn=a(ja),kr=s(ja,"P",{"data-svelte-h":!0}),c(kr)!=="svelte-hzqkde"&&(kr.innerHTML=ws),ja.forEach(n),eo=a(w),de=s(w,"DIV",{class:!0});var Ja=_(de);g(ct.$$.fragment,Ja),to=a(Ja),wr=s(Ja,"P",{"data-svelte-h":!0}),c(wr)!=="svelte-10eiwg0"&&(wr.textContent=Ms),Ja.forEach(n),ro=a(w),pe=s(w,"DIV",{class:!0});var Da=_(pe);g(mt.$$.fragment,Da),ao=a(Da),Mr=s(Da,"P",{"data-svelte-h":!0}),c(Mr)!=="svelte-1df7x4n"&&(Mr.textContent=ys),Da.forEach(n),no=a(w),fe=s(w,"DIV",{class:!0});var za=_(fe);g(dt.$$.fragment,za),oo=a(za),yr=s(za,"P",{"data-svelte-h":!0}),c(yr)!=="svelte-18swygp"&&(yr.textContent=xs),za.forEach(n),so=a(w),ge=s(w,"DIV",{class:!0});var Ua=_(ge);g(pt.$$.fragment,Ua),lo=a(Ua),xr=s(Ua,"P",{"data-svelte-h":!0}),c(xr)!=="svelte-19xp05v"&&(xr.textContent=Ls),Ua.forEach(n),io=a(w),he=s(w,"DIV",{class:!0});var Na=_(he);g(ft.$$.fragment,Na),co=a(Na),Lr=s(Na,"P",{"data-svelte-h":!0}),c(Lr)!=="svelte-7af61p"&&(Lr.textContent=Is),Na.forEach(n),mo=a(w),ue=s(w,"DIV",{class:!0});var Aa=_(ue);g(gt.$$.fragment,Aa),po=a(Aa),Ir=s(Aa,"P",{"data-svelte-h":!0}),c(Ir)!=="svelte-8cdxjr"&&(Ir.textContent=Es),Aa.forEach(n),fo=a(w),be=s(w,"DIV",{class:!0});var Fa=_(be);g(ht.$$.fragment,Fa),go=a(Fa),Er=s(Fa,"P",{"data-svelte-h":!0}),c(Er)!=="svelte-sluvs0"&&(Er.textContent=Hs),Fa.forEach(n),ho=a(w),ve=s(w,"DIV",{class:!0});var Sa=_(ve);g(ut.$$.fragment,Sa),uo=a(Sa),Hr=s(Sa,"P",{"data-svelte-h":!0}),c(Hr)!=="svelte-6bvy6d"&&(Hr.textContent=Ps),Sa.forEach(n),bo=a(w),_e=s(w,"DIV",{class:!0});var Wa=_(_e);g(bt.$$.fragment,Wa),vo=a(Wa),Pr=s(Wa,"P",{"data-svelte-h":!0}),c(Pr)!=="svelte-zzwxsv"&&(Pr.textContent=js),Wa.forEach(n),w.forEach(n),ga=a(e),vt=s(e,"P",{"data-svelte-h":!0}),c(vt)!=="svelte-87dqmt"&&(vt.textContent=Js),ha=a(e),_t=s(e,"P",{"data-svelte-h":!0}),c(_t)!=="svelte-17720zy"&&(_t.innerHTML=Ds),ua=a(e),g(Tt.$$.fragment,e),ba=a(e),$t=s(e,"P",{"data-svelte-h":!0}),c($t)!=="svelte-u9gp17"&&($t.innerHTML=zs),va=a(e),g(Ct.$$.fragment,e),_a=a(e),g(kt.$$.fragment,e),Ta=a(e),H=s(e,"DIV",{class:!0});var Y=_(H);g(wt.$$.fragment,Y),_o=a(Y),jr=s(Y,"P",{"data-svelte-h":!0}),c(jr)!=="svelte-1ecfz3"&&(jr.innerHTML=Us),To=a(Y),g(Te.$$.fragment,Y),$o=a(Y),$e=s(Y,"DIV",{class:!0});var Ba=_($e);g(Mt.$$.fragment,Ba),Co=a(Ba),Jr=s(Ba,"P",{"data-svelte-h":!0}),c(Jr)!=="svelte-hbs6ga"&&(Jr.innerHTML=Ns),Ba.forEach(n),ko=a(Y),Ce=s(Y,"DIV",{class:!0});var Qa=_(Ce);g(yt.$$.fragment,Qa),wo=a(Qa),Dr=s(Qa,"P",{"data-svelte-h":!0}),c(Dr)!=="svelte-dkslae"&&(Dr.innerHTML=As),Qa.forEach(n),Y.forEach(n),$a=a(e),g(xt.$$.fragment,e),Ca=a(e),re=s(e,"DIV",{class:!0});var Va=_(re);g(Lt.$$.fragment,Va),Mo=a(Va),zr=s(Va,"P",{"data-svelte-h":!0}),c(zr)!=="svelte-1o6cnzn"&&(zr.innerHTML=Fs),Va.forEach(n),ka=a(e),Br=s(e,"P",{}),_(Br).forEach(n),this.h()},h(){$(m,"name","hf:doc:metadata"),$(m,"content",ml),$(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ee,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(V,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(le,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ie,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(me,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(de,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(pe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(he,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(Ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,l){t(document.head,m),i(e,x,l),i(e,b,l),i(e,k,l),h(M,e,l),i(e,v,l),i(e,y,l),i(e,E,l),i(e,Ie,l),i(e,Vr,l),i(e,Ee,l),i(e,Rr,l),i(e,He,l),i(e,qr,l),i(e,Pe,l),i(e,Gr,l),i(e,je,l),i(e,Yr,l),h(Je,e,l),i(e,Or,l),i(e,De,l),i(e,Xr,l),i(e,F,l),h(ze,F,null),t(F,Ga),t(F,Ht),t(F,Ya),t(F,P),h(Ue,P,null),t(P,Oa),t(P,Pt),t(P,Xa),t(P,jt),t(P,Za),t(P,Jt),t(P,Ka),t(P,Dt),i(e,Zr,l),i(e,O,l),h(Ne,O,null),t(O,en),t(O,zt),i(e,Kr,l),i(e,X,l),h(Ae,X,null),t(X,tn),t(X,Ut),i(e,ea,l),i(e,Z,l),h(Fe,Z,null),t(Z,rn),t(Z,Nt),i(e,ta,l),i(e,S,l),h(Se,S,null),t(S,an),t(S,At),t(S,nn),t(S,Ft),i(e,ra,l),i(e,K,l),h(We,K,null),t(K,on),t(K,St),i(e,aa,l),i(e,W,l),h(Be,W,null),t(W,sn),t(W,Wt),t(W,ln),t(W,j),h(Qe,j,null),t(j,cn),t(j,Bt),t(j,mn),t(j,Qt),t(j,dn),t(j,Vt),t(j,pn),t(j,B),t(B,Ve),t(Ve,Rt),t(Ve,fn),h(ne,Ve,null),t(B,gn),t(B,qt),t(B,hn),t(B,Gt),t(B,un),t(B,Yt),i(e,na,l),i(e,Q,l),h(Re,Q,null),t(Q,bn),t(Q,Ot),t(Q,vn),t(Q,U),h(qe,U,null),t(U,_n),t(U,Xt),t(U,Tn),t(U,Zt),t(U,$n),t(U,Kt),i(e,oa,l),i(e,ee,l),h(Ge,ee,null),t(ee,Cn),t(ee,er),i(e,sa,l),i(e,te,l),h(Ye,te,null),t(te,kn),t(te,tr),i(e,la,l),i(e,V,l),h(Oe,V,null),t(V,wn),t(V,rr),t(V,Mn),t(V,ar),i(e,ia,l),i(e,J,l),h(Xe,J,null),t(J,yn),t(J,nr),t(J,xn),t(J,or),t(J,Ln),t(J,sr),i(e,ca,l),i(e,R,l),h(Ze,R,null),t(R,In),t(R,lr),t(R,En),t(R,N),h(Ke,N,null),t(N,Hn),t(N,ir),t(N,Pn),t(N,cr),t(N,jn),t(N,mr),i(e,ma,l),i(e,q,l),h(et,q,null),t(q,Jn),t(q,dr),t(q,Dn),h(oe,q,null),i(e,da,l),i(e,D,l),h(tt,D,null),t(D,zn),t(D,pr),t(D,Un),t(D,fr),t(D,Nn),t(D,A),h(rt,A,null),t(A,An),t(A,gr),t(A,Fn),t(A,hr),t(A,Sn),t(A,ur),i(e,pa,l),h(at,e,l),i(e,fa,l),i(e,T,l),h(nt,T,null),t(T,Wn),t(T,br),t(T,Bn),t(T,vr),t(T,Qn),t(T,_r),t(T,Vn),h(se,T,null),t(T,Rn),t(T,le),h(ot,le,null),t(le,qn),t(le,Tr),t(T,Gn),t(T,ie),h(st,ie,null),t(ie,Yn),t(ie,$r),t(T,On),t(T,ce),h(lt,ce,null),t(ce,Xn),t(ce,Cr),t(T,Zn),t(T,me),h(it,me,null),t(me,Kn),t(me,kr),t(T,eo),t(T,de),h(ct,de,null),t(de,to),t(de,wr),t(T,ro),t(T,pe),h(mt,pe,null),t(pe,ao),t(pe,Mr),t(T,no),t(T,fe),h(dt,fe,null),t(fe,oo),t(fe,yr),t(T,so),t(T,ge),h(pt,ge,null),t(ge,lo),t(ge,xr),t(T,io),t(T,he),h(ft,he,null),t(he,co),t(he,Lr),t(T,mo),t(T,ue),h(gt,ue,null),t(ue,po),t(ue,Ir),t(T,fo),t(T,be),h(ht,be,null),t(be,go),t(be,Er),t(T,ho),t(T,ve),h(ut,ve,null),t(ve,uo),t(ve,Hr),t(T,bo),t(T,_e),h(bt,_e,null),t(_e,vo),t(_e,Pr),i(e,ga,l),i(e,vt,l),i(e,ha,l),i(e,_t,l),i(e,ua,l),h(Tt,e,l),i(e,ba,l),i(e,$t,l),i(e,va,l),h(Ct,e,l),i(e,_a,l),h(kt,e,l),i(e,Ta,l),i(e,H,l),h(wt,H,null),t(H,_o),t(H,jr),t(H,To),h(Te,H,null),t(H,$o),t(H,$e),h(Mt,$e,null),t($e,Co),t($e,Jr),t(H,ko),t(H,Ce),h(yt,Ce,null),t(Ce,wo),t(Ce,Dr),i(e,$a,l),h(xt,e,l),i(e,Ca,l),i(e,re,l),h(Lt,re,null),t(re,Mo),t(re,zr),i(e,ka,l),i(e,Br,l),wa=!0},p(e,[l]){const ae={};l&2&&(ae.$$scope={dirty:l,ctx:e}),ne.$set(ae);const z={};l&2&&(z.$$scope={dirty:l,ctx:e}),oe.$set(z);const It={};l&2&&(It.$$scope={dirty:l,ctx:e}),se.$set(It);const Et={};l&2&&(Et.$$scope={dirty:l,ctx:e}),Te.$set(Et)},i(e){wa||(d(M.$$.fragment,e),d(Je.$$.fragment,e),d(ze.$$.fragment,e),d(Ue.$$.fragment,e),d(Ne.$$.fragment,e),d(Ae.$$.fragment,e),d(Fe.$$.fragment,e),d(Se.$$.fragment,e),d(We.$$.fragment,e),d(Be.$$.fragment,e),d(Qe.$$.fragment,e),d(ne.$$.fragment,e),d(Re.$$.fragment,e),d(qe.$$.fragment,e),d(Ge.$$.fragment,e),d(Ye.$$.fragment,e),d(Oe.$$.fragment,e),d(Xe.$$.fragment,e),d(Ze.$$.fragment,e),d(Ke.$$.fragment,e),d(et.$$.fragment,e),d(oe.$$.fragment,e),d(tt.$$.fragment,e),d(rt.$$.fragment,e),d(at.$$.fragment,e),d(nt.$$.fragment,e),d(se.$$.fragment,e),d(ot.$$.fragment,e),d(st.$$.fragment,e),d(lt.$$.fragment,e),d(it.$$.fragment,e),d(ct.$$.fragment,e),d(mt.$$.fragment,e),d(dt.$$.fragment,e),d(pt.$$.fragment,e),d(ft.$$.fragment,e),d(gt.$$.fragment,e),d(ht.$$.fragment,e),d(ut.$$.fragment,e),d(bt.$$.fragment,e),d(Tt.$$.fragment,e),d(Ct.$$.fragment,e),d(kt.$$.fragment,e),d(wt.$$.fragment,e),d(Te.$$.fragment,e),d(Mt.$$.fragment,e),d(yt.$$.fragment,e),d(xt.$$.fragment,e),d(Lt.$$.fragment,e),wa=!0)},o(e){p(M.$$.fragment,e),p(Je.$$.fragment,e),p(ze.$$.fragment,e),p(Ue.$$.fragment,e),p(Ne.$$.fragment,e),p(Ae.$$.fragment,e),p(Fe.$$.fragment,e),p(Se.$$.fragment,e),p(We.$$.fragment,e),p(Be.$$.fragment,e),p(Qe.$$.fragment,e),p(ne.$$.fragment,e),p(Re.$$.fragment,e),p(qe.$$.fragment,e),p(Ge.$$.fragment,e),p(Ye.$$.fragment,e),p(Oe.$$.fragment,e),p(Xe.$$.fragment,e),p(Ze.$$.fragment,e),p(Ke.$$.fragment,e),p(et.$$.fragment,e),p(oe.$$.fragment,e),p(tt.$$.fragment,e),p(rt.$$.fragment,e),p(at.$$.fragment,e),p(nt.$$.fragment,e),p(se.$$.fragment,e),p(ot.$$.fragment,e),p(st.$$.fragment,e),p(lt.$$.fragment,e),p(it.$$.fragment,e),p(ct.$$.fragment,e),p(mt.$$.fragment,e),p(dt.$$.fragment,e),p(pt.$$.fragment,e),p(ft.$$.fragment,e),p(gt.$$.fragment,e),p(ht.$$.fragment,e),p(ut.$$.fragment,e),p(bt.$$.fragment,e),p(Tt.$$.fragment,e),p(Ct.$$.fragment,e),p(kt.$$.fragment,e),p(wt.$$.fragment,e),p(Te.$$.fragment,e),p(Mt.$$.fragment,e),p(yt.$$.fragment,e),p(xt.$$.fragment,e),p(Lt.$$.fragment,e),wa=!1},d(e){e&&(n(x),n(b),n(k),n(v),n(y),n(E),n(Ie),n(Vr),n(Ee),n(Rr),n(He),n(qr),n(Pe),n(Gr),n(je),n(Yr),n(Or),n(De),n(Xr),n(F),n(Zr),n(O),n(Kr),n(X),n(ea),n(Z),n(ta),n(S),n(ra),n(K),n(aa),n(W),n(na),n(Q),n(oa),n(ee),n(sa),n(te),n(la),n(V),n(ia),n(J),n(ca),n(R),n(ma),n(q),n(da),n(D),n(pa),n(fa),n(T),n(ga),n(vt),n(ha),n(_t),n(ua),n(ba),n($t),n(va),n(_a),n(Ta),n(H),n($a),n(Ca),n(re),n(ka),n(Br)),n(m),u(M,e),u(Je,e),u(ze),u(Ue),u(Ne),u(Ae),u(Fe),u(Se),u(We),u(Be),u(Qe),u(ne),u(Re),u(qe),u(Ge),u(Ye),u(Oe),u(Xe),u(Ze),u(Ke),u(et),u(oe),u(tt),u(rt),u(at,e),u(nt),u(se),u(ot),u(st),u(lt),u(it),u(ct),u(mt),u(dt),u(pt),u(ft),u(gt),u(ht),u(ut),u(bt),u(Tt,e),u(Ct,e),u(kt,e),u(wt),u(Te),u(Mt),u(yt),u(xt,e),u(Lt)}}}const ml='{"title":"Callbacks","local":"callbacks","sections":[{"title":"可用的Callbacks","local":"transformers.integrations.CometCallback","sections":[],"depth":2},{"title":"TrainerCallback","local":"transformers.TrainerCallback","sections":[],"depth":2},{"title":"TrainerState","local":"transformers.TrainerState","sections":[],"depth":2},{"title":"TrainerControl","local":"transformers.TrainerControl","sections":[],"depth":2}],"depth":1}';function dl(I){return Zs(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _l extends Vs{constructor(m){super(),Rs(this,m,dl,cl,Qs,{})}}export{_l as component};
