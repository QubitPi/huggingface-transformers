import{s as Jl,o as Tl,n as We}from"../chunks/scheduler.9991993c.js";import{S as yl,i as hl,g as o,s,r as w,A as dl,h as f,f as l,c as M,j as ul,u as J,x as c,k as cl,y as Ul,a,v as T,d as y,t as h,w as d}from"../chunks/index.7fc9a5e7.js";import{C as _}from"../chunks/CodeBlock.e11cba92.js";import{F as wl,M as Ze}from"../chunks/Markdown.87f31c7e.js";import{H as g}from"../chunks/Heading.e3de321f.js";function _l(j){let n,u='示例脚本从🤗 <a href="https://huggingface.co/docs/datasets/" rel="nofollow">Datasets</a>库下载并预处理数据集。然后，脚本通过<a href="https://huggingface.co/docs/transformers/main_classes/trainer" rel="nofollow">Trainer</a>使用支持摘要任务的架构对数据集进行微调。以下示例展示了如何在<a href="https://huggingface.co/datasets/cnn_dailymail" rel="nofollow">CNN/DailyMail</a>数据集上微调<a href="https://huggingface.co/google-t5/t5-small" rel="nofollow">T5-small</a>。由于T5模型的训练方式，它需要一个额外的<code>source_prefix</code>参数。这个提示让T5知道这是一个摘要任务。',i,m,p;return m=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),{c(){n=o("p"),n.innerHTML=u,i=s(),w(m.$$.fragment)},l(r){n=f(r,"P",{"data-svelte-h":!0}),c(n)!=="svelte-1nzsvd0"&&(n.innerHTML=u),i=M(r),J(m.$$.fragment,r)},m(r,U){a(r,n,U),a(r,i,U),T(m,r,U),p=!0},p:We,i(r){p||(y(m.$$.fragment,r),p=!0)},o(r){h(m.$$.fragment,r),p=!1},d(r){r&&(l(n),l(i)),d(m,r)}}}function jl(j){let n,u;return n=new Ze({props:{$$slots:{default:[_l]},$$scope:{ctx:j}}}),{c(){w(n.$$.fragment)},l(i){J(n.$$.fragment,i)},m(i,m){T(n,i,m),u=!0},p(i,m){const p={};m&2&&(p.$$scope={dirty:m,ctx:i}),n.$set(p)},i(i){u||(y(n.$$.fragment,i),u=!0)},o(i){h(n.$$.fragment,i),u=!1},d(i){d(n,i)}}}function gl(j){let n,u='示例脚本从  🤗 <a href="https://huggingface.co/docs/datasets/" rel="nofollow">Datasets</a> 库下载并预处理数据集。然后，脚本使用 Keras 在支持摘要的架构上微调数据集。以下示例展示了如何在 <a href="https://huggingface.co/datasets/cnn_dailymail" rel="nofollow">CNN/DailyMail</a> 数据集上微调 <a href="https://huggingface.co/google-t5/t5-small" rel="nofollow">T5-small</a>。T5 模型由于训练方式需要额外的 <code>source_prefix</code> 参数。这个提示让 T5 知道这是一个摘要任务。',i,m,p;return m=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZ0ZW5zb3JmbG93JTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9uYW1lJTIwY25uX2RhaWx5bWFpbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9jb25maWclMjAlMjIzLjAuMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlMjA4JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUyMDE2JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMyUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWw=",highlighted:`python examples/tensorflow/summarization/run_summarization.py  \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,wrap:!1}}),{c(){n=o("p"),n.innerHTML=u,i=s(),w(m.$$.fragment)},l(r){n=f(r,"P",{"data-svelte-h":!0}),c(n)!=="svelte-l86hpd"&&(n.innerHTML=u),i=M(r),J(m.$$.fragment,r)},m(r,U){a(r,n,U),a(r,i,U),T(m,r,U),p=!0},p:We,i(r){p||(y(m.$$.fragment,r),p=!0)},o(r){h(m.$$.fragment,r),p=!1},d(r){r&&(l(n),l(i)),d(m,r)}}}function $l(j){let n,u;return n=new Ze({props:{$$slots:{default:[gl]},$$scope:{ctx:j}}}),{c(){w(n.$$.fragment)},l(i){J(n.$$.fragment,i)},m(i,m){T(n,i,m),u=!0},p(i,m){const p={};m&2&&(p.$$scope={dirty:m,ctx:i}),n.$set(p)},i(i){u||(y(n.$$.fragment,i),u=!0)},o(i){h(n.$$.fragment,i),u=!1},d(i){d(n,i)}}}function bl(j){let n,u='张量处理单元（TPUs）是专门设计用于加速性能的。PyTorch使用<a href="https://www.tensorflow.org/xla" rel="nofollow">XLA</a>深度学习编译器支持TPU（更多细节请参见<a href="https://github.com/pytorch/xla/blob/master/README.md" rel="nofollow">这里</a>）。要使用TPU，请启动<code>xla_spawn.py</code>脚本并使用<code>num_cores</code>参数设置要使用的TPU核心数量。',i,m,p;return m=new _({props:{code:"cHl0aG9uJTIweGxhX3NwYXduLnB5JTIwLS1udW1fY29yZXMlMjA4JTIwJTVDJTBBJTIwJTIwJTIwJTIwc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python xla_spawn.py --num_cores 8 \\
    summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),{c(){n=o("p"),n.innerHTML=u,i=s(),w(m.$$.fragment)},l(r){n=f(r,"P",{"data-svelte-h":!0}),c(n)!=="svelte-1a7iv41"&&(n.innerHTML=u),i=M(r),J(m.$$.fragment,r)},m(r,U){a(r,n,U),a(r,i,U),T(m,r,U),p=!0},p:We,i(r){p||(y(m.$$.fragment,r),p=!0)},o(r){h(m.$$.fragment,r),p=!1},d(r){r&&(l(n),l(i)),d(m,r)}}}function Cl(j){let n,u;return n=new Ze({props:{$$slots:{default:[bl]},$$scope:{ctx:j}}}),{c(){w(n.$$.fragment)},l(i){J(n.$$.fragment,i)},m(i,m){T(n,i,m),u=!0},p(i,m){const p={};m&2&&(p.$$scope={dirty:m,ctx:i}),n.$set(p)},i(i){u||(y(n.$$.fragment,i),u=!0)},o(i){h(n.$$.fragment,i),u=!1},d(i){d(n,i)}}}function Xl(j){let n,u='张量处理单元（TPUs）是专门设计用于加速性能的。TensorFlow脚本使用<a href="https://www.tensorflow.org/guide/distributed_training#tpustrategy" rel="nofollow"><code>TPUStrategy</code></a>在TPU上进行训练。要使用TPU，请将TPU资源的名称传递给<code>tpu</code>参数。',i,m,p;return m=new _({props:{code:"cHl0aG9uJTIwcnVuX3N1bW1hcml6YXRpb24ucHklMjAlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRwdSUyMG5hbWVfb2ZfdHB1X3Jlc291cmNlJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9uYW1lJTIwY25uX2RhaWx5bWFpbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9jb25maWclMjAlMjIzLjAuMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlMjA4JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUyMDE2JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1udW1fdHJhaW5fZXBvY2hzJTIwMyUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWw=",highlighted:`python run_summarization.py  \\
    --tpu name_of_tpu_resource \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --output_dir /tmp/tst-summarization  \\
    --per_device_train_batch_size 8 \\
    --per_device_eval_batch_size 16 \\
    --num_train_epochs 3 \\
    --do_train \\
    --do_eval`,wrap:!1}}),{c(){n=o("p"),n.innerHTML=u,i=s(),w(m.$$.fragment)},l(r){n=f(r,"P",{"data-svelte-h":!0}),c(n)!=="svelte-1aunkch"&&(n.innerHTML=u),i=M(r),J(m.$$.fragment,r)},m(r,U){a(r,n,U),a(r,i,U),T(m,r,U),p=!0},p:We,i(r){p||(y(m.$$.fragment,r),p=!0)},o(r){h(m.$$.fragment,r),p=!1},d(r){r&&(l(n),l(i)),d(m,r)}}}function Il(j){let n,u;return n=new Ze({props:{$$slots:{default:[Xl]},$$scope:{ctx:j}}}),{c(){w(n.$$.fragment)},l(i){J(n.$$.fragment,i)},m(i,m){T(n,i,m),u=!0},p(i,m){const p={};m&2&&(p.$$scope={dirty:m,ctx:i}),n.$set(p)},i(i){u||(y(n.$$.fragment,i),u=!0)},o(i){h(n.$$.fragment,i),u=!1},d(i){d(n,i)}}}function Al(j){let n,u,i,m,p,r,U,Ge='除了 🤗 Transformers <a href="./noteboks/README">notebooks</a>，还有示例脚本演示了如何使用<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch" rel="nofollow">PyTorch</a>、<a href="https://github.com/huggingface/transformers/tree/main/examples/tensorflow" rel="nofollow">TensorFlow</a>或<a href="https://github.com/huggingface/transformers/tree/main/examples/flax" rel="nofollow">JAX/Flax</a>训练模型以解决特定任务。',Xt,C,Re='您还可以在这些示例中找到我们在<a href="https://github.com/huggingface/transformers/tree/main/examples/research_projects" rel="nofollow">研究项目</a>和<a href="https://github.com/huggingface/transformers/tree/main/examples/legacy" rel="nofollow">遗留示例</a>中使用过的脚本，这些脚本主要是由社区贡献的。这些脚本已不再被积极维护，需要使用特定版本的🤗 Transformers， 可能与库的最新版本不兼容。',It,X,Le="示例脚本可能无法在初始配置下直接解决每个问题，您可能需要根据要解决的问题调整脚本。为了帮助您，大多数脚本都完全暴露了数据预处理的方式，允许您根据需要对其进行编辑。",At,I,xe='如果您想在示例脚本中实现任何功能，请在<a href="https://discuss.huggingface.co/" rel="nofollow">论坛</a>或<a href="https://github.com/huggingface/transformers/issues" rel="nofollow">issue</a>上讨论，然后再提交Pull Request。虽然我们欢迎修复错误，但不太可能合并添加更多功能的Pull Request，因为这会降低可读性。',vt,A,Ve='本指南将向您展示如何在<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/summarization" rel="nofollow">PyTorch</a>和<a href="https://github.com/huggingface/transformers/tree/main/examples/tensorflow/summarization" rel="nofollow">TensorFlow</a>中运行示例摘要训练脚本。除非另有说明，否则所有示例都可以在两个框架中工作。',Wt,v,Zt,W,Ne="要成功运行示例脚本的最新版本，您必须在新虚拟环境中<strong>从源代码安装 🤗 Transformers</strong>：",Gt,Z,Rt,G,Be="对于旧版本的示例脚本，请点击下面的切换按钮：",Lt,R,Fe='<summary>老版本🤗 Transformers示例</summary> <ul><li><a href="https://github.com/huggingface/transformers/tree/v4.5.1/examples">v4.5.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.4.2/examples">v4.4.2</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.3.3/examples">v4.3.3</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.2.2/examples">v4.2.2</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.1.1/examples">v4.1.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v4.0.1/examples">v4.0.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.5.1/examples">v3.5.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.4.0/examples">v3.4.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.3.1/examples">v3.3.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.2.0/examples">v3.2.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.1.0/examples">v3.1.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v3.0.2/examples">v3.0.2</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.11.0/examples">v2.11.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.10.0/examples">v2.10.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.9.1/examples">v2.9.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.8.0/examples">v2.8.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.7.0/examples">v2.7.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.6.0/examples">v2.6.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.5.1/examples">v2.5.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.4.0/examples">v2.4.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.3.0/examples">v2.3.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.2.0/examples">v2.2.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.1.0/examples">v2.1.1</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v2.0.0/examples">v2.0.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v1.2.0/examples">v1.2.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v1.1.0/examples">v1.1.0</a></li> <li><a href="https://github.com/huggingface/transformers/tree/v1.0.0/examples">v1.0.0</a></li></ul>',xt,L,ze="然后切换您clone的 🤗 Transformers 仓到特定的版本，例如v3.5.1：",Vt,x,Nt,V,Ye="在安装了正确的库版本后，进入您选择的版本的<code>example</code>文件夹并安装例子要求的环境：",Bt,N,Ft,B,zt,$,Yt,F,St,z,Se='<a href="https://huggingface.co/docs/transformers/main_classes/trainer" rel="nofollow">Trainer</a> 支持分布式训练和混合精度，这意味着你也可以在脚本中使用它。要启用这两个功能，可以做如下设置：',Ht,Y,He="<li>添加 <code>fp16</code> 参数以启用混合精度。</li> <li>使用 <code>nproc_per_node</code> 参数设置使用的GPU数量。</li>",Et,S,kt,H,Ee='TensorFlow脚本使用<a href="https://www.tensorflow.org/guide/distributed_training#mirroredstrategy" rel="nofollow"><code>MirroredStrategy</code></a>进行分布式训练，您无需在训练脚本中添加任何其他参数。如果可用，TensorFlow脚本将默认使用多个GPU。',Qt,E,Dt,b,Pt,k,qt,Q,ke='🤗 <a href="https://huggingface.co/docs/accelerate" rel="nofollow">Accelerate</a> 是一个仅支持 PyTorch 的库，它提供了一种统一的方法来在不同类型的设置（仅 CPU、多个 GPU、多个TPU）上训练模型，同时保持对 PyTorch 训练循环的完全可见性。如果你还没有安装 🤗 Accelerate，请确保你已经安装了它：',Ot,D,Qe="<p>注意：由于 Accelerate 正在快速发展，因此必须安装 git 版本的 accelerate 来运行脚本。</p>",Kt,P,te,q,De="你需要使用<code>run_summarization_no_trainer.py</code>脚本，而不是<code>run_summarization.py</code>脚本。🤗 Accelerate支持的脚本需要在文件夹中有一个<code>task_no_trainer.py</code>文件。首先运行以下命令以创建并保存配置文件：",ee,O,le,K,Pe="检测您的设置以确保配置正确：",ae,tt,ne,et,qe="现在您可以开始训练模型了：",ie,lt,re,at,se,nt,Oe="摘要脚本支持自定义数据集，只要它们是CSV或JSON Line文件。当你使用自己的数据集时，需要指定一些额外的参数：",Me,it,Ke="<li><code>train_file</code> 和 <code>validation_file</code> 分别指定您的训练和验证文件的路径。</li> <li><code>text_column</code> 是输入要进行摘要的文本。</li> <li><code>summary_column</code> 是目标输出的文本。</li>",me,rt,tl="使用自定义数据集的摘要脚本看起来是这样的：",pe,st,oe,Mt,fe,mt,el="通常，在提交整个数据集之前，最好先在较少的数据集示例上运行脚本，以确保一切按预期工作,因为完整数据集的处理可能需要花费几个小时的时间。使用以下参数将数据集截断为最大样本数：",ue,pt,ll="<li><code>max_train_samples</code></li> <li><code>max_eval_samples</code></li> <li><code>max_predict_samples</code></li>",ce,ot,we,ft,al="并非所有示例脚本都支持<code>max_predict_samples</code>参数。如果您不确定您的脚本是否支持此参数，请添加<code>-h</code>参数进行检查：",Je,ut,Te,ct,ye,wt,nl="另一个有用的选项是从之前的checkpoint恢复训练。这将确保在训练中断时，您可以从之前停止的地方继续进行，而无需重新开始。有两种方法可以从checkpoint恢复训练。",he,Jt,il="第一种方法使用<code>output_dir previous_output_dir</code>参数从存储在<code>output_dir</code>中的最新的checkpoint恢复训练。在这种情况下，您应该删除<code>overwrite_output_dir</code>：",de,Tt,Ue,yt,rl="第二种方法使用<code>resume_from_checkpoint path_to_specific_checkpoint</code>参数从特定的checkpoint文件夹恢复训练。",_e,ht,je,dt,ge,Ut,sl='所有脚本都可以将您的最终模型上传到<a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>。在开始之前，请确保您已登录Hugging Face：',$e,_t,be,jt,Ml="然后，在脚本中添加<code>push_to_hub</code>参数。这个参数会创建一个带有您Hugging Face用户名和<code>output_dir</code>中指定的文件夹名称的仓库。",Ce,gt,ml="为了给您的仓库指定一个特定的名称，使用<code>push_to_hub_model_id</code>参数来添加它。该仓库将自动列出在您的命名空间下。",Xe,$t,pl="以下示例展示了如何上传具有特定仓库名称的模型：",Ie,bt,Ae,Ct,ve;return p=new g({props:{title:"使用脚本进行训练",local:"使用脚本进行训练",headingTag:"h1"}}),v=new g({props:{title:"设置",local:"设置",headingTag:"h2"}}),Z=new _({props:{code:"Z2l0JTIwY2xvbmUlMjBodHRwcyUzQSUyRiUyRmdpdGh1Yi5jb20lMkZodWdnaW5nZmFjZSUyRnRyYW5zZm9ybWVycyUwQWNkJTIwdHJhbnNmb3JtZXJzJTBBcGlwJTIwaW5zdGFsbCUyMC4=",highlighted:`git <span class="hljs-built_in">clone</span> https://github.com/huggingface/transformers
<span class="hljs-built_in">cd</span> transformers
pip install .`,wrap:!1}}),x=new _({props:{code:"Z2l0JTIwY2hlY2tvdXQlMjB0YWdzJTJGdjMuNS4x",highlighted:"git checkout tags/v3.5.1",wrap:!1}}),N=new _({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1yJTIwcmVxdWlyZW1lbnRzLnR4dA==",highlighted:"pip install -r requirements.txt",wrap:!1}}),B=new g({props:{title:"运行脚本",local:"运行脚本",headingTag:"h2"}}),$=new wl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[$l],pytorch:[jl]},$$scope:{ctx:j}}}),F=new g({props:{title:"分布式训练和混合精度",local:"分布式训练和混合精度",headingTag:"h2"}}),S=new _({props:{code:"dG9yY2hydW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLW5wcm9jX3Blcl9ub2RlJTIwOCUyMHB5dG9yY2glMkZzdW1tYXJpemF0aW9uJTJGcnVuX3N1bW1hcml6YXRpb24ucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLWZwMTYlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW1vZGVsX25hbWVfb3JfcGF0aCUyMGdvb2dsZS10NSUyRnQ1LXNtYWxsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kb190cmFpbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fZXZhbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9uYW1lJTIwY25uX2RhaWx5bWFpbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZGF0YXNldF9jb25maWclMjAlMjIzLjAuMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tc291cmNlX3ByZWZpeCUyMCUyMnN1bW1hcml6ZSUzQSUyMCUyMiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3V0cHV0X2RpciUyMCUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9uJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW92ZXJ3cml0ZV9vdXRwdXRfZGlyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wcmVkaWN0X3dpdGhfZ2VuZXJhdGU=",highlighted:`torchrun \\
    --nproc_per_node 8 pytorch/summarization/run_summarization.py \\
    --fp16 \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),E=new g({props:{title:"在TPU上运行脚本",local:"在tpu上运行脚本",headingTag:"h2"}}),b=new wl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Il],pytorch:[Cl]},$$scope:{ctx:j}}}),k=new g({props:{title:"基于🤗 Accelerate运行脚本",local:"基于-accelerate运行脚本",headingTag:"h2"}}),P=new _({props:{code:"cGlwJTIwaW5zdGFsbCUyMGdpdCUyQmh0dHBzJTNBJTJGJTJGZ2l0aHViLmNvbSUyRmh1Z2dpbmdmYWNlJTJGYWNjZWxlcmF0ZQ==",highlighted:"pip install git+https://github.com/huggingface/accelerate",wrap:!1}}),O=new _({props:{code:"YWNjZWxlcmF0ZSUyMGNvbmZpZw==",highlighted:"accelerate config",wrap:!1}}),tt=new _({props:{code:"YWNjZWxlcmF0ZSUyMHRlc3Q=",highlighted:'accelerate <span class="hljs-built_in">test</span>',wrap:!1}}),lt=new _({props:{code:"YWNjZWxlcmF0ZSUyMGxhdW5jaCUyMHJ1bl9zdW1tYXJpemF0aW9uX25vX3RyYWluZXIucHklMjAlNUMlMEElMjAlMjAlMjAlMjAtLW1vZGVsX25hbWVfb3JfcGF0aCUyMGdvb2dsZS10NSUyRnQ1LXNtYWxsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X25hbWUlMjBjbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X2NvbmZpZyUyMCUyMjMuMC4wJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwfiUyRnRtcCUyRnRzdC1zdW1tYXJpemF0aW9u",highlighted:`accelerate launch run_summarization_no_trainer.py \\
    --model_name_or_path google-t5/t5-small \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir ~/tmp/tst-summarization`,wrap:!1}}),at=new g({props:{title:"使用自定义数据集",local:"使用自定义数据集",headingTag:"h2"}}),st=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRyYWluX2ZpbGUlMjBwYXRoX3RvX2Nzdl9vcl9qc29ubGluZXNfZmlsZSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tdmFsaWRhdGlvbl9maWxlJTIwcGF0aF90b19jc3Zfb3JfanNvbmxpbmVzX2ZpbGUlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXRleHRfY29sdW1uJTIwdGV4dF9jb2x1bW5fbmFtZSUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tc3VtbWFyeV9jb2x1bW4lMjBzdW1tYXJ5X2NvbHVtbl9uYW1lJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLW92ZXJ3cml0ZV9vdXRwdXRfZGlyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZQ==",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --train_file path_to_csv_or_jsonlines_file \\
    --validation_file path_to_csv_or_jsonlines_file \\
    --text_column text_column_name \\
    --summary_column summary_column_name \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --overwrite_output_dir \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --predict_with_generate`,wrap:!1}}),Mt=new g({props:{title:"测试脚本",local:"测试脚本",headingTag:"h2"}}),ot=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tbWF4X3RyYWluX3NhbXBsZXMlMjA1MCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tbWF4X2V2YWxfc2FtcGxlcyUyMDUwJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1tYXhfcHJlZGljdF9zYW1wbGVzJTIwNTAlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX3RyYWluJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kb19ldmFsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X25hbWUlMjBjbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1kYXRhc2V0X2NvbmZpZyUyMCUyMjMuMC4wJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1zb3VyY2VfcHJlZml4JTIwJTIyc3VtbWFyaXplJTNBJTIwJTIyJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3ZlcndyaXRlX291dHB1dF9kaXIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZQ==",highlighted:`python examples/pytorch/summarization/run_summarization.py \\
    --model_name_or_path google-t5/t5-small \\
    --max_train_samples 50 \\
    --max_eval_samples 50 \\
    --max_predict_samples 50 \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),ut=new _({props:{code:"ZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTIwLWg=",highlighted:"examples/pytorch/summarization/run_summarization.py -h",wrap:!1}}),ct=new g({props:{title:"从checkpoint恢复训练",local:"从checkpoint恢复训练",headingTag:"h2"}}),Tt=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwcHJldmlvdXNfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --output_dir previous_output_dir \\
    --predict_with_generate`,wrap:!1}}),ht=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLW91dHB1dF9kaXIlMjAlMkZ0bXAlMkZ0c3Qtc3VtbWFyaXphdGlvbiUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q0JTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdmVyd3JpdGVfb3V0cHV0X2RpciUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcmVzdW1lX2Zyb21fY2hlY2twb2ludCUyMHBhdGhfdG9fc3BlY2lmaWNfY2hlY2twb2ludCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tcHJlZGljdF93aXRoX2dlbmVyYXRl",highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --resume_from_checkpoint path_to_specific_checkpoint \\
    --predict_with_generate`,wrap:!1}}),dt=new g({props:{title:"分享模型",local:"分享模型",headingTag:"h2"}}),_t=new _({props:{code:"aHVnZ2luZ2ZhY2UtY2xpJTIwbG9naW4=",highlighted:"huggingface-cli login",wrap:!1}}),bt=new _({props:{code:"cHl0aG9uJTIwZXhhbXBsZXMlMkZweXRvcmNoJTJGc3VtbWFyaXphdGlvbiUyRnJ1bl9zdW1tYXJpemF0aW9uLnB5JTBBJTIwJTIwJTIwJTIwLS1tb2RlbF9uYW1lX29yX3BhdGglMjBnb29nbGUtdDUlMkZ0NS1zbWFsbCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tZG9fdHJhaW4lMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRvX2V2YWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfbmFtZSUyMGNubl9kYWlseW1haWwlMjAlNUMlMEElMjAlMjAlMjAlMjAtLWRhdGFzZXRfY29uZmlnJTIwJTIyMy4wLjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXNvdXJjZV9wcmVmaXglMjAlMjJzdW1tYXJpemUlM0ElMjAlMjIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXB1c2hfdG9faHViJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1wdXNoX3RvX2h1Yl9tb2RlbF9pZCUyMGZpbmV0dW5lZC10NS1jbm5fZGFpbHltYWlsJTIwJTVDJTBBJTIwJTIwJTIwJTIwLS1vdXRwdXRfZGlyJTIwJTJGdG1wJTJGdHN0LXN1bW1hcml6YXRpb24lMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfdHJhaW5fYmF0Y2hfc2l6ZSUzRDQlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNENCUyMCU1QyUwQSUyMCUyMCUyMCUyMC0tb3ZlcndyaXRlX291dHB1dF9kaXIlMjAlNUMlMEElMjAlMjAlMjAlMjAtLXByZWRpY3Rfd2l0aF9nZW5lcmF0ZQ==",highlighted:`python examples/pytorch/summarization/run_summarization.py
    --model_name_or_path google-t5/t5-small \\
    --do_train \\
    --do_eval \\
    --dataset_name cnn_dailymail \\
    --dataset_config <span class="hljs-string">&quot;3.0.0&quot;</span> \\
    --source_prefix <span class="hljs-string">&quot;summarize: &quot;</span> \\
    --push_to_hub \\
    --push_to_hub_model_id finetuned-t5-cnn_dailymail \\
    --output_dir /tmp/tst-summarization \\
    --per_device_train_batch_size=4 \\
    --per_device_eval_batch_size=4 \\
    --overwrite_output_dir \\
    --predict_with_generate`,wrap:!1}}),{c(){n=o("meta"),u=s(),i=o("p"),m=s(),w(p.$$.fragment),r=s(),U=o("p"),U.innerHTML=Ge,Xt=s(),C=o("p"),C.innerHTML=Re,It=s(),X=o("p"),X.textContent=Le,At=s(),I=o("p"),I.innerHTML=xe,vt=s(),A=o("p"),A.innerHTML=Ve,Wt=s(),w(v.$$.fragment),Zt=s(),W=o("p"),W.innerHTML=Ne,Gt=s(),w(Z.$$.fragment),Rt=s(),G=o("p"),G.textContent=Be,Lt=s(),R=o("details"),R.innerHTML=Fe,xt=s(),L=o("p"),L.textContent=ze,Vt=s(),w(x.$$.fragment),Nt=s(),V=o("p"),V.innerHTML=Ye,Bt=s(),w(N.$$.fragment),Ft=s(),w(B.$$.fragment),zt=s(),w($.$$.fragment),Yt=s(),w(F.$$.fragment),St=s(),z=o("p"),z.innerHTML=Se,Ht=s(),Y=o("ul"),Y.innerHTML=He,Et=s(),w(S.$$.fragment),kt=s(),H=o("p"),H.innerHTML=Ee,Qt=s(),w(E.$$.fragment),Dt=s(),w(b.$$.fragment),Pt=s(),w(k.$$.fragment),qt=s(),Q=o("p"),Q.innerHTML=ke,Ot=s(),D=o("blockquote"),D.innerHTML=Qe,Kt=s(),w(P.$$.fragment),te=s(),q=o("p"),q.innerHTML=De,ee=s(),w(O.$$.fragment),le=s(),K=o("p"),K.textContent=Pe,ae=s(),w(tt.$$.fragment),ne=s(),et=o("p"),et.textContent=qe,ie=s(),w(lt.$$.fragment),re=s(),w(at.$$.fragment),se=s(),nt=o("p"),nt.textContent=Oe,Me=s(),it=o("ul"),it.innerHTML=Ke,me=s(),rt=o("p"),rt.textContent=tl,pe=s(),w(st.$$.fragment),oe=s(),w(Mt.$$.fragment),fe=s(),mt=o("p"),mt.textContent=el,ue=s(),pt=o("ul"),pt.innerHTML=ll,ce=s(),w(ot.$$.fragment),we=s(),ft=o("p"),ft.innerHTML=al,Je=s(),w(ut.$$.fragment),Te=s(),w(ct.$$.fragment),ye=s(),wt=o("p"),wt.textContent=nl,he=s(),Jt=o("p"),Jt.innerHTML=il,de=s(),w(Tt.$$.fragment),Ue=s(),yt=o("p"),yt.innerHTML=rl,_e=s(),w(ht.$$.fragment),je=s(),w(dt.$$.fragment),ge=s(),Ut=o("p"),Ut.innerHTML=sl,$e=s(),w(_t.$$.fragment),be=s(),jt=o("p"),jt.innerHTML=Ml,Ce=s(),gt=o("p"),gt.innerHTML=ml,Xe=s(),$t=o("p"),$t.textContent=pl,Ie=s(),w(bt.$$.fragment),Ae=s(),Ct=o("p"),this.h()},l(t){const e=dl("svelte-u9bgzb",document.head);n=f(e,"META",{name:!0,content:!0}),e.forEach(l),u=M(t),i=f(t,"P",{}),ul(i).forEach(l),m=M(t),J(p.$$.fragment,t),r=M(t),U=f(t,"P",{"data-svelte-h":!0}),c(U)!=="svelte-xtf51o"&&(U.innerHTML=Ge),Xt=M(t),C=f(t,"P",{"data-svelte-h":!0}),c(C)!=="svelte-t9b9sq"&&(C.innerHTML=Re),It=M(t),X=f(t,"P",{"data-svelte-h":!0}),c(X)!=="svelte-y5rq4n"&&(X.textContent=Le),At=M(t),I=f(t,"P",{"data-svelte-h":!0}),c(I)!=="svelte-zuh3zf"&&(I.innerHTML=xe),vt=M(t),A=f(t,"P",{"data-svelte-h":!0}),c(A)!=="svelte-17m9h91"&&(A.innerHTML=Ve),Wt=M(t),J(v.$$.fragment,t),Zt=M(t),W=f(t,"P",{"data-svelte-h":!0}),c(W)!=="svelte-2nj8cj"&&(W.innerHTML=Ne),Gt=M(t),J(Z.$$.fragment,t),Rt=M(t),G=f(t,"P",{"data-svelte-h":!0}),c(G)!=="svelte-8nj16n"&&(G.textContent=Be),Lt=M(t),R=f(t,"DETAILS",{"data-svelte-h":!0}),c(R)!=="svelte-1ubwk1n"&&(R.innerHTML=Fe),xt=M(t),L=f(t,"P",{"data-svelte-h":!0}),c(L)!=="svelte-1ebeyhp"&&(L.textContent=ze),Vt=M(t),J(x.$$.fragment,t),Nt=M(t),V=f(t,"P",{"data-svelte-h":!0}),c(V)!=="svelte-rb945x"&&(V.innerHTML=Ye),Bt=M(t),J(N.$$.fragment,t),Ft=M(t),J(B.$$.fragment,t),zt=M(t),J($.$$.fragment,t),Yt=M(t),J(F.$$.fragment,t),St=M(t),z=f(t,"P",{"data-svelte-h":!0}),c(z)!=="svelte-1xszoa1"&&(z.innerHTML=Se),Ht=M(t),Y=f(t,"UL",{"data-svelte-h":!0}),c(Y)!=="svelte-zaadqd"&&(Y.innerHTML=He),Et=M(t),J(S.$$.fragment,t),kt=M(t),H=f(t,"P",{"data-svelte-h":!0}),c(H)!=="svelte-w6ormk"&&(H.innerHTML=Ee),Qt=M(t),J(E.$$.fragment,t),Dt=M(t),J(b.$$.fragment,t),Pt=M(t),J(k.$$.fragment,t),qt=M(t),Q=f(t,"P",{"data-svelte-h":!0}),c(Q)!=="svelte-1d5gx6n"&&(Q.innerHTML=ke),Ot=M(t),D=f(t,"BLOCKQUOTE",{"data-svelte-h":!0}),c(D)!=="svelte-1hi61t"&&(D.innerHTML=Qe),Kt=M(t),J(P.$$.fragment,t),te=M(t),q=f(t,"P",{"data-svelte-h":!0}),c(q)!=="svelte-1sqmzpd"&&(q.innerHTML=De),ee=M(t),J(O.$$.fragment,t),le=M(t),K=f(t,"P",{"data-svelte-h":!0}),c(K)!=="svelte-1sleoq5"&&(K.textContent=Pe),ae=M(t),J(tt.$$.fragment,t),ne=M(t),et=f(t,"P",{"data-svelte-h":!0}),c(et)!=="svelte-jem89t"&&(et.textContent=qe),ie=M(t),J(lt.$$.fragment,t),re=M(t),J(at.$$.fragment,t),se=M(t),nt=f(t,"P",{"data-svelte-h":!0}),c(nt)!=="svelte-1sbqsjd"&&(nt.textContent=Oe),Me=M(t),it=f(t,"UL",{"data-svelte-h":!0}),c(it)!=="svelte-1gfb9n1"&&(it.innerHTML=Ke),me=M(t),rt=f(t,"P",{"data-svelte-h":!0}),c(rt)!=="svelte-287ma3"&&(rt.textContent=tl),pe=M(t),J(st.$$.fragment,t),oe=M(t),J(Mt.$$.fragment,t),fe=M(t),mt=f(t,"P",{"data-svelte-h":!0}),c(mt)!=="svelte-1h7zdvc"&&(mt.textContent=el),ue=M(t),pt=f(t,"UL",{"data-svelte-h":!0}),c(pt)!=="svelte-14g5f8g"&&(pt.innerHTML=ll),ce=M(t),J(ot.$$.fragment,t),we=M(t),ft=f(t,"P",{"data-svelte-h":!0}),c(ft)!=="svelte-1e4r7qi"&&(ft.innerHTML=al),Je=M(t),J(ut.$$.fragment,t),Te=M(t),J(ct.$$.fragment,t),ye=M(t),wt=f(t,"P",{"data-svelte-h":!0}),c(wt)!=="svelte-ixjp8"&&(wt.textContent=nl),he=M(t),Jt=f(t,"P",{"data-svelte-h":!0}),c(Jt)!=="svelte-rn7fgf"&&(Jt.innerHTML=il),de=M(t),J(Tt.$$.fragment,t),Ue=M(t),yt=f(t,"P",{"data-svelte-h":!0}),c(yt)!=="svelte-y8jo8h"&&(yt.innerHTML=rl),_e=M(t),J(ht.$$.fragment,t),je=M(t),J(dt.$$.fragment,t),ge=M(t),Ut=f(t,"P",{"data-svelte-h":!0}),c(Ut)!=="svelte-14o7a7e"&&(Ut.innerHTML=sl),$e=M(t),J(_t.$$.fragment,t),be=M(t),jt=f(t,"P",{"data-svelte-h":!0}),c(jt)!=="svelte-s1qcjt"&&(jt.innerHTML=Ml),Ce=M(t),gt=f(t,"P",{"data-svelte-h":!0}),c(gt)!=="svelte-1dapele"&&(gt.innerHTML=ml),Xe=M(t),$t=f(t,"P",{"data-svelte-h":!0}),c($t)!=="svelte-dckksr"&&($t.textContent=pl),Ie=M(t),J(bt.$$.fragment,t),Ae=M(t),Ct=f(t,"P",{}),ul(Ct).forEach(l),this.h()},h(){cl(n,"name","hf:doc:metadata"),cl(n,"content",vl)},m(t,e){Ul(document.head,n),a(t,u,e),a(t,i,e),a(t,m,e),T(p,t,e),a(t,r,e),a(t,U,e),a(t,Xt,e),a(t,C,e),a(t,It,e),a(t,X,e),a(t,At,e),a(t,I,e),a(t,vt,e),a(t,A,e),a(t,Wt,e),T(v,t,e),a(t,Zt,e),a(t,W,e),a(t,Gt,e),T(Z,t,e),a(t,Rt,e),a(t,G,e),a(t,Lt,e),a(t,R,e),a(t,xt,e),a(t,L,e),a(t,Vt,e),T(x,t,e),a(t,Nt,e),a(t,V,e),a(t,Bt,e),T(N,t,e),a(t,Ft,e),T(B,t,e),a(t,zt,e),T($,t,e),a(t,Yt,e),T(F,t,e),a(t,St,e),a(t,z,e),a(t,Ht,e),a(t,Y,e),a(t,Et,e),T(S,t,e),a(t,kt,e),a(t,H,e),a(t,Qt,e),T(E,t,e),a(t,Dt,e),T(b,t,e),a(t,Pt,e),T(k,t,e),a(t,qt,e),a(t,Q,e),a(t,Ot,e),a(t,D,e),a(t,Kt,e),T(P,t,e),a(t,te,e),a(t,q,e),a(t,ee,e),T(O,t,e),a(t,le,e),a(t,K,e),a(t,ae,e),T(tt,t,e),a(t,ne,e),a(t,et,e),a(t,ie,e),T(lt,t,e),a(t,re,e),T(at,t,e),a(t,se,e),a(t,nt,e),a(t,Me,e),a(t,it,e),a(t,me,e),a(t,rt,e),a(t,pe,e),T(st,t,e),a(t,oe,e),T(Mt,t,e),a(t,fe,e),a(t,mt,e),a(t,ue,e),a(t,pt,e),a(t,ce,e),T(ot,t,e),a(t,we,e),a(t,ft,e),a(t,Je,e),T(ut,t,e),a(t,Te,e),T(ct,t,e),a(t,ye,e),a(t,wt,e),a(t,he,e),a(t,Jt,e),a(t,de,e),T(Tt,t,e),a(t,Ue,e),a(t,yt,e),a(t,_e,e),T(ht,t,e),a(t,je,e),T(dt,t,e),a(t,ge,e),a(t,Ut,e),a(t,$e,e),T(_t,t,e),a(t,be,e),a(t,jt,e),a(t,Ce,e),a(t,gt,e),a(t,Xe,e),a(t,$t,e),a(t,Ie,e),T(bt,t,e),a(t,Ae,e),a(t,Ct,e),ve=!0},p(t,[e]){const ol={};e&2&&(ol.$$scope={dirty:e,ctx:t}),$.$set(ol);const fl={};e&2&&(fl.$$scope={dirty:e,ctx:t}),b.$set(fl)},i(t){ve||(y(p.$$.fragment,t),y(v.$$.fragment,t),y(Z.$$.fragment,t),y(x.$$.fragment,t),y(N.$$.fragment,t),y(B.$$.fragment,t),y($.$$.fragment,t),y(F.$$.fragment,t),y(S.$$.fragment,t),y(E.$$.fragment,t),y(b.$$.fragment,t),y(k.$$.fragment,t),y(P.$$.fragment,t),y(O.$$.fragment,t),y(tt.$$.fragment,t),y(lt.$$.fragment,t),y(at.$$.fragment,t),y(st.$$.fragment,t),y(Mt.$$.fragment,t),y(ot.$$.fragment,t),y(ut.$$.fragment,t),y(ct.$$.fragment,t),y(Tt.$$.fragment,t),y(ht.$$.fragment,t),y(dt.$$.fragment,t),y(_t.$$.fragment,t),y(bt.$$.fragment,t),ve=!0)},o(t){h(p.$$.fragment,t),h(v.$$.fragment,t),h(Z.$$.fragment,t),h(x.$$.fragment,t),h(N.$$.fragment,t),h(B.$$.fragment,t),h($.$$.fragment,t),h(F.$$.fragment,t),h(S.$$.fragment,t),h(E.$$.fragment,t),h(b.$$.fragment,t),h(k.$$.fragment,t),h(P.$$.fragment,t),h(O.$$.fragment,t),h(tt.$$.fragment,t),h(lt.$$.fragment,t),h(at.$$.fragment,t),h(st.$$.fragment,t),h(Mt.$$.fragment,t),h(ot.$$.fragment,t),h(ut.$$.fragment,t),h(ct.$$.fragment,t),h(Tt.$$.fragment,t),h(ht.$$.fragment,t),h(dt.$$.fragment,t),h(_t.$$.fragment,t),h(bt.$$.fragment,t),ve=!1},d(t){t&&(l(u),l(i),l(m),l(r),l(U),l(Xt),l(C),l(It),l(X),l(At),l(I),l(vt),l(A),l(Wt),l(Zt),l(W),l(Gt),l(Rt),l(G),l(Lt),l(R),l(xt),l(L),l(Vt),l(Nt),l(V),l(Bt),l(Ft),l(zt),l(Yt),l(St),l(z),l(Ht),l(Y),l(Et),l(kt),l(H),l(Qt),l(Dt),l(Pt),l(qt),l(Q),l(Ot),l(D),l(Kt),l(te),l(q),l(ee),l(le),l(K),l(ae),l(ne),l(et),l(ie),l(re),l(se),l(nt),l(Me),l(it),l(me),l(rt),l(pe),l(oe),l(fe),l(mt),l(ue),l(pt),l(ce),l(we),l(ft),l(Je),l(Te),l(ye),l(wt),l(he),l(Jt),l(de),l(Ue),l(yt),l(_e),l(je),l(ge),l(Ut),l($e),l(be),l(jt),l(Ce),l(gt),l(Xe),l($t),l(Ie),l(Ae),l(Ct)),l(n),d(p,t),d(v,t),d(Z,t),d(x,t),d(N,t),d(B,t),d($,t),d(F,t),d(S,t),d(E,t),d(b,t),d(k,t),d(P,t),d(O,t),d(tt,t),d(lt,t),d(at,t),d(st,t),d(Mt,t),d(ot,t),d(ut,t),d(ct,t),d(Tt,t),d(ht,t),d(dt,t),d(_t,t),d(bt,t)}}}const vl='{"title":"使用脚本进行训练","local":"使用脚本进行训练","sections":[{"title":"设置","local":"设置","sections":[],"depth":2},{"title":"运行脚本","local":"运行脚本","sections":[],"depth":2},{"title":"分布式训练和混合精度","local":"分布式训练和混合精度","sections":[],"depth":2},{"title":"在TPU上运行脚本","local":"在tpu上运行脚本","sections":[],"depth":2},{"title":"基于🤗 Accelerate运行脚本","local":"基于-accelerate运行脚本","sections":[],"depth":2},{"title":"使用自定义数据集","local":"使用自定义数据集","sections":[],"depth":2},{"title":"测试脚本","local":"测试脚本","sections":[],"depth":2},{"title":"从checkpoint恢复训练","local":"从checkpoint恢复训练","sections":[],"depth":2},{"title":"分享模型","local":"分享模型","sections":[],"depth":2}],"depth":1}';function Wl(j){return Tl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Vl extends yl{constructor(n){super(),hl(this,n,Wl,Al,Jl,{})}}export{Vl as component};
