import{s as Ka,o as Ra,n as Ua}from"../chunks/scheduler.9991993c.js";import{S as Xa,i as Ga,g as l,s as a,r as m,A as Ja,h as s,f as r,c as o,j as v,u as c,x as d,k as _,y as t,a as i,v as p,d as g,t as f,w as u}from"../chunks/index.7fc9a5e7.js";import{T as Ba}from"../chunks/Tip.9de92fc6.js";import{D as C}from"../chunks/Docstring.8180f571.js";import{H}from"../chunks/Heading.e3de321f.js";function Ya(ye){let h,L=`For best performance, this data collator should be used with a dataset having items that are dictionaries or
BatchEncoding, with the <code>&quot;special_tokens_mask&quot;</code> key, as returned by a <a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a> or a
<a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a> with the argument <code>return_special_tokens_mask=True</code>.`;return{c(){h=l("p"),h.innerHTML=L},l($){h=s($,"P",{"data-svelte-h":!0}),d(h)!=="svelte-1gijru4"&&(h.innerHTML=L)},m($,V){i($,h,V)},p:Ua,d($){$&&r(h)}}}function Za(ye){let h,L=`This collator relies on details of the implementation of subword tokenization by <code>BertTokenizer</code>, specifically
that subword tokens are prefixed with <em>##</em>. For tokenizers that do not adhere to this scheme, this collator will
produce an output that is roughly equivalent to <code>.DataCollatorForLanguageModeling</code>.`;return{c(){h=l("p"),h.innerHTML=L},l($){h=s($,"P",{"data-svelte-h":!0}),d(h)!=="svelte-3v0y1u"&&(h.innerHTML=L)},m($,V){i($,h,V)},p:Ua,d($){$&&r(h)}}}function eo(ye){let h,L,$,V,R,tt,X,ua="Data collators是一个对象，通过使用数据集元素列表作为输入来形成一个批次。这些元素与 <code>train_dataset</code> 或 <code>eval_dataset</code> 的元素类型相同。",at,G,ha='为了能够构建批次，Data collators可能会应用一些预处理（比如填充）。其中一些（比如<a href="/docs/transformers/main/zh/main_classes/data_collator#transformers.DataCollatorForLanguageModeling">DataCollatorForLanguageModeling</a>）还会在形成的批次上应用一些随机数据增强（比如随机掩码）。',ot,J,_a='在<a href="../examples">示例脚本</a>或<a href="../notebooks">示例notebooks</a>中可以找到使用的示例。',rt,Y,nt,y,Z,Lt,Pe,ba=`Very simple data collator that simply collates batches of dict-like objects and performs special handling for
potential keys named:`,qt,we,va="<li><code>label</code>: handles a single value (int or float) per object</li> <li><code>label_ids</code>: handles a list of values per object</li>",Mt,ze,$a=`Does not do any additional preprocessing: property names of the input object will be used as corresponding inputs
to the model. See glue and ner for example of how it’s useful.`,lt,ee,st,T,te,St,Fe,ka=`Very simple data collator that simply collates batches of dict-like objects and performs special handling for
potential keys named:`,It,Le,xa="<li><code>label</code>: handles a single value (int or float) per object</li> <li><code>label_ids</code>: handles a list of values per object</li>",Wt,qe,Ca=`Does not do any additional preprocessing: property names of the input object will be used as corresponding inputs
to the model. See glue and ner for example of how it’s useful.`,At,Me,Ta=`This is an object (like other data collators) rather than a pure function like default_data_collator. This can be
helpful if you need to set a return_tensors value at initialization.`,it,ae,dt,I,oe,Ht,Se,Da="Data collator that will dynamically pad the inputs received.",mt,re,ct,W,ne,Vt,Ie,ya="Data collator that will dynamically pad the inputs received, as well as the labels.",pt,le,gt,A,se,Et,We,Pa="Data collator that will dynamically pad the inputs received, as well as the labels.",ft,ie,ut,k,de,jt,Ae,wa=`Data collator used for language modeling. Inputs are dynamically padded to the maximum length of a batch if they
are not all of the same length.`,Nt,E,Qt,j,me,Ot,He,za="Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.",Bt,N,ce,Ut,Ve,Fa="Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.",Kt,Q,pe,Rt,Ee,La="Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.",ht,ge,_t,b,fe,Xt,je,qa="Data collator used for language modeling that masks entire words.",Gt,Ne,Ma="<li>collates batches of tensors, honoring their tokenizer’s pad_token</li> <li>preprocesses batches for masked language modeling</li>",Jt,O,Yt,B,ue,Zt,Qe,Sa=`Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. Set
‘mask_labels’ means we use whole word mask (wwm), we directly mask idxs according to it’s ref.`,ea,U,he,ta,Oe,Ia=`Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. Set
‘mask_labels’ means we use whole word mask (wwm), we directly mask idxs according to it’s ref.`,aa,K,_e,oa,Be,Wa=`Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. Set
‘mask_labels’ means we use whole word mask (wwm), we directly mask idxs according to it’s ref.`,bt,be,vt,x,ve,ra,Ue,Aa="Data collator used for permutation language modeling.",na,Ke,Ha="<li>collates batches of tensors, honoring their tokenizer’s pad_token</li> <li>preprocesses batches for permutation language modeling with procedures specific to XLNet</li>",la,q,$e,sa,Re,Va="The masked tokens to be predicted for a particular sequence are determined by the following algorithm:",ia,ke,Ea=`<li>Start from the beginning of the sequence by setting <code>cur_len = 0</code> (number of tokens processed so far).</li> <li>Sample a <code>span_length</code> from the interval <code>[1, max_span_length]</code> (length of span of tokens to be masked)</li> <li>Reserve a context of length <code>context_length = span_length / plm_probability</code> to surround span to be
masked</li> <li>Sample a starting point <code>start_index</code> from the interval <code>[cur_len, cur_len + context_length - span_length]</code> and mask tokens <code>start_index:start_index + span_length</code></li> <li>Set <code>cur_len = cur_len + context_length</code>. If <code>cur_len &lt; max_len</code> (i.e. there are tokens remaining in the
sequence to be processed), repeat from Step 1.</li>`,da,M,xe,ma,Xe,ja="The masked tokens to be predicted for a particular sequence are determined by the following algorithm:",ca,Ce,Na=`<li>Start from the beginning of the sequence by setting <code>cur_len = 0</code> (number of tokens processed so far).</li> <li>Sample a <code>span_length</code> from the interval <code>[1, max_span_length]</code> (length of span of tokens to be masked)</li> <li>Reserve a context of length <code>context_length = span_length / plm_probability</code> to surround span to be
masked</li> <li>Sample a starting point <code>start_index</code> from the interval <code>[cur_len, cur_len + context_length - span_length]</code> and mask tokens <code>start_index:start_index + span_length</code></li> <li>Set <code>cur_len = cur_len + context_length</code>. If <code>cur_len &lt; max_len</code> (i.e. there are tokens remaining in the
sequence to be processed), repeat from Step 1.</li>`,pa,S,Te,ga,Ge,Qa="The masked tokens to be predicted for a particular sequence are determined by the following algorithm:",fa,De,Oa=`<li>Start from the beginning of the sequence by setting <code>cur_len = 0</code> (number of tokens processed so far).</li> <li>Sample a <code>span_length</code> from the interval <code>[1, max_span_length]</code> (length of span of tokens to be masked)</li> <li>Reserve a context of length <code>context_length = span_length / plm_probability</code> to surround span to be
masked</li> <li>Sample a starting point <code>start_index</code> from the interval <code>[cur_len, cur_len + context_length - span_length]</code> and mask tokens <code>start_index:start_index + span_length</code></li> <li>Set <code>cur_len = cur_len + context_length</code>. If <code>cur_len &lt; max_len</code> (i.e. there are tokens remaining in the
sequence to be processed), repeat from Step 1.</li>`,$t,et,kt;return R=new H({props:{title:"Data Collator",local:"data-collator",headingTag:"h1"}}),Y=new H({props:{title:"Default data collator",local:"transformers.default_data_collator",headingTag:"h2"}}),Z=new C({props:{name:"transformers.default_data_collator",anchor:"transformers.default_data_collator",parameters:[{name:"features",val:": List"},{name:"return_tensors",val:" = 'pt'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L74"}}),ee=new H({props:{title:"DefaultDataCollator",local:"transformers.DefaultDataCollator",headingTag:"h2"}}),te=new C({props:{name:"class transformers.DefaultDataCollator",anchor:"transformers.DefaultDataCollator",parameters:[{name:"return_tensors",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.DefaultDataCollator.return_tensors",description:`<strong>return_tensors</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The type of Tensor to return. Allowable values are &#x201C;np&#x201D;, &#x201C;pt&#x201D; and &#x201C;tf&#x201D;.`,name:"return_tensors"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L99"}}),ae=new H({props:{title:"DataCollatorWithPadding",local:"transformers.DataCollatorWithPadding",headingTag:"h2"}}),oe=new C({props:{name:"class transformers.DataCollatorWithPadding",anchor:"transformers.DataCollatorWithPadding",parameters:[{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"padding",val:": Union = True"},{name:"max_length",val:": Optional = None"},{name:"pad_to_multiple_of",val:": Optional = None"},{name:"return_tensors",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.DataCollatorWithPadding.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a> or <a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.DataCollatorWithPadding.padding",description:`<strong>padding</strong> (<code>bool</code>, <code>str</code> or <a href="/docs/transformers/main/zh/internal/file_utils#transformers.utils.PaddingStrategy">PaddingStrategy</a>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Select a strategy to pad the returned sequences (according to the model&#x2019;s padding side and padding index)
among:</p>
<ul>
<li><code>True</code> or <code>&apos;longest&apos;</code> (default): Pad to the longest sequence in the batch (or no padding if only a single
sequence is provided).</li>
<li><code>&apos;max_length&apos;</code>: Pad to a maximum length specified with the argument <code>max_length</code> or to the maximum
acceptable input length for the model if that argument is not provided.</li>
<li><code>False</code> or <code>&apos;do_not_pad&apos;</code>: No padding (i.e., can output a batch with sequences of different lengths).</li>
</ul>`,name:"padding"},{anchor:"transformers.DataCollatorWithPadding.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Maximum length of the returned list and optionally padding length (see above).`,name:"max_length"},{anchor:"transformers.DataCollatorWithPadding.pad_to_multiple_of",description:`<strong>pad_to_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If set will pad the sequence to a multiple of the provided value.</p>
<p>This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability &gt;=
7.5 (Volta).`,name:"pad_to_multiple_of"},{anchor:"transformers.DataCollatorWithPadding.return_tensors",description:`<strong>return_tensors</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The type of Tensor to return. Allowable values are &#x201C;np&#x201D;, &#x201C;pt&#x201D; and &#x201C;tf&#x201D;.`,name:"return_tensors"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L236"}}),re=new H({props:{title:"DataCollatorForTokenClassification",local:"transformers.DataCollatorForTokenClassification",headingTag:"h2"}}),ne=new C({props:{name:"class transformers.DataCollatorForTokenClassification",anchor:"transformers.DataCollatorForTokenClassification",parameters:[{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"padding",val:": Union = True"},{name:"max_length",val:": Optional = None"},{name:"pad_to_multiple_of",val:": Optional = None"},{name:"label_pad_token_id",val:": int = -100"},{name:"return_tensors",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.DataCollatorForTokenClassification.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a> or <a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.DataCollatorForTokenClassification.padding",description:`<strong>padding</strong> (<code>bool</code>, <code>str</code> or <a href="/docs/transformers/main/zh/internal/file_utils#transformers.utils.PaddingStrategy">PaddingStrategy</a>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Select a strategy to pad the returned sequences (according to the model&#x2019;s padding side and padding index)
among:</p>
<ul>
<li><code>True</code> or <code>&apos;longest&apos;</code> (default): Pad to the longest sequence in the batch (or no padding if only a single
sequence is provided).</li>
<li><code>&apos;max_length&apos;</code>: Pad to a maximum length specified with the argument <code>max_length</code> or to the maximum
acceptable input length for the model if that argument is not provided.</li>
<li><code>False</code> or <code>&apos;do_not_pad&apos;</code>: No padding (i.e., can output a batch with sequences of different lengths).</li>
</ul>`,name:"padding"},{anchor:"transformers.DataCollatorForTokenClassification.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Maximum length of the returned list and optionally padding length (see above).`,name:"max_length"},{anchor:"transformers.DataCollatorForTokenClassification.pad_to_multiple_of",description:`<strong>pad_to_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If set will pad the sequence to a multiple of the provided value.</p>
<p>This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability &gt;=
7.5 (Volta).`,name:"pad_to_multiple_of"},{anchor:"transformers.DataCollatorForTokenClassification.label_pad_token_id",description:`<strong>label_pad_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to -100) &#x2014;
The id to use when padding the labels (-100 will be automatically ignore by PyTorch loss functions).`,name:"label_pad_token_id"},{anchor:"transformers.DataCollatorForTokenClassification.return_tensors",description:`<strong>return_tensors</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The type of Tensor to return. Allowable values are &#x201C;np&#x201D;, &#x201C;pt&#x201D; and &#x201C;tf&#x201D;.`,name:"return_tensors"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L288"}}),le=new H({props:{title:"DataCollatorForSeq2Seq",local:"transformers.DataCollatorForSeq2Seq",headingTag:"h2"}}),se=new C({props:{name:"class transformers.DataCollatorForSeq2Seq",anchor:"transformers.DataCollatorForSeq2Seq",parameters:[{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"model",val:": Optional = None"},{name:"padding",val:": Union = True"},{name:"max_length",val:": Optional = None"},{name:"pad_to_multiple_of",val:": Optional = None"},{name:"label_pad_token_id",val:": int = -100"},{name:"return_tensors",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.DataCollatorForSeq2Seq.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a> or <a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.DataCollatorForSeq2Seq.model",description:`<strong>model</strong> (<a href="/docs/transformers/main/zh/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>, <em>optional</em>) &#x2014;
The model that is being trained. If set and has the <em>prepare_decoder_input_ids_from_labels</em>, use it to
prepare the <em>decoder_input_ids</em></p>
<p>This is useful when using <em>label_smoothing</em> to avoid calculating loss twice.`,name:"model"},{anchor:"transformers.DataCollatorForSeq2Seq.padding",description:`<strong>padding</strong> (<code>bool</code>, <code>str</code> or <a href="/docs/transformers/main/zh/internal/file_utils#transformers.utils.PaddingStrategy">PaddingStrategy</a>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Select a strategy to pad the returned sequences (according to the model&#x2019;s padding side and padding index)
among:</p>
<ul>
<li><code>True</code> or <code>&apos;longest&apos;</code> (default): Pad to the longest sequence in the batch (or no padding if only a single
sequence is provided).</li>
<li><code>&apos;max_length&apos;</code>: Pad to a maximum length specified with the argument <code>max_length</code> or to the maximum
acceptable input length for the model if that argument is not provided.</li>
<li><code>False</code> or <code>&apos;do_not_pad&apos;</code>: No padding (i.e., can output a batch with sequences of different lengths).</li>
</ul>`,name:"padding"},{anchor:"transformers.DataCollatorForSeq2Seq.max_length",description:`<strong>max_length</strong> (<code>int</code>, <em>optional</em>) &#x2014;
Maximum length of the returned list and optionally padding length (see above).`,name:"max_length"},{anchor:"transformers.DataCollatorForSeq2Seq.pad_to_multiple_of",description:`<strong>pad_to_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If set will pad the sequence to a multiple of the provided value.</p>
<p>This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability &gt;=
7.5 (Volta).`,name:"pad_to_multiple_of"},{anchor:"transformers.DataCollatorForSeq2Seq.label_pad_token_id",description:`<strong>label_pad_token_id</strong> (<code>int</code>, <em>optional</em>, defaults to -100) &#x2014;
The id to use when padding the labels (-100 will be automatically ignored by PyTorch loss functions).`,name:"label_pad_token_id"},{anchor:"transformers.DataCollatorForSeq2Seq.return_tensors",description:`<strong>return_tensors</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The type of Tensor to return. Allowable values are &#x201C;np&#x201D;, &#x201C;pt&#x201D; and &#x201C;tf&#x201D;.`,name:"return_tensors"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L542"}}),ie=new H({props:{title:"DataCollatorForLanguageModeling",local:"transformers.DataCollatorForLanguageModeling",headingTag:"h2"}}),de=new C({props:{name:"class transformers.DataCollatorForLanguageModeling",anchor:"transformers.DataCollatorForLanguageModeling",parameters:[{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"mlm",val:": bool = True"},{name:"mlm_probability",val:": float = 0.15"},{name:"pad_to_multiple_of",val:": Optional = None"},{name:"tf_experimental_compile",val:": bool = False"},{name:"return_tensors",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.DataCollatorForLanguageModeling.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a> or <a href="/docs/transformers/main/zh/main_classes/tokenizer#transformers.PreTrainedTokenizerFast">PreTrainedTokenizerFast</a>) &#x2014;
The tokenizer used for encoding the data.`,name:"tokenizer"},{anchor:"transformers.DataCollatorForLanguageModeling.mlm",description:`<strong>mlm</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>True</code>) &#x2014;
Whether or not to use masked language modeling. If set to <code>False</code>, the labels are the same as the inputs
with the padding tokens ignored (by setting them to -100). Otherwise, the labels are -100 for non-masked
tokens and the value to predict for the masked token.`,name:"mlm"},{anchor:"transformers.DataCollatorForLanguageModeling.mlm_probability",description:`<strong>mlm_probability</strong> (<code>float</code>, <em>optional</em>, defaults to 0.15) &#x2014;
The probability with which to (randomly) mask tokens in the input, when <code>mlm</code> is set to <code>True</code>.`,name:"mlm_probability"},{anchor:"transformers.DataCollatorForLanguageModeling.pad_to_multiple_of",description:`<strong>pad_to_multiple_of</strong> (<code>int</code>, <em>optional</em>) &#x2014;
If set will pad the sequence to a multiple of the provided value.`,name:"pad_to_multiple_of"},{anchor:"transformers.DataCollatorForLanguageModeling.return_tensors",description:`<strong>return_tensors</strong> (<code>str</code>) &#x2014;
The type of Tensor to return. Allowable values are &#x201C;np&#x201D;, &#x201C;pt&#x201D; and &#x201C;tf&#x201D;.`,name:"return_tensors"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L633"}}),E=new Ba({props:{$$slots:{default:[Ya]},$$scope:{ctx:ye}}}),me=new C({props:{name:"numpy_mask_tokens",anchor:"transformers.DataCollatorForLanguageModeling.numpy_mask_tokens",parameters:[{name:"inputs",val:": Any"},{name:"special_tokens_mask",val:": Optional = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L839"}}),ce=new C({props:{name:"tf_mask_tokens",anchor:"transformers.DataCollatorForLanguageModeling.tf_mask_tokens",parameters:[{name:"inputs",val:": Any"},{name:"vocab_size",val:""},{name:"mask_token_id",val:""},{name:"special_tokens_mask",val:": Optional = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L686"}}),pe=new C({props:{name:"torch_mask_tokens",anchor:"transformers.DataCollatorForLanguageModeling.torch_mask_tokens",parameters:[{name:"inputs",val:": Any"},{name:"special_tokens_mask",val:": Optional = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L782"}}),ge=new H({props:{title:"DataCollatorForWholeWordMask",local:"transformers.DataCollatorForWholeWordMask",headingTag:"h2"}}),fe=new C({props:{name:"class transformers.DataCollatorForWholeWordMask",anchor:"transformers.DataCollatorForWholeWordMask",parameters:[{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"mlm",val:": bool = True"},{name:"mlm_probability",val:": float = 0.15"},{name:"pad_to_multiple_of",val:": Optional = None"},{name:"tf_experimental_compile",val:": bool = False"},{name:"return_tensors",val:": str = 'pt'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L877"}}),O=new Ba({props:{$$slots:{default:[Za]},$$scope:{ctx:ye}}}),ue=new C({props:{name:"numpy_mask_tokens",anchor:"transformers.DataCollatorForWholeWordMask.numpy_mask_tokens",parameters:[{name:"inputs",val:": Any"},{name:"mask_labels",val:": Any"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1108"}}),he=new C({props:{name:"tf_mask_tokens",anchor:"transformers.DataCollatorForWholeWordMask.tf_mask_tokens",parameters:[{name:"inputs",val:": Any"},{name:"mask_labels",val:": Any"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1066"}}),_e=new C({props:{name:"torch_mask_tokens",anchor:"transformers.DataCollatorForWholeWordMask.torch_mask_tokens",parameters:[{name:"inputs",val:": Any"},{name:"mask_labels",val:": Any"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1026"}}),be=new H({props:{title:"DataCollatorForPermutationLanguageModeling",local:"transformers.DataCollatorForPermutationLanguageModeling",headingTag:"h2"}}),ve=new C({props:{name:"class transformers.DataCollatorForPermutationLanguageModeling",anchor:"transformers.DataCollatorForPermutationLanguageModeling",parameters:[{name:"tokenizer",val:": PreTrainedTokenizerBase"},{name:"plm_probability",val:": float = 0.16666666666666666"},{name:"max_span_length",val:": int = 5"},{name:"return_tensors",val:": str = 'pt'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1232"}}),$e=new C({props:{name:"numpy_mask_tokens",anchor:"transformers.DataCollatorForPermutationLanguageModeling.numpy_mask_tokens",parameters:[{name:"inputs",val:": Any"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1473"}}),xe=new C({props:{name:"tf_mask_tokens",anchor:"transformers.DataCollatorForPermutationLanguageModeling.tf_mask_tokens",parameters:[{name:"inputs",val:": Any"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1366"}}),Te=new C({props:{name:"torch_mask_tokens",anchor:"transformers.DataCollatorForPermutationLanguageModeling.torch_mask_tokens",parameters:[{name:"inputs",val:": Any"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/data/data_collator.py#L1267"}}),{c(){h=l("meta"),L=a(),$=l("p"),V=a(),m(R.$$.fragment),tt=a(),X=l("p"),X.innerHTML=ua,at=a(),G=l("p"),G.innerHTML=ha,ot=a(),J=l("p"),J.innerHTML=_a,rt=a(),m(Y.$$.fragment),nt=a(),y=l("div"),m(Z.$$.fragment),Lt=a(),Pe=l("p"),Pe.textContent=ba,qt=a(),we=l("ul"),we.innerHTML=va,Mt=a(),ze=l("p"),ze.textContent=$a,lt=a(),m(ee.$$.fragment),st=a(),T=l("div"),m(te.$$.fragment),St=a(),Fe=l("p"),Fe.textContent=ka,It=a(),Le=l("ul"),Le.innerHTML=xa,Wt=a(),qe=l("p"),qe.textContent=Ca,At=a(),Me=l("p"),Me.textContent=Ta,it=a(),m(ae.$$.fragment),dt=a(),I=l("div"),m(oe.$$.fragment),Ht=a(),Se=l("p"),Se.textContent=Da,mt=a(),m(re.$$.fragment),ct=a(),W=l("div"),m(ne.$$.fragment),Vt=a(),Ie=l("p"),Ie.textContent=ya,pt=a(),m(le.$$.fragment),gt=a(),A=l("div"),m(se.$$.fragment),Et=a(),We=l("p"),We.textContent=Pa,ft=a(),m(ie.$$.fragment),ut=a(),k=l("div"),m(de.$$.fragment),jt=a(),Ae=l("p"),Ae.textContent=wa,Nt=a(),m(E.$$.fragment),Qt=a(),j=l("div"),m(me.$$.fragment),Ot=a(),He=l("p"),He.textContent=za,Bt=a(),N=l("div"),m(ce.$$.fragment),Ut=a(),Ve=l("p"),Ve.textContent=Fa,Kt=a(),Q=l("div"),m(pe.$$.fragment),Rt=a(),Ee=l("p"),Ee.textContent=La,ht=a(),m(ge.$$.fragment),_t=a(),b=l("div"),m(fe.$$.fragment),Xt=a(),je=l("p"),je.textContent=qa,Gt=a(),Ne=l("ul"),Ne.innerHTML=Ma,Jt=a(),m(O.$$.fragment),Yt=a(),B=l("div"),m(ue.$$.fragment),Zt=a(),Qe=l("p"),Qe.textContent=Sa,ea=a(),U=l("div"),m(he.$$.fragment),ta=a(),Oe=l("p"),Oe.textContent=Ia,aa=a(),K=l("div"),m(_e.$$.fragment),oa=a(),Be=l("p"),Be.textContent=Wa,bt=a(),m(be.$$.fragment),vt=a(),x=l("div"),m(ve.$$.fragment),ra=a(),Ue=l("p"),Ue.textContent=Aa,na=a(),Ke=l("ul"),Ke.innerHTML=Ha,la=a(),q=l("div"),m($e.$$.fragment),sa=a(),Re=l("p"),Re.textContent=Va,ia=a(),ke=l("ol"),ke.innerHTML=Ea,da=a(),M=l("div"),m(xe.$$.fragment),ma=a(),Xe=l("p"),Xe.textContent=ja,ca=a(),Ce=l("ol"),Ce.innerHTML=Na,pa=a(),S=l("div"),m(Te.$$.fragment),ga=a(),Ge=l("p"),Ge.textContent=Qa,fa=a(),De=l("ol"),De.innerHTML=Oa,$t=a(),et=l("p"),this.h()},l(e){const n=Ja("svelte-u9bgzb",document.head);h=s(n,"META",{name:!0,content:!0}),n.forEach(r),L=o(e),$=s(e,"P",{}),v($).forEach(r),V=o(e),c(R.$$.fragment,e),tt=o(e),X=s(e,"P",{"data-svelte-h":!0}),d(X)!=="svelte-1t1zoyx"&&(X.innerHTML=ua),at=o(e),G=s(e,"P",{"data-svelte-h":!0}),d(G)!=="svelte-aec1vj"&&(G.innerHTML=ha),ot=o(e),J=s(e,"P",{"data-svelte-h":!0}),d(J)!=="svelte-54nsx2"&&(J.innerHTML=_a),rt=o(e),c(Y.$$.fragment,e),nt=o(e),y=s(e,"DIV",{class:!0});var F=v(y);c(Z.$$.fragment,F),Lt=o(F),Pe=s(F,"P",{"data-svelte-h":!0}),d(Pe)!=="svelte-1hmsgsg"&&(Pe.textContent=ba),qt=o(F),we=s(F,"UL",{"data-svelte-h":!0}),d(we)!=="svelte-1pq8qks"&&(we.innerHTML=va),Mt=o(F),ze=s(F,"P",{"data-svelte-h":!0}),d(ze)!=="svelte-1vi1gug"&&(ze.textContent=$a),F.forEach(r),lt=o(e),c(ee.$$.fragment,e),st=o(e),T=s(e,"DIV",{class:!0});var P=v(T);c(te.$$.fragment,P),St=o(P),Fe=s(P,"P",{"data-svelte-h":!0}),d(Fe)!=="svelte-1hmsgsg"&&(Fe.textContent=ka),It=o(P),Le=s(P,"UL",{"data-svelte-h":!0}),d(Le)!=="svelte-1pq8qks"&&(Le.innerHTML=xa),Wt=o(P),qe=s(P,"P",{"data-svelte-h":!0}),d(qe)!=="svelte-1vi1gug"&&(qe.textContent=Ca),At=o(P),Me=s(P,"P",{"data-svelte-h":!0}),d(Me)!=="svelte-vfvbwr"&&(Me.textContent=Ta),P.forEach(r),it=o(e),c(ae.$$.fragment,e),dt=o(e),I=s(e,"DIV",{class:!0});var xt=v(I);c(oe.$$.fragment,xt),Ht=o(xt),Se=s(xt,"P",{"data-svelte-h":!0}),d(Se)!=="svelte-1iebpai"&&(Se.textContent=Da),xt.forEach(r),mt=o(e),c(re.$$.fragment,e),ct=o(e),W=s(e,"DIV",{class:!0});var Ct=v(W);c(ne.$$.fragment,Ct),Vt=o(Ct),Ie=s(Ct,"P",{"data-svelte-h":!0}),d(Ie)!=="svelte-4uvw1w"&&(Ie.textContent=ya),Ct.forEach(r),pt=o(e),c(le.$$.fragment,e),gt=o(e),A=s(e,"DIV",{class:!0});var Tt=v(A);c(se.$$.fragment,Tt),Et=o(Tt),We=s(Tt,"P",{"data-svelte-h":!0}),d(We)!=="svelte-4uvw1w"&&(We.textContent=Pa),Tt.forEach(r),ft=o(e),c(ie.$$.fragment,e),ut=o(e),k=s(e,"DIV",{class:!0});var w=v(k);c(de.$$.fragment,w),jt=o(w),Ae=s(w,"P",{"data-svelte-h":!0}),d(Ae)!=="svelte-10km8jk"&&(Ae.textContent=wa),Nt=o(w),c(E.$$.fragment,w),Qt=o(w),j=s(w,"DIV",{class:!0});var Dt=v(j);c(me.$$.fragment,Dt),Ot=o(Dt),He=s(Dt,"P",{"data-svelte-h":!0}),d(He)!=="svelte-iv4xqf"&&(He.textContent=za),Dt.forEach(r),Bt=o(w),N=s(w,"DIV",{class:!0});var yt=v(N);c(ce.$$.fragment,yt),Ut=o(yt),Ve=s(yt,"P",{"data-svelte-h":!0}),d(Ve)!=="svelte-iv4xqf"&&(Ve.textContent=Fa),yt.forEach(r),Kt=o(w),Q=s(w,"DIV",{class:!0});var Pt=v(Q);c(pe.$$.fragment,Pt),Rt=o(Pt),Ee=s(Pt,"P",{"data-svelte-h":!0}),d(Ee)!=="svelte-iv4xqf"&&(Ee.textContent=La),Pt.forEach(r),w.forEach(r),ht=o(e),c(ge.$$.fragment,e),_t=o(e),b=s(e,"DIV",{class:!0});var D=v(b);c(fe.$$.fragment,D),Xt=o(D),je=s(D,"P",{"data-svelte-h":!0}),d(je)!=="svelte-sjqk55"&&(je.textContent=qa),Gt=o(D),Ne=s(D,"UL",{"data-svelte-h":!0}),d(Ne)!=="svelte-d2ozxj"&&(Ne.innerHTML=Ma),Jt=o(D),c(O.$$.fragment,D),Yt=o(D),B=s(D,"DIV",{class:!0});var wt=v(B);c(ue.$$.fragment,wt),Zt=o(wt),Qe=s(wt,"P",{"data-svelte-h":!0}),d(Qe)!=="svelte-10msjh1"&&(Qe.textContent=Sa),wt.forEach(r),ea=o(D),U=s(D,"DIV",{class:!0});var zt=v(U);c(he.$$.fragment,zt),ta=o(zt),Oe=s(zt,"P",{"data-svelte-h":!0}),d(Oe)!=="svelte-10msjh1"&&(Oe.textContent=Ia),zt.forEach(r),aa=o(D),K=s(D,"DIV",{class:!0});var Ft=v(K);c(_e.$$.fragment,Ft),oa=o(Ft),Be=s(Ft,"P",{"data-svelte-h":!0}),d(Be)!=="svelte-10msjh1"&&(Be.textContent=Wa),Ft.forEach(r),D.forEach(r),bt=o(e),c(be.$$.fragment,e),vt=o(e),x=s(e,"DIV",{class:!0});var z=v(x);c(ve.$$.fragment,z),ra=o(z),Ue=s(z,"P",{"data-svelte-h":!0}),d(Ue)!=="svelte-12inif1"&&(Ue.textContent=Aa),na=o(z),Ke=s(z,"UL",{"data-svelte-h":!0}),d(Ke)!=="svelte-1t4qh7k"&&(Ke.innerHTML=Ha),la=o(z),q=s(z,"DIV",{class:!0});var Je=v(q);c($e.$$.fragment,Je),sa=o(Je),Re=s(Je,"P",{"data-svelte-h":!0}),d(Re)!=="svelte-1u70phx"&&(Re.textContent=Va),ia=o(Je),ke=s(Je,"OL",{start:!0,"data-svelte-h":!0}),d(ke)!=="svelte-1r6jrbi"&&(ke.innerHTML=Ea),Je.forEach(r),da=o(z),M=s(z,"DIV",{class:!0});var Ye=v(M);c(xe.$$.fragment,Ye),ma=o(Ye),Xe=s(Ye,"P",{"data-svelte-h":!0}),d(Xe)!=="svelte-1u70phx"&&(Xe.textContent=ja),ca=o(Ye),Ce=s(Ye,"OL",{start:!0,"data-svelte-h":!0}),d(Ce)!=="svelte-1r6jrbi"&&(Ce.innerHTML=Na),Ye.forEach(r),pa=o(z),S=s(z,"DIV",{class:!0});var Ze=v(S);c(Te.$$.fragment,Ze),ga=o(Ze),Ge=s(Ze,"P",{"data-svelte-h":!0}),d(Ge)!=="svelte-1u70phx"&&(Ge.textContent=Qa),fa=o(Ze),De=s(Ze,"OL",{start:!0,"data-svelte-h":!0}),d(De)!=="svelte-1r6jrbi"&&(De.innerHTML=Oa),Ze.forEach(r),z.forEach(r),$t=o(e),et=s(e,"P",{}),v(et).forEach(r),this.h()},h(){_(h,"name","hf:doc:metadata"),_(h,"content",to),_(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(W,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(A,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(j,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(Q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(K,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(b,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(ke,"start","0"),_(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(Ce,"start","0"),_(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(De,"start","0"),_(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),_(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,n){t(document.head,h),i(e,L,n),i(e,$,n),i(e,V,n),p(R,e,n),i(e,tt,n),i(e,X,n),i(e,at,n),i(e,G,n),i(e,ot,n),i(e,J,n),i(e,rt,n),p(Y,e,n),i(e,nt,n),i(e,y,n),p(Z,y,null),t(y,Lt),t(y,Pe),t(y,qt),t(y,we),t(y,Mt),t(y,ze),i(e,lt,n),p(ee,e,n),i(e,st,n),i(e,T,n),p(te,T,null),t(T,St),t(T,Fe),t(T,It),t(T,Le),t(T,Wt),t(T,qe),t(T,At),t(T,Me),i(e,it,n),p(ae,e,n),i(e,dt,n),i(e,I,n),p(oe,I,null),t(I,Ht),t(I,Se),i(e,mt,n),p(re,e,n),i(e,ct,n),i(e,W,n),p(ne,W,null),t(W,Vt),t(W,Ie),i(e,pt,n),p(le,e,n),i(e,gt,n),i(e,A,n),p(se,A,null),t(A,Et),t(A,We),i(e,ft,n),p(ie,e,n),i(e,ut,n),i(e,k,n),p(de,k,null),t(k,jt),t(k,Ae),t(k,Nt),p(E,k,null),t(k,Qt),t(k,j),p(me,j,null),t(j,Ot),t(j,He),t(k,Bt),t(k,N),p(ce,N,null),t(N,Ut),t(N,Ve),t(k,Kt),t(k,Q),p(pe,Q,null),t(Q,Rt),t(Q,Ee),i(e,ht,n),p(ge,e,n),i(e,_t,n),i(e,b,n),p(fe,b,null),t(b,Xt),t(b,je),t(b,Gt),t(b,Ne),t(b,Jt),p(O,b,null),t(b,Yt),t(b,B),p(ue,B,null),t(B,Zt),t(B,Qe),t(b,ea),t(b,U),p(he,U,null),t(U,ta),t(U,Oe),t(b,aa),t(b,K),p(_e,K,null),t(K,oa),t(K,Be),i(e,bt,n),p(be,e,n),i(e,vt,n),i(e,x,n),p(ve,x,null),t(x,ra),t(x,Ue),t(x,na),t(x,Ke),t(x,la),t(x,q),p($e,q,null),t(q,sa),t(q,Re),t(q,ia),t(q,ke),t(x,da),t(x,M),p(xe,M,null),t(M,ma),t(M,Xe),t(M,ca),t(M,Ce),t(x,pa),t(x,S),p(Te,S,null),t(S,ga),t(S,Ge),t(S,fa),t(S,De),i(e,$t,n),i(e,et,n),kt=!0},p(e,[n]){const F={};n&2&&(F.$$scope={dirty:n,ctx:e}),E.$set(F);const P={};n&2&&(P.$$scope={dirty:n,ctx:e}),O.$set(P)},i(e){kt||(g(R.$$.fragment,e),g(Y.$$.fragment,e),g(Z.$$.fragment,e),g(ee.$$.fragment,e),g(te.$$.fragment,e),g(ae.$$.fragment,e),g(oe.$$.fragment,e),g(re.$$.fragment,e),g(ne.$$.fragment,e),g(le.$$.fragment,e),g(se.$$.fragment,e),g(ie.$$.fragment,e),g(de.$$.fragment,e),g(E.$$.fragment,e),g(me.$$.fragment,e),g(ce.$$.fragment,e),g(pe.$$.fragment,e),g(ge.$$.fragment,e),g(fe.$$.fragment,e),g(O.$$.fragment,e),g(ue.$$.fragment,e),g(he.$$.fragment,e),g(_e.$$.fragment,e),g(be.$$.fragment,e),g(ve.$$.fragment,e),g($e.$$.fragment,e),g(xe.$$.fragment,e),g(Te.$$.fragment,e),kt=!0)},o(e){f(R.$$.fragment,e),f(Y.$$.fragment,e),f(Z.$$.fragment,e),f(ee.$$.fragment,e),f(te.$$.fragment,e),f(ae.$$.fragment,e),f(oe.$$.fragment,e),f(re.$$.fragment,e),f(ne.$$.fragment,e),f(le.$$.fragment,e),f(se.$$.fragment,e),f(ie.$$.fragment,e),f(de.$$.fragment,e),f(E.$$.fragment,e),f(me.$$.fragment,e),f(ce.$$.fragment,e),f(pe.$$.fragment,e),f(ge.$$.fragment,e),f(fe.$$.fragment,e),f(O.$$.fragment,e),f(ue.$$.fragment,e),f(he.$$.fragment,e),f(_e.$$.fragment,e),f(be.$$.fragment,e),f(ve.$$.fragment,e),f($e.$$.fragment,e),f(xe.$$.fragment,e),f(Te.$$.fragment,e),kt=!1},d(e){e&&(r(L),r($),r(V),r(tt),r(X),r(at),r(G),r(ot),r(J),r(rt),r(nt),r(y),r(lt),r(st),r(T),r(it),r(dt),r(I),r(mt),r(ct),r(W),r(pt),r(gt),r(A),r(ft),r(ut),r(k),r(ht),r(_t),r(b),r(bt),r(vt),r(x),r($t),r(et)),r(h),u(R,e),u(Y,e),u(Z),u(ee,e),u(te),u(ae,e),u(oe),u(re,e),u(ne),u(le,e),u(se),u(ie,e),u(de),u(E),u(me),u(ce),u(pe),u(ge,e),u(fe),u(O),u(ue),u(he),u(_e),u(be,e),u(ve),u($e),u(xe),u(Te)}}}const to='{"title":"Data Collator","local":"data-collator","sections":[{"title":"Default data collator","local":"transformers.default_data_collator","sections":[],"depth":2},{"title":"DefaultDataCollator","local":"transformers.DefaultDataCollator","sections":[],"depth":2},{"title":"DataCollatorWithPadding","local":"transformers.DataCollatorWithPadding","sections":[],"depth":2},{"title":"DataCollatorForTokenClassification","local":"transformers.DataCollatorForTokenClassification","sections":[],"depth":2},{"title":"DataCollatorForSeq2Seq","local":"transformers.DataCollatorForSeq2Seq","sections":[],"depth":2},{"title":"DataCollatorForLanguageModeling","local":"transformers.DataCollatorForLanguageModeling","sections":[],"depth":2},{"title":"DataCollatorForWholeWordMask","local":"transformers.DataCollatorForWholeWordMask","sections":[],"depth":2},{"title":"DataCollatorForPermutationLanguageModeling","local":"transformers.DataCollatorForPermutationLanguageModeling","sections":[],"depth":2}],"depth":1}';function ao(ye){return Ra(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class io extends Xa{constructor(h){super(),Ga(this,h,ao,eo,Ka,{})}}export{io as component};
