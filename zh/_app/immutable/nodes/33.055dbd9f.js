import{s as dn,n as pn,o as cn}from"../chunks/scheduler.9991993c.js";import{S as gn,i as un,g as a,s as r,r as l,A as hn,h as s,f as n,c as o,j as _,u as f,x as u,k as $,y as t,a as m,v as d,d as p,t as c,w as g}from"../chunks/index.7fc9a5e7.js";import{D as v}from"../chunks/Docstring.8180f571.js";import{H as ue}from"../chunks/Heading.e3de321f.js";function xn(Vt){let O,Ie,Fe,Ee,W,Se,Q,Ht="ğŸ¤— Transformersæä¾›äº†ä¸€ä¸ª<code>transformers.onnx</code>åŒ…ï¼Œé€šè¿‡åˆ©ç”¨é…ç½®å¯¹è±¡ï¼Œæ‚¨å¯ä»¥å°†æ¨¡å‹checkpointsè½¬æ¢ä¸ºONNXå›¾ã€‚",ze,V,Xt='æœ‰å…³æ›´å¤šè¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…å¯¼å‡º ğŸ¤— Transformers æ¨¡å‹çš„<a href="../serialization">æŒ‡å—</a>ã€‚',We,H,Qe,X,At="æˆ‘ä»¬æä¾›äº†ä¸‰ä¸ªæŠ½è±¡ç±»ï¼Œå–å†³äºæ‚¨å¸Œæœ›å¯¼å‡ºçš„æ¨¡å‹æ¶æ„ç±»å‹ï¼š",Ve,A,jt='<li>åŸºäºç¼–ç å™¨çš„æ¨¡å‹ç»§æ‰¿ <a href="/docs/transformers/main/zh/main_classes/onnx#transformers.onnx.OnnxConfig">OnnxConfig</a></li> <li>åŸºäºè§£ç å™¨çš„æ¨¡å‹ç»§æ‰¿ <a href="/docs/transformers/main/zh/main_classes/onnx#transformers.onnx.OnnxConfigWithPast">OnnxConfigWithPast</a></li> <li>ç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ç»§æ‰¿ <a href="/docs/transformers/main/zh/main_classes/onnx#transformers.onnx.OnnxSeq2SeqConfigWithPast">OnnxSeq2SeqConfigWithPast</a></li>',He,j,Xe,h,U,pt,he,Ut="Base class for ONNX exportable model describing metadata on how to export the model through the ONNX format.",ct,T,G,gt,xe,Gt=`Flatten any potential nested structure expanding the name of the field with the index of the element within the
structure.`,ut,P,R,ht,_e,Rt="Instantiate a OnnxConfig for a specific model",xt,k,B,_t,$e,Bt="Generate inputs to provide to the ONNX exporter for the specific framework",$t,M,J,vt,ve,Jt=`Generate inputs for ONNX Runtime using the reference model inputs. Override this to run inference with seq2seq
models which have the encoder and decoder exported as separate ONNX files.`,bt,q,K,Ct,be,Kt="Flag indicating if the model requires using external data format",Ae,Y,je,w,Z,yt,D,ee,wt,Ce,Yt="Fill the input_or_outputs mapping with past_key_values dynamic axes considering.",Ot,N,te,Tt,ye,Zt="Instantiate a OnnxConfig with <code>use_past</code> attribute set to True",Ue,ne,Ge,re,oe,Re,ae,Be,se,en="æ¯ä¸ªONNXé…ç½®ä¸ä¸€ç»„ <em>ç‰¹æ€§</em> ç›¸å…³è”ï¼Œä½¿æ‚¨èƒ½å¤Ÿä¸ºä¸åŒç±»å‹çš„æ‹“æ‰‘ç»“æ„æˆ–ä»»åŠ¡å¯¼å‡ºæ¨¡å‹ã€‚",Je,ie,Ke,x,me,Pt,F,le,kt,we,tn="Check whether or not the model has the requested features.",Mt,y,fe,qt,Oe,nn="Determines the framework to use for the export.",Dt,Te,rn="The priority is in the following order:",Nt,Pe,on="<li>User input via <code>framework</code>.</li> <li>If local checkpoint is provided, use the same framework as the checkpoint.</li> <li>Available framework in environment, with priority given to PyTorch</li>",Ft,L,de,Lt,ke,an="Gets the OnnxConfig for a model_type and feature combination.",It,I,pe,Et,Me,sn="Attempts to retrieve an AutoModel class from a feature name.",St,E,ce,zt,qe,mn="Attempts to retrieve a model from a modelâ€™s name and the feature to be enabled.",Wt,S,ge,Qt,De,ln="Tries to retrieve the feature -> OnnxConfig constructor map from the model type.",Ye,Le,Ze;return W=new ue({props:{title:"å¯¼å‡º ğŸ¤— Transformers æ¨¡å‹åˆ° ONNX",local:"å¯¼å‡º--transformers-æ¨¡å‹åˆ°-onnx",headingTag:"h1"}}),H=new ue({props:{title:"ONNX Configurations",local:"onnx-configurations",headingTag:"h2"}}),j=new ue({props:{title:"OnnxConfig",local:"transformers.onnx.OnnxConfig",headingTag:"h3"}}),U=new v({props:{name:"class transformers.onnx.OnnxConfig",anchor:"transformers.onnx.OnnxConfig",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": List = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L68"}}),G=new v({props:{name:"flatten_output_collection_property",anchor:"transformers.onnx.OnnxConfig.flatten_output_collection_property",parameters:[{name:"name",val:": str"},{name:"field",val:": Iterable"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L424",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>Outputs with flattened structure and key mapping this new structure.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(Dict[str, Any])</p>
`}}),R=new v({props:{name:"from_model_config",anchor:"transformers.onnx.OnnxConfig.from_model_config",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L127",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>OnnxConfig for this model</p>
`}}),B=new v({props:{name:"generate_dummy_inputs",anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs",parameters:[{name:"preprocessor",val:": Union"},{name:"batch_size",val:": int = -1"},{name:"seq_length",val:": int = -1"},{name:"num_choices",val:": int = -1"},{name:"is_pair",val:": bool = False"},{name:"framework",val:": Optional = None"},{name:"num_channels",val:": int = 3"},{name:"image_width",val:": int = 40"},{name:"image_height",val:": int = 40"},{name:"sampling_rate",val:": int = 22050"},{name:"time_duration",val:": float = 5.0"},{name:"frequency",val:": int = 220"},{name:"tokenizer",val:": PreTrainedTokenizerBase = None"}],parametersDescription:[{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The batch size to export the model for (-1 means dynamic axis).`,name:"batch_size"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.num_choices",description:`<strong>num_choices</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The number of candidate answers provided for multiple choice task (-1 means dynamic axis).`,name:"num_choices"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.seq_length",description:`<strong>seq_length</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The sequence length to export the model for (-1 means dynamic axis).`,name:"seq_length"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.is_pair",description:`<strong>is_pair</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Indicate if the input is a pair (sentence 1, sentence 2)`,name:"is_pair"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.framework",description:`<strong>framework</strong> (<code>TensorType</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework (PyTorch or TensorFlow) that the tokenizer will generate tensors for.`,name:"framework"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.num_channels",description:`<strong>num_channels</strong> (<code>int</code>, <em>optional</em>, defaults to 3) &#x2014;
The number of channels of the generated images.`,name:"num_channels"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.image_width",description:`<strong>image_width</strong> (<code>int</code>, <em>optional</em>, defaults to 40) &#x2014;
The width of the generated images.`,name:"image_width"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.image_height",description:`<strong>image_height</strong> (<code>int</code>, <em>optional</em>, defaults to 40) &#x2014;
The height of the generated images.`,name:"image_height"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.sampling_rate",description:`<strong>sampling_rate</strong> (<code>int</code>, <em>optional</em> defaults to 22050) &#x2014;
The sampling rate for audio data generation.`,name:"sampling_rate"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.time_duration",description:`<strong>time_duration</strong> (<code>float</code>, <em>optional</em> defaults to 5.0) &#x2014;
Total seconds of sampling for audio data generation.`,name:"time_duration"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.frequency",description:`<strong>frequency</strong> (<code>int</code>, <em>optional</em> defaults to 220) &#x2014;
The desired natural frequency of generated audio.`,name:"frequency"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L280",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>Mapping[str, Tensor] holding the kwargs to provide to the modelâ€™s forward function</p>
`}}),J=new v({props:{name:"generate_dummy_inputs_onnxruntime",anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs_onnxruntime",parameters:[{name:"reference_model_inputs",val:": Mapping"}],parametersDescription:[{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs_onnxruntime.reference_model_inputs",description:`<strong>reference_model_inputs</strong> ([<code>Mapping[str, Tensor]</code>) &#x2014;
Reference inputs for the model.`,name:"reference_model_inputs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L400",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The mapping holding the kwargs to provide to the modelâ€™s forward function</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>Mapping[str, Tensor]</code></p>
`}}),K=new v({props:{name:"use_external_data_format",anchor:"transformers.onnx.OnnxConfig.use_external_data_format",parameters:[{name:"num_parameters",val:": int"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L241",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>True if model.num_parameters() * size_of(float32) >= 2Gb False otherwise</p>
`}}),Y=new ue({props:{title:"OnnxConfigWithPast",local:"transformers.onnx.OnnxConfigWithPast",headingTag:"h3"}}),Z=new v({props:{name:"class transformers.onnx.OnnxConfigWithPast",anchor:"transformers.onnx.OnnxConfigWithPast",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": List = None"},{name:"use_past",val:": bool = False"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L443"}}),ee=new v({props:{name:"fill_with_past_key_values_",anchor:"transformers.onnx.OnnxConfigWithPast.fill_with_past_key_values_",parameters:[{name:"inputs_or_outputs",val:": Mapping"},{name:"direction",val:": str"},{name:"inverted_values_shape",val:": bool = False"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L550"}}),te=new v({props:{name:"with_past",anchor:"transformers.onnx.OnnxConfigWithPast.with_past",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L454",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>OnnxConfig with <code>.use_past = True</code></p>
`}}),ne=new ue({props:{title:"OnnxSeq2SeqConfigWithPast",local:"transformers.onnx.OnnxSeq2SeqConfigWithPast",headingTag:"h3"}}),oe=new v({props:{name:"class transformers.onnx.OnnxSeq2SeqConfigWithPast",anchor:"transformers.onnx.OnnxSeq2SeqConfigWithPast",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": List = None"},{name:"use_past",val:": bool = False"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L590"}}),ae=new ue({props:{title:"ONNX Features",local:"onnx-features",headingTag:"h2"}}),ie=new ue({props:{title:"FeaturesManager",local:"transformers.onnx.FeaturesManager",headingTag:"h3"}}),me=new v({props:{name:"class transformers.onnx.FeaturesManager",anchor:"transformers.onnx.FeaturesManager",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L85"}}),le=new v({props:{name:"check_supported_model_or_raise",anchor:"transformers.onnx.FeaturesManager.check_supported_model_or_raise",parameters:[{name:"model",val:": Union"},{name:"feature",val:": str = 'default'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L711",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(str) The type of the model (OnnxConfig) The OnnxConfig instance holding the model export properties.</p>
`}}),fe=new v({props:{name:"determine_framework",anchor:"transformers.onnx.FeaturesManager.determine_framework",parameters:[{name:"model",val:": str"},{name:"framework",val:": str = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.determine_framework.model",description:`<strong>model</strong> (<code>str</code>) &#x2014;
The name of the model to export.`,name:"model"},{anchor:"transformers.onnx.FeaturesManager.determine_framework.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework to use for the export. See above for priority if none provided.`,name:"framework"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L628",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The framework to use for the export.</p>
`}}),de=new v({props:{name:"get_config",anchor:"transformers.onnx.FeaturesManager.get_config",parameters:[{name:"model_type",val:": str"},{name:"feature",val:": str"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_config.model_type",description:`<strong>model_type</strong> (<code>str</code>) &#x2014;
The model type to retrieve the config for.`,name:"model_type"},{anchor:"transformers.onnx.FeaturesManager.get_config.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature to retrieve the config for.`,name:"feature"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L736",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>config for the combination</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>OnnxConfig</code></p>
`}}),pe=new v({props:{name:"get_model_class_for_feature",anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature",parameters:[{name:"feature",val:": str"},{name:"framework",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature required.`,name:"feature"},{anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The framework to use for the export.`,name:"framework"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L601",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The AutoModel class corresponding to the feature.</p>
`}}),ce=new v({props:{name:"get_model_from_feature",anchor:"transformers.onnx.FeaturesManager.get_model_from_feature",parameters:[{name:"feature",val:": str"},{name:"model",val:": str"},{name:"framework",val:": str = None"},{name:"cache_dir",val:": str = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature required.`,name:"feature"},{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.model",description:`<strong>model</strong> (<code>str</code>) &#x2014;
The name of the model to export.`,name:"model"},{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework to use for the export. See <code>FeaturesManager.determine_framework</code> for the priority should
none be provided.`,name:"framework"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L678",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The instance of the model.</p>
`}}),ge=new v({props:{name:"get_supported_features_for_model_type",anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type",parameters:[{name:"model_type",val:": str"},{name:"model_name",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type.model_type",description:`<strong>model_type</strong> (<code>str</code>) &#x2014;
The model type to retrieve the supported features for.`,name:"model_type"},{anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type.model_name",description:`<strong>model_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name attribute of the model object, only used for the exception message.`,name:"model_name"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L556",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The dictionary mapping each feature to a corresponding OnnxConfig constructor.</p>
`}}),{c(){O=a("meta"),Ie=r(),Fe=a("p"),Ee=r(),l(W.$$.fragment),Se=r(),Q=a("p"),Q.innerHTML=Ht,ze=r(),V=a("p"),V.innerHTML=Xt,We=r(),l(H.$$.fragment),Qe=r(),X=a("p"),X.textContent=At,Ve=r(),A=a("ul"),A.innerHTML=jt,He=r(),l(j.$$.fragment),Xe=r(),h=a("div"),l(U.$$.fragment),pt=r(),he=a("p"),he.textContent=Ut,ct=r(),T=a("div"),l(G.$$.fragment),gt=r(),xe=a("p"),xe.textContent=Gt,ut=r(),P=a("div"),l(R.$$.fragment),ht=r(),_e=a("p"),_e.textContent=Rt,xt=r(),k=a("div"),l(B.$$.fragment),_t=r(),$e=a("p"),$e.textContent=Bt,$t=r(),M=a("div"),l(J.$$.fragment),vt=r(),ve=a("p"),ve.textContent=Jt,bt=r(),q=a("div"),l(K.$$.fragment),Ct=r(),be=a("p"),be.textContent=Kt,Ae=r(),l(Y.$$.fragment),je=r(),w=a("div"),l(Z.$$.fragment),yt=r(),D=a("div"),l(ee.$$.fragment),wt=r(),Ce=a("p"),Ce.textContent=Yt,Ot=r(),N=a("div"),l(te.$$.fragment),Tt=r(),ye=a("p"),ye.innerHTML=Zt,Ue=r(),l(ne.$$.fragment),Ge=r(),re=a("div"),l(oe.$$.fragment),Re=r(),l(ae.$$.fragment),Be=r(),se=a("p"),se.innerHTML=en,Je=r(),l(ie.$$.fragment),Ke=r(),x=a("div"),l(me.$$.fragment),Pt=r(),F=a("div"),l(le.$$.fragment),kt=r(),we=a("p"),we.textContent=tn,Mt=r(),y=a("div"),l(fe.$$.fragment),qt=r(),Oe=a("p"),Oe.textContent=nn,Dt=r(),Te=a("p"),Te.textContent=rn,Nt=r(),Pe=a("ol"),Pe.innerHTML=on,Ft=r(),L=a("div"),l(de.$$.fragment),Lt=r(),ke=a("p"),ke.textContent=an,It=r(),I=a("div"),l(pe.$$.fragment),Et=r(),Me=a("p"),Me.textContent=sn,St=r(),E=a("div"),l(ce.$$.fragment),zt=r(),qe=a("p"),qe.textContent=mn,Wt=r(),S=a("div"),l(ge.$$.fragment),Qt=r(),De=a("p"),De.textContent=ln,Ye=r(),Le=a("p"),this.h()},l(e){const i=hn("svelte-u9bgzb",document.head);O=s(i,"META",{name:!0,content:!0}),i.forEach(n),Ie=o(e),Fe=s(e,"P",{}),_(Fe).forEach(n),Ee=o(e),f(W.$$.fragment,e),Se=o(e),Q=s(e,"P",{"data-svelte-h":!0}),u(Q)!=="svelte-pfau1i"&&(Q.innerHTML=Ht),ze=o(e),V=s(e,"P",{"data-svelte-h":!0}),u(V)!=="svelte-4zmuwp"&&(V.innerHTML=Xt),We=o(e),f(H.$$.fragment,e),Qe=o(e),X=s(e,"P",{"data-svelte-h":!0}),u(X)!=="svelte-k36o3g"&&(X.textContent=At),Ve=o(e),A=s(e,"UL",{"data-svelte-h":!0}),u(A)!=="svelte-1fnebdo"&&(A.innerHTML=jt),He=o(e),f(j.$$.fragment,e),Xe=o(e),h=s(e,"DIV",{class:!0});var b=_(h);f(U.$$.fragment,b),pt=o(b),he=s(b,"P",{"data-svelte-h":!0}),u(he)!=="svelte-1gqzpaz"&&(he.textContent=Ut),ct=o(b),T=s(b,"DIV",{class:!0});var et=_(T);f(G.$$.fragment,et),gt=o(et),xe=s(et,"P",{"data-svelte-h":!0}),u(xe)!=="svelte-1lfqihc"&&(xe.textContent=Gt),et.forEach(n),ut=o(b),P=s(b,"DIV",{class:!0});var tt=_(P);f(R.$$.fragment,tt),ht=o(tt),_e=s(tt,"P",{"data-svelte-h":!0}),u(_e)!=="svelte-1u54gj1"&&(_e.textContent=Rt),tt.forEach(n),xt=o(b),k=s(b,"DIV",{class:!0});var nt=_(k);f(B.$$.fragment,nt),_t=o(nt),$e=s(nt,"P",{"data-svelte-h":!0}),u($e)!=="svelte-1oyyynq"&&($e.textContent=Bt),nt.forEach(n),$t=o(b),M=s(b,"DIV",{class:!0});var rt=_(M);f(J.$$.fragment,rt),vt=o(rt),ve=s(rt,"P",{"data-svelte-h":!0}),u(ve)!=="svelte-tenqiw"&&(ve.textContent=Jt),rt.forEach(n),bt=o(b),q=s(b,"DIV",{class:!0});var ot=_(q);f(K.$$.fragment,ot),Ct=o(ot),be=s(ot,"P",{"data-svelte-h":!0}),u(be)!=="svelte-coevd"&&(be.textContent=Kt),ot.forEach(n),b.forEach(n),Ae=o(e),f(Y.$$.fragment,e),je=o(e),w=s(e,"DIV",{class:!0});var Ne=_(w);f(Z.$$.fragment,Ne),yt=o(Ne),D=s(Ne,"DIV",{class:!0});var at=_(D);f(ee.$$.fragment,at),wt=o(at),Ce=s(at,"P",{"data-svelte-h":!0}),u(Ce)!=="svelte-1bh80il"&&(Ce.textContent=Yt),at.forEach(n),Ot=o(Ne),N=s(Ne,"DIV",{class:!0});var st=_(N);f(te.$$.fragment,st),Tt=o(st),ye=s(st,"P",{"data-svelte-h":!0}),u(ye)!=="svelte-1kg2yu2"&&(ye.innerHTML=Zt),st.forEach(n),Ne.forEach(n),Ue=o(e),f(ne.$$.fragment,e),Ge=o(e),re=s(e,"DIV",{class:!0});var fn=_(re);f(oe.$$.fragment,fn),fn.forEach(n),Re=o(e),f(ae.$$.fragment,e),Be=o(e),se=s(e,"P",{"data-svelte-h":!0}),u(se)!=="svelte-1vrkova"&&(se.innerHTML=en),Je=o(e),f(ie.$$.fragment,e),Ke=o(e),x=s(e,"DIV",{class:!0});var C=_(x);f(me.$$.fragment,C),Pt=o(C),F=s(C,"DIV",{class:!0});var it=_(F);f(le.$$.fragment,it),kt=o(it),we=s(it,"P",{"data-svelte-h":!0}),u(we)!=="svelte-rlyyl3"&&(we.textContent=tn),it.forEach(n),Mt=o(C),y=s(C,"DIV",{class:!0});var z=_(y);f(fe.$$.fragment,z),qt=o(z),Oe=s(z,"P",{"data-svelte-h":!0}),u(Oe)!=="svelte-rshgf5"&&(Oe.textContent=nn),Dt=o(z),Te=s(z,"P",{"data-svelte-h":!0}),u(Te)!=="svelte-1wbth9c"&&(Te.textContent=rn),Nt=o(z),Pe=s(z,"OL",{"data-svelte-h":!0}),u(Pe)!=="svelte-qby6wj"&&(Pe.innerHTML=on),z.forEach(n),Ft=o(C),L=s(C,"DIV",{class:!0});var mt=_(L);f(de.$$.fragment,mt),Lt=o(mt),ke=s(mt,"P",{"data-svelte-h":!0}),u(ke)!=="svelte-il0adz"&&(ke.textContent=an),mt.forEach(n),It=o(C),I=s(C,"DIV",{class:!0});var lt=_(I);f(pe.$$.fragment,lt),Et=o(lt),Me=s(lt,"P",{"data-svelte-h":!0}),u(Me)!=="svelte-k5ftuy"&&(Me.textContent=sn),lt.forEach(n),St=o(C),E=s(C,"DIV",{class:!0});var ft=_(E);f(ce.$$.fragment,ft),zt=o(ft),qe=s(ft,"P",{"data-svelte-h":!0}),u(qe)!=="svelte-auvjm5"&&(qe.textContent=mn),ft.forEach(n),Wt=o(C),S=s(C,"DIV",{class:!0});var dt=_(S);f(ge.$$.fragment,dt),Qt=o(dt),De=s(dt,"P",{"data-svelte-h":!0}),u(De)!=="svelte-tbalh5"&&(De.textContent=ln),dt.forEach(n),C.forEach(n),Ye=o(e),Le=s(e,"P",{}),_(Le).forEach(n),this.h()},h(){$(O,"name","hf:doc:metadata"),$(O,"content",_n),$(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),$(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,i){t(document.head,O),m(e,Ie,i),m(e,Fe,i),m(e,Ee,i),d(W,e,i),m(e,Se,i),m(e,Q,i),m(e,ze,i),m(e,V,i),m(e,We,i),d(H,e,i),m(e,Qe,i),m(e,X,i),m(e,Ve,i),m(e,A,i),m(e,He,i),d(j,e,i),m(e,Xe,i),m(e,h,i),d(U,h,null),t(h,pt),t(h,he),t(h,ct),t(h,T),d(G,T,null),t(T,gt),t(T,xe),t(h,ut),t(h,P),d(R,P,null),t(P,ht),t(P,_e),t(h,xt),t(h,k),d(B,k,null),t(k,_t),t(k,$e),t(h,$t),t(h,M),d(J,M,null),t(M,vt),t(M,ve),t(h,bt),t(h,q),d(K,q,null),t(q,Ct),t(q,be),m(e,Ae,i),d(Y,e,i),m(e,je,i),m(e,w,i),d(Z,w,null),t(w,yt),t(w,D),d(ee,D,null),t(D,wt),t(D,Ce),t(w,Ot),t(w,N),d(te,N,null),t(N,Tt),t(N,ye),m(e,Ue,i),d(ne,e,i),m(e,Ge,i),m(e,re,i),d(oe,re,null),m(e,Re,i),d(ae,e,i),m(e,Be,i),m(e,se,i),m(e,Je,i),d(ie,e,i),m(e,Ke,i),m(e,x,i),d(me,x,null),t(x,Pt),t(x,F),d(le,F,null),t(F,kt),t(F,we),t(x,Mt),t(x,y),d(fe,y,null),t(y,qt),t(y,Oe),t(y,Dt),t(y,Te),t(y,Nt),t(y,Pe),t(x,Ft),t(x,L),d(de,L,null),t(L,Lt),t(L,ke),t(x,It),t(x,I),d(pe,I,null),t(I,Et),t(I,Me),t(x,St),t(x,E),d(ce,E,null),t(E,zt),t(E,qe),t(x,Wt),t(x,S),d(ge,S,null),t(S,Qt),t(S,De),m(e,Ye,i),m(e,Le,i),Ze=!0},p:pn,i(e){Ze||(p(W.$$.fragment,e),p(H.$$.fragment,e),p(j.$$.fragment,e),p(U.$$.fragment,e),p(G.$$.fragment,e),p(R.$$.fragment,e),p(B.$$.fragment,e),p(J.$$.fragment,e),p(K.$$.fragment,e),p(Y.$$.fragment,e),p(Z.$$.fragment,e),p(ee.$$.fragment,e),p(te.$$.fragment,e),p(ne.$$.fragment,e),p(oe.$$.fragment,e),p(ae.$$.fragment,e),p(ie.$$.fragment,e),p(me.$$.fragment,e),p(le.$$.fragment,e),p(fe.$$.fragment,e),p(de.$$.fragment,e),p(pe.$$.fragment,e),p(ce.$$.fragment,e),p(ge.$$.fragment,e),Ze=!0)},o(e){c(W.$$.fragment,e),c(H.$$.fragment,e),c(j.$$.fragment,e),c(U.$$.fragment,e),c(G.$$.fragment,e),c(R.$$.fragment,e),c(B.$$.fragment,e),c(J.$$.fragment,e),c(K.$$.fragment,e),c(Y.$$.fragment,e),c(Z.$$.fragment,e),c(ee.$$.fragment,e),c(te.$$.fragment,e),c(ne.$$.fragment,e),c(oe.$$.fragment,e),c(ae.$$.fragment,e),c(ie.$$.fragment,e),c(me.$$.fragment,e),c(le.$$.fragment,e),c(fe.$$.fragment,e),c(de.$$.fragment,e),c(pe.$$.fragment,e),c(ce.$$.fragment,e),c(ge.$$.fragment,e),Ze=!1},d(e){e&&(n(Ie),n(Fe),n(Ee),n(Se),n(Q),n(ze),n(V),n(We),n(Qe),n(X),n(Ve),n(A),n(He),n(Xe),n(h),n(Ae),n(je),n(w),n(Ue),n(Ge),n(re),n(Re),n(Be),n(se),n(Je),n(Ke),n(x),n(Ye),n(Le)),n(O),g(W,e),g(H,e),g(j,e),g(U),g(G),g(R),g(B),g(J),g(K),g(Y,e),g(Z),g(ee),g(te),g(ne,e),g(oe),g(ae,e),g(ie,e),g(me),g(le),g(fe),g(de),g(pe),g(ce),g(ge)}}}const _n='{"title":"å¯¼å‡º ğŸ¤— Transformers æ¨¡å‹åˆ° ONNX","local":"å¯¼å‡º--transformers-æ¨¡å‹åˆ°-onnx","sections":[{"title":"ONNX Configurations","local":"onnx-configurations","sections":[{"title":"OnnxConfig","local":"transformers.onnx.OnnxConfig","sections":[],"depth":3},{"title":"OnnxConfigWithPast","local":"transformers.onnx.OnnxConfigWithPast","sections":[],"depth":3},{"title":"OnnxSeq2SeqConfigWithPast","local":"transformers.onnx.OnnxSeq2SeqConfigWithPast","sections":[],"depth":3}],"depth":2},{"title":"ONNX Features","local":"onnx-features","sections":[{"title":"FeaturesManager","local":"transformers.onnx.FeaturesManager","sections":[],"depth":3}],"depth":2}],"depth":1}';function $n(Vt){return cn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class wn extends gn{constructor(O){super(),un(this,O,$n,xn,dn,{})}}export{wn as component};
