import{s as Ve,o as Xe,n as cs}from"../chunks/scheduler.9bc65507.js";import{S as We,i as Be,g as b,s as i,r as d,A as ve,h as T,f as a,c,j as Ze,u as y,x as g,k as Ie,y as Ae,a as t,v as u,d as j,t as f,w,m as Ge,n as Re}from"../chunks/index.707bf1b6.js";import{T as me}from"../chunks/Tip.c2ecdbf4.js";import{C as R}from"../chunks/CodeBlock.54a9f38d.js";import{D as xe}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as Me,M as vs}from"../chunks/Markdown.fef84341.js";import{H as Bs}from"../chunks/Heading.342b1fa6.js";function Ye(_){let l,o,e='<a href="../model_doc/albert">ALBERT</a>, <a href="../model_doc/bert">BERT</a>, <a href="../model_doc/big_bird">BigBird</a>, <a href="../model_doc/camembert">CamemBERT</a>, <a href="../model_doc/canine">CANINE</a>, <a href="../model_doc/convbert">ConvBERT</a>, <a href="../model_doc/data2vec-text">Data2VecText</a>, <a href="../model_doc/deberta-v2">DeBERTa-v2</a>, <a href="../model_doc/distilbert">DistilBERT</a>, <a href="../model_doc/electra">ELECTRA</a>, <a href="../model_doc/ernie">ERNIE</a>, <a href="../model_doc/ernie_m">ErnieM</a>, <a href="../model_doc/flaubert">FlauBERT</a>, <a href="../model_doc/fnet">FNet</a>, <a href="../model_doc/funnel">Funnel Transformer</a>, <a href="../model_doc/ibert">I-BERT</a>, <a href="../model_doc/longformer">Longformer</a>, <a href="../model_doc/luke">LUKE</a>, <a href="../model_doc/mega">MEGA</a>, <a href="../model_doc/megatron-bert">Megatron-BERT</a>, <a href="../model_doc/mobilebert">MobileBERT</a>, <a href="../model_doc/mpnet">MPNet</a>, <a href="../model_doc/mra">MRA</a>, <a href="../model_doc/nezha">Nezha</a>, <a href="../model_doc/nystromformer">Nystr√∂mformer</a>, <a href="../model_doc/qdqbert">QDQBert</a>, <a href="../model_doc/rembert">RemBERT</a>, <a href="../model_doc/roberta">RoBERTa</a>, <a href="../model_doc/roberta-prelayernorm">RoBERTa-PreLayerNorm</a>, <a href="../model_doc/roc_bert">RoCBert</a>, <a href="../model_doc/roformer">RoFormer</a>, <a href="../model_doc/squeezebert">SqueezeBERT</a>, <a href="../model_doc/xlm">XLM</a>, <a href="../model_doc/xlm-roberta">XLM-RoBERTa</a>, <a href="../model_doc/xlm-roberta-xl">XLM-RoBERTa-XL</a>, <a href="../model_doc/xlnet">XLNet</a>, <a href="../model_doc/xmod">X-MOD</a>, <a href="../model_doc/yoso">YOSO</a>';return{c(){l=Ge(`The task illustrated in this tutorial is supported by the following model architectures:

`),o=b("p"),o.innerHTML=e},l(m){l=Re(m,`The task illustrated in this tutorial is supported by the following model architectures:

`),o=T(m,"P",{"data-svelte-h":!0}),g(o)!=="svelte-nxrbbi"&&(o.innerHTML=e)},m(m,h){t(m,l,h),t(m,o,h)},p:cs,d(m){m&&(a(l),a(o))}}}function Ee(_){let l,o;return l=new R({props:{code:"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",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.tokenization_utils_base <span class="hljs-keyword">import</span> PreTrainedTokenizerBase, PaddingStrategy
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">Union</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch


<span class="hljs-meta">&gt;&gt;&gt; </span>@dataclass
<span class="hljs-meta">... </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataCollatorForMultipleChoice</span>:
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;&quot;&quot;
<span class="hljs-meta">... </span>    Data collator that will dynamically pad the inputs for multiple choice received.
<span class="hljs-meta">... </span>    &quot;&quot;&quot;</span>

<span class="hljs-meta">... </span>    tokenizer: PreTrainedTokenizerBase
<span class="hljs-meta">... </span>    padding: <span class="hljs-type">Union</span>[<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">str</span>, PaddingStrategy] = <span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>    max_length: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>
<span class="hljs-meta">... </span>    pad_to_multiple_of: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>

<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, features</span>):
<span class="hljs-meta">... </span>        label_name = <span class="hljs-string">&quot;label&quot;</span> <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;label&quot;</span> <span class="hljs-keyword">in</span> features[<span class="hljs-number">0</span>].keys() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;labels&quot;</span>
<span class="hljs-meta">... </span>        labels = [feature.pop(label_name) <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features]
<span class="hljs-meta">... </span>        batch_size = <span class="hljs-built_in">len</span>(features)
<span class="hljs-meta">... </span>        num_choices = <span class="hljs-built_in">len</span>(features[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-meta">... </span>        flattened_features = [
<span class="hljs-meta">... </span>            [{k: v[i] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> feature.items()} <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_choices)] <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features
<span class="hljs-meta">... </span>        ]
<span class="hljs-meta">... </span>        flattened_features = <span class="hljs-built_in">sum</span>(flattened_features, [])

<span class="hljs-meta">... </span>        batch = self.tokenizer.pad(
<span class="hljs-meta">... </span>            flattened_features,
<span class="hljs-meta">... </span>            padding=self.padding,
<span class="hljs-meta">... </span>            max_length=self.max_length,
<span class="hljs-meta">... </span>            pad_to_multiple_of=self.pad_to_multiple_of,
<span class="hljs-meta">... </span>            return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>        )

<span class="hljs-meta">... </span>        batch = {k: v.view(batch_size, num_choices, -<span class="hljs-number">1</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        batch[<span class="hljs-string">&quot;labels&quot;</span>] = torch.tensor(labels, dtype=torch.int64)
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> batch`,wrap:!1}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p:cs,i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function Fe(_){let l,o;return l=new vs({props:{$$slots:{default:[Ee]},$$scope:{ctx:_}}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p(e,m){const h={};m&2&&(h.$$scope={dirty:m,ctx:e}),l.$set(h)},i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function Ne(_){let l,o;return l=new R({props:{code:"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",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> dataclasses <span class="hljs-keyword">import</span> dataclass
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.tokenization_utils_base <span class="hljs-keyword">import</span> PreTrainedTokenizerBase, PaddingStrategy
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Optional</span>, <span class="hljs-type">Union</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf


<span class="hljs-meta">&gt;&gt;&gt; </span>@dataclass
<span class="hljs-meta">... </span><span class="hljs-keyword">class</span> <span class="hljs-title class_">DataCollatorForMultipleChoice</span>:
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;&quot;&quot;
<span class="hljs-meta">... </span>    Data collator that will dynamically pad the inputs for multiple choice received.
<span class="hljs-meta">... </span>    &quot;&quot;&quot;</span>

<span class="hljs-meta">... </span>    tokenizer: PreTrainedTokenizerBase
<span class="hljs-meta">... </span>    padding: <span class="hljs-type">Union</span>[<span class="hljs-built_in">bool</span>, <span class="hljs-built_in">str</span>, PaddingStrategy] = <span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>    max_length: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>
<span class="hljs-meta">... </span>    pad_to_multiple_of: <span class="hljs-type">Optional</span>[<span class="hljs-built_in">int</span>] = <span class="hljs-literal">None</span>

<span class="hljs-meta">... </span>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, features</span>):
<span class="hljs-meta">... </span>        label_name = <span class="hljs-string">&quot;label&quot;</span> <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;label&quot;</span> <span class="hljs-keyword">in</span> features[<span class="hljs-number">0</span>].keys() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;labels&quot;</span>
<span class="hljs-meta">... </span>        labels = [feature.pop(label_name) <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features]
<span class="hljs-meta">... </span>        batch_size = <span class="hljs-built_in">len</span>(features)
<span class="hljs-meta">... </span>        num_choices = <span class="hljs-built_in">len</span>(features[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-meta">... </span>        flattened_features = [
<span class="hljs-meta">... </span>            [{k: v[i] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> feature.items()} <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_choices)] <span class="hljs-keyword">for</span> feature <span class="hljs-keyword">in</span> features
<span class="hljs-meta">... </span>        ]
<span class="hljs-meta">... </span>        flattened_features = <span class="hljs-built_in">sum</span>(flattened_features, [])

<span class="hljs-meta">... </span>        batch = self.tokenizer.pad(
<span class="hljs-meta">... </span>            flattened_features,
<span class="hljs-meta">... </span>            padding=self.padding,
<span class="hljs-meta">... </span>            max_length=self.max_length,
<span class="hljs-meta">... </span>            pad_to_multiple_of=self.pad_to_multiple_of,
<span class="hljs-meta">... </span>            return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>        )

<span class="hljs-meta">... </span>        batch = {k: tf.reshape(v, (batch_size, num_choices, -<span class="hljs-number">1</span>)) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> batch.items()}
<span class="hljs-meta">... </span>        batch[<span class="hljs-string">&quot;labels&quot;</span>] = tf.convert_to_tensor(labels, dtype=tf.int64)
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> batch`,wrap:!1}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p:cs,i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function ze(_){let l,o;return l=new vs({props:{$$slots:{default:[Ne]},$$scope:{ctx:_}}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p(e,m){const h={};m&2&&(h.$$scope={dirty:m,ctx:e}),l.$set(h)},i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function Qe(_){let l,o='If you aren‚Äôt familiar with finetuning a model with the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a>, take a look at the basic tutorial <a href="../training#train-with-pytorch-trainer">here</a>!';return{c(){l=b("p"),l.innerHTML=o},l(e){l=T(e,"P",{"data-svelte-h":!0}),g(l)!=="svelte-15s4um0"&&(l.innerHTML=o)},m(e,m){t(e,l,m)},p:cs,d(e){e&&a(l)}}}function He(_){let l,o,e,m='You‚Äôre ready to start training your model now! Load BERT with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForMultipleChoice">AutoModelForMultipleChoice</a>:',h,C,B,I,k="At this point, only three steps remain:",X,Z,v='<li>Define your training hyperparameters in <a href="/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. The only required parameter is <code>output_dir</code> which specifies where to save your model. You‚Äôll push this model to the Hub by setting <code>push_to_hub=True</code> (you need to be signed in to Hugging Face to upload your model). At the end of each epoch, the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> will evaluate the accuracy and save the training checkpoint.</li> <li>Pass the training arguments to <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> along with the model, dataset, tokenizer, data collator, and <code>compute_metrics</code> function.</li> <li>Call <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train">train()</a> to finetune your model.</li>',W,$,G,r,U='Once training is completed, share your model to the Hub with the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> method so everyone can use your model:',A,E,x;return l=new me({props:{$$slots:{default:[Qe]},$$scope:{ctx:_}}}),C=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvck11bHRpcGxlQ2hvaWNlJTJDJTIwVHJhaW5pbmdBcmd1bWVudHMlMkMlMjBUcmFpbmVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNdWx0aXBsZUNob2ljZS5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMultipleChoice, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),$=new R({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX3N3YWdfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjBldmFsdWF0aW9uX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyZXBvY2glMjIlMkMlMEElMjAlMjAlMjAlMjBsb2FkX2Jlc3RfbW9kZWxfYXRfZW5kJTNEVHJ1ZSUyQyUwQSUyMCUyMCUyMCUyMGxlYXJuaW5nX3JhdGUlM0Q1ZS01JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX2V2YWxfYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwbnVtX3RyYWluX2Vwb2NocyUzRDMlMkMlMEElMjAlMjAlMjAlMjB3ZWlnaHRfZGVjYXklM0QwLjAxJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0R0b2tlbml6ZWRfc3dhZyU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEdG9rZW5pemVkX3N3YWclNUIlMjJ2YWxpZGF0aW9uJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwdG9rZW5pemVyJTNEdG9rZW5pemVyJTJDJTBBJTIwJTIwJTIwJTIwZGF0YV9jb2xsYXRvciUzRERhdGFDb2xsYXRvckZvck11bHRpcGxlQ2hvaWNlKHRva2VuaXplciUzRHRva2VuaXplciklMkMlMEElMjAlMjAlMjAlMjBjb21wdXRlX21ldHJpY3MlM0Rjb21wdXRlX21ldHJpY3MlMkMlMEEpJTBBJTBBdHJhaW5lci50cmFpbigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_swag_model&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    load_best_model_at_end=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">5e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=tokenized_swag[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=tokenized_swag[<span class="hljs-string">&quot;validation&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=DataCollatorForMultipleChoice(tokenizer=tokenizer),
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),E=new R({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){d(l.$$.fragment),o=i(),e=b("p"),e.innerHTML=m,h=i(),d(C.$$.fragment),B=i(),I=b("p"),I.textContent=k,X=i(),Z=b("ol"),Z.innerHTML=v,W=i(),d($.$$.fragment),G=i(),r=b("p"),r.innerHTML=U,A=i(),d(E.$$.fragment)},l(M){y(l.$$.fragment,M),o=c(M),e=T(M,"P",{"data-svelte-h":!0}),g(e)!=="svelte-2bs5wx"&&(e.innerHTML=m),h=c(M),y(C.$$.fragment,M),B=c(M),I=T(M,"P",{"data-svelte-h":!0}),g(I)!=="svelte-l42k0i"&&(I.textContent=k),X=c(M),Z=T(M,"OL",{"data-svelte-h":!0}),g(Z)!=="svelte-18vvra9"&&(Z.innerHTML=v),W=c(M),y($.$$.fragment,M),G=c(M),r=T(M,"P",{"data-svelte-h":!0}),g(r)!=="svelte-1v13hlo"&&(r.innerHTML=U),A=c(M),y(E.$$.fragment,M)},m(M,V){u(l,M,V),t(M,o,V),t(M,e,V),t(M,h,V),u(C,M,V),t(M,B,V),t(M,I,V),t(M,X,V),t(M,Z,V),t(M,W,V),u($,M,V),t(M,G,V),t(M,r,V),t(M,A,V),u(E,M,V),x=!0},p(M,V){const Y={};V&2&&(Y.$$scope={dirty:V,ctx:M}),l.$set(Y)},i(M){x||(j(l.$$.fragment,M),j(C.$$.fragment,M),j($.$$.fragment,M),j(E.$$.fragment,M),x=!0)},o(M){f(l.$$.fragment,M),f(C.$$.fragment,M),f($.$$.fragment,M),f(E.$$.fragment,M),x=!1},d(M){M&&(a(o),a(e),a(h),a(B),a(I),a(X),a(Z),a(W),a(G),a(r),a(A)),w(l,M),w(C,M),w($,M),w(E,M)}}}function Se(_){let l,o;return l=new vs({props:{$$slots:{default:[He]},$$scope:{ctx:_}}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p(e,m){const h={};m&2&&(h.$$scope={dirty:m,ctx:e}),l.$set(h)},i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function qe(_){let l,o='If you aren‚Äôt familiar with finetuning a model with Keras, take a look at the basic tutorial <a href="../training#train-a-tensorflow-model-with-keras">here</a>!';return{c(){l=b("p"),l.innerHTML=o},l(e){l=T(e,"P",{"data-svelte-h":!0}),g(l)!=="svelte-1rd4nl8"&&(l.innerHTML=o)},m(e,m){t(e,l,m)},p:cs,d(e){e&&a(l)}}}function Le(_){let l,o,e,m,h,C='Then you can load BERT with <a href="/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForMultipleChoice">TFAutoModelForMultipleChoice</a>:',B,I,k,X,Z='Convert your datasets to the <code>tf.data.Dataset</code> format with <a href="/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset">prepare_tf_dataset()</a>:',v,W,$,G,r='Configure the model for training with <a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a>. Note that Transformers models all have a default task-relevant loss function, so you don‚Äôt need to specify one unless you want to:',U,A,E,x,M='The last two things to setup before you start training is to compute the accuracy from the predictions, and provide a way to push your model to the Hub. Both are done by using <a href="../main_classes/keras_callbacks">Keras callbacks</a>.',V,Y,ms='Pass your <code>compute_metrics</code> function to <a href="/docs/transformers/main/en/main_classes/keras_callbacks#transformers.KerasMetricCallback">KerasMetricCallback</a>:',N,ss,ns,F,Ms='Specify where to push your model and tokenizer in the <a href="/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a>:',z,Q,H,es,hs="Then bundle your callbacks together:",S,q,L,ls,ds='Finally, you‚Äôre ready to start training your model! Call <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a> with your training and validation datasets, the number of epochs, and your callbacks to finetune the model:',D,P,K,as,ys="Once training is completed, your model is automatically uploaded to the Hub so everyone can use it!",O;return l=new me({props:{$$slots:{default:[qe]},$$scope:{ctx:_}}}),e=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMEElMEFiYXRjaF9zaXplJTIwJTNEJTIwMTYlMEFudW1fdHJhaW5fZXBvY2hzJTIwJTNEJTIwMiUwQXRvdGFsX3RyYWluX3N0ZXBzJTIwJTNEJTIwKGxlbih0b2tlbml6ZWRfc3dhZyU1QiUyMnRyYWluJTIyJTVEKSUyMCUyRiUyRiUyMGJhdGNoX3NpemUpJTIwKiUyMG51bV90cmFpbl9lcG9jaHMlMEFvcHRpbWl6ZXIlMkMlMjBzY2hlZHVsZSUyMCUzRCUyMGNyZWF0ZV9vcHRpbWl6ZXIoaW5pdF9sciUzRDVlLTUlMkMlMjBudW1fd2FybXVwX3N0ZXBzJTNEMCUyQyUyMG51bV90cmFpbl9zdGVwcyUzRHRvdGFsX3RyYWluX3N0ZXBzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>batch_size = <span class="hljs-number">16</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_train_epochs = <span class="hljs-number">2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>total_train_steps = (<span class="hljs-built_in">len</span>(tokenized_swag[<span class="hljs-string">&quot;train&quot;</span>]) // batch_size) * num_train_epochs
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer, schedule = create_optimizer(init_lr=<span class="hljs-number">5e-5</span>, num_warmup_steps=<span class="hljs-number">0</span>, num_train_steps=total_train_steps)`,wrap:!1}}),I=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yTXVsdGlwbGVDaG9pY2UlMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yTXVsdGlwbGVDaG9pY2UuZnJvbV9wcmV0cmFpbmVkKCUyMmdvb2dsZS1iZXJ0JTJGYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),W=new R({props:{code:"ZGF0YV9jb2xsYXRvciUyMCUzRCUyMERhdGFDb2xsYXRvckZvck11bHRpcGxlQ2hvaWNlKHRva2VuaXplciUzRHRva2VuaXplciklMEF0Zl90cmFpbl9zZXQlMjAlM0QlMjBtb2RlbC5wcmVwYXJlX3RmX2RhdGFzZXQoJTBBJTIwJTIwJTIwJTIwdG9rZW5pemVkX3N3YWclNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hfc2l6ZSUzRGJhdGNoX3NpemUlMkMlMEElMjAlMjAlMjAlMjBjb2xsYXRlX2ZuJTNEZGF0YV9jb2xsYXRvciUyQyUwQSklMEElMEF0Zl92YWxpZGF0aW9uX3NldCUyMCUzRCUyMG1vZGVsLnByZXBhcmVfdGZfZGF0YXNldCglMEElMjAlMjAlMjAlMjB0b2tlbml6ZWRfc3dhZyU1QiUyMnZhbGlkYXRpb24lMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBzaHVmZmxlJTNERmFsc2UlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNEYmF0Y2hfc2l6ZSUyQyUwQSUyMCUyMCUyMCUyMGNvbGxhdGVfZm4lM0RkYXRhX2NvbGxhdG9yJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_swag[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=batch_size,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_swag[<span class="hljs-string">&quot;validation&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=batch_size,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),A=new R({props:{code:"bW9kZWwuY29tcGlsZShvcHRpbWl6ZXIlM0RvcHRpbWl6ZXIpJTIwJTIwJTIzJTIwTm8lMjBsb3NzJTIwYXJndW1lbnQh",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)  <span class="hljs-comment"># No loss argument!</span>',wrap:!1}}),ss=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBLZXJhc01ldHJpY0NhbGxiYWNrJTBBJTBBbWV0cmljX2NhbGxiYWNrJTIwJTNEJTIwS2VyYXNNZXRyaWNDYWxsYmFjayhtZXRyaWNfZm4lM0Rjb21wdXRlX21ldHJpY3MlMkMlMjBldmFsX2RhdGFzZXQlM0R0Zl92YWxpZGF0aW9uX3NldCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> KerasMetricCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_set)`,wrap:!1}}),Q=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBQdXNoVG9IdWJDYWxsYmFjayUwQSUwQXB1c2hfdG9faHViX2NhbGxiYWNrJTIwJTNEJTIwUHVzaFRvSHViQ2FsbGJhY2soJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMm15X2F3ZXNvbWVfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>push_to_hub_callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_model&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>)`,wrap:!1}}),q=new R({props:{code:"Y2FsbGJhY2tzJTIwJTNEJTIwJTVCbWV0cmljX2NhbGxiYWNrJTJDJTIwcHVzaF90b19odWJfY2FsbGJhY2slNUQ=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>callbacks = [metric_callback, push_to_hub_callback]',wrap:!1}}),P=new R({props:{code:"bW9kZWwuZml0KHglM0R0Zl90cmFpbl9zZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl92YWxpZGF0aW9uX3NldCUyQyUyMGVwb2NocyUzRDIlMkMlMjBjYWxsYmFja3MlM0RjYWxsYmFja3Mp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=<span class="hljs-number">2</span>, callbacks=callbacks)',wrap:!1}}),{c(){d(l.$$.fragment),o=Ge(`
To finetune a model in TensorFlow, start by setting up an optimizer function, learning rate schedule, and some training hyperparameters:

	`),d(e.$$.fragment),m=i(),h=b("p"),h.innerHTML=C,B=i(),d(I.$$.fragment),k=i(),X=b("p"),X.innerHTML=Z,v=i(),d(W.$$.fragment),$=i(),G=b("p"),G.innerHTML=r,U=i(),d(A.$$.fragment),E=i(),x=b("p"),x.innerHTML=M,V=i(),Y=b("p"),Y.innerHTML=ms,N=i(),d(ss.$$.fragment),ns=i(),F=b("p"),F.innerHTML=Ms,z=i(),d(Q.$$.fragment),H=i(),es=b("p"),es.textContent=hs,S=i(),d(q.$$.fragment),L=i(),ls=b("p"),ls.innerHTML=ds,D=i(),d(P.$$.fragment),K=i(),as=b("p"),as.textContent=ys},l(n){y(l.$$.fragment,n),o=Re(n,`
To finetune a model in TensorFlow, start by setting up an optimizer function, learning rate schedule, and some training hyperparameters:

	`),y(e.$$.fragment,n),m=c(n),h=T(n,"P",{"data-svelte-h":!0}),g(h)!=="svelte-1hmpm03"&&(h.innerHTML=C),B=c(n),y(I.$$.fragment,n),k=c(n),X=T(n,"P",{"data-svelte-h":!0}),g(X)!=="svelte-9ymftz"&&(X.innerHTML=Z),v=c(n),y(W.$$.fragment,n),$=c(n),G=T(n,"P",{"data-svelte-h":!0}),g(G)!=="svelte-17cxx5e"&&(G.innerHTML=r),U=c(n),y(A.$$.fragment,n),E=c(n),x=T(n,"P",{"data-svelte-h":!0}),g(x)!=="svelte-6l1wkp"&&(x.innerHTML=M),V=c(n),Y=T(n,"P",{"data-svelte-h":!0}),g(Y)!=="svelte-bi2rpv"&&(Y.innerHTML=ms),N=c(n),y(ss.$$.fragment,n),ns=c(n),F=T(n,"P",{"data-svelte-h":!0}),g(F)!=="svelte-1b3skyn"&&(F.innerHTML=Ms),z=c(n),y(Q.$$.fragment,n),H=c(n),es=T(n,"P",{"data-svelte-h":!0}),g(es)!=="svelte-1lw9xm8"&&(es.textContent=hs),S=c(n),y(q.$$.fragment,n),L=c(n),ls=T(n,"P",{"data-svelte-h":!0}),g(ls)!=="svelte-1hrpv1v"&&(ls.innerHTML=ds),D=c(n),y(P.$$.fragment,n),K=c(n),as=T(n,"P",{"data-svelte-h":!0}),g(as)!=="svelte-2s71om"&&(as.textContent=ys)},m(n,J){u(l,n,J),t(n,o,J),u(e,n,J),t(n,m,J),t(n,h,J),t(n,B,J),u(I,n,J),t(n,k,J),t(n,X,J),t(n,v,J),u(W,n,J),t(n,$,J),t(n,G,J),t(n,U,J),u(A,n,J),t(n,E,J),t(n,x,J),t(n,V,J),t(n,Y,J),t(n,N,J),u(ss,n,J),t(n,ns,J),t(n,F,J),t(n,z,J),u(Q,n,J),t(n,H,J),t(n,es,J),t(n,S,J),u(q,n,J),t(n,L,J),t(n,ls,J),t(n,D,J),u(P,n,J),t(n,K,J),t(n,as,J),O=!0},p(n,J){const ts={};J&2&&(ts.$$scope={dirty:J,ctx:n}),l.$set(ts)},i(n){O||(j(l.$$.fragment,n),j(e.$$.fragment,n),j(I.$$.fragment,n),j(W.$$.fragment,n),j(A.$$.fragment,n),j(ss.$$.fragment,n),j(Q.$$.fragment,n),j(q.$$.fragment,n),j(P.$$.fragment,n),O=!0)},o(n){f(l.$$.fragment,n),f(e.$$.fragment,n),f(I.$$.fragment,n),f(W.$$.fragment,n),f(A.$$.fragment,n),f(ss.$$.fragment,n),f(Q.$$.fragment,n),f(q.$$.fragment,n),f(P.$$.fragment,n),O=!1},d(n){n&&(a(o),a(m),a(h),a(B),a(k),a(X),a(v),a($),a(G),a(U),a(E),a(x),a(V),a(Y),a(N),a(ns),a(F),a(z),a(H),a(es),a(S),a(L),a(ls),a(D),a(K),a(as)),w(l,n),w(e,n),w(I,n),w(W,n),w(A,n),w(ss,n),w(Q,n),w(q,n),w(P,n)}}}function De(_){let l,o;return l=new vs({props:{$$slots:{default:[Le]},$$scope:{ctx:_}}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p(e,m){const h={};m&2&&(h.$$scope={dirty:m,ctx:e}),l.$set(h)},i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function Pe(_){let l,o=`For a more in-depth example of how to finetune a model for multiple choice, take a look at the corresponding
<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice.ipynb" rel="nofollow">PyTorch notebook</a>
or <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/multiple_choice-tf.ipynb" rel="nofollow">TensorFlow notebook</a>.`;return{c(){l=b("p"),l.innerHTML=o},l(e){l=T(e,"P",{"data-svelte-h":!0}),g(l)!=="svelte-1c9mh52"&&(l.innerHTML=o)},m(e,m){t(e,l,m)},p:cs,d(e){e&&a(l)}}}function Ke(_){let l,o="Tokenize each prompt and candidate answer pair and return PyTorch tensors. You should also create some <code>labels</code>:",e,m,h,C,B="Pass your inputs and labels to the model and return the <code>logits</code>:",I,k,X,Z,v="Get the class with the highest probability:",W,$,G;return m=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3N3YWdfbW9kZWwlMjIpJTBBaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKCU1QiU1QnByb21wdCUyQyUyMGNhbmRpZGF0ZTElNUQlMkMlMjAlNUJwcm9tcHQlMkMlMjBjYW5kaWRhdGUyJTVEJTVEJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiUyQyUyMHBhZGRpbmclM0RUcnVlKSUwQWxhYmVscyUyMCUzRCUyMHRvcmNoLnRlbnNvcigwKS51bnNxdWVlemUoMCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_swag_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=<span class="hljs-string">&quot;pt&quot;</span>, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>labels = torch.tensor(<span class="hljs-number">0</span>).unsqueeze(<span class="hljs-number">0</span>)`,wrap:!1}}),k=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvck11bHRpcGxlQ2hvaWNlJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JNdWx0aXBsZUNob2ljZS5mcm9tX3ByZXRyYWluZWQoJTIybXlfYXdlc29tZV9zd2FnX21vZGVsJTIyKSUwQW91dHB1dHMlMjAlM0QlMjBtb2RlbCgqKiU3QmslM0ElMjB2LnVuc3F1ZWV6ZSgwKSUyMGZvciUyMGslMkMlMjB2JTIwaW4lMjBpbnB1dHMuaXRlbXMoKSU3RCUyQyUyMGxhYmVscyUzRGxhYmVscyklMEFsb2dpdHMlMjAlM0QlMjBvdXRwdXRzLmxvZ2l0cw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;my_awesome_swag_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**{k: v.unsqueeze(<span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> inputs.items()}, labels=labels)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`,wrap:!1}}),$=new R({props:{code:"cHJlZGljdGVkX2NsYXNzJTIwJTNEJTIwbG9naXRzLmFyZ21heCgpLml0ZW0oKSUwQXByZWRpY3RlZF9jbGFzcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class = logits.argmax().item()
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class
<span class="hljs-string">&#x27;0&#x27;</span>`,wrap:!1}}),{c(){l=b("p"),l.innerHTML=o,e=i(),d(m.$$.fragment),h=i(),C=b("p"),C.innerHTML=B,I=i(),d(k.$$.fragment),X=i(),Z=b("p"),Z.textContent=v,W=i(),d($.$$.fragment)},l(r){l=T(r,"P",{"data-svelte-h":!0}),g(l)!=="svelte-1qxmddt"&&(l.innerHTML=o),e=c(r),y(m.$$.fragment,r),h=c(r),C=T(r,"P",{"data-svelte-h":!0}),g(C)!=="svelte-10twm8n"&&(C.innerHTML=B),I=c(r),y(k.$$.fragment,r),X=c(r),Z=T(r,"P",{"data-svelte-h":!0}),g(Z)!=="svelte-18e4iwl"&&(Z.textContent=v),W=c(r),y($.$$.fragment,r)},m(r,U){t(r,l,U),t(r,e,U),u(m,r,U),t(r,h,U),t(r,C,U),t(r,I,U),u(k,r,U),t(r,X,U),t(r,Z,U),t(r,W,U),u($,r,U),G=!0},p:cs,i(r){G||(j(m.$$.fragment,r),j(k.$$.fragment,r),j($.$$.fragment,r),G=!0)},o(r){f(m.$$.fragment,r),f(k.$$.fragment,r),f($.$$.fragment,r),G=!1},d(r){r&&(a(l),a(e),a(h),a(C),a(I),a(X),a(Z),a(W)),w(m,r),w(k,r),w($,r)}}}function Oe(_){let l,o;return l=new vs({props:{$$slots:{default:[Ke]},$$scope:{ctx:_}}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p(e,m){const h={};m&2&&(h.$$scope={dirty:m,ctx:e}),l.$set(h)},i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function sl(_){let l,o="Tokenize each prompt and candidate answer pair and return TensorFlow tensors:",e,m,h,C,B="Pass your inputs to the model and return the <code>logits</code>:",I,k,X,Z,v="Get the class with the highest probability:",W,$,G;return m=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3N3YWdfbW9kZWwlMjIpJTBBaW5wdXRzJTIwJTNEJTIwdG9rZW5pemVyKCU1QiU1QnByb21wdCUyQyUyMGNhbmRpZGF0ZTElNUQlMkMlMjAlNUJwcm9tcHQlMkMlMjBjYW5kaWRhdGUyJTVEJTVEJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMiUyQyUyMHBhZGRpbmclM0RUcnVlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_swag_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer([[prompt, candidate1], [prompt, candidate2]], return_tensors=<span class="hljs-string">&quot;tf&quot;</span>, padding=<span class="hljs-literal">True</span>)`,wrap:!1}}),k=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yTXVsdGlwbGVDaG9pY2UlMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yTXVsdGlwbGVDaG9pY2UuZnJvbV9wcmV0cmFpbmVkKCUyMm15X2F3ZXNvbWVfc3dhZ19tb2RlbCUyMiklMEFpbnB1dHMlMjAlM0QlMjAlN0JrJTNBJTIwdGYuZXhwYW5kX2RpbXModiUyQyUyMDApJTIwZm9yJTIwayUyQyUyMHYlMjBpbiUyMGlucHV0cy5pdGVtcygpJTdEJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKGlucHV0cyklMEFsb2dpdHMlMjAlM0QlMjBvdXRwdXRzLmxvZ2l0cw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForMultipleChoice

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForMultipleChoice.from_pretrained(<span class="hljs-string">&quot;my_awesome_swag_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = {k: tf.expand_dims(v, <span class="hljs-number">0</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> inputs.items()}
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits`,wrap:!1}}),$=new R({props:{code:"cHJlZGljdGVkX2NsYXNzJTIwJTNEJTIwaW50KHRmLm1hdGguYXJnbWF4KGxvZ2l0cyUyQyUyMGF4aXMlM0QtMSklNUIwJTVEKSUwQXByZWRpY3RlZF9jbGFzcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class = <span class="hljs-built_in">int</span>(tf.math.argmax(logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class
<span class="hljs-string">&#x27;0&#x27;</span>`,wrap:!1}}),{c(){l=b("p"),l.textContent=o,e=i(),d(m.$$.fragment),h=i(),C=b("p"),C.innerHTML=B,I=i(),d(k.$$.fragment),X=i(),Z=b("p"),Z.textContent=v,W=i(),d($.$$.fragment)},l(r){l=T(r,"P",{"data-svelte-h":!0}),g(l)!=="svelte-q8vskg"&&(l.textContent=o),e=c(r),y(m.$$.fragment,r),h=c(r),C=T(r,"P",{"data-svelte-h":!0}),g(C)!=="svelte-f3g043"&&(C.innerHTML=B),I=c(r),y(k.$$.fragment,r),X=c(r),Z=T(r,"P",{"data-svelte-h":!0}),g(Z)!=="svelte-18e4iwl"&&(Z.textContent=v),W=c(r),y($.$$.fragment,r)},m(r,U){t(r,l,U),t(r,e,U),u(m,r,U),t(r,h,U),t(r,C,U),t(r,I,U),u(k,r,U),t(r,X,U),t(r,Z,U),t(r,W,U),u($,r,U),G=!0},p:cs,i(r){G||(j(m.$$.fragment,r),j(k.$$.fragment,r),j($.$$.fragment,r),G=!0)},o(r){f(m.$$.fragment,r),f(k.$$.fragment,r),f($.$$.fragment,r),G=!1},d(r){r&&(a(l),a(e),a(h),a(C),a(I),a(X),a(Z),a(W)),w(m,r),w(k,r),w($,r)}}}function el(_){let l,o;return l=new vs({props:{$$slots:{default:[sl]},$$scope:{ctx:_}}}),{c(){d(l.$$.fragment)},l(e){y(l.$$.fragment,e)},m(e,m){u(l,e,m),o=!0},p(e,m){const h={};m&2&&(h.$$scope={dirty:m,ctx:e}),l.$set(h)},i(e){o||(j(l.$$.fragment,e),o=!0)},o(e){f(l.$$.fragment,e),o=!1},d(e){w(l,e)}}}function ll(_){let l,o,e,m,h,C,B,I,k,X="A multiple choice task is similar to question answering, except several candidate answers are provided along with a context and the model is trained to select the correct answer.",Z,v,W="This guide will show you how to:",$,G,r='<li>Finetune <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a> on the <code>regular</code> configuration of the <a href="https://huggingface.co/datasets/swag" rel="nofollow">SWAG</a> dataset to select the best answer given multiple options and some context.</li> <li>Use your finetuned model for inference.</li>',U,A,E,x,M="Before you begin, make sure you have all the necessary libraries installed:",V,Y,ms,N,ss="We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:",ns,F,Ms,z,Q,H,es="Start by loading the <code>regular</code> configuration of the SWAG dataset from the ü§ó Datasets library:",hs,S,q,L,ls="Then take a look at an example:",ds,D,P,K,as="While it looks like there are a lot of fields here, it is actually pretty straightforward:",ys,O,n="<li><code>sent1</code> and <code>sent2</code>: these fields show how a sentence starts, and if you put the two together, you get the <code>startphrase</code> field.</li> <li><code>ending</code>: suggests a possible ending for how a sentence can end, but only one of them is correct.</li> <li><code>label</code>: identifies the correct sentence ending.</li>",J,ts,xs,us,he="The next step is to load a BERT tokenizer to process the sentence starts and the four possible endings:",Ys,js,Es,fs,de="The preprocessing function you want to create needs to:",Fs,ws,ye="<li>Make four copies of the <code>sent1</code> field and combine each of them with <code>sent2</code> to recreate how a sentence starts.</li> <li>Combine <code>sent2</code> with each of the four possible sentence endings.</li> <li>Flatten these two lists so you can tokenize them, and then unflatten them afterward so each example has a corresponding <code>input_ids</code>, <code>attention_mask</code>, and <code>labels</code> field.</li>",Ns,bs,zs,Ts,ue='To apply the preprocessing function over the entire dataset, use ü§ó Datasets <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map" rel="nofollow">map</a> method. You can speed up the <code>map</code> function by setting <code>batched=True</code> to process multiple elements of the dataset at once:',Qs,Js,Hs,gs,je='ü§ó Transformers doesn‚Äôt have a data collator for multiple choice, so you‚Äôll need to adapt the <a href="/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding">DataCollatorWithPadding</a> to create a batch of examples. It‚Äôs more efficient to <em>dynamically pad</em> the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length.',Ss,Us,fe="<code>DataCollatorForMultipleChoice</code> flattens all the model inputs, applies padding, and then unflattens the results:",qs,ps,Ls,$s,Ds,_s,we='Including a metric during training is often helpful for evaluating your model‚Äôs performance. You can quickly load a evaluation method with the ü§ó <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> library. For this task, load the <a href="https://huggingface.co/spaces/evaluate-metric/accuracy" rel="nofollow">accuracy</a> metric (see the ü§ó Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">quick tour</a> to learn more about how to load and compute a metric):',Ps,Cs,Ks,ks,be='Then create a function that passes your predictions and labels to <a href="https://huggingface.co/docs/evaluate/main/en/package_reference/main_classes#evaluate.EvaluationModule.compute" rel="nofollow">compute</a> to calculate the accuracy:',Os,Zs,se,Is,Te="Your <code>compute_metrics</code> function is ready to go now, and you‚Äôll return to it when you setup your training.",ee,Gs,le,rs,ae,os,te,Rs,ne,Vs,Je="Great, now that you‚Äôve finetuned a model, you can use it for inference!",pe,Xs,ge="Come up with some text and two candidate answers:",re,Ws,oe,is,ie,As,ce;return h=new Bs({props:{title:"Multiple choice",local:"multiple-choice",headingTag:"h1"}}),B=new xe({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/multiple_choice.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/multiple_choice.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/multiple_choice.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/multiple_choice.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/multiple_choice.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/multiple_choice.ipynb"}]}}),A=new me({props:{$$slots:{default:[Ye]},$$scope:{ctx:_}}}),Y=new R({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),F=new R({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),z=new Bs({props:{title:"Load SWAG dataset",local:"load-swag-dataset",headingTag:"h2"}}),S=new R({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBc3dhZyUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJzd2FnJTIyJTJDJTIwJTIycmVndWxhciUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>swag = load_dataset(<span class="hljs-string">&quot;swag&quot;</span>, <span class="hljs-string">&quot;regular&quot;</span>)`,wrap:!1}}),D=new R({props:{code:"c3dhZyU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>swag[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;ending0&#x27;</span>: <span class="hljs-string">&#x27;passes by walking down the street playing their instruments.&#x27;</span>,
 <span class="hljs-string">&#x27;ending1&#x27;</span>: <span class="hljs-string">&#x27;has heard approaching them.&#x27;</span>,
 <span class="hljs-string">&#x27;ending2&#x27;</span>: <span class="hljs-string">&quot;arrives and they&#x27;re outside dancing and asleep.&quot;</span>,
 <span class="hljs-string">&#x27;ending3&#x27;</span>: <span class="hljs-string">&#x27;turns the lead singer watches the performance.&#x27;</span>,
 <span class="hljs-string">&#x27;fold-ind&#x27;</span>: <span class="hljs-string">&#x27;3416&#x27;</span>,
 <span class="hljs-string">&#x27;gold-source&#x27;</span>: <span class="hljs-string">&#x27;gold&#x27;</span>,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">0</span>,
 <span class="hljs-string">&#x27;sent1&#x27;</span>: <span class="hljs-string">&#x27;Members of the procession walk down the street holding small horn brass instruments.&#x27;</span>,
 <span class="hljs-string">&#x27;sent2&#x27;</span>: <span class="hljs-string">&#x27;A drum line&#x27;</span>,
 <span class="hljs-string">&#x27;startphrase&#x27;</span>: <span class="hljs-string">&#x27;Members of the procession walk down the street holding small horn brass instruments. A drum line&#x27;</span>,
 <span class="hljs-string">&#x27;video-id&#x27;</span>: <span class="hljs-string">&#x27;anetv_jkn6uvmqwh4&#x27;</span>}`,wrap:!1}}),ts=new Bs({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),js=new R({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),bs=new R({props:{code:"ZW5kaW5nX25hbWVzJTIwJTNEJTIwJTVCJTIyZW5kaW5nMCUyMiUyQyUyMCUyMmVuZGluZzElMjIlMkMlMjAlMjJlbmRpbmcyJTIyJTJDJTIwJTIyZW5kaW5nMyUyMiU1RCUwQSUwQSUwQWRlZiUyMHByZXByb2Nlc3NfZnVuY3Rpb24oZXhhbXBsZXMpJTNBJTBBJTIwJTIwJTIwJTIwZmlyc3Rfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTVCY29udGV4dCU1RCUyMColMjA0JTIwZm9yJTIwY29udGV4dCUyMGluJTIwZXhhbXBsZXMlNUIlMjJzZW50MSUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMHF1ZXN0aW9uX2hlYWRlcnMlMjAlM0QlMjBleGFtcGxlcyU1QiUyMnNlbnQyJTIyJTVEJTBBJTIwJTIwJTIwJTIwc2Vjb25kX3NlbnRlbmNlcyUyMCUzRCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCU1QmYlMjIlN0JoZWFkZXIlN0QlMjAlN0JleGFtcGxlcyU1QmVuZCU1RCU1QmklNUQlN0QlMjIlMjBmb3IlMjBlbmQlMjBpbiUyMGVuZGluZ19uYW1lcyU1RCUyMGZvciUyMGklMkMlMjBoZWFkZXIlMjBpbiUyMGVudW1lcmF0ZShxdWVzdGlvbl9oZWFkZXJzKSUwQSUyMCUyMCUyMCUyMCU1RCUwQSUwQSUyMCUyMCUyMCUyMGZpcnN0X3NlbnRlbmNlcyUyMCUzRCUyMHN1bShmaXJzdF9zZW50ZW5jZXMlMkMlMjAlNUIlNUQpJTBBJTIwJTIwJTIwJTIwc2Vjb25kX3NlbnRlbmNlcyUyMCUzRCUyMHN1bShzZWNvbmRfc2VudGVuY2VzJTJDJTIwJTVCJTVEKSUwQSUwQSUyMCUyMCUyMCUyMHRva2VuaXplZF9leGFtcGxlcyUyMCUzRCUyMHRva2VuaXplcihmaXJzdF9zZW50ZW5jZXMlMkMlMjBzZWNvbmRfc2VudGVuY2VzJTJDJTIwdHJ1bmNhdGlvbiUzRFRydWUpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwJTdCayUzQSUyMCU1QnYlNUJpJTIwJTNBJTIwaSUyMCUyQiUyMDQlNUQlMjBmb3IlMjBpJTIwaW4lMjByYW5nZSgwJTJDJTIwbGVuKHYpJTJDJTIwNCklNUQlMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwdG9rZW5pemVkX2V4YW1wbGVzLml0ZW1zKCklN0Q=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ending_names = [<span class="hljs-string">&quot;ending0&quot;</span>, <span class="hljs-string">&quot;ending1&quot;</span>, <span class="hljs-string">&quot;ending2&quot;</span>, <span class="hljs-string">&quot;ending3&quot;</span>]


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    first_sentences = [[context] * <span class="hljs-number">4</span> <span class="hljs-keyword">for</span> context <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;sent1&quot;</span>]]
<span class="hljs-meta">... </span>    question_headers = examples[<span class="hljs-string">&quot;sent2&quot;</span>]
<span class="hljs-meta">... </span>    second_sentences = [
<span class="hljs-meta">... </span>        [<span class="hljs-string">f&quot;<span class="hljs-subst">{header}</span> <span class="hljs-subst">{examples[end][i]}</span>&quot;</span> <span class="hljs-keyword">for</span> end <span class="hljs-keyword">in</span> ending_names] <span class="hljs-keyword">for</span> i, header <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(question_headers)
<span class="hljs-meta">... </span>    ]

<span class="hljs-meta">... </span>    first_sentences = <span class="hljs-built_in">sum</span>(first_sentences, [])
<span class="hljs-meta">... </span>    second_sentences = <span class="hljs-built_in">sum</span>(second_sentences, [])

<span class="hljs-meta">... </span>    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=<span class="hljs-literal">True</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {k: [v[i : i + <span class="hljs-number">4</span>] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(v), <span class="hljs-number">4</span>)] <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> tokenized_examples.items()}`,wrap:!1}}),Js=new R({props:{code:"dG9rZW5pemVkX3N3YWclMjAlM0QlMjBzd2FnLm1hcChwcmVwcm9jZXNzX2Z1bmN0aW9uJTJDJTIwYmF0Y2hlZCUzRFRydWUp",highlighted:'tokenized_swag = swag.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)',wrap:!1}}),ps=new Me({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ze],pytorch:[Fe]},$$scope:{ctx:_}}}),$s=new Bs({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),Cs=new R({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEFhY2N1cmFjeSUyMCUzRCUyMGV2YWx1YXRlLmxvYWQoJTIyYWNjdXJhY3klMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>accuracy = evaluate.load(<span class="hljs-string">&quot;accuracy&quot;</span>)`,wrap:!1}}),Zs=new R({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKGV2YWxfcHJlZCklM0ElMEElMjAlMjAlMjAlMjBwcmVkaWN0aW9ucyUyQyUyMGxhYmVscyUyMCUzRCUyMGV2YWxfcHJlZCUwQSUyMCUyMCUyMCUyMHByZWRpY3Rpb25zJTIwJTNEJTIwbnAuYXJnbWF4KHByZWRpY3Rpb25zJTJDJTIwYXhpcyUzRDEpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwYWNjdXJhY3kuY29tcHV0ZShwcmVkaWN0aW9ucyUzRHByZWRpY3Rpb25zJTJDJTIwcmVmZXJlbmNlcyUzRGxhYmVscyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    predictions, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(predictions, axis=<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> accuracy.compute(predictions=predictions, references=labels)`,wrap:!1}}),Gs=new Bs({props:{title:"Train",local:"train",headingTag:"h2"}}),rs=new Me({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[De],pytorch:[Se]},$$scope:{ctx:_}}}),os=new me({props:{$$slots:{default:[Pe]},$$scope:{ctx:_}}}),Rs=new Bs({props:{title:"Inference",local:"inference",headingTag:"h2"}}),Ws=new R({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyRnJhbmNlJTIwaGFzJTIwYSUyMGJyZWFkJTIwbGF3JTJDJTIwTGUlMjBEJUMzJUE5Y3JldCUyMFBhaW4lMkMlMjB3aXRoJTIwc3RyaWN0JTIwcnVsZXMlMjBvbiUyMHdoYXQlMjBpcyUyMGFsbG93ZWQlMjBpbiUyMGElMjB0cmFkaXRpb25hbCUyMGJhZ3VldHRlLiUyMiUwQWNhbmRpZGF0ZTElMjAlM0QlMjAlMjJUaGUlMjBsYXclMjBkb2VzJTIwbm90JTIwYXBwbHklMjB0byUyMGNyb2lzc2FudHMlMjBhbmQlMjBicmlvY2hlLiUyMiUwQWNhbmRpZGF0ZTIlMjAlM0QlMjAlMjJUaGUlMjBsYXclMjBhcHBsaWVzJTIwdG8lMjBiYWd1ZXR0ZXMuJTIy",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>prompt = <span class="hljs-string">&quot;France has a bread law, Le D√©cret Pain, with strict rules on what is allowed in a traditional baguette.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>candidate1 = <span class="hljs-string">&quot;The law does not apply to croissants and brioche.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>candidate2 = <span class="hljs-string">&quot;The law applies to baguettes.&quot;</span>`,wrap:!1}}),is=new Me({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[el],pytorch:[Oe]},$$scope:{ctx:_}}}),{c(){l=b("meta"),o=i(),e=b("p"),m=i(),d(h.$$.fragment),C=i(),d(B.$$.fragment),I=i(),k=b("p"),k.textContent=X,Z=i(),v=b("p"),v.textContent=W,$=i(),G=b("ol"),G.innerHTML=r,U=i(),d(A.$$.fragment),E=i(),x=b("p"),x.textContent=M,V=i(),d(Y.$$.fragment),ms=i(),N=b("p"),N.textContent=ss,ns=i(),d(F.$$.fragment),Ms=i(),d(z.$$.fragment),Q=i(),H=b("p"),H.innerHTML=es,hs=i(),d(S.$$.fragment),q=i(),L=b("p"),L.textContent=ls,ds=i(),d(D.$$.fragment),P=i(),K=b("p"),K.textContent=as,ys=i(),O=b("ul"),O.innerHTML=n,J=i(),d(ts.$$.fragment),xs=i(),us=b("p"),us.textContent=he,Ys=i(),d(js.$$.fragment),Es=i(),fs=b("p"),fs.textContent=de,Fs=i(),ws=b("ol"),ws.innerHTML=ye,Ns=i(),d(bs.$$.fragment),zs=i(),Ts=b("p"),Ts.innerHTML=ue,Qs=i(),d(Js.$$.fragment),Hs=i(),gs=b("p"),gs.innerHTML=je,Ss=i(),Us=b("p"),Us.innerHTML=fe,qs=i(),d(ps.$$.fragment),Ls=i(),d($s.$$.fragment),Ds=i(),_s=b("p"),_s.innerHTML=we,Ps=i(),d(Cs.$$.fragment),Ks=i(),ks=b("p"),ks.innerHTML=be,Os=i(),d(Zs.$$.fragment),se=i(),Is=b("p"),Is.innerHTML=Te,ee=i(),d(Gs.$$.fragment),le=i(),d(rs.$$.fragment),ae=i(),d(os.$$.fragment),te=i(),d(Rs.$$.fragment),ne=i(),Vs=b("p"),Vs.textContent=Je,pe=i(),Xs=b("p"),Xs.textContent=ge,re=i(),d(Ws.$$.fragment),oe=i(),d(is.$$.fragment),ie=i(),As=b("p"),this.h()},l(s){const p=ve("svelte-u9bgzb",document.head);l=T(p,"META",{name:!0,content:!0}),p.forEach(a),o=c(s),e=T(s,"P",{}),Ze(e).forEach(a),m=c(s),y(h.$$.fragment,s),C=c(s),y(B.$$.fragment,s),I=c(s),k=T(s,"P",{"data-svelte-h":!0}),g(k)!=="svelte-gcifhg"&&(k.textContent=X),Z=c(s),v=T(s,"P",{"data-svelte-h":!0}),g(v)!=="svelte-1aff4p7"&&(v.textContent=W),$=c(s),G=T(s,"OL",{"data-svelte-h":!0}),g(G)!=="svelte-1iw2sa5"&&(G.innerHTML=r),U=c(s),y(A.$$.fragment,s),E=c(s),x=T(s,"P",{"data-svelte-h":!0}),g(x)!=="svelte-1c9nexd"&&(x.textContent=M),V=c(s),y(Y.$$.fragment,s),ms=c(s),N=T(s,"P",{"data-svelte-h":!0}),g(N)!=="svelte-k76o1m"&&(N.textContent=ss),ns=c(s),y(F.$$.fragment,s),Ms=c(s),y(z.$$.fragment,s),Q=c(s),H=T(s,"P",{"data-svelte-h":!0}),g(H)!=="svelte-ndvump"&&(H.innerHTML=es),hs=c(s),y(S.$$.fragment,s),q=c(s),L=T(s,"P",{"data-svelte-h":!0}),g(L)!=="svelte-1m91ua0"&&(L.textContent=ls),ds=c(s),y(D.$$.fragment,s),P=c(s),K=T(s,"P",{"data-svelte-h":!0}),g(K)!=="svelte-1dgdrcg"&&(K.textContent=as),ys=c(s),O=T(s,"UL",{"data-svelte-h":!0}),g(O)!=="svelte-vj0noe"&&(O.innerHTML=n),J=c(s),y(ts.$$.fragment,s),xs=c(s),us=T(s,"P",{"data-svelte-h":!0}),g(us)!=="svelte-j3i2fe"&&(us.textContent=he),Ys=c(s),y(js.$$.fragment,s),Es=c(s),fs=T(s,"P",{"data-svelte-h":!0}),g(fs)!=="svelte-pduvot"&&(fs.textContent=de),Fs=c(s),ws=T(s,"OL",{"data-svelte-h":!0}),g(ws)!=="svelte-tso4vc"&&(ws.innerHTML=ye),Ns=c(s),y(bs.$$.fragment,s),zs=c(s),Ts=T(s,"P",{"data-svelte-h":!0}),g(Ts)!=="svelte-74644w"&&(Ts.innerHTML=ue),Qs=c(s),y(Js.$$.fragment,s),Hs=c(s),gs=T(s,"P",{"data-svelte-h":!0}),g(gs)!=="svelte-168hm6y"&&(gs.innerHTML=je),Ss=c(s),Us=T(s,"P",{"data-svelte-h":!0}),g(Us)!=="svelte-1ytir7e"&&(Us.innerHTML=fe),qs=c(s),y(ps.$$.fragment,s),Ls=c(s),y($s.$$.fragment,s),Ds=c(s),_s=T(s,"P",{"data-svelte-h":!0}),g(_s)!=="svelte-j1ipe9"&&(_s.innerHTML=we),Ps=c(s),y(Cs.$$.fragment,s),Ks=c(s),ks=T(s,"P",{"data-svelte-h":!0}),g(ks)!=="svelte-14irt3v"&&(ks.innerHTML=be),Os=c(s),y(Zs.$$.fragment,s),se=c(s),Is=T(s,"P",{"data-svelte-h":!0}),g(Is)!=="svelte-183aynn"&&(Is.innerHTML=Te),ee=c(s),y(Gs.$$.fragment,s),le=c(s),y(rs.$$.fragment,s),ae=c(s),y(os.$$.fragment,s),te=c(s),y(Rs.$$.fragment,s),ne=c(s),Vs=T(s,"P",{"data-svelte-h":!0}),g(Vs)!=="svelte-633ppb"&&(Vs.textContent=Je),pe=c(s),Xs=T(s,"P",{"data-svelte-h":!0}),g(Xs)!=="svelte-nni2mt"&&(Xs.textContent=ge),re=c(s),y(Ws.$$.fragment,s),oe=c(s),y(is.$$.fragment,s),ie=c(s),As=T(s,"P",{}),Ze(As).forEach(a),this.h()},h(){Ie(l,"name","hf:doc:metadata"),Ie(l,"content",al)},m(s,p){Ae(document.head,l),t(s,o,p),t(s,e,p),t(s,m,p),u(h,s,p),t(s,C,p),u(B,s,p),t(s,I,p),t(s,k,p),t(s,Z,p),t(s,v,p),t(s,$,p),t(s,G,p),t(s,U,p),u(A,s,p),t(s,E,p),t(s,x,p),t(s,V,p),u(Y,s,p),t(s,ms,p),t(s,N,p),t(s,ns,p),u(F,s,p),t(s,Ms,p),u(z,s,p),t(s,Q,p),t(s,H,p),t(s,hs,p),u(S,s,p),t(s,q,p),t(s,L,p),t(s,ds,p),u(D,s,p),t(s,P,p),t(s,K,p),t(s,ys,p),t(s,O,p),t(s,J,p),u(ts,s,p),t(s,xs,p),t(s,us,p),t(s,Ys,p),u(js,s,p),t(s,Es,p),t(s,fs,p),t(s,Fs,p),t(s,ws,p),t(s,Ns,p),u(bs,s,p),t(s,zs,p),t(s,Ts,p),t(s,Qs,p),u(Js,s,p),t(s,Hs,p),t(s,gs,p),t(s,Ss,p),t(s,Us,p),t(s,qs,p),u(ps,s,p),t(s,Ls,p),u($s,s,p),t(s,Ds,p),t(s,_s,p),t(s,Ps,p),u(Cs,s,p),t(s,Ks,p),t(s,ks,p),t(s,Os,p),u(Zs,s,p),t(s,se,p),t(s,Is,p),t(s,ee,p),u(Gs,s,p),t(s,le,p),u(rs,s,p),t(s,ae,p),u(os,s,p),t(s,te,p),u(Rs,s,p),t(s,ne,p),t(s,Vs,p),t(s,pe,p),t(s,Xs,p),t(s,re,p),u(Ws,s,p),t(s,oe,p),u(is,s,p),t(s,ie,p),t(s,As,p),ce=!0},p(s,[p]){const Ue={};p&2&&(Ue.$$scope={dirty:p,ctx:s}),A.$set(Ue);const $e={};p&2&&($e.$$scope={dirty:p,ctx:s}),ps.$set($e);const _e={};p&2&&(_e.$$scope={dirty:p,ctx:s}),rs.$set(_e);const Ce={};p&2&&(Ce.$$scope={dirty:p,ctx:s}),os.$set(Ce);const ke={};p&2&&(ke.$$scope={dirty:p,ctx:s}),is.$set(ke)},i(s){ce||(j(h.$$.fragment,s),j(B.$$.fragment,s),j(A.$$.fragment,s),j(Y.$$.fragment,s),j(F.$$.fragment,s),j(z.$$.fragment,s),j(S.$$.fragment,s),j(D.$$.fragment,s),j(ts.$$.fragment,s),j(js.$$.fragment,s),j(bs.$$.fragment,s),j(Js.$$.fragment,s),j(ps.$$.fragment,s),j($s.$$.fragment,s),j(Cs.$$.fragment,s),j(Zs.$$.fragment,s),j(Gs.$$.fragment,s),j(rs.$$.fragment,s),j(os.$$.fragment,s),j(Rs.$$.fragment,s),j(Ws.$$.fragment,s),j(is.$$.fragment,s),ce=!0)},o(s){f(h.$$.fragment,s),f(B.$$.fragment,s),f(A.$$.fragment,s),f(Y.$$.fragment,s),f(F.$$.fragment,s),f(z.$$.fragment,s),f(S.$$.fragment,s),f(D.$$.fragment,s),f(ts.$$.fragment,s),f(js.$$.fragment,s),f(bs.$$.fragment,s),f(Js.$$.fragment,s),f(ps.$$.fragment,s),f($s.$$.fragment,s),f(Cs.$$.fragment,s),f(Zs.$$.fragment,s),f(Gs.$$.fragment,s),f(rs.$$.fragment,s),f(os.$$.fragment,s),f(Rs.$$.fragment,s),f(Ws.$$.fragment,s),f(is.$$.fragment,s),ce=!1},d(s){s&&(a(o),a(e),a(m),a(C),a(I),a(k),a(Z),a(v),a($),a(G),a(U),a(E),a(x),a(V),a(ms),a(N),a(ns),a(Ms),a(Q),a(H),a(hs),a(q),a(L),a(ds),a(P),a(K),a(ys),a(O),a(J),a(xs),a(us),a(Ys),a(Es),a(fs),a(Fs),a(ws),a(Ns),a(zs),a(Ts),a(Qs),a(Hs),a(gs),a(Ss),a(Us),a(qs),a(Ls),a(Ds),a(_s),a(Ps),a(Ks),a(ks),a(Os),a(se),a(Is),a(ee),a(le),a(ae),a(te),a(ne),a(Vs),a(pe),a(Xs),a(re),a(oe),a(ie),a(As)),a(l),w(h,s),w(B,s),w(A,s),w(Y,s),w(F,s),w(z,s),w(S,s),w(D,s),w(ts,s),w(js,s),w(bs,s),w(Js,s),w(ps,s),w($s,s),w(Cs,s),w(Zs,s),w(Gs,s),w(rs,s),w(os,s),w(Rs,s),w(Ws,s),w(is,s)}}}const al='{"title":"Multiple choice","local":"multiple-choice","sections":[{"title":"Load SWAG dataset","local":"load-swag-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function tl(_){return Xe(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ml extends We{constructor(l){super(),Be(this,l,tl,ll,Ve,{})}}export{Ml as component};
