import{s as Yl,o as ql,n as k}from"../chunks/scheduler.9bc65507.js";import{S as Xl,i as Nl,g as m,s as l,r as h,A as Fl,h as c,f as n,c as t,j as Hl,u as o,x as u,k as _,y as Ll,a as e,v as i,d as j,t as b,w as d,m as Al,n as Ql}from"../chunks/index.707bf1b6.js";import{T as L}from"../chunks/Tip.c2ecdbf4.js";import{Y as El}from"../chunks/Youtube.e1129c6f.js";import{C as M}from"../chunks/CodeBlock.54a9f38d.js";import{D as Pl}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as Sl,M as Rl}from"../chunks/Markdown.fef84341.js";import{H as I}from"../chunks/Heading.342b1fa6.js";function Dl(y){let p,f="<code>AutoProcessor</code> <strong>always</strong> works and automatically chooses the correct class for the model youâ€™re using, whether youâ€™re using a tokenizer, image processor, feature extractor or processor.";return{c(){p=m("p"),p.innerHTML=f},l(r){p=c(r,"P",{"data-svelte-h":!0}),u(p)!=="svelte-15om5of"&&(p.innerHTML=f)},m(r,g){e(r,p,g)},p:k,d(r){r&&n(p)}}}function Kl(y){let p,f="If you plan on using a pretrained model, itâ€™s important to use the associated pretrained tokenizer. This ensures the text is split the same way as the pretraining corpus, and uses the same corresponding tokens-to-index (usually referred to as the <em>vocab</em>) during pretraining.";return{c(){p=m("p"),p.innerHTML=f},l(r){p=c(r,"P",{"data-svelte-h":!0}),u(p)!=="svelte-1irmkk5"&&(p.innerHTML=f)},m(r,g){e(r,p,g)},p:k,d(r){r&&n(p)}}}function Ol(y){let p,f='Check out the <a href="./pad_truncation">Padding and truncation</a> concept guide to learn more different padding and truncation arguments.';return{c(){p=m("p"),p.innerHTML=f},l(r){p=c(r,"P",{"data-svelte-h":!0}),u(p)!=="svelte-4vcsqp"&&(p.innerHTML=f)},m(r,g){e(r,p,g)},p:k,d(r){r&&n(p)}}}function st(y){let p,f;return p=new M({props:{code:"YmF0Y2hfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIyQnV0JTIwd2hhdCUyMGFib3V0JTIwc2Vjb25kJTIwYnJlYWtmYXN0JTNGJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIyRG9uJ3QlMjB0aGluayUyMGhlJTIwa25vd3MlMjBhYm91dCUyMHNlY29uZCUyMGJyZWFrZmFzdCUyQyUyMFBpcC4lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjJXaGF0JTIwYWJvdXQlMjBlbGV2ZW5zaWVzJTNGJTIyJTJDJTBBJTVEJTBBZW5jb2RlZF9pbnB1dCUyMCUzRCUyMHRva2VuaXplcihiYXRjaF9zZW50ZW5jZXMlMkMlMjBwYWRkaW5nJTNEVHJ1ZSUyQyUyMHRydW5jYXRpb24lM0RUcnVlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklMEFwcmludChlbmNvZGVkX2lucHV0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: tensor([[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                      [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
                      [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]),
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: tensor([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]),
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                           [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])}`,wrap:!1}}),{c(){h(p.$$.fragment)},l(r){o(p.$$.fragment,r)},m(r,g){i(p,r,g),f=!0},p:k,i(r){f||(j(p.$$.fragment,r),f=!0)},o(r){b(p.$$.fragment,r),f=!1},d(r){d(p,r)}}}function at(y){let p,f;return p=new Rl({props:{$$slots:{default:[st]},$$scope:{ctx:y}}}),{c(){h(p.$$.fragment)},l(r){o(p.$$.fragment,r)},m(r,g){i(p,r,g),f=!0},p(r,g){const J={};g&2&&(J.$$scope={dirty:g,ctx:r}),p.$set(J)},i(r){f||(j(p.$$.fragment,r),f=!0)},o(r){b(p.$$.fragment,r),f=!1},d(r){d(p,r)}}}function nt(y){let p,f;return p=new M({props:{code:"YmF0Y2hfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIyQnV0JTIwd2hhdCUyMGFib3V0JTIwc2Vjb25kJTIwYnJlYWtmYXN0JTNGJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIyRG9uJ3QlMjB0aGluayUyMGhlJTIwa25vd3MlMjBhYm91dCUyMHNlY29uZCUyMGJyZWFrZmFzdCUyQyUyMFBpcC4lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjJXaGF0JTIwYWJvdXQlMjBlbGV2ZW5zaWVzJTNGJTIyJTJDJTBBJTVEJTBBZW5jb2RlZF9pbnB1dCUyMCUzRCUyMHRva2VuaXplcihiYXRjaF9zZW50ZW5jZXMlMkMlMjBwYWRkaW5nJTNEVHJ1ZSUyQyUyMHRydW5jYXRpb24lM0RUcnVlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMiklMEFwcmludChlbmNvZGVkX2lucHV0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
       [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
      dtype=int32)&gt;,
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=int32)&gt;,
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: &lt;tf.Tensor: shape=(<span class="hljs-number">2</span>, <span class="hljs-number">9</span>), dtype=int32, numpy=
array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
       [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]], dtype=int32)&gt;}`,wrap:!1}}),{c(){h(p.$$.fragment)},l(r){o(p.$$.fragment,r)},m(r,g){i(p,r,g),f=!0},p:k,i(r){f||(j(p.$$.fragment,r),f=!0)},o(r){b(p.$$.fragment,r),f=!1},d(r){d(p,r)}}}function et(y){let p,f;return p=new Rl({props:{$$slots:{default:[nt]},$$scope:{ctx:y}}}),{c(){h(p.$$.fragment)},l(r){o(p.$$.fragment,r)},m(r,g){i(p,r,g),f=!0},p(r,g){const J={};g&2&&(J.$$scope={dirty:g,ctx:r}),p.$set(J)},i(r){f||(j(p.$$.fragment,r),f=!0)},o(r){b(p.$$.fragment,r),f=!1},d(r){d(p,r)}}}function lt(y){let p;return{c(){p=Al("Different pipelines support tokenizer arguments in their `__call__()` differently. `text-2-text-generation` pipelines support (i.e. pass on)\nonly `truncation`. `text-generation` pipelines support `max_length`, `truncation`, `padding` and `add_special_tokens`. \nIn `fill-mask` pipelines, tokenizer arguments can be passed in the `tokenizer_kwargs` argument (dictionary).")},l(f){p=Ql(f,"Different pipelines support tokenizer arguments in their `__call__()` differently. `text-2-text-generation` pipelines support (i.e. pass on)\nonly `truncation`. `text-generation` pipelines support `max_length`, `truncation`, `padding` and `add_special_tokens`. \nIn `fill-mask` pipelines, tokenizer arguments can be passed in the `tokenizer_kwargs` argument (dictionary).")},m(f,r){e(f,p,r)},d(f){f&&n(p)}}}function tt(y){let p,f=`Image preprocessing often follows some form of image augmentation. Both image preprocessing and image augmentation
transform image data, but they serve different purposes:`,r,g,J="<li>Image augmentation alters images in a way that can help prevent overfitting and increase the robustness of the model. You can get creative in how you augment your data - adjust brightness and colors, crop, rotate, resize, zoom, etc. However, be mindful not to change the meaning of the images with your augmentations.</li> <li>Image preprocessing guarantees that the images match the modelâ€™s expected input format. When fine-tuning a computer vision model, images must be preprocessed exactly as when the model was initially trained.</li>",$,w,A="You can use any library you like for image augmentation. For image preprocessing, use the <code>ImageProcessor</code> associated with the model.";return{c(){p=m("p"),p.textContent=f,r=l(),g=m("ul"),g.innerHTML=J,$=l(),w=m("p"),w.innerHTML=A},l(T){p=c(T,"P",{"data-svelte-h":!0}),u(p)!=="svelte-aepj6y"&&(p.textContent=f),r=t(T),g=c(T,"UL",{"data-svelte-h":!0}),u(g)!=="svelte-mzhu6i"&&(g.innerHTML=J),$=t(T),w=c(T,"P",{"data-svelte-h":!0}),u(w)!=="svelte-dwyc8n"&&(w.innerHTML=A)},m(T,v){e(T,p,v),e(T,r,v),e(T,g,v),e(T,$,v),e(T,w,v)},p:k,d(T){T&&(n(p),n(r),n(g),n($),n(w))}}}function pt(y){let p,f="Use ðŸ¤— Datasets <code>split</code> parameter to only load a small sample from the training split since the dataset is quite large!";return{c(){p=m("p"),p.innerHTML=f},l(r){p=c(r,"P",{"data-svelte-h":!0}),u(p)!=="svelte-14ltu7c"&&(p.innerHTML=f)},m(r,g){e(r,p,g)},p:k,d(r){r&&n(p)}}}function rt(y){let p,f=`In the example above we set <code>do_resize=False</code> because we have already resized the images in the image augmentation transformation,
and leveraged the <code>size</code> attribute from the appropriate <code>image_processor</code>. If you do not resize images during image augmentation,
leave this parameter out. By default, <code>ImageProcessor</code> will handle the resizing.`,r,g,J=`If you wish to normalize images as a part of the augmentation transformation, use the <code>image_processor.image_mean</code>,
and <code>image_processor.image_std</code> values.`;return{c(){p=m("p"),p.innerHTML=f,r=l(),g=m("p"),g.innerHTML=J},l($){p=c($,"P",{"data-svelte-h":!0}),u(p)!=="svelte-nqgnl7"&&(p.innerHTML=f),r=t($),g=c($,"P",{"data-svelte-h":!0}),u(g)!=="svelte-13w97bd"&&(g.innerHTML=J)},m($,w){e($,p,w),e($,r,w),e($,g,w)},p:k,d($){$&&(n(p),n(r),n(g))}}}function mt(y){let p,f=`For tasks like object detection, semantic segmentation, instance segmentation, and panoptic segmentation, <code>ImageProcessor</code>
offers post processing methods. These methods convert modelâ€™s raw outputs into meaningful predictions such as bounding boxes,
or segmentation maps.`;return{c(){p=m("p"),p.innerHTML=f},l(r){p=c(r,"P",{"data-svelte-h":!0}),u(p)!=="svelte-p4rlwj"&&(p.innerHTML=f)},m(r,g){e(r,p,g)},p:k,d(r){r&&n(p)}}}function ct(y){let p,f,r,g,J,$,w,A,T,v="Before you can train a model on a dataset, it needs to be preprocessed into the expected model input format. Whether your data is text, images, or audio, they need to be converted and assembled into batches of tensors. ðŸ¤— Transformers provides a set of preprocessing classes to help prepare your data for the model. In this tutorial, youâ€™ll learn that for:",Ua,Q,Ue='<li>Text, use a <a href="./main_classes/tokenizer">Tokenizer</a> to convert text into a sequence of tokens, create a numerical representation of the tokens, and assemble them into tensors.</li> <li>Speech and audio, use a <a href="./main_classes/feature_extractor">Feature extractor</a> to extract sequential features from audio waveforms and convert them into tensors.</li> <li>Image inputs use a <a href="./main_classes/image_processor">ImageProcessor</a> to convert images into tensors.</li> <li>Multimodal inputs, use a <a href="./main_classes/processors">Processor</a> to combine a tokenizer and a feature extractor or image processor.</li>',xa,U,Ca,E,xe="Before you begin, install ðŸ¤— Datasets so you can load some datasets to experiment with:",Za,P,Ga,S,Va,D,Ba,K,Ce='The main tool for preprocessing textual data is a <a href="main_classes/tokenizer">tokenizer</a>. A tokenizer splits text into <em>tokens</em> according to a set of rules. The tokens are converted into numbers and then tensors, which become the model inputs. Any additional inputs required by the model are added by the tokenizer.',Wa,x,za,O,Ze='Get started by loading a pretrained tokenizer with the <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained">AutoTokenizer.from_pretrained()</a> method. This downloads the <em>vocab</em> a model was pretrained with:',Ha,ss,Ra,as,Ge="Then pass your text to the tokenizer:",Ya,ns,qa,es,Ve="The tokenizer returns a dictionary with three important items:",Xa,ls,Be='<li><a href="glossary#input-ids">input_ids</a> are the indices corresponding to each token in the sentence.</li> <li><a href="glossary#attention-mask">attention_mask</a> indicates whether a token should be attended to or not.</li> <li><a href="glossary#token-type-ids">token_type_ids</a> identifies which sequence a token belongs to when there is more than one sequence.</li>',Na,ts,We="Return your input by decoding the <code>input_ids</code>:",Fa,ps,La,rs,ze=`As you can see, the tokenizer added two special tokens - <code>CLS</code> and <code>SEP</code> (classifier and separator) - to the sentence. Not all models need
special tokens, but if they do, the tokenizer automatically adds them for you.`,Aa,ms,He="If there are several sentences you want to preprocess, pass them as a list to the tokenizer:",Qa,cs,Ea,us,Pa,hs,Re="Sentences arenâ€™t always the same length which can be an issue because tensors, the model inputs, need to have a uniform shape. Padding is a strategy for ensuring tensors are rectangular by adding a special <em>padding token</em> to shorter sentences.",Sa,os,Ye="Set the <code>padding</code> parameter to <code>True</code> to pad the shorter sequences in the batch to match the longest sequence:",Da,is,Ka,js,qe="The first and third sentences are now padded with <code>0</code>â€™s because they are shorter.",Oa,bs,sn,ds,Xe="On the other end of the spectrum, sometimes a sequence may be too long for a model to handle. In this case, youâ€™ll need to truncate the sequence to a shorter length.",an,fs,Ne="Set the <code>truncation</code> parameter to <code>True</code> to truncate a sequence to the maximum length accepted by the model:",nn,gs,en,C,ln,Ms,tn,ys,Fe="Finally, you want the tokenizer to return the actual tensors that get fed to the model.",pn,Ts,Le="Set the <code>return_tensors</code> parameter to either <code>pt</code> for PyTorch, or <code>tf</code> for TensorFlow:",rn,Z,mn,G,cn,Js,un,$s,Ae='For audio tasks, youâ€™ll need a <a href="main_classes/feature_extractor">feature extractor</a> to prepare your dataset for the model. The feature extractor is designed to extract features from raw audio data, and convert them into tensors.',hn,ws,Qe='Load the <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> dataset (see the ðŸ¤— <a href="https://huggingface.co/docs/datasets/load_hub" rel="nofollow">Datasets tutorial</a> for more details on how to load a dataset) to see how you can use a feature extractor with audio datasets:',on,_s,jn,Is,Ee="Access the first element of the <code>audio</code> column to take a look at the input. Calling the <code>audio</code> column automatically loads and resamples the audio file:",bn,ks,dn,vs,Pe="This returns three items:",fn,Us,Se="<li><code>array</code> is the speech signal loaded - and potentially resampled - as a 1D array.</li> <li><code>path</code> points to the location of the audio file.</li> <li><code>sampling_rate</code> refers to how many data points in the speech signal are measured per second.</li>",gn,xs,De='For this tutorial, youâ€™ll use the <a href="https://huggingface.co/facebook/wav2vec2-base" rel="nofollow">Wav2Vec2</a> model. Take a look at the model card, and youâ€™ll learn Wav2Vec2 is pretrained on 16kHz sampled speech audio. It is important your audio dataâ€™s sampling rate matches the sampling rate of the dataset used to pretrain the model. If your dataâ€™s sampling rate isnâ€™t the same, then you need to resample your data.',Mn,Cs,Ke='<li>Use ðŸ¤— Datasetsâ€™ <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.cast_column" rel="nofollow">cast_column</a> method to upsample the sampling rate to 16kHz:</li>',yn,Zs,Tn,V,Oe="<li>Call the <code>audio</code> column again to resample the audio file:</li>",Jn,Gs,$n,Vs,sl="Next, load a feature extractor to normalize and pad the input. When padding textual data, a <code>0</code> is added for shorter sequences. The same idea applies to audio data. The feature extractor adds a <code>0</code> - interpreted as silence - to <code>array</code>.",wn,Bs,al='Load the feature extractor with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained">AutoFeatureExtractor.from_pretrained()</a>:',_n,Ws,In,zs,nl="Pass the audio <code>array</code> to the feature extractor. We also recommend adding the <code>sampling_rate</code> argument in the feature extractor in order to better debug any silent errors that may occur.",kn,Hs,vn,Rs,el="Just like the tokenizer, you can apply padding or truncation to handle variable sequences in a batch. Take a look at the sequence length of these two audio samples:",Un,Ys,xn,qs,ll="Create a function to preprocess the dataset so the audio samples are the same lengths. Specify a maximum sample length, and the feature extractor will either pad or truncate the sequences to match it:",Cn,Xs,Zn,Ns,tl="Apply the <code>preprocess_function</code> to the first few examples in the dataset:",Gn,Fs,Vn,Ls,pl="The sample lengths are now the same and match the specified maximum length. You can pass your processed dataset to the model now!",Bn,As,Wn,Qs,zn,Es,rl=`For computer vision tasks, youâ€™ll need an <a href="main_classes/image_processor">image processor</a> to prepare your dataset for the model.
Image preprocessing consists of several steps that convert images into the input expected by the model. These steps
include but are not limited to resizing, normalizing, color channel correction, and converting images to tensors.`,Hn,B,Rn,Ps,ml='Load the <a href="https://huggingface.co/datasets/food101" rel="nofollow">food101</a> dataset (see the ðŸ¤— <a href="https://huggingface.co/docs/datasets/load_hub" rel="nofollow">Datasets tutorial</a> for more details on how to load a dataset) to see how you can use an image processor with computer vision datasets:',Yn,W,qn,Ss,Xn,Ds,cl='Next, take a look at the image with ðŸ¤— Datasets <a href="https://huggingface.co/docs/datasets/package_reference/main_classes?highlight=image#datasets.Image" rel="nofollow"><code>Image</code></a> feature:',Nn,Ks,Fn,z,ul='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vision-preprocess-tutorial.png"/>',Ln,Os,hl='Load the image processor with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoImageProcessor.from_pretrained">AutoImageProcessor.from_pretrained()</a>:',An,sa,Qn,aa,ol='First, letâ€™s add some image augmentation. You can use any library you prefer, but in this tutorial, weâ€™ll use torchvisionâ€™s <a href="https://pytorch.org/vision/stable/transforms.html" rel="nofollow"><code>transforms</code></a> module. If youâ€™re interested in using another data augmentation library, learn how in the <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_albumentations.ipynb" rel="nofollow">Albumentations</a> or <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb" rel="nofollow">Kornia notebooks</a>.',En,na,il=`<li>Here we use <a href="https://pytorch.org/vision/master/generated/torchvision.transforms.Compose.html" rel="nofollow"><code>Compose</code></a> to chain together a couple of
transforms - <a href="https://pytorch.org/vision/main/generated/torchvision.transforms.RandomResizedCrop.html" rel="nofollow"><code>RandomResizedCrop</code></a> and <a href="https://pytorch.org/vision/main/generated/torchvision.transforms.ColorJitter.html" rel="nofollow"><code>ColorJitter</code></a>.
Note that for resizing, we can get the image size requirements from the <code>image_processor</code>. For some models, an exact height and
width are expected, for others only the <code>shortest_edge</code> is defined.</li>`,Pn,ea,Sn,H,jl=`<li>The model accepts <a href="model_doc/vision-encoder-decoder#transformers.VisionEncoderDecoderModel.forward.pixel_values"><code>pixel_values</code></a>
as its input. <code>ImageProcessor</code> can take care of normalizing the images, and generating appropriate tensors.
Create a function that combines image augmentation and image preprocessing for a batch of images and generates <code>pixel_values</code>:</li>`,Dn,la,Kn,R,On,Y,bl='<li>Then use ðŸ¤— Datasets<a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.set_transform" rel="nofollow">set_transform</a> to apply the transforms on the fly:</li>',se,ta,ae,q,dl="<li>Now when you access the image, youâ€™ll notice the image processor has added <code>pixel_values</code>. You can pass your processed dataset to the model now!</li>",ne,pa,ee,ra,fl="Here is what the image looks like after the transforms are applied. The image has been randomly cropped and itâ€™s color properties are different.",le,ma,te,X,gl='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/preprocessed_image.png"/>',pe,N,re,ca,me,ua,Ml=`In some cases, for instance, when fine-tuning <a href="./model_doc/detr">DETR</a>, the model applies scale augmentation at training
time. This may cause images to be different sizes in a batch. You can use <code>DetrImageProcessor.pad()</code>
from <a href="/docs/transformers/main/en/model_doc/detr#transformers.DetrImageProcessor">DetrImageProcessor</a> and define a custom <code>collate_fn</code> to batch images together.`,ce,ha,ue,oa,he,ia,yl='For tasks involving multimodal inputs, youâ€™ll need a <a href="main_classes/processors">processor</a> to prepare your dataset for the model. A processor couples together two processing objects such as as tokenizer and feature extractor.',oe,ja,Tl='Load the <a href="https://huggingface.co/datasets/lj_speech" rel="nofollow">LJ Speech</a> dataset (see the ðŸ¤— <a href="https://huggingface.co/docs/datasets/load_hub" rel="nofollow">Datasets tutorial</a> for more details on how to load a dataset) to see how you can use a processor for automatic speech recognition (ASR):',ie,ba,je,da,Jl="For ASR, youâ€™re mainly focused on <code>audio</code> and <code>text</code> so you can remove the other columns:",be,fa,de,ga,$l="Now take a look at the <code>audio</code> and <code>text</code> columns:",fe,Ma,ge,ya,wl='Remember you should always <a href="preprocessing#audio">resample</a> your audio datasetâ€™s sampling rate to match the sampling rate of the dataset used to pretrain a model!',Me,Ta,ye,Ja,_l='Load a processor with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained">AutoProcessor.from_pretrained()</a>:',Te,$a,Je,wa,Il="<li>Create a function to process the audio data contained in <code>array</code> to <code>input_values</code>, and tokenize <code>text</code> to <code>labels</code>. These are the inputs to the model:</li>",$e,_a,we,F,kl="<li>Apply the <code>prepare_dataset</code> function to a sample:</li>",_e,Ia,Ie,ka,vl="The processor has now added <code>input_values</code> and <code>labels</code>, and the sampling rate has also been correctly downsampled to 16kHz. You can pass your processed dataset to the model now!",ke,va,ve;return J=new I({props:{title:"Preprocess",local:"preprocess",headingTag:"h1"}}),w=new Pl({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/preprocessing.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/preprocessing.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/preprocessing.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/preprocessing.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/preprocessing.ipynb"}]}}),U=new L({props:{$$slots:{default:[Dl]},$$scope:{ctx:y}}}),P=new M({props:{code:"cGlwJTIwaW5zdGFsbCUyMGRhdGFzZXRz",highlighted:"pip install datasets",wrap:!1}}),S=new I({props:{title:"Natural Language Processing",local:"natural-language-processing",headingTag:"h2"}}),D=new El({props:{id:"Yffk5aydLzg"}}),x=new L({props:{$$slots:{default:[Kl]},$$scope:{ctx:y}}}),ss=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS1jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-cased&quot;</span>)`,wrap:!1}}),ns=new M({props:{code:"ZW5jb2RlZF9pbnB1dCUyMCUzRCUyMHRva2VuaXplciglMjJEbyUyMG5vdCUyMG1lZGRsZSUyMGluJTIwdGhlJTIwYWZmYWlycyUyMG9mJTIwd2l6YXJkcyUyQyUyMGZvciUyMHRoZXklMjBhcmUlMjBzdWJ0bGUlMjBhbmQlMjBxdWljayUyMHRvJTIwYW5nZXIuJTIyKSUwQXByaW50KGVuY29kZWRfaW5wdXQp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(<span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">2079</span>, <span class="hljs-number">2025</span>, <span class="hljs-number">19960</span>, <span class="hljs-number">10362</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">3821</span>, <span class="hljs-number">1997</span>, <span class="hljs-number">16657</span>, <span class="hljs-number">1010</span>, <span class="hljs-number">2005</span>, <span class="hljs-number">2027</span>, <span class="hljs-number">2024</span>, <span class="hljs-number">11259</span>, <span class="hljs-number">1998</span>, <span class="hljs-number">4248</span>, <span class="hljs-number">2000</span>, <span class="hljs-number">4963</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),ps=new M({props:{code:"dG9rZW5pemVyLmRlY29kZShlbmNvZGVkX2lucHV0JTVCJTIyaW5wdXRfaWRzJTIyJTVEKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(encoded_input[<span class="hljs-string">&quot;input_ids&quot;</span>])
<span class="hljs-string">&#x27;[CLS] Do not meddle in the affairs of wizards, for they are subtle and quick to anger. [SEP]&#x27;</span>`,wrap:!1}}),cs=new M({props:{code:"YmF0Y2hfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIyQnV0JTIwd2hhdCUyMGFib3V0JTIwc2Vjb25kJTIwYnJlYWtmYXN0JTNGJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIyRG9uJ3QlMjB0aGluayUyMGhlJTIwa25vd3MlMjBhYm91dCUyMHNlY29uZCUyMGJyZWFrZmFzdCUyQyUyMFBpcC4lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjJXaGF0JTIwYWJvdXQlMjBlbGV2ZW5zaWVzJTNGJTIyJTJDJTBBJTVEJTBBZW5jb2RlZF9pbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoYmF0Y2hfc2VudGVuY2VzKSUwQXByaW50KGVuY29kZWRfaW5wdXRzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_inputs = tokenizer(batch_sentences)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_inputs)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>],
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>]],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]]}`,wrap:!1}}),us=new I({props:{title:"Pad",local:"pad",headingTag:"h3"}}),is=new M({props:{code:"YmF0Y2hfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIyQnV0JTIwd2hhdCUyMGFib3V0JTIwc2Vjb25kJTIwYnJlYWtmYXN0JTNGJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIyRG9uJ3QlMjB0aGluayUyMGhlJTIwa25vd3MlMjBhYm91dCUyMHNlY29uZCUyMGJyZWFrZmFzdCUyQyUyMFBpcC4lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjJXaGF0JTIwYWJvdXQlMjBlbGV2ZW5zaWVzJTNGJTIyJTJDJTBBJTVEJTBBZW5jb2RlZF9pbnB1dCUyMCUzRCUyMHRva2VuaXplcihiYXRjaF9zZW50ZW5jZXMlMkMlMjBwYWRkaW5nJTNEVHJ1ZSklMEFwcmludChlbmNvZGVkX2lucHV0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]}`,wrap:!1}}),bs=new I({props:{title:"Truncation",local:"truncation",headingTag:"h3"}}),gs=new M({props:{code:"YmF0Y2hfc2VudGVuY2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIyQnV0JTIwd2hhdCUyMGFib3V0JTIwc2Vjb25kJTIwYnJlYWtmYXN0JTNGJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIyRG9uJ3QlMjB0aGluayUyMGhlJTIwa25vd3MlMjBhYm91dCUyMHNlY29uZCUyMGJyZWFrZmFzdCUyQyUyMFBpcC4lMjIlMkMlMEElMjAlMjAlMjAlMjAlMjJXaGF0JTIwYWJvdXQlMjBlbGV2ZW5zaWVzJTNGJTIyJTJDJTBBJTVEJTBBZW5jb2RlZF9pbnB1dCUyMCUzRCUyMHRva2VuaXplcihiYXRjaF9zZW50ZW5jZXMlMkMlMjBwYWRkaW5nJTNEVHJ1ZSUyQyUyMHRydW5jYXRpb24lM0RUcnVlKSUwQXByaW50KGVuY29kZWRfaW5wdXQp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>batch_sentences = [
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;But what about second breakfast?&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;Don&#x27;t think he knows about second breakfast, Pip.&quot;</span>,
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;What about elevensies?&quot;</span>,
<span class="hljs-meta">... </span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_input = tokenizer(batch_sentences, padding=<span class="hljs-literal">True</span>, truncation=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoded_input)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [[<span class="hljs-number">101</span>, <span class="hljs-number">1252</span>, <span class="hljs-number">1184</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
               [<span class="hljs-number">101</span>, <span class="hljs-number">1790</span>, <span class="hljs-number">112</span>, <span class="hljs-number">189</span>, <span class="hljs-number">1341</span>, <span class="hljs-number">1119</span>, <span class="hljs-number">3520</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">1248</span>, <span class="hljs-number">6462</span>, <span class="hljs-number">117</span>, <span class="hljs-number">21902</span>, <span class="hljs-number">1643</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
               [<span class="hljs-number">101</span>, <span class="hljs-number">1327</span>, <span class="hljs-number">1164</span>, <span class="hljs-number">5450</span>, <span class="hljs-number">23434</span>, <span class="hljs-number">136</span>, <span class="hljs-number">102</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>],
                    [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]]}`,wrap:!1}}),C=new L({props:{$$slots:{default:[Ol]},$$scope:{ctx:y}}}),Ms=new I({props:{title:"Build tensors",local:"build-tensors",headingTag:"h3"}}),Z=new Sl({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[et],pytorch:[at]},$$scope:{ctx:y}}}),G=new L({props:{$$slots:{default:[lt]},$$scope:{ctx:y}}}),Js=new I({props:{title:"Audio",local:"audio",headingTag:"h2"}}),_s=new M({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjBuYW1lJTNEJTIyZW4tVVMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),ks=new M({props:{code:"ZGF0YXNldCU1QjAlNUQlNUIlMjJhdWRpbyUyMiU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.00024414</span>, -<span class="hljs-number">0.00024414</span>, ..., -<span class="hljs-number">0.00024414</span>,
         <span class="hljs-number">0.</span>        ,  <span class="hljs-number">0.</span>        ], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">8000</span>}`,wrap:!1}}),Zs=new M({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEMTZfMDAwKSk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))',wrap:!1}}),Gs=new M({props:{code:"ZGF0YXNldCU1QjAlNUQlNUIlMjJhdWRpbyUyMiU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([ <span class="hljs-number">2.3443763e-05</span>,  <span class="hljs-number">2.1729663e-04</span>,  <span class="hljs-number">2.2145823e-04</span>, ...,
         <span class="hljs-number">3.8356509e-05</span>, -<span class="hljs-number">7.3497440e-06</span>, -<span class="hljs-number">2.1754686e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/f14948e0e84be638dd7943ac36518a4cf3324e8b7aa331c5ab11541518e9368c/en-US~JOINT_ACCOUNT/602ba55abb1e6d0fbce92065.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">16000</span>}`,wrap:!1}}),Ws=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZ3YXYydmVjMi1iYXNlJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base&quot;</span>)`,wrap:!1}}),Hs=new M({props:{code:"YXVkaW9faW5wdXQlMjAlM0QlMjAlNUJkYXRhc2V0JTVCMCU1RCU1QiUyMmF1ZGlvJTIyJTVEJTVCJTIyYXJyYXklMjIlNUQlNUQlMEFmZWF0dXJlX2V4dHJhY3RvcihhdWRpb19pbnB1dCUyQyUyMHNhbXBsaW5nX3JhdGUlM0QxNjAwMCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>audio_input = [dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>]]
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor(audio_input, sampling_rate=<span class="hljs-number">16000</span>)
{<span class="hljs-string">&#x27;input_values&#x27;</span>: [array([ <span class="hljs-number">3.8106556e-04</span>,  <span class="hljs-number">2.7506407e-03</span>,  <span class="hljs-number">2.8015103e-03</span>, ...,
        <span class="hljs-number">5.6335266e-04</span>,  <span class="hljs-number">4.6588284e-06</span>, -<span class="hljs-number">1.7142107e-04</span>], dtype=float32)]}`,wrap:!1}}),Ys=new M({props:{code:"ZGF0YXNldCU1QjAlNUQlNUIlMjJhdWRpbyUyMiU1RCU1QiUyMmFycmF5JTIyJTVELnNoYXBlJTBBJTBBZGF0YXNldCU1QjElNUQlNUIlMjJhdWRpbyUyMiU1RCU1QiUyMmFycmF5JTIyJTVELnNoYXBl",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>].shape
(<span class="hljs-number">173398</span>,)

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">1</span>][<span class="hljs-string">&quot;audio&quot;</span>][<span class="hljs-string">&quot;array&quot;</span>].shape
(<span class="hljs-number">106496</span>,)`,wrap:!1}}),Xs=new M({props:{code:"ZGVmJTIwcHJlcHJvY2Vzc19mdW5jdGlvbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBhdWRpb19hcnJheXMlMjAlM0QlMjAlNUJ4JTVCJTIyYXJyYXklMjIlNUQlMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlcyU1QiUyMmF1ZGlvJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwaW5wdXRzJTIwJTNEJTIwZmVhdHVyZV9leHRyYWN0b3IoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwYXVkaW9fYXJyYXlzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwc2FtcGxpbmdfcmF0ZSUzRDE2MDAwJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcGFkZGluZyUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNEMTAwMDAwJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjApJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW5wdXRz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    audio_arrays = [x[<span class="hljs-string">&quot;array&quot;</span>] <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;audio&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = feature_extractor(
<span class="hljs-meta">... </span>        audio_arrays,
<span class="hljs-meta">... </span>        sampling_rate=<span class="hljs-number">16000</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">100000</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    )
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`,wrap:!1}}),Fs=new M({props:{code:"cHJvY2Vzc2VkX2RhdGFzZXQlMjAlM0QlMjBwcmVwcm9jZXNzX2Z1bmN0aW9uKGRhdGFzZXQlNUIlM0E1JTVEKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset = preprocess_function(dataset[:<span class="hljs-number">5</span>])',wrap:!1}}),As=new M({props:{code:"cHJvY2Vzc2VkX2RhdGFzZXQlNUIlMjJpbnB1dF92YWx1ZXMlMjIlNUQlNUIwJTVELnNoYXBlJTBBJTBBcHJvY2Vzc2VkX2RhdGFzZXQlNUIlMjJpbnB1dF92YWx1ZXMlMjIlNUQlNUIxJTVELnNoYXBl",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">0</span>].shape
(<span class="hljs-number">100000</span>,)

<span class="hljs-meta">&gt;&gt;&gt; </span>processed_dataset[<span class="hljs-string">&quot;input_values&quot;</span>][<span class="hljs-number">1</span>].shape
(<span class="hljs-number">100000</span>,)`,wrap:!1}}),Qs=new I({props:{title:"Computer vision",local:"computer-vision",headingTag:"h2"}}),B=new L({props:{$$slots:{default:[tt]},$$scope:{ctx:y}}}),W=new L({props:{$$slots:{default:[pt]},$$scope:{ctx:y}}}),Ss=new M({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJmb29kMTAxJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiU1QiUzQTEwMCU1RCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:100]&quot;</span>)`,wrap:!1}}),Ks=new M({props:{code:"ZGF0YXNldCU1QjAlNUQlNUIlMjJpbWFnZSUyMiU1RA==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]',wrap:!1}}),sa=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGdml0LWJhc2UtcGF0Y2gxNi0yMjQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224&quot;</span>)`,wrap:!1}}),ea=new M({props:{code:"ZnJvbSUyMHRvcmNodmlzaW9uLnRyYW5zZm9ybXMlMjBpbXBvcnQlMjBSYW5kb21SZXNpemVkQ3JvcCUyQyUyMENvbG9ySml0dGVyJTJDJTIwQ29tcG9zZSUwQSUwQXNpemUlMjAlM0QlMjAoJTBBJTIwJTIwJTIwJTIwaW1hZ2VfcHJvY2Vzc29yLnNpemUlNUIlMjJzaG9ydGVzdF9lZGdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwaWYlMjAlMjJzaG9ydGVzdF9lZGdlJTIyJTIwaW4lMjBpbWFnZV9wcm9jZXNzb3Iuc2l6ZSUwQSUyMCUyMCUyMCUyMGVsc2UlMjAoaW1hZ2VfcHJvY2Vzc29yLnNpemUlNUIlMjJoZWlnaHQlMjIlNUQlMkMlMjBpbWFnZV9wcm9jZXNzb3Iuc2l6ZSU1QiUyMndpZHRoJTIyJTVEKSUwQSklMEElMEFfdHJhbnNmb3JtcyUyMCUzRCUyMENvbXBvc2UoJTVCUmFuZG9tUmVzaXplZENyb3Aoc2l6ZSklMkMlMjBDb2xvckppdHRlcihicmlnaHRuZXNzJTNEMC41JTJDJTIwaHVlJTNEMC41KSU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> RandomResizedCrop, ColorJitter, Compose

<span class="hljs-meta">&gt;&gt;&gt; </span>size = (
<span class="hljs-meta">... </span>    image_processor.size[<span class="hljs-string">&quot;shortest_edge&quot;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;shortest_edge&quot;</span> <span class="hljs-keyword">in</span> image_processor.size
<span class="hljs-meta">... </span>    <span class="hljs-keyword">else</span> (image_processor.size[<span class="hljs-string">&quot;height&quot;</span>], image_processor.size[<span class="hljs-string">&quot;width&quot;</span>])
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>_transforms = Compose([RandomResizedCrop(size), ColorJitter(brightness=<span class="hljs-number">0.5</span>, hue=<span class="hljs-number">0.5</span>)])`,wrap:!1}}),la=new M({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBpbWFnZXMlMjAlM0QlMjAlNUJfdHJhbnNmb3JtcyhpbWcuY29udmVydCglMjJSR0IlMjIpKSUyMGZvciUyMGltZyUyMGluJTIwZXhhbXBsZXMlNUIlMjJpbWFnZSUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGV4YW1wbGVzJTVCJTIycGl4ZWxfdmFsdWVzJTIyJTVEJTIwJTNEJTIwaW1hZ2VfcHJvY2Vzc29yKGltYWdlcyUyQyUyMGRvX3Jlc2l6ZSUzREZhbHNlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklNUIlMjJwaXhlbF92YWx1ZXMlMjIlNUQlMEElMjAlMjAlMjAlMjByZXR1cm4lMjBleGFtcGxlcw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    images = [_transforms(img.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> img <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = image_processor(images, do_resize=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)[<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`,wrap:!1}}),R=new L({props:{$$slots:{default:[rt]},$$scope:{ctx:y}}}),ta=new M({props:{code:"ZGF0YXNldC5zZXRfdHJhbnNmb3JtKHRyYW5zZm9ybXMp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset.set_transform(transforms)',wrap:!1}}),pa=new M({props:{code:"ZGF0YXNldCU1QjAlNUQua2V5cygp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset[<span class="hljs-number">0</span>].keys()',wrap:!1}}),ma=new M({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBaW1wb3J0JTIwbWF0cGxvdGxpYi5weXBsb3QlMjBhcyUyMHBsdCUwQSUwQWltZyUyMCUzRCUyMGRhdGFzZXQlNUIwJTVEJTVCJTIycGl4ZWxfdmFsdWVzJTIyJTVEJTBBcGx0Lmltc2hvdyhpbWcucGVybXV0ZSgxJTJDJTIwMiUyQyUyMDApKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt

<span class="hljs-meta">&gt;&gt;&gt; </span>img = dataset[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img.permute(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>))`,wrap:!1}}),N=new L({props:{$$slots:{default:[mt]},$$scope:{ctx:y}}}),ca=new I({props:{title:"Pad",local:"pad",headingTag:"h3"}}),ha=new M({props:{code:"ZGVmJTIwY29sbGF0ZV9mbihiYXRjaCklM0ElMEElMjAlMjAlMjAlMjBwaXhlbF92YWx1ZXMlMjAlM0QlMjAlNUJpdGVtJTVCJTIycGl4ZWxfdmFsdWVzJTIyJTVEJTIwZm9yJTIwaXRlbSUyMGluJTIwYmF0Y2glNUQlMEElMjAlMjAlMjAlMjBlbmNvZGluZyUyMCUzRCUyMGltYWdlX3Byb2Nlc3Nvci5wYWQocGl4ZWxfdmFsdWVzJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklMEElMjAlMjAlMjAlMjBsYWJlbHMlMjAlM0QlMjAlNUJpdGVtJTVCJTIybGFiZWxzJTIyJTVEJTIwZm9yJTIwaXRlbSUyMGluJTIwYmF0Y2glNUQlMEElMjAlMjAlMjAlMjBiYXRjaCUyMCUzRCUyMCU3QiU3RCUwQSUyMCUyMCUyMCUyMGJhdGNoJTVCJTIycGl4ZWxfdmFsdWVzJTIyJTVEJTIwJTNEJTIwZW5jb2RpbmclNUIlMjJwaXhlbF92YWx1ZXMlMjIlNUQlMEElMjAlMjAlMjAlMjBiYXRjaCU1QiUyMnBpeGVsX21hc2slMjIlNUQlMjAlM0QlMjBlbmNvZGluZyU1QiUyMnBpeGVsX21hc2slMjIlNUQlMEElMjAlMjAlMjAlMjBiYXRjaCU1QiUyMmxhYmVscyUyMiU1RCUyMCUzRCUyMGxhYmVscyUwQSUyMCUyMCUyMCUyMHJldHVybiUyMGJhdGNo",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">collate_fn</span>(<span class="hljs-params">batch</span>):
<span class="hljs-meta">... </span>    pixel_values = [item[<span class="hljs-string">&quot;pixel_values&quot;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch]
<span class="hljs-meta">... </span>    encoding = image_processor.pad(pixel_values, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">... </span>    labels = [item[<span class="hljs-string">&quot;labels&quot;</span>] <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> batch]
<span class="hljs-meta">... </span>    batch = {}
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;pixel_values&quot;</span>] = encoding[<span class="hljs-string">&quot;pixel_values&quot;</span>]
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;pixel_mask&quot;</span>] = encoding[<span class="hljs-string">&quot;pixel_mask&quot;</span>]
<span class="hljs-meta">... </span>    batch[<span class="hljs-string">&quot;labels&quot;</span>] = labels
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> batch`,wrap:!1}}),oa=new I({props:{title:"Multimodal",local:"multimodal",headingTag:"h2"}}),ba=new M({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBbGpfc3BlZWNoJTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMmxqX3NwZWVjaCUyMiUyQyUyMHNwbGl0JTNEJTIydHJhaW4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = load_dataset(<span class="hljs-string">&quot;lj_speech&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),fa=new M({props:{code:"bGpfc3BlZWNoJTIwJTNEJTIwbGpfc3BlZWNoLm1hcChyZW1vdmVfY29sdW1ucyUzRCU1QiUyMmZpbGUlMjIlMkMlMjAlMjJpZCUyMiUyQyUyMCUyMm5vcm1hbGl6ZWRfdGV4dCUyMiU1RCk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.<span class="hljs-built_in">map</span>(remove_columns=[<span class="hljs-string">&quot;file&quot;</span>, <span class="hljs-string">&quot;id&quot;</span>, <span class="hljs-string">&quot;normalized_text&quot;</span>])',wrap:!1}}),Ma=new M({props:{code:"bGpfc3BlZWNoJTVCMCU1RCU1QiUyMmF1ZGlvJTIyJTVEJTBBJTBBbGpfc3BlZWNoJTVCMCU1RCU1QiUyMnRleHQlMjIlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;audio&quot;</span>]
{<span class="hljs-string">&#x27;array&#x27;</span>: array([-<span class="hljs-number">7.3242188e-04</span>, -<span class="hljs-number">7.6293945e-04</span>, -<span class="hljs-number">6.4086914e-04</span>, ...,
         <span class="hljs-number">7.3242188e-04</span>,  <span class="hljs-number">2.1362305e-04</span>,  <span class="hljs-number">6.1035156e-05</span>], dtype=float32),
 <span class="hljs-string">&#x27;path&#x27;</span>: <span class="hljs-string">&#x27;/root/.cache/huggingface/datasets/downloads/extracted/917ece08c95cf0c4115e45294e3cd0dee724a1165b7fc11798369308a465bd26/LJSpeech-1.1/wavs/LJ001-0001.wav&#x27;</span>,
 <span class="hljs-string">&#x27;sampling_rate&#x27;</span>: <span class="hljs-number">22050</span>}

<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;text&quot;</span>]
<span class="hljs-string">&#x27;Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition&#x27;</span>`,wrap:!1}}),Ta=new M({props:{code:"bGpfc3BlZWNoJTIwJTNEJTIwbGpfc3BlZWNoLmNhc3RfY29sdW1uKCUyMmF1ZGlvJTIyJTJDJTIwQXVkaW8oc2FtcGxpbmdfcmF0ZSUzRDE2XzAwMCkp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lj_speech = lj_speech.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=<span class="hljs-number">16_000</span>))',wrap:!1}}),$a=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJmYWNlYm9vayUyRndhdjJ2ZWMyLWJhc2UtOTYwaCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`,wrap:!1}}),_a=new M({props:{code:"ZGVmJTIwcHJlcGFyZV9kYXRhc2V0KGV4YW1wbGUpJTNBJTBBJTIwJTIwJTIwJTIwYXVkaW8lMjAlM0QlMjBleGFtcGxlJTVCJTIyYXVkaW8lMjIlNUQlMEElMEElMjAlMjAlMjAlMjBleGFtcGxlLnVwZGF0ZShwcm9jZXNzb3IoYXVkaW8lM0RhdWRpbyU1QiUyMmFycmF5JTIyJTVEJTJDJTIwdGV4dCUzRGV4YW1wbGUlNUIlMjJ0ZXh0JTIyJTVEJTJDJTIwc2FtcGxpbmdfcmF0ZSUzRDE2MDAwKSklMEElMEElMjAlMjAlMjAlMjByZXR1cm4lMjBleGFtcGxl",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">prepare_dataset</span>(<span class="hljs-params">example</span>):
<span class="hljs-meta">... </span>    audio = example[<span class="hljs-string">&quot;audio&quot;</span>]

<span class="hljs-meta">... </span>    example.update(processor(audio=audio[<span class="hljs-string">&quot;array&quot;</span>], text=example[<span class="hljs-string">&quot;text&quot;</span>], sampling_rate=<span class="hljs-number">16000</span>))

<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example`,wrap:!1}}),Ia=new M({props:{code:"cHJlcGFyZV9kYXRhc2V0KGxqX3NwZWVjaCU1QjAlNUQp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>prepare_dataset(lj_speech[<span class="hljs-number">0</span>])',wrap:!1}}),{c(){p=m("meta"),f=l(),r=m("p"),g=l(),h(J.$$.fragment),$=l(),h(w.$$.fragment),A=l(),T=m("p"),T.textContent=v,Ua=l(),Q=m("ul"),Q.innerHTML=Ue,xa=l(),h(U.$$.fragment),Ca=l(),E=m("p"),E.textContent=xe,Za=l(),h(P.$$.fragment),Ga=l(),h(S.$$.fragment),Va=l(),h(D.$$.fragment),Ba=l(),K=m("p"),K.innerHTML=Ce,Wa=l(),h(x.$$.fragment),za=l(),O=m("p"),O.innerHTML=Ze,Ha=l(),h(ss.$$.fragment),Ra=l(),as=m("p"),as.textContent=Ge,Ya=l(),h(ns.$$.fragment),qa=l(),es=m("p"),es.textContent=Ve,Xa=l(),ls=m("ul"),ls.innerHTML=Be,Na=l(),ts=m("p"),ts.innerHTML=We,Fa=l(),h(ps.$$.fragment),La=l(),rs=m("p"),rs.innerHTML=ze,Aa=l(),ms=m("p"),ms.textContent=He,Qa=l(),h(cs.$$.fragment),Ea=l(),h(us.$$.fragment),Pa=l(),hs=m("p"),hs.innerHTML=Re,Sa=l(),os=m("p"),os.innerHTML=Ye,Da=l(),h(is.$$.fragment),Ka=l(),js=m("p"),js.innerHTML=qe,Oa=l(),h(bs.$$.fragment),sn=l(),ds=m("p"),ds.textContent=Xe,an=l(),fs=m("p"),fs.innerHTML=Ne,nn=l(),h(gs.$$.fragment),en=l(),h(C.$$.fragment),ln=l(),h(Ms.$$.fragment),tn=l(),ys=m("p"),ys.textContent=Fe,pn=l(),Ts=m("p"),Ts.innerHTML=Le,rn=l(),h(Z.$$.fragment),mn=l(),h(G.$$.fragment),cn=l(),h(Js.$$.fragment),un=l(),$s=m("p"),$s.innerHTML=Ae,hn=l(),ws=m("p"),ws.innerHTML=Qe,on=l(),h(_s.$$.fragment),jn=l(),Is=m("p"),Is.innerHTML=Ee,bn=l(),h(ks.$$.fragment),dn=l(),vs=m("p"),vs.textContent=Pe,fn=l(),Us=m("ul"),Us.innerHTML=Se,gn=l(),xs=m("p"),xs.innerHTML=De,Mn=l(),Cs=m("ol"),Cs.innerHTML=Ke,yn=l(),h(Zs.$$.fragment),Tn=l(),V=m("ol"),V.innerHTML=Oe,Jn=l(),h(Gs.$$.fragment),$n=l(),Vs=m("p"),Vs.innerHTML=sl,wn=l(),Bs=m("p"),Bs.innerHTML=al,_n=l(),h(Ws.$$.fragment),In=l(),zs=m("p"),zs.innerHTML=nl,kn=l(),h(Hs.$$.fragment),vn=l(),Rs=m("p"),Rs.textContent=el,Un=l(),h(Ys.$$.fragment),xn=l(),qs=m("p"),qs.textContent=ll,Cn=l(),h(Xs.$$.fragment),Zn=l(),Ns=m("p"),Ns.innerHTML=tl,Gn=l(),h(Fs.$$.fragment),Vn=l(),Ls=m("p"),Ls.textContent=pl,Bn=l(),h(As.$$.fragment),Wn=l(),h(Qs.$$.fragment),zn=l(),Es=m("p"),Es.innerHTML=rl,Hn=l(),h(B.$$.fragment),Rn=l(),Ps=m("p"),Ps.innerHTML=ml,Yn=l(),h(W.$$.fragment),qn=l(),h(Ss.$$.fragment),Xn=l(),Ds=m("p"),Ds.innerHTML=cl,Nn=l(),h(Ks.$$.fragment),Fn=l(),z=m("div"),z.innerHTML=ul,Ln=l(),Os=m("p"),Os.innerHTML=hl,An=l(),h(sa.$$.fragment),Qn=l(),aa=m("p"),aa.innerHTML=ol,En=l(),na=m("ol"),na.innerHTML=il,Pn=l(),h(ea.$$.fragment),Sn=l(),H=m("ol"),H.innerHTML=jl,Dn=l(),h(la.$$.fragment),Kn=l(),h(R.$$.fragment),On=l(),Y=m("ol"),Y.innerHTML=bl,se=l(),h(ta.$$.fragment),ae=l(),q=m("ol"),q.innerHTML=dl,ne=l(),h(pa.$$.fragment),ee=l(),ra=m("p"),ra.textContent=fl,le=l(),h(ma.$$.fragment),te=l(),X=m("div"),X.innerHTML=gl,pe=l(),h(N.$$.fragment),re=l(),h(ca.$$.fragment),me=l(),ua=m("p"),ua.innerHTML=Ml,ce=l(),h(ha.$$.fragment),ue=l(),h(oa.$$.fragment),he=l(),ia=m("p"),ia.innerHTML=yl,oe=l(),ja=m("p"),ja.innerHTML=Tl,ie=l(),h(ba.$$.fragment),je=l(),da=m("p"),da.innerHTML=Jl,be=l(),h(fa.$$.fragment),de=l(),ga=m("p"),ga.innerHTML=$l,fe=l(),h(Ma.$$.fragment),ge=l(),ya=m("p"),ya.innerHTML=wl,Me=l(),h(Ta.$$.fragment),ye=l(),Ja=m("p"),Ja.innerHTML=_l,Te=l(),h($a.$$.fragment),Je=l(),wa=m("ol"),wa.innerHTML=Il,$e=l(),h(_a.$$.fragment),we=l(),F=m("ol"),F.innerHTML=kl,_e=l(),h(Ia.$$.fragment),Ie=l(),ka=m("p"),ka.innerHTML=vl,ke=l(),va=m("p"),this.h()},l(s){const a=Fl("svelte-u9bgzb",document.head);p=c(a,"META",{name:!0,content:!0}),a.forEach(n),f=t(s),r=c(s,"P",{}),Hl(r).forEach(n),g=t(s),o(J.$$.fragment,s),$=t(s),o(w.$$.fragment,s),A=t(s),T=c(s,"P",{"data-svelte-h":!0}),u(T)!=="svelte-16m3n59"&&(T.textContent=v),Ua=t(s),Q=c(s,"UL",{"data-svelte-h":!0}),u(Q)!=="svelte-1akoncx"&&(Q.innerHTML=Ue),xa=t(s),o(U.$$.fragment,s),Ca=t(s),E=c(s,"P",{"data-svelte-h":!0}),u(E)!=="svelte-miijey"&&(E.textContent=xe),Za=t(s),o(P.$$.fragment,s),Ga=t(s),o(S.$$.fragment,s),Va=t(s),o(D.$$.fragment,s),Ba=t(s),K=c(s,"P",{"data-svelte-h":!0}),u(K)!=="svelte-1kdxp2p"&&(K.innerHTML=Ce),Wa=t(s),o(x.$$.fragment,s),za=t(s),O=c(s,"P",{"data-svelte-h":!0}),u(O)!=="svelte-9bp198"&&(O.innerHTML=Ze),Ha=t(s),o(ss.$$.fragment,s),Ra=t(s),as=c(s,"P",{"data-svelte-h":!0}),u(as)!=="svelte-uv8q8p"&&(as.textContent=Ge),Ya=t(s),o(ns.$$.fragment,s),qa=t(s),es=c(s,"P",{"data-svelte-h":!0}),u(es)!=="svelte-19z6qke"&&(es.textContent=Ve),Xa=t(s),ls=c(s,"UL",{"data-svelte-h":!0}),u(ls)!=="svelte-1l83r3n"&&(ls.innerHTML=Be),Na=t(s),ts=c(s,"P",{"data-svelte-h":!0}),u(ts)!=="svelte-1nvt1pa"&&(ts.innerHTML=We),Fa=t(s),o(ps.$$.fragment,s),La=t(s),rs=c(s,"P",{"data-svelte-h":!0}),u(rs)!=="svelte-1b2ebhq"&&(rs.innerHTML=ze),Aa=t(s),ms=c(s,"P",{"data-svelte-h":!0}),u(ms)!=="svelte-838qsc"&&(ms.textContent=He),Qa=t(s),o(cs.$$.fragment,s),Ea=t(s),o(us.$$.fragment,s),Pa=t(s),hs=c(s,"P",{"data-svelte-h":!0}),u(hs)!=="svelte-uq7hrd"&&(hs.innerHTML=Re),Sa=t(s),os=c(s,"P",{"data-svelte-h":!0}),u(os)!=="svelte-1ahwezm"&&(os.innerHTML=Ye),Da=t(s),o(is.$$.fragment,s),Ka=t(s),js=c(s,"P",{"data-svelte-h":!0}),u(js)!=="svelte-375nfh"&&(js.innerHTML=qe),Oa=t(s),o(bs.$$.fragment,s),sn=t(s),ds=c(s,"P",{"data-svelte-h":!0}),u(ds)!=="svelte-1pf21dx"&&(ds.textContent=Xe),an=t(s),fs=c(s,"P",{"data-svelte-h":!0}),u(fs)!=="svelte-1nn988l"&&(fs.innerHTML=Ne),nn=t(s),o(gs.$$.fragment,s),en=t(s),o(C.$$.fragment,s),ln=t(s),o(Ms.$$.fragment,s),tn=t(s),ys=c(s,"P",{"data-svelte-h":!0}),u(ys)!=="svelte-190ympp"&&(ys.textContent=Fe),pn=t(s),Ts=c(s,"P",{"data-svelte-h":!0}),u(Ts)!=="svelte-ynk6ab"&&(Ts.innerHTML=Le),rn=t(s),o(Z.$$.fragment,s),mn=t(s),o(G.$$.fragment,s),cn=t(s),o(Js.$$.fragment,s),un=t(s),$s=c(s,"P",{"data-svelte-h":!0}),u($s)!=="svelte-1h9zu4s"&&($s.innerHTML=Ae),hn=t(s),ws=c(s,"P",{"data-svelte-h":!0}),u(ws)!=="svelte-16xmqn"&&(ws.innerHTML=Qe),on=t(s),o(_s.$$.fragment,s),jn=t(s),Is=c(s,"P",{"data-svelte-h":!0}),u(Is)!=="svelte-1hq7vhu"&&(Is.innerHTML=Ee),bn=t(s),o(ks.$$.fragment,s),dn=t(s),vs=c(s,"P",{"data-svelte-h":!0}),u(vs)!=="svelte-1c6azkv"&&(vs.textContent=Pe),fn=t(s),Us=c(s,"UL",{"data-svelte-h":!0}),u(Us)!=="svelte-ykpien"&&(Us.innerHTML=Se),gn=t(s),xs=c(s,"P",{"data-svelte-h":!0}),u(xs)!=="svelte-6giqvb"&&(xs.innerHTML=De),Mn=t(s),Cs=c(s,"OL",{"data-svelte-h":!0}),u(Cs)!=="svelte-1hjs96z"&&(Cs.innerHTML=Ke),yn=t(s),o(Zs.$$.fragment,s),Tn=t(s),V=c(s,"OL",{start:!0,"data-svelte-h":!0}),u(V)!=="svelte-1965xun"&&(V.innerHTML=Oe),Jn=t(s),o(Gs.$$.fragment,s),$n=t(s),Vs=c(s,"P",{"data-svelte-h":!0}),u(Vs)!=="svelte-1a0ukdn"&&(Vs.innerHTML=sl),wn=t(s),Bs=c(s,"P",{"data-svelte-h":!0}),u(Bs)!=="svelte-1jbot9k"&&(Bs.innerHTML=al),_n=t(s),o(Ws.$$.fragment,s),In=t(s),zs=c(s,"P",{"data-svelte-h":!0}),u(zs)!=="svelte-1yb546a"&&(zs.innerHTML=nl),kn=t(s),o(Hs.$$.fragment,s),vn=t(s),Rs=c(s,"P",{"data-svelte-h":!0}),u(Rs)!=="svelte-bo476j"&&(Rs.textContent=el),Un=t(s),o(Ys.$$.fragment,s),xn=t(s),qs=c(s,"P",{"data-svelte-h":!0}),u(qs)!=="svelte-1407gba"&&(qs.textContent=ll),Cn=t(s),o(Xs.$$.fragment,s),Zn=t(s),Ns=c(s,"P",{"data-svelte-h":!0}),u(Ns)!=="svelte-mxr6t4"&&(Ns.innerHTML=tl),Gn=t(s),o(Fs.$$.fragment,s),Vn=t(s),Ls=c(s,"P",{"data-svelte-h":!0}),u(Ls)!=="svelte-1n00f7l"&&(Ls.textContent=pl),Bn=t(s),o(As.$$.fragment,s),Wn=t(s),o(Qs.$$.fragment,s),zn=t(s),Es=c(s,"P",{"data-svelte-h":!0}),u(Es)!=="svelte-14l1a6u"&&(Es.innerHTML=rl),Hn=t(s),o(B.$$.fragment,s),Rn=t(s),Ps=c(s,"P",{"data-svelte-h":!0}),u(Ps)!=="svelte-1aqi6mt"&&(Ps.innerHTML=ml),Yn=t(s),o(W.$$.fragment,s),qn=t(s),o(Ss.$$.fragment,s),Xn=t(s),Ds=c(s,"P",{"data-svelte-h":!0}),u(Ds)!=="svelte-9ffc4n"&&(Ds.innerHTML=cl),Nn=t(s),o(Ks.$$.fragment,s),Fn=t(s),z=c(s,"DIV",{class:!0,"data-svelte-h":!0}),u(z)!=="svelte-1jzdron"&&(z.innerHTML=ul),Ln=t(s),Os=c(s,"P",{"data-svelte-h":!0}),u(Os)!=="svelte-1fya52v"&&(Os.innerHTML=hl),An=t(s),o(sa.$$.fragment,s),Qn=t(s),aa=c(s,"P",{"data-svelte-h":!0}),u(aa)!=="svelte-1k4l269"&&(aa.innerHTML=ol),En=t(s),na=c(s,"OL",{"data-svelte-h":!0}),u(na)!=="svelte-iu2fmq"&&(na.innerHTML=il),Pn=t(s),o(ea.$$.fragment,s),Sn=t(s),H=c(s,"OL",{start:!0,"data-svelte-h":!0}),u(H)!=="svelte-1beco9e"&&(H.innerHTML=jl),Dn=t(s),o(la.$$.fragment,s),Kn=t(s),o(R.$$.fragment,s),On=t(s),Y=c(s,"OL",{start:!0,"data-svelte-h":!0}),u(Y)!=="svelte-4dlgnd"&&(Y.innerHTML=bl),se=t(s),o(ta.$$.fragment,s),ae=t(s),q=c(s,"OL",{start:!0,"data-svelte-h":!0}),u(q)!=="svelte-z5mlcc"&&(q.innerHTML=dl),ne=t(s),o(pa.$$.fragment,s),ee=t(s),ra=c(s,"P",{"data-svelte-h":!0}),u(ra)!=="svelte-trcbp4"&&(ra.textContent=fl),le=t(s),o(ma.$$.fragment,s),te=t(s),X=c(s,"DIV",{class:!0,"data-svelte-h":!0}),u(X)!=="svelte-mp8qzc"&&(X.innerHTML=gl),pe=t(s),o(N.$$.fragment,s),re=t(s),o(ca.$$.fragment,s),me=t(s),ua=c(s,"P",{"data-svelte-h":!0}),u(ua)!=="svelte-hk42dw"&&(ua.innerHTML=Ml),ce=t(s),o(ha.$$.fragment,s),ue=t(s),o(oa.$$.fragment,s),he=t(s),ia=c(s,"P",{"data-svelte-h":!0}),u(ia)!=="svelte-199ztpc"&&(ia.innerHTML=yl),oe=t(s),ja=c(s,"P",{"data-svelte-h":!0}),u(ja)!=="svelte-d9ps8f"&&(ja.innerHTML=Tl),ie=t(s),o(ba.$$.fragment,s),je=t(s),da=c(s,"P",{"data-svelte-h":!0}),u(da)!=="svelte-1k5hdjd"&&(da.innerHTML=Jl),be=t(s),o(fa.$$.fragment,s),de=t(s),ga=c(s,"P",{"data-svelte-h":!0}),u(ga)!=="svelte-115u1vs"&&(ga.innerHTML=$l),fe=t(s),o(Ma.$$.fragment,s),ge=t(s),ya=c(s,"P",{"data-svelte-h":!0}),u(ya)!=="svelte-mn9i5v"&&(ya.innerHTML=wl),Me=t(s),o(Ta.$$.fragment,s),ye=t(s),Ja=c(s,"P",{"data-svelte-h":!0}),u(Ja)!=="svelte-wn0ar2"&&(Ja.innerHTML=_l),Te=t(s),o($a.$$.fragment,s),Je=t(s),wa=c(s,"OL",{"data-svelte-h":!0}),u(wa)!=="svelte-1rrl7ud"&&(wa.innerHTML=Il),$e=t(s),o(_a.$$.fragment,s),we=t(s),F=c(s,"OL",{start:!0,"data-svelte-h":!0}),u(F)!=="svelte-ub4yka"&&(F.innerHTML=kl),_e=t(s),o(Ia.$$.fragment,s),Ie=t(s),ka=c(s,"P",{"data-svelte-h":!0}),u(ka)!=="svelte-1fqvd5l"&&(ka.innerHTML=vl),ke=t(s),va=c(s,"P",{}),Hl(va).forEach(n),this.h()},h(){_(p,"name","hf:doc:metadata"),_(p,"content",ut),_(V,"start","2"),_(z,"class","flex justify-center"),_(H,"start","2"),_(Y,"start","3"),_(q,"start","4"),_(X,"class","flex justify-center"),_(F,"start","2")},m(s,a){Ll(document.head,p),e(s,f,a),e(s,r,a),e(s,g,a),i(J,s,a),e(s,$,a),i(w,s,a),e(s,A,a),e(s,T,a),e(s,Ua,a),e(s,Q,a),e(s,xa,a),i(U,s,a),e(s,Ca,a),e(s,E,a),e(s,Za,a),i(P,s,a),e(s,Ga,a),i(S,s,a),e(s,Va,a),i(D,s,a),e(s,Ba,a),e(s,K,a),e(s,Wa,a),i(x,s,a),e(s,za,a),e(s,O,a),e(s,Ha,a),i(ss,s,a),e(s,Ra,a),e(s,as,a),e(s,Ya,a),i(ns,s,a),e(s,qa,a),e(s,es,a),e(s,Xa,a),e(s,ls,a),e(s,Na,a),e(s,ts,a),e(s,Fa,a),i(ps,s,a),e(s,La,a),e(s,rs,a),e(s,Aa,a),e(s,ms,a),e(s,Qa,a),i(cs,s,a),e(s,Ea,a),i(us,s,a),e(s,Pa,a),e(s,hs,a),e(s,Sa,a),e(s,os,a),e(s,Da,a),i(is,s,a),e(s,Ka,a),e(s,js,a),e(s,Oa,a),i(bs,s,a),e(s,sn,a),e(s,ds,a),e(s,an,a),e(s,fs,a),e(s,nn,a),i(gs,s,a),e(s,en,a),i(C,s,a),e(s,ln,a),i(Ms,s,a),e(s,tn,a),e(s,ys,a),e(s,pn,a),e(s,Ts,a),e(s,rn,a),i(Z,s,a),e(s,mn,a),i(G,s,a),e(s,cn,a),i(Js,s,a),e(s,un,a),e(s,$s,a),e(s,hn,a),e(s,ws,a),e(s,on,a),i(_s,s,a),e(s,jn,a),e(s,Is,a),e(s,bn,a),i(ks,s,a),e(s,dn,a),e(s,vs,a),e(s,fn,a),e(s,Us,a),e(s,gn,a),e(s,xs,a),e(s,Mn,a),e(s,Cs,a),e(s,yn,a),i(Zs,s,a),e(s,Tn,a),e(s,V,a),e(s,Jn,a),i(Gs,s,a),e(s,$n,a),e(s,Vs,a),e(s,wn,a),e(s,Bs,a),e(s,_n,a),i(Ws,s,a),e(s,In,a),e(s,zs,a),e(s,kn,a),i(Hs,s,a),e(s,vn,a),e(s,Rs,a),e(s,Un,a),i(Ys,s,a),e(s,xn,a),e(s,qs,a),e(s,Cn,a),i(Xs,s,a),e(s,Zn,a),e(s,Ns,a),e(s,Gn,a),i(Fs,s,a),e(s,Vn,a),e(s,Ls,a),e(s,Bn,a),i(As,s,a),e(s,Wn,a),i(Qs,s,a),e(s,zn,a),e(s,Es,a),e(s,Hn,a),i(B,s,a),e(s,Rn,a),e(s,Ps,a),e(s,Yn,a),i(W,s,a),e(s,qn,a),i(Ss,s,a),e(s,Xn,a),e(s,Ds,a),e(s,Nn,a),i(Ks,s,a),e(s,Fn,a),e(s,z,a),e(s,Ln,a),e(s,Os,a),e(s,An,a),i(sa,s,a),e(s,Qn,a),e(s,aa,a),e(s,En,a),e(s,na,a),e(s,Pn,a),i(ea,s,a),e(s,Sn,a),e(s,H,a),e(s,Dn,a),i(la,s,a),e(s,Kn,a),i(R,s,a),e(s,On,a),e(s,Y,a),e(s,se,a),i(ta,s,a),e(s,ae,a),e(s,q,a),e(s,ne,a),i(pa,s,a),e(s,ee,a),e(s,ra,a),e(s,le,a),i(ma,s,a),e(s,te,a),e(s,X,a),e(s,pe,a),i(N,s,a),e(s,re,a),i(ca,s,a),e(s,me,a),e(s,ua,a),e(s,ce,a),i(ha,s,a),e(s,ue,a),i(oa,s,a),e(s,he,a),e(s,ia,a),e(s,oe,a),e(s,ja,a),e(s,ie,a),i(ba,s,a),e(s,je,a),e(s,da,a),e(s,be,a),i(fa,s,a),e(s,de,a),e(s,ga,a),e(s,fe,a),i(Ma,s,a),e(s,ge,a),e(s,ya,a),e(s,Me,a),i(Ta,s,a),e(s,ye,a),e(s,Ja,a),e(s,Te,a),i($a,s,a),e(s,Je,a),e(s,wa,a),e(s,$e,a),i(_a,s,a),e(s,we,a),e(s,F,a),e(s,_e,a),i(Ia,s,a),e(s,Ie,a),e(s,ka,a),e(s,ke,a),e(s,va,a),ve=!0},p(s,[a]){const Ul={};a&2&&(Ul.$$scope={dirty:a,ctx:s}),U.$set(Ul);const xl={};a&2&&(xl.$$scope={dirty:a,ctx:s}),x.$set(xl);const Cl={};a&2&&(Cl.$$scope={dirty:a,ctx:s}),C.$set(Cl);const Zl={};a&2&&(Zl.$$scope={dirty:a,ctx:s}),Z.$set(Zl);const Gl={};a&2&&(Gl.$$scope={dirty:a,ctx:s}),G.$set(Gl);const Vl={};a&2&&(Vl.$$scope={dirty:a,ctx:s}),B.$set(Vl);const Bl={};a&2&&(Bl.$$scope={dirty:a,ctx:s}),W.$set(Bl);const Wl={};a&2&&(Wl.$$scope={dirty:a,ctx:s}),R.$set(Wl);const zl={};a&2&&(zl.$$scope={dirty:a,ctx:s}),N.$set(zl)},i(s){ve||(j(J.$$.fragment,s),j(w.$$.fragment,s),j(U.$$.fragment,s),j(P.$$.fragment,s),j(S.$$.fragment,s),j(D.$$.fragment,s),j(x.$$.fragment,s),j(ss.$$.fragment,s),j(ns.$$.fragment,s),j(ps.$$.fragment,s),j(cs.$$.fragment,s),j(us.$$.fragment,s),j(is.$$.fragment,s),j(bs.$$.fragment,s),j(gs.$$.fragment,s),j(C.$$.fragment,s),j(Ms.$$.fragment,s),j(Z.$$.fragment,s),j(G.$$.fragment,s),j(Js.$$.fragment,s),j(_s.$$.fragment,s),j(ks.$$.fragment,s),j(Zs.$$.fragment,s),j(Gs.$$.fragment,s),j(Ws.$$.fragment,s),j(Hs.$$.fragment,s),j(Ys.$$.fragment,s),j(Xs.$$.fragment,s),j(Fs.$$.fragment,s),j(As.$$.fragment,s),j(Qs.$$.fragment,s),j(B.$$.fragment,s),j(W.$$.fragment,s),j(Ss.$$.fragment,s),j(Ks.$$.fragment,s),j(sa.$$.fragment,s),j(ea.$$.fragment,s),j(la.$$.fragment,s),j(R.$$.fragment,s),j(ta.$$.fragment,s),j(pa.$$.fragment,s),j(ma.$$.fragment,s),j(N.$$.fragment,s),j(ca.$$.fragment,s),j(ha.$$.fragment,s),j(oa.$$.fragment,s),j(ba.$$.fragment,s),j(fa.$$.fragment,s),j(Ma.$$.fragment,s),j(Ta.$$.fragment,s),j($a.$$.fragment,s),j(_a.$$.fragment,s),j(Ia.$$.fragment,s),ve=!0)},o(s){b(J.$$.fragment,s),b(w.$$.fragment,s),b(U.$$.fragment,s),b(P.$$.fragment,s),b(S.$$.fragment,s),b(D.$$.fragment,s),b(x.$$.fragment,s),b(ss.$$.fragment,s),b(ns.$$.fragment,s),b(ps.$$.fragment,s),b(cs.$$.fragment,s),b(us.$$.fragment,s),b(is.$$.fragment,s),b(bs.$$.fragment,s),b(gs.$$.fragment,s),b(C.$$.fragment,s),b(Ms.$$.fragment,s),b(Z.$$.fragment,s),b(G.$$.fragment,s),b(Js.$$.fragment,s),b(_s.$$.fragment,s),b(ks.$$.fragment,s),b(Zs.$$.fragment,s),b(Gs.$$.fragment,s),b(Ws.$$.fragment,s),b(Hs.$$.fragment,s),b(Ys.$$.fragment,s),b(Xs.$$.fragment,s),b(Fs.$$.fragment,s),b(As.$$.fragment,s),b(Qs.$$.fragment,s),b(B.$$.fragment,s),b(W.$$.fragment,s),b(Ss.$$.fragment,s),b(Ks.$$.fragment,s),b(sa.$$.fragment,s),b(ea.$$.fragment,s),b(la.$$.fragment,s),b(R.$$.fragment,s),b(ta.$$.fragment,s),b(pa.$$.fragment,s),b(ma.$$.fragment,s),b(N.$$.fragment,s),b(ca.$$.fragment,s),b(ha.$$.fragment,s),b(oa.$$.fragment,s),b(ba.$$.fragment,s),b(fa.$$.fragment,s),b(Ma.$$.fragment,s),b(Ta.$$.fragment,s),b($a.$$.fragment,s),b(_a.$$.fragment,s),b(Ia.$$.fragment,s),ve=!1},d(s){s&&(n(f),n(r),n(g),n($),n(A),n(T),n(Ua),n(Q),n(xa),n(Ca),n(E),n(Za),n(Ga),n(Va),n(Ba),n(K),n(Wa),n(za),n(O),n(Ha),n(Ra),n(as),n(Ya),n(qa),n(es),n(Xa),n(ls),n(Na),n(ts),n(Fa),n(La),n(rs),n(Aa),n(ms),n(Qa),n(Ea),n(Pa),n(hs),n(Sa),n(os),n(Da),n(Ka),n(js),n(Oa),n(sn),n(ds),n(an),n(fs),n(nn),n(en),n(ln),n(tn),n(ys),n(pn),n(Ts),n(rn),n(mn),n(cn),n(un),n($s),n(hn),n(ws),n(on),n(jn),n(Is),n(bn),n(dn),n(vs),n(fn),n(Us),n(gn),n(xs),n(Mn),n(Cs),n(yn),n(Tn),n(V),n(Jn),n($n),n(Vs),n(wn),n(Bs),n(_n),n(In),n(zs),n(kn),n(vn),n(Rs),n(Un),n(xn),n(qs),n(Cn),n(Zn),n(Ns),n(Gn),n(Vn),n(Ls),n(Bn),n(Wn),n(zn),n(Es),n(Hn),n(Rn),n(Ps),n(Yn),n(qn),n(Xn),n(Ds),n(Nn),n(Fn),n(z),n(Ln),n(Os),n(An),n(Qn),n(aa),n(En),n(na),n(Pn),n(Sn),n(H),n(Dn),n(Kn),n(On),n(Y),n(se),n(ae),n(q),n(ne),n(ee),n(ra),n(le),n(te),n(X),n(pe),n(re),n(me),n(ua),n(ce),n(ue),n(he),n(ia),n(oe),n(ja),n(ie),n(je),n(da),n(be),n(de),n(ga),n(fe),n(ge),n(ya),n(Me),n(ye),n(Ja),n(Te),n(Je),n(wa),n($e),n(we),n(F),n(_e),n(Ie),n(ka),n(ke),n(va)),n(p),d(J,s),d(w,s),d(U,s),d(P,s),d(S,s),d(D,s),d(x,s),d(ss,s),d(ns,s),d(ps,s),d(cs,s),d(us,s),d(is,s),d(bs,s),d(gs,s),d(C,s),d(Ms,s),d(Z,s),d(G,s),d(Js,s),d(_s,s),d(ks,s),d(Zs,s),d(Gs,s),d(Ws,s),d(Hs,s),d(Ys,s),d(Xs,s),d(Fs,s),d(As,s),d(Qs,s),d(B,s),d(W,s),d(Ss,s),d(Ks,s),d(sa,s),d(ea,s),d(la,s),d(R,s),d(ta,s),d(pa,s),d(ma,s),d(N,s),d(ca,s),d(ha,s),d(oa,s),d(ba,s),d(fa,s),d(Ma,s),d(Ta,s),d($a,s),d(_a,s),d(Ia,s)}}}const ut='{"title":"Preprocess","local":"preprocess","sections":[{"title":"Natural Language Processing","local":"natural-language-processing","sections":[{"title":"Pad","local":"pad","sections":[],"depth":3},{"title":"Truncation","local":"truncation","sections":[],"depth":3},{"title":"Build tensors","local":"build-tensors","sections":[],"depth":3}],"depth":2},{"title":"Audio","local":"audio","sections":[],"depth":2},{"title":"Computer vision","local":"computer-vision","sections":[{"title":"Pad","local":"pad","sections":[],"depth":3}],"depth":2},{"title":"Multimodal","local":"multimodal","sections":[],"depth":2}],"depth":1}';function ht(y){return ql(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class yt extends Xl{constructor(p){super(),Nl(this,p,ht,ct,Yl,{})}}export{yt as component};
