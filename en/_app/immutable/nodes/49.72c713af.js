import{s as fn,n as pn,o as cn}from"../chunks/scheduler.9bc65507.js";import{S as gn,i as un,g as a,s as r,r as l,A as hn,h as s,f as n,c as o,j as _,u as d,x as u,k as v,y as t,a as m,v as f,d as p,t as c,w as g}from"../chunks/index.707bf1b6.js";import{D as $}from"../chunks/Docstring.17db21ae.js";import{H as ue}from"../chunks/Heading.342b1fa6.js";function xn(zt){let O,Ee,Fe,Ie,Q,Se,V,Ht=`ðŸ¤— Transformers provides a <code>transformers.onnx</code> package that enables you to
convert model checkpoints to an ONNX graph by leveraging configuration objects.`,We,z,Xt=`See the <a href="../serialization">guide</a> on exporting ðŸ¤— Transformers models for more
details.`,Qe,H,Ve,X,At=`We provide three abstract classes that you should inherit from, depending on the
type of model architecture you wish to export:`,ze,A,jt='<li>Encoder-based models inherit from <a href="/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfig">OnnxConfig</a></li> <li>Decoder-based models inherit from <a href="/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxConfigWithPast">OnnxConfigWithPast</a></li> <li>Encoder-decoder models inherit from <a href="/docs/transformers/main/en/main_classes/onnx#transformers.onnx.OnnxSeq2SeqConfigWithPast">OnnxSeq2SeqConfigWithPast</a></li>',He,j,Xe,h,U,pt,he,Ut="Base class for ONNX exportable model describing metadata on how to export the model through the ONNX format.",ct,T,G,gt,xe,Gt=`Flatten any potential nested structure expanding the name of the field with the index of the element within the
structure.`,ut,P,R,ht,_e,Rt="Instantiate a OnnxConfig for a specific model",xt,k,B,_t,ve,Bt="Generate inputs to provide to the ONNX exporter for the specific framework",vt,M,J,$t,$e,Jt=`Generate inputs for ONNX Runtime using the reference model inputs. Override this to run inference with seq2seq
models which have the encoder and decoder exported as separate ONNX files.`,bt,D,K,yt,be,Kt="Flag indicating if the model requires using external data format",Ae,Y,je,w,Z,Ct,q,ee,wt,ye,Yt="Fill the input_or_outputs mapping with past_key_values dynamic axes considering.",Ot,N,te,Tt,Ce,Zt="Instantiate a OnnxConfig with <code>use_past</code> attribute set to True",Ue,ne,Ge,re,oe,Re,ae,Be,se,en=`Each ONNX configuration is associated with a set of <em>features</em> that enable you
to export models for different types of topologies or tasks.`,Je,ie,Ke,x,me,Pt,F,le,kt,we,tn="Check whether or not the model has the requested features.",Mt,C,de,Dt,Oe,nn="Determines the framework to use for the export.",qt,Te,rn="The priority is in the following order:",Nt,Pe,on="<li>User input via <code>framework</code>.</li> <li>If local checkpoint is provided, use the same framework as the checkpoint.</li> <li>Available framework in environment, with priority given to PyTorch</li>",Ft,L,fe,Lt,ke,an="Gets the OnnxConfig for a model_type and feature combination.",Et,E,pe,It,Me,sn="Attempts to retrieve an AutoModel class from a feature name.",St,I,ce,Wt,De,mn="Attempts to retrieve a model from a modelâ€™s name and the feature to be enabled.",Qt,S,ge,Vt,qe,ln="Tries to retrieve the feature -> OnnxConfig constructor map from the model type.",Ye,Le,Ze;return Q=new ue({props:{title:"Exporting ðŸ¤— Transformers models to ONNX",local:"exporting--transformers-models-to-onnx",headingTag:"h1"}}),H=new ue({props:{title:"ONNX Configurations",local:"onnx-configurations",headingTag:"h2"}}),j=new ue({props:{title:"OnnxConfig",local:"transformers.onnx.OnnxConfig",headingTag:"h3"}}),U=new $({props:{name:"class transformers.onnx.OnnxConfig",anchor:"transformers.onnx.OnnxConfig",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": List = None"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L68"}}),G=new $({props:{name:"flatten_output_collection_property",anchor:"transformers.onnx.OnnxConfig.flatten_output_collection_property",parameters:[{name:"name",val:": str"},{name:"field",val:": Iterable"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L424",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>Outputs with flattened structure and key mapping this new structure.</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(Dict[str, Any])</p>
`}}),R=new $({props:{name:"from_model_config",anchor:"transformers.onnx.OnnxConfig.from_model_config",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L127",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>OnnxConfig for this model</p>
`}}),B=new $({props:{name:"generate_dummy_inputs",anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs",parameters:[{name:"preprocessor",val:": Union"},{name:"batch_size",val:": int = -1"},{name:"seq_length",val:": int = -1"},{name:"num_choices",val:": int = -1"},{name:"is_pair",val:": bool = False"},{name:"framework",val:": Optional = None"},{name:"num_channels",val:": int = 3"},{name:"image_width",val:": int = 40"},{name:"image_height",val:": int = 40"},{name:"sampling_rate",val:": int = 22050"},{name:"time_duration",val:": float = 5.0"},{name:"frequency",val:": int = 220"},{name:"tokenizer",val:": PreTrainedTokenizerBase = None"}],parametersDescription:[{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.batch_size",description:`<strong>batch_size</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The batch size to export the model for (-1 means dynamic axis).`,name:"batch_size"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.num_choices",description:`<strong>num_choices</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The number of candidate answers provided for multiple choice task (-1 means dynamic axis).`,name:"num_choices"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.seq_length",description:`<strong>seq_length</strong> (<code>int</code>, <em>optional</em>, defaults to -1) &#x2014;
The sequence length to export the model for (-1 means dynamic axis).`,name:"seq_length"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.is_pair",description:`<strong>is_pair</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Indicate if the input is a pair (sentence 1, sentence 2)`,name:"is_pair"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.framework",description:`<strong>framework</strong> (<code>TensorType</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework (PyTorch or TensorFlow) that the tokenizer will generate tensors for.`,name:"framework"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.num_channels",description:`<strong>num_channels</strong> (<code>int</code>, <em>optional</em>, defaults to 3) &#x2014;
The number of channels of the generated images.`,name:"num_channels"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.image_width",description:`<strong>image_width</strong> (<code>int</code>, <em>optional</em>, defaults to 40) &#x2014;
The width of the generated images.`,name:"image_width"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.image_height",description:`<strong>image_height</strong> (<code>int</code>, <em>optional</em>, defaults to 40) &#x2014;
The height of the generated images.`,name:"image_height"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.sampling_rate",description:`<strong>sampling_rate</strong> (<code>int</code>, <em>optional</em> defaults to 22050) &#x2014;
The sampling rate for audio data generation.`,name:"sampling_rate"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.time_duration",description:`<strong>time_duration</strong> (<code>float</code>, <em>optional</em> defaults to 5.0) &#x2014;
Total seconds of sampling for audio data generation.`,name:"time_duration"},{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs.frequency",description:`<strong>frequency</strong> (<code>int</code>, <em>optional</em> defaults to 220) &#x2014;
The desired natural frequency of generated audio.`,name:"frequency"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L280",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>Mapping[str, Tensor] holding the kwargs to provide to the modelâ€™s forward function</p>
`}}),J=new $({props:{name:"generate_dummy_inputs_onnxruntime",anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs_onnxruntime",parameters:[{name:"reference_model_inputs",val:": Mapping"}],parametersDescription:[{anchor:"transformers.onnx.OnnxConfig.generate_dummy_inputs_onnxruntime.reference_model_inputs",description:`<strong>reference_model_inputs</strong> ([<code>Mapping[str, Tensor]</code>) &#x2014;
Reference inputs for the model.`,name:"reference_model_inputs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L400",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The mapping holding the kwargs to provide to the modelâ€™s forward function</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>Mapping[str, Tensor]</code></p>
`}}),K=new $({props:{name:"use_external_data_format",anchor:"transformers.onnx.OnnxConfig.use_external_data_format",parameters:[{name:"num_parameters",val:": int"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L241",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>True if model.num_parameters() * size_of(float32) >= 2Gb False otherwise</p>
`}}),Y=new ue({props:{title:"OnnxConfigWithPast",local:"transformers.onnx.OnnxConfigWithPast",headingTag:"h3"}}),Z=new $({props:{name:"class transformers.onnx.OnnxConfigWithPast",anchor:"transformers.onnx.OnnxConfigWithPast",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": List = None"},{name:"use_past",val:": bool = False"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L443"}}),ee=new $({props:{name:"fill_with_past_key_values_",anchor:"transformers.onnx.OnnxConfigWithPast.fill_with_past_key_values_",parameters:[{name:"inputs_or_outputs",val:": Mapping"},{name:"direction",val:": str"},{name:"inverted_values_shape",val:": bool = False"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L550"}}),te=new $({props:{name:"with_past",anchor:"transformers.onnx.OnnxConfigWithPast.with_past",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L454",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>OnnxConfig with <code>.use_past = True</code></p>
`}}),ne=new ue({props:{title:"OnnxSeq2SeqConfigWithPast",local:"transformers.onnx.OnnxSeq2SeqConfigWithPast",headingTag:"h3"}}),oe=new $({props:{name:"class transformers.onnx.OnnxSeq2SeqConfigWithPast",anchor:"transformers.onnx.OnnxSeq2SeqConfigWithPast",parameters:[{name:"config",val:": PretrainedConfig"},{name:"task",val:": str = 'default'"},{name:"patching_specs",val:": List = None"},{name:"use_past",val:": bool = False"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/config.py#L590"}}),ae=new ue({props:{title:"ONNX Features",local:"onnx-features",headingTag:"h2"}}),ie=new ue({props:{title:"FeaturesManager",local:"transformers.onnx.FeaturesManager",headingTag:"h3"}}),me=new $({props:{name:"class transformers.onnx.FeaturesManager",anchor:"transformers.onnx.FeaturesManager",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L85"}}),le=new $({props:{name:"check_supported_model_or_raise",anchor:"transformers.onnx.FeaturesManager.check_supported_model_or_raise",parameters:[{name:"model",val:": Union"},{name:"feature",val:": str = 'default'"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L711",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>(str) The type of the model (OnnxConfig) The OnnxConfig instance holding the model export properties.</p>
`}}),de=new $({props:{name:"determine_framework",anchor:"transformers.onnx.FeaturesManager.determine_framework",parameters:[{name:"model",val:": str"},{name:"framework",val:": str = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.determine_framework.model",description:`<strong>model</strong> (<code>str</code>) &#x2014;
The name of the model to export.`,name:"model"},{anchor:"transformers.onnx.FeaturesManager.determine_framework.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework to use for the export. See above for priority if none provided.`,name:"framework"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L628",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The framework to use for the export.</p>
`}}),fe=new $({props:{name:"get_config",anchor:"transformers.onnx.FeaturesManager.get_config",parameters:[{name:"model_type",val:": str"},{name:"feature",val:": str"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_config.model_type",description:`<strong>model_type</strong> (<code>str</code>) &#x2014;
The model type to retrieve the config for.`,name:"model_type"},{anchor:"transformers.onnx.FeaturesManager.get_config.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature to retrieve the config for.`,name:"feature"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L736",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>config for the combination</p>
`,returnType:`<script context="module">export const metadata = 'undefined';<\/script>


<p><code>OnnxConfig</code></p>
`}}),pe=new $({props:{name:"get_model_class_for_feature",anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature",parameters:[{name:"feature",val:": str"},{name:"framework",val:": str = 'pt'"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature required.`,name:"feature"},{anchor:"transformers.onnx.FeaturesManager.get_model_class_for_feature.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;pt&quot;</code>) &#x2014;
The framework to use for the export.`,name:"framework"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L601",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The AutoModel class corresponding to the feature.</p>
`}}),ce=new $({props:{name:"get_model_from_feature",anchor:"transformers.onnx.FeaturesManager.get_model_from_feature",parameters:[{name:"feature",val:": str"},{name:"model",val:": str"},{name:"framework",val:": str = None"},{name:"cache_dir",val:": str = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.feature",description:`<strong>feature</strong> (<code>str</code>) &#x2014;
The feature required.`,name:"feature"},{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.model",description:`<strong>model</strong> (<code>str</code>) &#x2014;
The name of the model to export.`,name:"model"},{anchor:"transformers.onnx.FeaturesManager.get_model_from_feature.framework",description:`<strong>framework</strong> (<code>str</code>, <em>optional</em>, defaults to <code>None</code>) &#x2014;
The framework to use for the export. See <code>FeaturesManager.determine_framework</code> for the priority should
none be provided.`,name:"framework"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L678",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The instance of the model.</p>
`}}),ge=new $({props:{name:"get_supported_features_for_model_type",anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type",parameters:[{name:"model_type",val:": str"},{name:"model_name",val:": Optional = None"}],parametersDescription:[{anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type.model_type",description:`<strong>model_type</strong> (<code>str</code>) &#x2014;
The model type to retrieve the supported features for.`,name:"model_type"},{anchor:"transformers.onnx.FeaturesManager.get_supported_features_for_model_type.model_name",description:`<strong>model_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name attribute of the model object, only used for the exception message.`,name:"model_name"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/onnx/features.py#L556",returnDescription:`<script context="module">export const metadata = 'undefined';<\/script>


<p>The dictionary mapping each feature to a corresponding OnnxConfig constructor.</p>
`}}),{c(){O=a("meta"),Ee=r(),Fe=a("p"),Ie=r(),l(Q.$$.fragment),Se=r(),V=a("p"),V.innerHTML=Ht,We=r(),z=a("p"),z.innerHTML=Xt,Qe=r(),l(H.$$.fragment),Ve=r(),X=a("p"),X.textContent=At,ze=r(),A=a("ul"),A.innerHTML=jt,He=r(),l(j.$$.fragment),Xe=r(),h=a("div"),l(U.$$.fragment),pt=r(),he=a("p"),he.textContent=Ut,ct=r(),T=a("div"),l(G.$$.fragment),gt=r(),xe=a("p"),xe.textContent=Gt,ut=r(),P=a("div"),l(R.$$.fragment),ht=r(),_e=a("p"),_e.textContent=Rt,xt=r(),k=a("div"),l(B.$$.fragment),_t=r(),ve=a("p"),ve.textContent=Bt,vt=r(),M=a("div"),l(J.$$.fragment),$t=r(),$e=a("p"),$e.textContent=Jt,bt=r(),D=a("div"),l(K.$$.fragment),yt=r(),be=a("p"),be.textContent=Kt,Ae=r(),l(Y.$$.fragment),je=r(),w=a("div"),l(Z.$$.fragment),Ct=r(),q=a("div"),l(ee.$$.fragment),wt=r(),ye=a("p"),ye.textContent=Yt,Ot=r(),N=a("div"),l(te.$$.fragment),Tt=r(),Ce=a("p"),Ce.innerHTML=Zt,Ue=r(),l(ne.$$.fragment),Ge=r(),re=a("div"),l(oe.$$.fragment),Re=r(),l(ae.$$.fragment),Be=r(),se=a("p"),se.innerHTML=en,Je=r(),l(ie.$$.fragment),Ke=r(),x=a("div"),l(me.$$.fragment),Pt=r(),F=a("div"),l(le.$$.fragment),kt=r(),we=a("p"),we.textContent=tn,Mt=r(),C=a("div"),l(de.$$.fragment),Dt=r(),Oe=a("p"),Oe.textContent=nn,qt=r(),Te=a("p"),Te.textContent=rn,Nt=r(),Pe=a("ol"),Pe.innerHTML=on,Ft=r(),L=a("div"),l(fe.$$.fragment),Lt=r(),ke=a("p"),ke.textContent=an,Et=r(),E=a("div"),l(pe.$$.fragment),It=r(),Me=a("p"),Me.textContent=sn,St=r(),I=a("div"),l(ce.$$.fragment),Wt=r(),De=a("p"),De.textContent=mn,Qt=r(),S=a("div"),l(ge.$$.fragment),Vt=r(),qe=a("p"),qe.textContent=ln,Ye=r(),Le=a("p"),this.h()},l(e){const i=hn("svelte-u9bgzb",document.head);O=s(i,"META",{name:!0,content:!0}),i.forEach(n),Ee=o(e),Fe=s(e,"P",{}),_(Fe).forEach(n),Ie=o(e),d(Q.$$.fragment,e),Se=o(e),V=s(e,"P",{"data-svelte-h":!0}),u(V)!=="svelte-4jsgzi"&&(V.innerHTML=Ht),We=o(e),z=s(e,"P",{"data-svelte-h":!0}),u(z)!=="svelte-1nfy7l0"&&(z.innerHTML=Xt),Qe=o(e),d(H.$$.fragment,e),Ve=o(e),X=s(e,"P",{"data-svelte-h":!0}),u(X)!=="svelte-10ifyz5"&&(X.textContent=At),ze=o(e),A=s(e,"UL",{"data-svelte-h":!0}),u(A)!=="svelte-1g38hxy"&&(A.innerHTML=jt),He=o(e),d(j.$$.fragment,e),Xe=o(e),h=s(e,"DIV",{class:!0});var b=_(h);d(U.$$.fragment,b),pt=o(b),he=s(b,"P",{"data-svelte-h":!0}),u(he)!=="svelte-1gqzpaz"&&(he.textContent=Ut),ct=o(b),T=s(b,"DIV",{class:!0});var et=_(T);d(G.$$.fragment,et),gt=o(et),xe=s(et,"P",{"data-svelte-h":!0}),u(xe)!=="svelte-1lfqihc"&&(xe.textContent=Gt),et.forEach(n),ut=o(b),P=s(b,"DIV",{class:!0});var tt=_(P);d(R.$$.fragment,tt),ht=o(tt),_e=s(tt,"P",{"data-svelte-h":!0}),u(_e)!=="svelte-1u54gj1"&&(_e.textContent=Rt),tt.forEach(n),xt=o(b),k=s(b,"DIV",{class:!0});var nt=_(k);d(B.$$.fragment,nt),_t=o(nt),ve=s(nt,"P",{"data-svelte-h":!0}),u(ve)!=="svelte-1oyyynq"&&(ve.textContent=Bt),nt.forEach(n),vt=o(b),M=s(b,"DIV",{class:!0});var rt=_(M);d(J.$$.fragment,rt),$t=o(rt),$e=s(rt,"P",{"data-svelte-h":!0}),u($e)!=="svelte-tenqiw"&&($e.textContent=Jt),rt.forEach(n),bt=o(b),D=s(b,"DIV",{class:!0});var ot=_(D);d(K.$$.fragment,ot),yt=o(ot),be=s(ot,"P",{"data-svelte-h":!0}),u(be)!=="svelte-coevd"&&(be.textContent=Kt),ot.forEach(n),b.forEach(n),Ae=o(e),d(Y.$$.fragment,e),je=o(e),w=s(e,"DIV",{class:!0});var Ne=_(w);d(Z.$$.fragment,Ne),Ct=o(Ne),q=s(Ne,"DIV",{class:!0});var at=_(q);d(ee.$$.fragment,at),wt=o(at),ye=s(at,"P",{"data-svelte-h":!0}),u(ye)!=="svelte-1bh80il"&&(ye.textContent=Yt),at.forEach(n),Ot=o(Ne),N=s(Ne,"DIV",{class:!0});var st=_(N);d(te.$$.fragment,st),Tt=o(st),Ce=s(st,"P",{"data-svelte-h":!0}),u(Ce)!=="svelte-1kg2yu2"&&(Ce.innerHTML=Zt),st.forEach(n),Ne.forEach(n),Ue=o(e),d(ne.$$.fragment,e),Ge=o(e),re=s(e,"DIV",{class:!0});var dn=_(re);d(oe.$$.fragment,dn),dn.forEach(n),Re=o(e),d(ae.$$.fragment,e),Be=o(e),se=s(e,"P",{"data-svelte-h":!0}),u(se)!=="svelte-a66ofi"&&(se.innerHTML=en),Je=o(e),d(ie.$$.fragment,e),Ke=o(e),x=s(e,"DIV",{class:!0});var y=_(x);d(me.$$.fragment,y),Pt=o(y),F=s(y,"DIV",{class:!0});var it=_(F);d(le.$$.fragment,it),kt=o(it),we=s(it,"P",{"data-svelte-h":!0}),u(we)!=="svelte-rlyyl3"&&(we.textContent=tn),it.forEach(n),Mt=o(y),C=s(y,"DIV",{class:!0});var W=_(C);d(de.$$.fragment,W),Dt=o(W),Oe=s(W,"P",{"data-svelte-h":!0}),u(Oe)!=="svelte-rshgf5"&&(Oe.textContent=nn),qt=o(W),Te=s(W,"P",{"data-svelte-h":!0}),u(Te)!=="svelte-1wbth9c"&&(Te.textContent=rn),Nt=o(W),Pe=s(W,"OL",{"data-svelte-h":!0}),u(Pe)!=="svelte-qby6wj"&&(Pe.innerHTML=on),W.forEach(n),Ft=o(y),L=s(y,"DIV",{class:!0});var mt=_(L);d(fe.$$.fragment,mt),Lt=o(mt),ke=s(mt,"P",{"data-svelte-h":!0}),u(ke)!=="svelte-il0adz"&&(ke.textContent=an),mt.forEach(n),Et=o(y),E=s(y,"DIV",{class:!0});var lt=_(E);d(pe.$$.fragment,lt),It=o(lt),Me=s(lt,"P",{"data-svelte-h":!0}),u(Me)!=="svelte-k5ftuy"&&(Me.textContent=sn),lt.forEach(n),St=o(y),I=s(y,"DIV",{class:!0});var dt=_(I);d(ce.$$.fragment,dt),Wt=o(dt),De=s(dt,"P",{"data-svelte-h":!0}),u(De)!=="svelte-auvjm5"&&(De.textContent=mn),dt.forEach(n),Qt=o(y),S=s(y,"DIV",{class:!0});var ft=_(S);d(ge.$$.fragment,ft),Vt=o(ft),qe=s(ft,"P",{"data-svelte-h":!0}),u(qe)!=="svelte-tbalh5"&&(qe.textContent=ln),ft.forEach(n),y.forEach(n),Ye=o(e),Le=s(e,"P",{}),_(Le).forEach(n),this.h()},h(){v(O,"name","hf:doc:metadata"),v(O,"content",_n),v(T,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(P,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(k,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(h,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(w,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(re,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(F,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(C,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),v(x,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,i){t(document.head,O),m(e,Ee,i),m(e,Fe,i),m(e,Ie,i),f(Q,e,i),m(e,Se,i),m(e,V,i),m(e,We,i),m(e,z,i),m(e,Qe,i),f(H,e,i),m(e,Ve,i),m(e,X,i),m(e,ze,i),m(e,A,i),m(e,He,i),f(j,e,i),m(e,Xe,i),m(e,h,i),f(U,h,null),t(h,pt),t(h,he),t(h,ct),t(h,T),f(G,T,null),t(T,gt),t(T,xe),t(h,ut),t(h,P),f(R,P,null),t(P,ht),t(P,_e),t(h,xt),t(h,k),f(B,k,null),t(k,_t),t(k,ve),t(h,vt),t(h,M),f(J,M,null),t(M,$t),t(M,$e),t(h,bt),t(h,D),f(K,D,null),t(D,yt),t(D,be),m(e,Ae,i),f(Y,e,i),m(e,je,i),m(e,w,i),f(Z,w,null),t(w,Ct),t(w,q),f(ee,q,null),t(q,wt),t(q,ye),t(w,Ot),t(w,N),f(te,N,null),t(N,Tt),t(N,Ce),m(e,Ue,i),f(ne,e,i),m(e,Ge,i),m(e,re,i),f(oe,re,null),m(e,Re,i),f(ae,e,i),m(e,Be,i),m(e,se,i),m(e,Je,i),f(ie,e,i),m(e,Ke,i),m(e,x,i),f(me,x,null),t(x,Pt),t(x,F),f(le,F,null),t(F,kt),t(F,we),t(x,Mt),t(x,C),f(de,C,null),t(C,Dt),t(C,Oe),t(C,qt),t(C,Te),t(C,Nt),t(C,Pe),t(x,Ft),t(x,L),f(fe,L,null),t(L,Lt),t(L,ke),t(x,Et),t(x,E),f(pe,E,null),t(E,It),t(E,Me),t(x,St),t(x,I),f(ce,I,null),t(I,Wt),t(I,De),t(x,Qt),t(x,S),f(ge,S,null),t(S,Vt),t(S,qe),m(e,Ye,i),m(e,Le,i),Ze=!0},p:pn,i(e){Ze||(p(Q.$$.fragment,e),p(H.$$.fragment,e),p(j.$$.fragment,e),p(U.$$.fragment,e),p(G.$$.fragment,e),p(R.$$.fragment,e),p(B.$$.fragment,e),p(J.$$.fragment,e),p(K.$$.fragment,e),p(Y.$$.fragment,e),p(Z.$$.fragment,e),p(ee.$$.fragment,e),p(te.$$.fragment,e),p(ne.$$.fragment,e),p(oe.$$.fragment,e),p(ae.$$.fragment,e),p(ie.$$.fragment,e),p(me.$$.fragment,e),p(le.$$.fragment,e),p(de.$$.fragment,e),p(fe.$$.fragment,e),p(pe.$$.fragment,e),p(ce.$$.fragment,e),p(ge.$$.fragment,e),Ze=!0)},o(e){c(Q.$$.fragment,e),c(H.$$.fragment,e),c(j.$$.fragment,e),c(U.$$.fragment,e),c(G.$$.fragment,e),c(R.$$.fragment,e),c(B.$$.fragment,e),c(J.$$.fragment,e),c(K.$$.fragment,e),c(Y.$$.fragment,e),c(Z.$$.fragment,e),c(ee.$$.fragment,e),c(te.$$.fragment,e),c(ne.$$.fragment,e),c(oe.$$.fragment,e),c(ae.$$.fragment,e),c(ie.$$.fragment,e),c(me.$$.fragment,e),c(le.$$.fragment,e),c(de.$$.fragment,e),c(fe.$$.fragment,e),c(pe.$$.fragment,e),c(ce.$$.fragment,e),c(ge.$$.fragment,e),Ze=!1},d(e){e&&(n(Ee),n(Fe),n(Ie),n(Se),n(V),n(We),n(z),n(Qe),n(Ve),n(X),n(ze),n(A),n(He),n(Xe),n(h),n(Ae),n(je),n(w),n(Ue),n(Ge),n(re),n(Re),n(Be),n(se),n(Je),n(Ke),n(x),n(Ye),n(Le)),n(O),g(Q,e),g(H,e),g(j,e),g(U),g(G),g(R),g(B),g(J),g(K),g(Y,e),g(Z),g(ee),g(te),g(ne,e),g(oe),g(ae,e),g(ie,e),g(me),g(le),g(de),g(fe),g(pe),g(ce),g(ge)}}}const _n='{"title":"Exporting ðŸ¤— Transformers models to ONNX","local":"exporting--transformers-models-to-onnx","sections":[{"title":"ONNX Configurations","local":"onnx-configurations","sections":[{"title":"OnnxConfig","local":"transformers.onnx.OnnxConfig","sections":[],"depth":3},{"title":"OnnxConfigWithPast","local":"transformers.onnx.OnnxConfigWithPast","sections":[],"depth":3},{"title":"OnnxSeq2SeqConfigWithPast","local":"transformers.onnx.OnnxSeq2SeqConfigWithPast","sections":[],"depth":3}],"depth":2},{"title":"ONNX Features","local":"onnx-features","sections":[{"title":"FeaturesManager","local":"transformers.onnx.FeaturesManager","sections":[],"depth":3}],"depth":2}],"depth":1}';function vn(zt){return cn(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class wn extends gn{constructor(O){super(),un(this,O,vn,xn,fn,{})}}export{wn as component};
