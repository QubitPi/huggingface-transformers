import{s as ct,o as mt,n as Re}from"../chunks/scheduler.9bc65507.js";import{S as ut,i as ft,g as u,s as r,r as b,A as dt,h as f,f as s,c as o,j as lt,u as y,x as d,k as rt,l as ot,y as ht,a,v as $,d as M,t as j,w}from"../chunks/index.707bf1b6.js";import{T as it}from"../chunks/Tip.c2ecdbf4.js";import{C as U}from"../chunks/CodeBlock.54a9f38d.js";import{F as gt,M as pt}from"../chunks/Markdown.fef84341.js";import{H as pe}from"../chunks/Heading.342b1fa6.js";function bt(W){let n,h='Remember, architecture refers to the skeleton of the model and checkpoints are the weights for a given architecture. For example, <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a> is an architecture, while <code>google-bert/bert-base-uncased</code> is a checkpoint. Model is a general term that can mean either architecture or checkpoint.';return{c(){n=u("p"),n.innerHTML=h},l(l){n=f(l,"P",{"data-svelte-h":!0}),d(n)!=="svelte-c6e0um"&&(n.innerHTML=h)},m(l,p){a(l,n,p)},p:Re,d(l){l&&s(n)}}}function yt(W){let n,h='For PyTorch models, the <code>from_pretrained()</code> method uses <code>torch.load()</code> which internally uses <code>pickle</code> and is known to be insecure. In general, never load a model that could have come from an untrusted source, or that could have been tampered with. This security risk is partially mitigated for public models hosted on the Hugging Face Hub, which are <a href="https://huggingface.co/docs/hub/security-malware" rel="nofollow">scanned for malware</a> at each commit. See the <a href="https://huggingface.co/docs/hub/security" rel="nofollow">Hub documentation</a> for best practices like <a href="https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg" rel="nofollow">signed commit verification</a> with GPG.',l,p,g="TensorFlow and Flax checkpoints are not affected, and can be loaded within PyTorch architectures using the <code>from_tf</code> and <code>from_flax</code> kwargs for the <code>from_pretrained</code> method to circumvent this issue.";return{c(){n=u("p"),n.innerHTML=h,l=r(),p=u("p"),p.innerHTML=g},l(m){n=f(m,"P",{"data-svelte-h":!0}),d(n)!=="svelte-12xgjc6"&&(n.innerHTML=h),l=o(m),p=f(m,"P",{"data-svelte-h":!0}),d(p)!=="svelte-gbqaor"&&(p.innerHTML=g)},m(m,x){a(m,n,x),a(m,l,x),a(m,p,x)},p:Re,d(m){m&&(s(n),s(l),s(p))}}}function $t(W){let n,h='The <code>AutoModelFor</code> classes let you load a pretrained model for a given task (see <a href="model_doc/auto">here</a> for a complete list of available tasks). For example, load a model for sequence classification with <a href="/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained">AutoModelForSequenceClassification.from_pretrained()</a>:',l,p,g,m,x="Easily reuse the same checkpoint to load an architecture for a different task:",F,T,_,v,Z,C,c='Generally, we recommend using the <code>AutoTokenizer</code> class and the <code>AutoModelFor</code> class to load pretrained instances of models. This will ensure you load the correct architecture every time. In the next <a href="preprocessing">tutorial</a>, learn how to use your newly loaded tokenizer, image processor, feature extractor and processor to preprocess a dataset for fine-tuning.',k;return p=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),T=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),v=new it({props:{warning:!0,$$slots:{default:[yt]},$$scope:{ctx:W}}}),{c(){n=u("p"),n.innerHTML=h,l=r(),b(p.$$.fragment),g=r(),m=u("p"),m.textContent=x,F=r(),b(T.$$.fragment),_=r(),b(v.$$.fragment),Z=r(),C=u("p"),C.innerHTML=c},l(i){n=f(i,"P",{"data-svelte-h":!0}),d(n)!=="svelte-13pcg8m"&&(n.innerHTML=h),l=o(i),y(p.$$.fragment,i),g=o(i),m=f(i,"P",{"data-svelte-h":!0}),d(m)!=="svelte-98u76l"&&(m.textContent=x),F=o(i),y(T.$$.fragment,i),_=o(i),y(v.$$.fragment,i),Z=o(i),C=f(i,"P",{"data-svelte-h":!0}),d(C)!=="svelte-a18ug5"&&(C.innerHTML=c)},m(i,J){a(i,n,J),a(i,l,J),$(p,i,J),a(i,g,J),a(i,m,J),a(i,F,J),$(T,i,J),a(i,_,J),$(v,i,J),a(i,Z,J),a(i,C,J),k=!0},p(i,J){const V={};J&2&&(V.$$scope={dirty:J,ctx:i}),v.$set(V)},i(i){k||(M(p.$$.fragment,i),M(T.$$.fragment,i),M(v.$$.fragment,i),k=!0)},o(i){j(p.$$.fragment,i),j(T.$$.fragment,i),j(v.$$.fragment,i),k=!1},d(i){i&&(s(n),s(l),s(g),s(m),s(F),s(_),s(Z),s(C)),w(p,i),w(T,i),w(v,i)}}}function Mt(W){let n,h;return n=new pt({props:{$$slots:{default:[$t]},$$scope:{ctx:W}}}),{c(){b(n.$$.fragment)},l(l){y(n.$$.fragment,l)},m(l,p){$(n,l,p),h=!0},p(l,p){const g={};p&2&&(g.$$scope={dirty:p,ctx:l}),n.$set(g)},i(l){h||(M(n.$$.fragment,l),h=!0)},o(l){j(n.$$.fragment,l),h=!1},d(l){w(n,l)}}}function jt(W){let n,h='Finally, the <code>TFAutoModelFor</code> classes let you load a pretrained model for a given task (see <a href="model_doc/auto">here</a> for a complete list of available tasks). For example, load a model for sequence classification with <a href="/docs/transformers/main/en/model_doc/auto#transformers.FlaxAutoModelForVision2Seq.from_pretrained">TFAutoModelForSequenceClassification.from_pretrained()</a>:',l,p,g,m,x="Easily reuse the same checkpoint to load an architecture for a different task:",F,T,_,v,Z='Generally, we recommend using the <code>AutoTokenizer</code> class and the <code>TFAutoModelFor</code> class to load pretrained instances of models. This will ensure you load the correct architecture every time. In the next <a href="preprocessing">tutorial</a>, learn how to use your newly loaded tokenizer, image processor, feature extractor and processor to preprocess a dataset for fine-tuning.',C;return p=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),T=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){n=u("p"),n.innerHTML=h,l=r(),b(p.$$.fragment),g=r(),m=u("p"),m.textContent=x,F=r(),b(T.$$.fragment),_=r(),v=u("p"),v.innerHTML=Z},l(c){n=f(c,"P",{"data-svelte-h":!0}),d(n)!=="svelte-1nrzgox"&&(n.innerHTML=h),l=o(c),y(p.$$.fragment,c),g=o(c),m=f(c,"P",{"data-svelte-h":!0}),d(m)!=="svelte-98u76l"&&(m.textContent=x),F=o(c),y(T.$$.fragment,c),_=o(c),v=f(c,"P",{"data-svelte-h":!0}),d(v)!=="svelte-19d9o2j"&&(v.innerHTML=Z)},m(c,k){a(c,n,k),a(c,l,k),$(p,c,k),a(c,g,k),a(c,m,k),a(c,F,k),$(T,c,k),a(c,_,k),a(c,v,k),C=!0},p:Re,i(c){C||(M(p.$$.fragment,c),M(T.$$.fragment,c),C=!0)},o(c){j(p.$$.fragment,c),j(T.$$.fragment,c),C=!1},d(c){c&&(s(n),s(l),s(g),s(m),s(F),s(_),s(v)),w(p,c),w(T,c)}}}function wt(W){let n,h;return n=new pt({props:{$$slots:{default:[jt]},$$scope:{ctx:W}}}),{c(){b(n.$$.fragment)},l(l){y(n.$$.fragment,l)},m(l,p){$(n,l,p),h=!0},p(l,p){const g={};p&2&&(g.$$scope={dirty:p,ctx:l}),n.$set(g)},i(l){h||(M(n.$$.fragment,l),h=!0)},o(l){j(n.$$.fragment,l),h=!1},d(l){w(n,l)}}}function kt(W){let n,h,l,p,g,m,x,F="With so many different Transformer architectures, it can be challenging to create one for your checkpoint. As a part of ðŸ¤— Transformers core philosophy to make the library easy, simple and flexible to use, an <code>AutoClass</code> automatically infers and loads the correct architecture from a given checkpoint. The <code>from_pretrained()</code> method lets you quickly load a pretrained model for any architecture so you donâ€™t have to devote time and resources to train a model from scratch. Producing this type of checkpoint-agnostic code means if your code works for one checkpoint, it will work with another checkpoint - as long as it was trained for a similar task - even if the architecture is different.",T,_,v,Z,C="In this tutorial, learn to:",c,k,i="<li>Load a pretrained tokenizer.</li> <li>Load a pretrained image processor</li> <li>Load a pretrained feature extractor.</li> <li>Load a pretrained processor.</li> <li>Load a pretrained model.</li> <li>Load a model as a backbone.</li>",J,V,me,X,ze="Nearly every NLP task begins with a tokenizer. A tokenizer converts your input into a format that can be processed by the model.",ue,A,Ye='Load a tokenizer with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained">AutoTokenizer.from_pretrained()</a>:',fe,N,de,R,Ie="Then tokenize your input as shown below:",he,z,ge,Y,be,I,Ee="For vision tasks, an image processor processes the image into the correct input format.",ye,E,$e,B,Me,H,Be='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/Swin%20Stages.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">A Swin backbone with multiple stages for outputting a feature map.</figcaption>',je,q,qe='The <a href="/docs/transformers/main/en/main_classes/backbones#transformers.AutoBackbone">AutoBackbone</a> lets you use pretrained models as backbones to get feature maps from different stages of the backbone. You should specify one of the following parameters in <a href="/docs/transformers/main/en/main_classes/configuration#transformers.PretrainedConfig.from_pretrained">from_pretrained()</a>:',we,P,Pe="<li><code>out_indices</code> is the index of the layer youâ€™d like to get the feature map from</li> <li><code>out_features</code> is the name of the layer youâ€™d like to get the feature map from</li>",ke,Q,Qe="These parameters can be used interchangeably, but if you use both, make sure theyâ€™re aligned with each other! If you donâ€™t pass any of these parameters, the backbone returns the feature map from the last layer.",ve,L,Se='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/Swin%20Stage%201.png"/> <figcaption class="mt-2 text-center text-sm text-gray-500">A feature map from the first stage of the backbone. The patch partition refers to the model stem.</figcaption>',Te,S,Ke="For example, in the above diagram, to return the feature map from the first stage of the Swin backbone, you can set <code>out_indices=(1,)</code>:",Je,K,_e,D,De="Now you can access the <code>feature_maps</code> object from the first stage of the backbone:",xe,O,Ze,ee,Ce,te,Oe="For audio tasks, a feature extractor processes the audio signal the correct input format.",We,se,et='Load a feature extractor with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoFeatureExtractor.from_pretrained">AutoFeatureExtractor.from_pretrained()</a>:',Fe,ae,Ue,ne,Ve,le,tt='Multimodal tasks require a processor that combines two types of preprocessing tools. For example, the <a href="model_doc/layoutlmv2">LayoutLMV2</a> model requires an image processor to handle images and a tokenizer to handle text; a processor combines both of them.',He,re,st='Load a processor with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor.from_pretrained">AutoProcessor.from_pretrained()</a>:',Le,oe,Ge,ie,Xe,G,Ae,ce,Ne;return g=new pe({props:{title:"Load pretrained instances with an AutoClass",local:"load-pretrained-instances-with-an-autoclass",headingTag:"h1"}}),_=new it({props:{$$slots:{default:[bt]},$$scope:{ctx:W}}}),V=new pe({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h2"}}),N=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),z=new U({props:{code:"c2VxdWVuY2UlMjAlM0QlMjAlMjJJbiUyMGElMjBob2xlJTIwaW4lMjB0aGUlMjBncm91bmQlMjB0aGVyZSUyMGxpdmVkJTIwYSUyMGhvYmJpdC4lMjIlMEFwcmludCh0b2tlbml6ZXIoc2VxdWVuY2UpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),Y=new pe({props:{title:"AutoImageProcessor",local:"autoimageprocessor",headingTag:"h2"}}),E=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGdml0LWJhc2UtcGF0Y2gxNi0yMjQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224&quot;</span>)`,wrap:!1}}),B=new pe({props:{title:"AutoBackbone",local:"autobackbone",headingTag:"h2"}}),K=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUyQyUyMEF1dG9CYWNrYm9uZSUwQWltcG9ydCUyMHRvcmNoJTBBZnJvbSUyMFBJTCUyMGltcG9ydCUyMEltYWdlJTBBaW1wb3J0JTIwcmVxdWVzdHMlMEF1cmwlMjAlM0QlMjAlMjJodHRwJTNBJTJGJTJGaW1hZ2VzLmNvY29kYXRhc2V0Lm9yZyUyRnZhbDIwMTclMkYwMDAwMDAwMzk3NjkuanBnJTIyJTBBaW1hZ2UlMjAlM0QlMjBJbWFnZS5vcGVuKHJlcXVlc3RzLmdldCh1cmwlMkMlMjBzdHJlYW0lM0RUcnVlKS5yYXcpJTBBcHJvY2Vzc29yJTIwJTNEJTIwQXV0b0ltYWdlUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZzd2luLXRpbnktcGF0Y2g0LXdpbmRvdzctMjI0JTIyKSUwQW1vZGVsJTIwJTNEJTIwQXV0b0JhY2tib25lLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZzd2luLXRpbnktcGF0Y2g0LXdpbmRvdzctMjI0JTIyJTJDJTIwb3V0X2luZGljZXMlM0QoMSUyQykpJTBBJTBBaW5wdXRzJTIwJTNEJTIwcHJvY2Vzc29yKGltYWdlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklMEFvdXRwdXRzJTIwJTNEJTIwbW9kZWwoKippbnB1dHMpJTBBZmVhdHVyZV9tYXBzJTIwJTNEJTIwb3V0cHV0cy5mZWF0dXJlX21hcHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor, AutoBackbone
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests
<span class="hljs-meta">&gt;&gt;&gt; </span>url = <span class="hljs-string">&quot;http://images.cocodataset.org/val2017/000000039769.jpg&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image = Image.<span class="hljs-built_in">open</span>(requests.get(url, stream=<span class="hljs-literal">True</span>).raw)
<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/swin-tiny-patch4-window7-224&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoBackbone.from_pretrained(<span class="hljs-string">&quot;microsoft/swin-tiny-patch4-window7-224&quot;</span>, out_indices=(<span class="hljs-number">1</span>,))

<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = processor(image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)
<span class="hljs-meta">&gt;&gt;&gt; </span>feature_maps = outputs.feature_maps`,wrap:!1}}),O=new U({props:{code:"bGlzdChmZWF0dXJlX21hcHMlNUIwJTVELnNoYXBlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">list</span>(feature_maps[<span class="hljs-number">0</span>].shape)
[<span class="hljs-number">1</span>, <span class="hljs-number">96</span>, <span class="hljs-number">56</span>, <span class="hljs-number">56</span>]`,wrap:!1}}),ee=new pe({props:{title:"AutoFeatureExtractor",local:"autofeatureextractor",headingTag:"h2"}}),ae=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZWhjYWxhYnJlcyUyRndhdjJ2ZWMyLWxnLXhsc3ItZW4tc3BlZWNoLWVtb3Rpb24tcmVjb2duaXRpb24lMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),ne=new pe({props:{title:"AutoProcessor",local:"autoprocessor",headingTag:"h2"}}),oe=new U({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZsYXlvdXRsbXYyLWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`,wrap:!1}}),ie=new pe({props:{title:"AutoModel",local:"automodel",headingTag:"h2"}}),G=new gt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[wt],pytorch:[Mt]},$$scope:{ctx:W}}}),{c(){n=u("meta"),h=r(),l=u("p"),p=r(),b(g.$$.fragment),m=r(),x=u("p"),x.innerHTML=F,T=r(),b(_.$$.fragment),v=r(),Z=u("p"),Z.textContent=C,c=r(),k=u("ul"),k.innerHTML=i,J=r(),b(V.$$.fragment),me=r(),X=u("p"),X.textContent=ze,ue=r(),A=u("p"),A.innerHTML=Ye,fe=r(),b(N.$$.fragment),de=r(),R=u("p"),R.textContent=Ie,he=r(),b(z.$$.fragment),ge=r(),b(Y.$$.fragment),be=r(),I=u("p"),I.textContent=Ee,ye=r(),b(E.$$.fragment),$e=r(),b(B.$$.fragment),Me=r(),H=u("div"),H.innerHTML=Be,je=r(),q=u("p"),q.innerHTML=qe,we=r(),P=u("ul"),P.innerHTML=Pe,ke=r(),Q=u("p"),Q.textContent=Qe,ve=r(),L=u("div"),L.innerHTML=Se,Te=r(),S=u("p"),S.innerHTML=Ke,Je=r(),b(K.$$.fragment),_e=r(),D=u("p"),D.innerHTML=De,xe=r(),b(O.$$.fragment),Ze=r(),b(ee.$$.fragment),Ce=r(),te=u("p"),te.textContent=Oe,We=r(),se=u("p"),se.innerHTML=et,Fe=r(),b(ae.$$.fragment),Ue=r(),b(ne.$$.fragment),Ve=r(),le=u("p"),le.innerHTML=tt,He=r(),re=u("p"),re.innerHTML=st,Le=r(),b(oe.$$.fragment),Ge=r(),b(ie.$$.fragment),Xe=r(),b(G.$$.fragment),Ae=r(),ce=u("p"),this.h()},l(e){const t=dt("svelte-u9bgzb",document.head);n=f(t,"META",{name:!0,content:!0}),t.forEach(s),h=o(e),l=f(e,"P",{}),lt(l).forEach(s),p=o(e),y(g.$$.fragment,e),m=o(e),x=f(e,"P",{"data-svelte-h":!0}),d(x)!=="svelte-j0p9ct"&&(x.innerHTML=F),T=o(e),y(_.$$.fragment,e),v=o(e),Z=f(e,"P",{"data-svelte-h":!0}),d(Z)!=="svelte-1kmbcqk"&&(Z.textContent=C),c=o(e),k=f(e,"UL",{"data-svelte-h":!0}),d(k)!=="svelte-gmadry"&&(k.innerHTML=i),J=o(e),y(V.$$.fragment,e),me=o(e),X=f(e,"P",{"data-svelte-h":!0}),d(X)!=="svelte-8r2c79"&&(X.textContent=ze),ue=o(e),A=f(e,"P",{"data-svelte-h":!0}),d(A)!=="svelte-1kt9dw1"&&(A.innerHTML=Ye),fe=o(e),y(N.$$.fragment,e),de=o(e),R=f(e,"P",{"data-svelte-h":!0}),d(R)!=="svelte-1idptsb"&&(R.textContent=Ie),he=o(e),y(z.$$.fragment,e),ge=o(e),y(Y.$$.fragment,e),be=o(e),I=f(e,"P",{"data-svelte-h":!0}),d(I)!=="svelte-1d6dyuq"&&(I.textContent=Ee),ye=o(e),y(E.$$.fragment,e),$e=o(e),y(B.$$.fragment,e),Me=o(e),H=f(e,"DIV",{style:!0,"data-svelte-h":!0}),d(H)!=="svelte-1fytqp6"&&(H.innerHTML=Be),je=o(e),q=f(e,"P",{"data-svelte-h":!0}),d(q)!=="svelte-he6aam"&&(q.innerHTML=qe),we=o(e),P=f(e,"UL",{"data-svelte-h":!0}),d(P)!=="svelte-1bdrs99"&&(P.innerHTML=Pe),ke=o(e),Q=f(e,"P",{"data-svelte-h":!0}),d(Q)!=="svelte-457zio"&&(Q.textContent=Qe),ve=o(e),L=f(e,"DIV",{style:!0,"data-svelte-h":!0}),d(L)!=="svelte-1n58jef"&&(L.innerHTML=Se),Te=o(e),S=f(e,"P",{"data-svelte-h":!0}),d(S)!=="svelte-kbe43d"&&(S.innerHTML=Ke),Je=o(e),y(K.$$.fragment,e),_e=o(e),D=f(e,"P",{"data-svelte-h":!0}),d(D)!=="svelte-h2y0p0"&&(D.innerHTML=De),xe=o(e),y(O.$$.fragment,e),Ze=o(e),y(ee.$$.fragment,e),Ce=o(e),te=f(e,"P",{"data-svelte-h":!0}),d(te)!=="svelte-f3nvdu"&&(te.textContent=Oe),We=o(e),se=f(e,"P",{"data-svelte-h":!0}),d(se)!=="svelte-w6dlio"&&(se.innerHTML=et),Fe=o(e),y(ae.$$.fragment,e),Ue=o(e),y(ne.$$.fragment,e),Ve=o(e),le=f(e,"P",{"data-svelte-h":!0}),d(le)!=="svelte-p2h4f9"&&(le.innerHTML=tt),He=o(e),re=f(e,"P",{"data-svelte-h":!0}),d(re)!=="svelte-wn0ar2"&&(re.innerHTML=st),Le=o(e),y(oe.$$.fragment,e),Ge=o(e),y(ie.$$.fragment,e),Xe=o(e),y(G.$$.fragment,e),Ae=o(e),ce=f(e,"P",{}),lt(ce).forEach(s),this.h()},h(){rt(n,"name","hf:doc:metadata"),rt(n,"content",vt),ot(H,"text-align","center"),ot(L,"text-align","center")},m(e,t){ht(document.head,n),a(e,h,t),a(e,l,t),a(e,p,t),$(g,e,t),a(e,m,t),a(e,x,t),a(e,T,t),$(_,e,t),a(e,v,t),a(e,Z,t),a(e,c,t),a(e,k,t),a(e,J,t),$(V,e,t),a(e,me,t),a(e,X,t),a(e,ue,t),a(e,A,t),a(e,fe,t),$(N,e,t),a(e,de,t),a(e,R,t),a(e,he,t),$(z,e,t),a(e,ge,t),$(Y,e,t),a(e,be,t),a(e,I,t),a(e,ye,t),$(E,e,t),a(e,$e,t),$(B,e,t),a(e,Me,t),a(e,H,t),a(e,je,t),a(e,q,t),a(e,we,t),a(e,P,t),a(e,ke,t),a(e,Q,t),a(e,ve,t),a(e,L,t),a(e,Te,t),a(e,S,t),a(e,Je,t),$(K,e,t),a(e,_e,t),a(e,D,t),a(e,xe,t),$(O,e,t),a(e,Ze,t),$(ee,e,t),a(e,Ce,t),a(e,te,t),a(e,We,t),a(e,se,t),a(e,Fe,t),$(ae,e,t),a(e,Ue,t),$(ne,e,t),a(e,Ve,t),a(e,le,t),a(e,He,t),a(e,re,t),a(e,Le,t),$(oe,e,t),a(e,Ge,t),$(ie,e,t),a(e,Xe,t),$(G,e,t),a(e,Ae,t),a(e,ce,t),Ne=!0},p(e,[t]){const at={};t&2&&(at.$$scope={dirty:t,ctx:e}),_.$set(at);const nt={};t&2&&(nt.$$scope={dirty:t,ctx:e}),G.$set(nt)},i(e){Ne||(M(g.$$.fragment,e),M(_.$$.fragment,e),M(V.$$.fragment,e),M(N.$$.fragment,e),M(z.$$.fragment,e),M(Y.$$.fragment,e),M(E.$$.fragment,e),M(B.$$.fragment,e),M(K.$$.fragment,e),M(O.$$.fragment,e),M(ee.$$.fragment,e),M(ae.$$.fragment,e),M(ne.$$.fragment,e),M(oe.$$.fragment,e),M(ie.$$.fragment,e),M(G.$$.fragment,e),Ne=!0)},o(e){j(g.$$.fragment,e),j(_.$$.fragment,e),j(V.$$.fragment,e),j(N.$$.fragment,e),j(z.$$.fragment,e),j(Y.$$.fragment,e),j(E.$$.fragment,e),j(B.$$.fragment,e),j(K.$$.fragment,e),j(O.$$.fragment,e),j(ee.$$.fragment,e),j(ae.$$.fragment,e),j(ne.$$.fragment,e),j(oe.$$.fragment,e),j(ie.$$.fragment,e),j(G.$$.fragment,e),Ne=!1},d(e){e&&(s(h),s(l),s(p),s(m),s(x),s(T),s(v),s(Z),s(c),s(k),s(J),s(me),s(X),s(ue),s(A),s(fe),s(de),s(R),s(he),s(ge),s(be),s(I),s(ye),s($e),s(Me),s(H),s(je),s(q),s(we),s(P),s(ke),s(Q),s(ve),s(L),s(Te),s(S),s(Je),s(_e),s(D),s(xe),s(Ze),s(Ce),s(te),s(We),s(se),s(Fe),s(Ue),s(Ve),s(le),s(He),s(re),s(Le),s(Ge),s(Xe),s(Ae),s(ce)),s(n),w(g,e),w(_,e),w(V,e),w(N,e),w(z,e),w(Y,e),w(E,e),w(B,e),w(K,e),w(O,e),w(ee,e),w(ae,e),w(ne,e),w(oe,e),w(ie,e),w(G,e)}}}const vt='{"title":"Load pretrained instances with an AutoClass","local":"load-pretrained-instances-with-an-autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":2},{"title":"AutoImageProcessor","local":"autoimageprocessor","sections":[],"depth":2},{"title":"AutoBackbone","local":"autobackbone","sections":[],"depth":2},{"title":"AutoFeatureExtractor","local":"autofeatureextractor","sections":[],"depth":2},{"title":"AutoProcessor","local":"autoprocessor","sections":[],"depth":2},{"title":"AutoModel","local":"automodel","sections":[],"depth":2}],"depth":1}';function Tt(W){return mt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ft extends ut{constructor(n){super(),ft(this,n,Tt,kt,ct,{})}}export{Ft as component};
