import{s as Yt,o as Lt,n as ee}from"../chunks/scheduler.9bc65507.js";import{S as St,i as Dt,g,s as p,r as h,A as Pt,h as T,f as l,c as i,j as Ft,u as M,x as J,k as Nt,y as Kt,a as n,v as f,d as w,t as y,w as j,m as Qt,n as qt}from"../chunks/index.707bf1b6.js";import{T as yt}from"../chunks/Tip.c2ecdbf4.js";import{Y as Ht}from"../chunks/Youtube.e1129c6f.js";import{C as X}from"../chunks/CodeBlock.54a9f38d.js";import{D as Ot}from"../chunks/DocNotebookDropdown.41f65cb5.js";import{F as jt,M as xe}from"../chunks/Markdown.fef84341.js";import{H as Re}from"../chunks/Heading.342b1fa6.js";function es(C){let a,m,s='<a href="../model_doc/albert">ALBERT</a>, <a href="../model_doc/bart">BART</a>, <a href="../model_doc/bert">BERT</a>, <a href="../model_doc/big_bird">BigBird</a>, <a href="../model_doc/bigbird_pegasus">BigBird-Pegasus</a>, <a href="../model_doc/bloom">BLOOM</a>, <a href="../model_doc/camembert">CamemBERT</a>, <a href="../model_doc/canine">CANINE</a>, <a href="../model_doc/convbert">ConvBERT</a>, <a href="../model_doc/data2vec-text">Data2VecText</a>, <a href="../model_doc/deberta">DeBERTa</a>, <a href="../model_doc/deberta-v2">DeBERTa-v2</a>, <a href="../model_doc/distilbert">DistilBERT</a>, <a href="../model_doc/electra">ELECTRA</a>, <a href="../model_doc/ernie">ERNIE</a>, <a href="../model_doc/ernie_m">ErnieM</a>, <a href="../model_doc/falcon">Falcon</a>, <a href="../model_doc/flaubert">FlauBERT</a>, <a href="../model_doc/fnet">FNet</a>, <a href="../model_doc/funnel">Funnel Transformer</a>, <a href="../model_doc/gpt2">OpenAI GPT-2</a>, <a href="../model_doc/gpt_neo">GPT Neo</a>, <a href="../model_doc/gpt_neox">GPT NeoX</a>, <a href="../model_doc/gptj">GPT-J</a>, <a href="../model_doc/ibert">I-BERT</a>, <a href="../model_doc/layoutlmv2">LayoutLMv2</a>, <a href="../model_doc/layoutlmv3">LayoutLMv3</a>, <a href="../model_doc/led">LED</a>, <a href="../model_doc/lilt">LiLT</a>, <a href="../model_doc/llama">LLaMA</a>, <a href="../model_doc/longformer">Longformer</a>, <a href="../model_doc/luke">LUKE</a>, <a href="../model_doc/lxmert">LXMERT</a>, <a href="../model_doc/markuplm">MarkupLM</a>, <a href="../model_doc/mbart">mBART</a>, <a href="../model_doc/mega">MEGA</a>, <a href="../model_doc/megatron-bert">Megatron-BERT</a>, <a href="../model_doc/mobilebert">MobileBERT</a>, <a href="../model_doc/mpnet">MPNet</a>, <a href="../model_doc/mpt">MPT</a>, <a href="../model_doc/mra">MRA</a>, <a href="../model_doc/mt5">MT5</a>, <a href="../model_doc/mvp">MVP</a>, <a href="../model_doc/nezha">Nezha</a>, <a href="../model_doc/nystromformer">Nyströmformer</a>, <a href="../model_doc/opt">OPT</a>, <a href="../model_doc/qdqbert">QDQBert</a>, <a href="../model_doc/reformer">Reformer</a>, <a href="../model_doc/rembert">RemBERT</a>, <a href="../model_doc/roberta">RoBERTa</a>, <a href="../model_doc/roberta-prelayernorm">RoBERTa-PreLayerNorm</a>, <a href="../model_doc/roc_bert">RoCBert</a>, <a href="../model_doc/roformer">RoFormer</a>, <a href="../model_doc/splinter">Splinter</a>, <a href="../model_doc/squeezebert">SqueezeBERT</a>, <a href="../model_doc/t5">T5</a>, <a href="../model_doc/umt5">UMT5</a>, <a href="../model_doc/xlm">XLM</a>, <a href="../model_doc/xlm-roberta">XLM-RoBERTa</a>, <a href="../model_doc/xlm-roberta-xl">XLM-RoBERTa-XL</a>, <a href="../model_doc/xlnet">XLNet</a>, <a href="../model_doc/xmod">X-MOD</a>, <a href="../model_doc/yoso">YOSO</a>';return{c(){a=Qt(`The task illustrated in this tutorial is supported by the following model architectures:

`),m=g("p"),m.innerHTML=s},l(c){a=qt(c,`The task illustrated in this tutorial is supported by the following model architectures:

`),m=T(c,"P",{"data-svelte-h":!0}),J(m)!=="svelte-1enh4z9"&&(m.innerHTML=s)},m(c,u){n(c,a,u),n(c,m,u)},p:ee,d(c){c&&(l(a),l(m))}}}function ts(C){let a,m;return a=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator()`,wrap:!1}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p:ee,i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function ss(C){let a,m;return a=new xe({props:{$$slots:{default:[ts]},$$scope:{ctx:C}}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p(s,c){const u={};c&2&&(u.$$scope={dirty:c,ctx:s}),a.$set(u)},i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function as(C){let a,m;return a=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcihyZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p:ee,i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function ls(C){let a,m;return a=new xe({props:{$$slots:{default:[as]},$$scope:{ctx:C}}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p(s,c){const u={};c&2&&(u.$$scope={dirty:c,ctx:s}),a.$set(u)},i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function ns(C){let a,m='If you aren’t familiar with finetuning a model with the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a>, take a look at the basic tutorial <a href="../training#train-with-pytorch-trainer">here</a>!';return{c(){a=g("p"),a.innerHTML=m},l(s){a=T(s,"P",{"data-svelte-h":!0}),J(a)!=="svelte-15s4um0"&&(a.innerHTML=m)},m(s,c){n(s,a,c)},p:ee,d(s){s&&l(a)}}}function rs(C){let a,m,s,c='You’re ready to start training your model now! Load DistilBERT with <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForQuestionAnswering">AutoModelForQuestionAnswering</a>:',u,I,W,R,k="At this point, only three steps remain:",v,$,z='<li>Define your training hyperparameters in <a href="/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>. The only required parameter is <code>output_dir</code> which specifies where to save your model. You’ll push this model to the Hub by setting <code>push_to_hub=True</code> (you need to be signed in to Hugging Face to upload your model).</li> <li>Pass the training arguments to <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> along with the model, dataset, tokenizer, and data collator.</li> <li>Call <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train">train()</a> to finetune your model.</li>',B,b,A,Z,E='Once training is completed, share your model to the Hub with the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> method so everyone can use your model:',G,U,x;return a=new yt({props:{$$slots:{default:[ns]},$$scope:{ctx:C}}}),I=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclF1ZXN0aW9uQW5zd2VyaW5nJTJDJTIwVHJhaW5pbmdBcmd1bWVudHMlMkMlMjBUcmFpbmVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JRdWVzdGlvbkFuc3dlcmluZy5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),b=new X({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwZXZhbHVhdGlvbl9zdHJhdGVneSUzRCUyMmVwb2NoJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMyUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheSUzRDAuMDElMkMlMEElMjAlMjAlMjAlMjBwdXNoX3RvX2h1YiUzRFRydWUlMkMlMEEpJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHRva2VuaXplZF9zcXVhZCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEdG9rZW5pemVkX3NxdWFkJTVCJTIydGVzdCUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHRva2VuaXplciUzRHRva2VuaXplciUyQyUwQSUyMCUyMCUyMCUyMGRhdGFfY29sbGF0b3IlM0RkYXRhX2NvbGxhdG9yJTJDJTBBKSUwQSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=tokenized_squad[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=tokenized_squad[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),U=new X({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){h(a.$$.fragment),m=p(),s=g("p"),s.innerHTML=c,u=p(),h(I.$$.fragment),W=p(),R=g("p"),R.textContent=k,v=p(),$=g("ol"),$.innerHTML=z,B=p(),h(b.$$.fragment),A=p(),Z=g("p"),Z.innerHTML=E,G=p(),h(U.$$.fragment)},l(t){M(a.$$.fragment,t),m=i(t),s=T(t,"P",{"data-svelte-h":!0}),J(s)!=="svelte-ymj5iq"&&(s.innerHTML=c),u=i(t),M(I.$$.fragment,t),W=i(t),R=T(t,"P",{"data-svelte-h":!0}),J(R)!=="svelte-l42k0i"&&(R.textContent=k),v=i(t),$=T(t,"OL",{"data-svelte-h":!0}),J($)!=="svelte-uz043g"&&($.innerHTML=z),B=i(t),M(b.$$.fragment,t),A=i(t),Z=T(t,"P",{"data-svelte-h":!0}),J(Z)!=="svelte-1v13hlo"&&(Z.innerHTML=E),G=i(t),M(U.$$.fragment,t)},m(t,d){f(a,t,d),n(t,m,d),n(t,s,d),n(t,u,d),f(I,t,d),n(t,W,d),n(t,R,d),n(t,v,d),n(t,$,d),n(t,B,d),f(b,t,d),n(t,A,d),n(t,Z,d),n(t,G,d),f(U,t,d),x=!0},p(t,d){const V={};d&2&&(V.$$scope={dirty:d,ctx:t}),a.$set(V)},i(t){x||(w(a.$$.fragment,t),w(I.$$.fragment,t),w(b.$$.fragment,t),w(U.$$.fragment,t),x=!0)},o(t){y(a.$$.fragment,t),y(I.$$.fragment,t),y(b.$$.fragment,t),y(U.$$.fragment,t),x=!1},d(t){t&&(l(m),l(s),l(u),l(W),l(R),l(v),l($),l(B),l(A),l(Z),l(G)),j(a,t),j(I,t),j(b,t),j(U,t)}}}function os(C){let a,m;return a=new xe({props:{$$slots:{default:[rs]},$$scope:{ctx:C}}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p(s,c){const u={};c&2&&(u.$$scope={dirty:c,ctx:s}),a.$set(u)},i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function ps(C){let a,m='If you aren’t familiar with finetuning a model with Keras, take a look at the basic tutorial <a href="../training#train-a-tensorflow-model-with-keras">here</a>!';return{c(){a=g("p"),a.innerHTML=m},l(s){a=T(s,"P",{"data-svelte-h":!0}),J(a)!=="svelte-1rd4nl8"&&(a.innerHTML=m)},m(s,c){n(s,a,c)},p:ee,d(s){s&&l(a)}}}function is(C){let a,m,s,c,u,I='Then you can load DistilBERT with <a href="/docs/transformers/main/en/model_doc/auto#transformers.TFAutoModelForQuestionAnswering">TFAutoModelForQuestionAnswering</a>:',W,R,k,v,$='Convert your datasets to the <code>tf.data.Dataset</code> format with <a href="/docs/transformers/main/en/main_classes/model#transformers.TFPreTrainedModel.prepare_tf_dataset">prepare_tf_dataset()</a>:',z,B,b,A,Z='Configure the model for training with <a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a>:',E,G,U,x,t='The last thing to setup before you start training is to provide a way to push your model to the Hub. This can be done by specifying where to push your model and tokenizer in the <a href="/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a>:',d,V,q,F,Xe='Finally, you’re ready to start training your model! Call <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a> with your training and validation datasets, the number of epochs, and your callback to finetune the model:',Y,N,L,H,ve="Once training is completed, your model is automatically uploaded to the Hub so everyone can use it!",S;return a=new yt({props:{$$slots:{default:[ps]},$$scope:{ctx:C}}}),s=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMEElMEFiYXRjaF9zaXplJTIwJTNEJTIwMTYlMEFudW1fZXBvY2hzJTIwJTNEJTIwMiUwQXRvdGFsX3RyYWluX3N0ZXBzJTIwJTNEJTIwKGxlbih0b2tlbml6ZWRfc3F1YWQlNUIlMjJ0cmFpbiUyMiU1RCklMjAlMkYlMkYlMjBiYXRjaF9zaXplKSUyMColMjBudW1fZXBvY2hzJTBBb3B0aW1pemVyJTJDJTIwc2NoZWR1bGUlMjAlM0QlMjBjcmVhdGVfb3B0aW1pemVyKCUwQSUyMCUyMCUyMCUyMGluaXRfbHIlM0QyZS01JTJDJTBBJTIwJTIwJTIwJTIwbnVtX3dhcm11cF9zdGVwcyUzRDAlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fc3RlcHMlM0R0b3RhbF90cmFpbl9zdGVwcyUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>batch_size = <span class="hljs-number">16</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>total_train_steps = (<span class="hljs-built_in">len</span>(tokenized_squad[<span class="hljs-string">&quot;train&quot;</span>]) // batch_size) * num_epochs
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer, schedule = create_optimizer(
<span class="hljs-meta">... </span>    init_lr=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    num_warmup_steps=<span class="hljs-number">0</span>,
<span class="hljs-meta">... </span>    num_train_steps=total_train_steps,
<span class="hljs-meta">... </span>)`,wrap:!1}}),R=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmclMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmcuZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),B=new X({props:{code:"dGZfdHJhaW5fc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMHRva2VuaXplZF9zcXVhZCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwc2h1ZmZsZSUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBjb2xsYXRlX2ZuJTNEZGF0YV9jb2xsYXRvciUyQyUwQSklMEElMEF0Zl92YWxpZGF0aW9uX3NldCUyMCUzRCUyMG1vZGVsLnByZXBhcmVfdGZfZGF0YXNldCglMEElMjAlMjAlMjAlMjB0b2tlbml6ZWRfc3F1YWQlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwc2h1ZmZsZSUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwY29sbGF0ZV9mbiUzRGRhdGFfY29sbGF0b3IlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_squad[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_squad[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),G=new X({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`,wrap:!1}}),V=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBQdXNoVG9IdWJDYWxsYmFjayUwQSUwQWNhbGxiYWNrJTIwJTNEJTIwUHVzaFRvSHViQ2FsbGJhY2soJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMm15X2F3ZXNvbWVfcWFfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>)`,wrap:!1}}),N=new X({props:{code:"bW9kZWwuZml0KHglM0R0Zl90cmFpbl9zZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl92YWxpZGF0aW9uX3NldCUyQyUyMGVwb2NocyUzRDMlMkMlMjBjYWxsYmFja3MlM0QlNUJjYWxsYmFjayU1RCk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=<span class="hljs-number">3</span>, callbacks=[callback])',wrap:!1}}),{c(){h(a.$$.fragment),m=Qt(`
To finetune a model in TensorFlow, start by setting up an optimizer function, learning rate schedule, and some training hyperparameters:

	`),h(s.$$.fragment),c=p(),u=g("p"),u.innerHTML=I,W=p(),h(R.$$.fragment),k=p(),v=g("p"),v.innerHTML=$,z=p(),h(B.$$.fragment),b=p(),A=g("p"),A.innerHTML=Z,E=p(),h(G.$$.fragment),U=p(),x=g("p"),x.innerHTML=t,d=p(),h(V.$$.fragment),q=p(),F=g("p"),F.innerHTML=Xe,Y=p(),h(N.$$.fragment),L=p(),H=g("p"),H.textContent=ve},l(o){M(a.$$.fragment,o),m=qt(o,`
To finetune a model in TensorFlow, start by setting up an optimizer function, learning rate schedule, and some training hyperparameters:

	`),M(s.$$.fragment,o),c=i(o),u=T(o,"P",{"data-svelte-h":!0}),J(u)!=="svelte-14d13tk"&&(u.innerHTML=I),W=i(o),M(R.$$.fragment,o),k=i(o),v=T(o,"P",{"data-svelte-h":!0}),J(v)!=="svelte-9ymftz"&&(v.innerHTML=$),z=i(o),M(B.$$.fragment,o),b=i(o),A=T(o,"P",{"data-svelte-h":!0}),J(A)!=="svelte-rt1r5v"&&(A.innerHTML=Z),E=i(o),M(G.$$.fragment,o),U=i(o),x=T(o,"P",{"data-svelte-h":!0}),J(x)!=="svelte-1iofjok"&&(x.innerHTML=t),d=i(o),M(V.$$.fragment,o),q=i(o),F=T(o,"P",{"data-svelte-h":!0}),J(F)!=="svelte-1pfsro2"&&(F.innerHTML=Xe),Y=i(o),M(N.$$.fragment,o),L=i(o),H=T(o,"P",{"data-svelte-h":!0}),J(H)!=="svelte-2s71om"&&(H.textContent=ve)},m(o,_){f(a,o,_),n(o,m,_),f(s,o,_),n(o,c,_),n(o,u,_),n(o,W,_),f(R,o,_),n(o,k,_),n(o,v,_),n(o,z,_),f(B,o,_),n(o,b,_),n(o,A,_),n(o,E,_),f(G,o,_),n(o,U,_),n(o,x,_),n(o,d,_),f(V,o,_),n(o,q,_),n(o,F,_),n(o,Y,_),f(N,o,_),n(o,L,_),n(o,H,_),S=!0},p(o,_){const Q={};_&2&&(Q.$$scope={dirty:_,ctx:o}),a.$set(Q)},i(o){S||(w(a.$$.fragment,o),w(s.$$.fragment,o),w(R.$$.fragment,o),w(B.$$.fragment,o),w(G.$$.fragment,o),w(V.$$.fragment,o),w(N.$$.fragment,o),S=!0)},o(o){y(a.$$.fragment,o),y(s.$$.fragment,o),y(R.$$.fragment,o),y(B.$$.fragment,o),y(G.$$.fragment,o),y(V.$$.fragment,o),y(N.$$.fragment,o),S=!1},d(o){o&&(l(m),l(c),l(u),l(W),l(k),l(v),l(z),l(b),l(A),l(E),l(U),l(x),l(d),l(q),l(F),l(Y),l(L),l(H)),j(a,o),j(s,o),j(R,o),j(B,o),j(G,o),j(V,o),j(N,o)}}}function ms(C){let a,m;return a=new xe({props:{$$slots:{default:[is]},$$scope:{ctx:C}}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p(s,c){const u={};c&2&&(u.$$scope={dirty:c,ctx:s}),a.$set(u)},i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function cs(C){let a,m=`For a more in-depth example of how to finetune a model for question answering, take a look at the corresponding
<a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb" rel="nofollow">PyTorch notebook</a>
or <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb" rel="nofollow">TensorFlow notebook</a>.`;return{c(){a=g("p"),a.innerHTML=m},l(s){a=T(s,"P",{"data-svelte-h":!0}),J(a)!=="svelte-14amlb3"&&(a.innerHTML=m)},m(s,c){n(s,a,c)},p:ee,d(s){s&&l(a)}}}function ds(C){let a,m="Tokenize the text and return PyTorch tensors:",s,c,u,I,W="Pass your inputs to the model and return the <code>logits</code>:",R,k,v,$,z="Get the highest probability from the model output for the start and end positions:",B,b,A,Z,E="Decode the predicted tokens to get the answer:",G,U,x;return c=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihxdWVzdGlvbiUyQyUyMGNvbnRleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(question, context, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),k=new X({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmclMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclF1ZXN0aW9uQW5zd2VyaW5nLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyKSUwQXdpdGglMjB0b3JjaC5ub19ncmFkKCklM0ElMEElMjAlMjAlMjAlMjBvdXRwdXRzJTIwJTNEJTIwbW9kZWwoKippbnB1dHMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    outputs = model(**inputs)`,wrap:!1}}),b=new X({props:{code:"YW5zd2VyX3N0YXJ0X2luZGV4JTIwJTNEJTIwb3V0cHV0cy5zdGFydF9sb2dpdHMuYXJnbWF4KCklMEFhbnN3ZXJfZW5kX2luZGV4JTIwJTNEJTIwb3V0cHV0cy5lbmRfbG9naXRzLmFyZ21heCgp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>answer_start_index = outputs.start_logits.argmax()
<span class="hljs-meta">&gt;&gt;&gt; </span>answer_end_index = outputs.end_logits.argmax()`,wrap:!1}}),U=new X({props:{code:"cHJlZGljdF9hbnN3ZXJfdG9rZW5zJTIwJTNEJTIwaW5wdXRzLmlucHV0X2lkcyU1QjAlMkMlMjBhbnN3ZXJfc3RhcnRfaW5kZXglMjAlM0ElMjBhbnN3ZXJfZW5kX2luZGV4JTIwJTJCJTIwMSU1RCUwQXRva2VuaXplci5kZWNvZGUocHJlZGljdF9hbnN3ZXJfdG9rZW5zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predict_answer_tokens = inputs.input_ids[<span class="hljs-number">0</span>, answer_start_index : answer_end_index + <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predict_answer_tokens)
<span class="hljs-string">&#x27;176 billion parameters and can generate text in 46 languages natural languages and 13&#x27;</span>`,wrap:!1}}),{c(){a=g("p"),a.textContent=m,s=p(),h(c.$$.fragment),u=p(),I=g("p"),I.innerHTML=W,R=p(),h(k.$$.fragment),v=p(),$=g("p"),$.textContent=z,B=p(),h(b.$$.fragment),A=p(),Z=g("p"),Z.textContent=E,G=p(),h(U.$$.fragment)},l(t){a=T(t,"P",{"data-svelte-h":!0}),J(a)!=="svelte-1qcz1wr"&&(a.textContent=m),s=i(t),M(c.$$.fragment,t),u=i(t),I=T(t,"P",{"data-svelte-h":!0}),J(I)!=="svelte-f3g043"&&(I.innerHTML=W),R=i(t),M(k.$$.fragment,t),v=i(t),$=T(t,"P",{"data-svelte-h":!0}),J($)!=="svelte-v8itmt"&&($.textContent=z),B=i(t),M(b.$$.fragment,t),A=i(t),Z=T(t,"P",{"data-svelte-h":!0}),J(Z)!=="svelte-66bsyj"&&(Z.textContent=E),G=i(t),M(U.$$.fragment,t)},m(t,d){n(t,a,d),n(t,s,d),f(c,t,d),n(t,u,d),n(t,I,d),n(t,R,d),f(k,t,d),n(t,v,d),n(t,$,d),n(t,B,d),f(b,t,d),n(t,A,d),n(t,Z,d),n(t,G,d),f(U,t,d),x=!0},p:ee,i(t){x||(w(c.$$.fragment,t),w(k.$$.fragment,t),w(b.$$.fragment,t),w(U.$$.fragment,t),x=!0)},o(t){y(c.$$.fragment,t),y(k.$$.fragment,t),y(b.$$.fragment,t),y(U.$$.fragment,t),x=!1},d(t){t&&(l(a),l(s),l(u),l(I),l(R),l(v),l($),l(B),l(A),l(Z),l(G)),j(c,t),j(k,t),j(b,t),j(U,t)}}}function us(C){let a,m;return a=new xe({props:{$$slots:{default:[ds]},$$scope:{ctx:C}}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p(s,c){const u={};c&2&&(u.$$scope={dirty:c,ctx:s}),a.$set(u)},i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function hs(C){let a,m="Tokenize the text and return TensorFlow tensors:",s,c,u,I,W="Pass your inputs to the model and return the <code>logits</code>:",R,k,v,$,z="Get the highest probability from the model output for the start and end positions:",B,b,A,Z,E="Decode the predicted tokens to get the answer:",G,U,x;return c=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihxdWVzdGlvbiUyQyUyMHRleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(question, text, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),k=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmclMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmcuZnJvbV9wcmV0cmFpbmVkKCUyMm15X2F3ZXNvbWVfcWFfbW9kZWwlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)`,wrap:!1}}),b=new X({props:{code:"YW5zd2VyX3N0YXJ0X2luZGV4JTIwJTNEJTIwaW50KHRmLm1hdGguYXJnbWF4KG91dHB1dHMuc3RhcnRfbG9naXRzJTJDJTIwYXhpcyUzRC0xKSU1QjAlNUQpJTBBYW5zd2VyX2VuZF9pbmRleCUyMCUzRCUyMGludCh0Zi5tYXRoLmFyZ21heChvdXRwdXRzLmVuZF9sb2dpdHMlMkMlMjBheGlzJTNELTEpJTVCMCU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>answer_start_index = <span class="hljs-built_in">int</span>(tf.math.argmax(outputs.start_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>answer_end_index = <span class="hljs-built_in">int</span>(tf.math.argmax(outputs.end_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])`,wrap:!1}}),U=new X({props:{code:"cHJlZGljdF9hbnN3ZXJfdG9rZW5zJTIwJTNEJTIwaW5wdXRzLmlucHV0X2lkcyU1QjAlMkMlMjBhbnN3ZXJfc3RhcnRfaW5kZXglMjAlM0ElMjBhbnN3ZXJfZW5kX2luZGV4JTIwJTJCJTIwMSU1RCUwQXRva2VuaXplci5kZWNvZGUocHJlZGljdF9hbnN3ZXJfdG9rZW5zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predict_answer_tokens = inputs.input_ids[<span class="hljs-number">0</span>, answer_start_index : answer_end_index + <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predict_answer_tokens)
<span class="hljs-string">&#x27;176 billion parameters and can generate text in 46 languages natural languages and 13&#x27;</span>`,wrap:!1}}),{c(){a=g("p"),a.textContent=m,s=p(),h(c.$$.fragment),u=p(),I=g("p"),I.innerHTML=W,R=p(),h(k.$$.fragment),v=p(),$=g("p"),$.textContent=z,B=p(),h(b.$$.fragment),A=p(),Z=g("p"),Z.textContent=E,G=p(),h(U.$$.fragment)},l(t){a=T(t,"P",{"data-svelte-h":!0}),J(a)!=="svelte-s1qr7b"&&(a.textContent=m),s=i(t),M(c.$$.fragment,t),u=i(t),I=T(t,"P",{"data-svelte-h":!0}),J(I)!=="svelte-f3g043"&&(I.innerHTML=W),R=i(t),M(k.$$.fragment,t),v=i(t),$=T(t,"P",{"data-svelte-h":!0}),J($)!=="svelte-v8itmt"&&($.textContent=z),B=i(t),M(b.$$.fragment,t),A=i(t),Z=T(t,"P",{"data-svelte-h":!0}),J(Z)!=="svelte-66bsyj"&&(Z.textContent=E),G=i(t),M(U.$$.fragment,t)},m(t,d){n(t,a,d),n(t,s,d),f(c,t,d),n(t,u,d),n(t,I,d),n(t,R,d),f(k,t,d),n(t,v,d),n(t,$,d),n(t,B,d),f(b,t,d),n(t,A,d),n(t,Z,d),n(t,G,d),f(U,t,d),x=!0},p:ee,i(t){x||(w(c.$$.fragment,t),w(k.$$.fragment,t),w(b.$$.fragment,t),w(U.$$.fragment,t),x=!0)},o(t){y(c.$$.fragment,t),y(k.$$.fragment,t),y(b.$$.fragment,t),y(U.$$.fragment,t),x=!1},d(t){t&&(l(a),l(s),l(u),l(I),l(R),l(v),l($),l(B),l(A),l(Z),l(G)),j(c,t),j(k,t),j(b,t),j(U,t)}}}function Ms(C){let a,m;return a=new xe({props:{$$slots:{default:[hs]},$$scope:{ctx:C}}}),{c(){h(a.$$.fragment)},l(s){M(a.$$.fragment,s)},m(s,c){f(a,s,c),m=!0},p(s,c){const u={};c&2&&(u.$$scope={dirty:c,ctx:s}),a.$set(u)},i(s){m||(w(a.$$.fragment,s),m=!0)},o(s){y(a.$$.fragment,s),m=!1},d(s){j(a,s)}}}function fs(C){let a,m,s,c,u,I,W,R,k,v,$,z="Question answering tasks return an answer given a question. If you’ve ever asked a virtual assistant like Alexa, Siri or Google what the weather is, then you’ve used a question answering model before. There are two common types of question answering tasks:",B,b,A="<li>Extractive: extract the answer from the given context.</li> <li>Abstractive: generate an answer from the context that correctly answers the question.</li>",Z,E,G="This guide will show you how to:",U,x,t='<li>Finetune <a href="https://huggingface.co/distilbert/distilbert-base-uncased" rel="nofollow">DistilBERT</a> on the <a href="https://huggingface.co/datasets/squad" rel="nofollow">SQuAD</a> dataset for extractive question answering.</li> <li>Use your finetuned model for inference.</li>',d,V,q,F,Xe="Before you begin, make sure you have all the necessary libraries installed:",Y,N,L,H,ve="We encourage you to login to your Hugging Face account so you can upload and share your model with the community. When prompted, enter your token to login:",S,o,_,Q,Ae,te,gt="Start by loading a smaller subset of the SQuAD dataset from the 🤗 Datasets library. This’ll give you a chance to experiment and make sure everything works before spending more time training on the full dataset.",Ge,se,We,ae,Tt='Split the dataset’s <code>train</code> split into a train and test set with the <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.train_test_split" rel="nofollow">train_test_split</a> method:',Ee,le,Ve,ne,Jt="Then take a look at an example:",ze,re,Fe,oe,bt="There are several important fields here:",Ne,pe,$t="<li><code>answers</code>: the starting location of the answer token and the answer text.</li> <li><code>context</code>: background information from which the model needs to extract the answer.</li> <li><code>question</code>: the question a model should answer.</li>",He,ie,Qe,me,qe,ce,Ut="The next step is to load a DistilBERT tokenizer to process the <code>question</code> and <code>context</code> fields:",Ye,de,Le,ue,_t="There are a few preprocessing steps particular to question answering tasks you should be aware of:",Se,he,Ct=`<li>Some examples in a dataset may have a very long <code>context</code> that exceeds the maximum input length of the model. To deal with longer sequences, truncate only the <code>context</code> by setting <code>truncation=&quot;only_second&quot;</code>.</li> <li>Next, map the start and end positions of the answer to the original <code>context</code> by setting
<code>return_offset_mapping=True</code>.</li> <li>With the mapping in hand, now you can find the start and end tokens of the answer. Use the <a href="https://huggingface.co/docs/tokenizers/main/en/api/encoding#tokenizers.Encoding.sequence_ids" rel="nofollow">sequence_ids</a> method to
find which part of the offset corresponds to the <code>question</code> and which corresponds to the <code>context</code>.</li>`,De,Me,It="Here is how you can create a function to truncate and map the start and end tokens of the <code>answer</code> to the <code>context</code>:",Pe,fe,Ke,we,kt='To apply the preprocessing function over the entire dataset, use 🤗 Datasets <a href="https://huggingface.co/docs/datasets/main/en/package_reference/main_classes#datasets.Dataset.map" rel="nofollow">map</a> function. You can speed up the <code>map</code> function by setting <code>batched=True</code> to process multiple elements of the dataset at once. Remove any columns you don’t need:',Oe,ye,et,je,Zt='Now create a batch of examples using <a href="/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator">DefaultDataCollator</a>. Unlike other data collators in 🤗 Transformers, the <a href="/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator">DefaultDataCollator</a> does not apply any additional preprocessing such as padding.',tt,D,st,ge,at,P,lt,K,nt,Te,rt,Je,Rt='Evaluation for question answering requires a significant amount of postprocessing. To avoid taking up too much of your time, this guide skips the evaluation step. The <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> still calculates the evaluation loss during training so you’re not completely in the dark about your model’s performance.',ot,be,xt='If have more time and you’re interested in how to evaluate your model for question answering, take a look at the <a href="https://huggingface.co/course/chapter7/7?fw=pt#postprocessing" rel="nofollow">Question answering</a> chapter from the 🤗 Hugging Face Course!',pt,$e,it,Ue,Xt="Great, now that you’ve finetuned a model, you can use it for inference!",mt,_e,vt="Come up with a question and some context you’d like the model to predict:",ct,Ce,dt,Ie,Bt='The simplest way to try out your finetuned model for inference is to use it in a <a href="/docs/transformers/main/en/main_classes/pipelines#transformers.pipeline">pipeline()</a>. Instantiate a <code>pipeline</code> for question answering with your model, and pass your text to it:',ut,ke,ht,Ze,At="You can also manually replicate the results of the <code>pipeline</code> if you’d like:",Mt,O,ft,Be,wt;return u=new Re({props:{title:"Question answering",local:"question-answering",headingTag:"h1"}}),W=new Ot({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/question_answering.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/question_answering.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/question_answering.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/question_answering.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/pytorch/question_answering.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/en/tensorflow/question_answering.ipynb"}]}}),k=new Ht({props:{id:"ajPx5LwJD-I"}}),V=new yt({props:{$$slots:{default:[es]},$$scope:{ctx:C}}}),N=new X({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),o=new X({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),Q=new Re({props:{title:"Load SQuAD dataset",local:"load-squad-dataset",headingTag:"h2"}}),se=new X({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBc3F1YWQlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyc3F1YWQlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTVCJTNBNTAwMCU1RCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>squad = load_dataset(<span class="hljs-string">&quot;squad&quot;</span>, split=<span class="hljs-string">&quot;train[:5000]&quot;</span>)`,wrap:!1}}),le=new X({props:{code:"c3F1YWQlMjAlM0QlMjBzcXVhZC50cmFpbl90ZXN0X3NwbGl0KHRlc3Rfc2l6ZSUzRDAuMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>squad = squad.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),re=new X({props:{code:"c3F1YWQlNUIlMjJ0cmFpbiUyMiU1RCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>squad[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers&#x27;</span>: {<span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">515</span>], <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Saint Bernadette Soubirous&#x27;</span>]},
 <span class="hljs-string">&#x27;context&#x27;</span>: <span class="hljs-string">&#x27;Architecturally, the school has a Catholic character. Atop the Main Building\\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot;Venite Ad Me Omnes&quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.&#x27;</span>,
 <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;5733be284776f41900661182&#x27;</span>,
 <span class="hljs-string">&#x27;question&#x27;</span>: <span class="hljs-string">&#x27;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;University_of_Notre_Dame&#x27;</span>
}`,wrap:!1}}),ie=new Re({props:{title:"Preprocess",local:"preprocess",headingTag:"h2"}}),me=new Ht({props:{id:"qgaM0weJHpA"}}),de=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),fe=new X({props:{code:"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",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    questions = [q.strip() <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;question&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = tokenizer(
<span class="hljs-meta">... </span>        questions,
<span class="hljs-meta">... </span>        examples[<span class="hljs-string">&quot;context&quot;</span>],
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">384</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
<span class="hljs-meta">... </span>        return_offsets_mapping=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-string">&quot;max_length&quot;</span>,
<span class="hljs-meta">... </span>    )

<span class="hljs-meta">... </span>    offset_mapping = inputs.pop(<span class="hljs-string">&quot;offset_mapping&quot;</span>)
<span class="hljs-meta">... </span>    answers = examples[<span class="hljs-string">&quot;answers&quot;</span>]
<span class="hljs-meta">... </span>    start_positions = []
<span class="hljs-meta">... </span>    end_positions = []

<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, offset <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(offset_mapping):
<span class="hljs-meta">... </span>        answer = answers[i]
<span class="hljs-meta">... </span>        start_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>        end_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>] + <span class="hljs-built_in">len</span>(answer[<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>])
<span class="hljs-meta">... </span>        sequence_ids = inputs.sequence_ids(i)

<span class="hljs-meta">... </span>        <span class="hljs-comment"># Find the start and end of the context</span>
<span class="hljs-meta">... </span>        idx = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>        <span class="hljs-keyword">while</span> sequence_ids[idx] != <span class="hljs-number">1</span>:
<span class="hljs-meta">... </span>            idx += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>        context_start = idx
<span class="hljs-meta">... </span>        <span class="hljs-keyword">while</span> sequence_ids[idx] == <span class="hljs-number">1</span>:
<span class="hljs-meta">... </span>            idx += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>        context_end = idx - <span class="hljs-number">1</span>

<span class="hljs-meta">... </span>        <span class="hljs-comment"># If the answer is not fully inside the context, label it (0, 0)</span>
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> offset[context_start][<span class="hljs-number">0</span>] &gt; end_char <span class="hljs-keyword">or</span> offset[context_end][<span class="hljs-number">1</span>] &lt; start_char:
<span class="hljs-meta">... </span>            start_positions.append(<span class="hljs-number">0</span>)
<span class="hljs-meta">... </span>            end_positions.append(<span class="hljs-number">0</span>)
<span class="hljs-meta">... </span>        <span class="hljs-keyword">else</span>:
<span class="hljs-meta">... </span>            <span class="hljs-comment"># Otherwise it&#x27;s the start and end token positions</span>
<span class="hljs-meta">... </span>            idx = context_start
<span class="hljs-meta">... </span>            <span class="hljs-keyword">while</span> idx &lt;= context_end <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">0</span>] &lt;= start_char:
<span class="hljs-meta">... </span>                idx += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>            start_positions.append(idx - <span class="hljs-number">1</span>)

<span class="hljs-meta">... </span>            idx = context_end
<span class="hljs-meta">... </span>            <span class="hljs-keyword">while</span> idx &gt;= context_start <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">1</span>] &gt;= end_char:
<span class="hljs-meta">... </span>                idx -= <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>            end_positions.append(idx + <span class="hljs-number">1</span>)

<span class="hljs-meta">... </span>    inputs[<span class="hljs-string">&quot;start_positions&quot;</span>] = start_positions
<span class="hljs-meta">... </span>    inputs[<span class="hljs-string">&quot;end_positions&quot;</span>] = end_positions
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`,wrap:!1}}),ye=new X({props:{code:"dG9rZW5pemVkX3NxdWFkJTIwJTNEJTIwc3F1YWQubWFwKHByZXByb2Nlc3NfZnVuY3Rpb24lMkMlMjBiYXRjaGVkJTNEVHJ1ZSUyQyUyMHJlbW92ZV9jb2x1bW5zJTNEc3F1YWQlNUIlMjJ0cmFpbiUyMiU1RC5jb2x1bW5fbmFtZXMp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_squad = squad.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>, remove_columns=squad[<span class="hljs-string">&quot;train&quot;</span>].column_names)',wrap:!1}}),D=new jt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ls],pytorch:[ss]},$$scope:{ctx:C}}}),ge=new Re({props:{title:"Train",local:"train",headingTag:"h2"}}),P=new jt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ms],pytorch:[os]},$$scope:{ctx:C}}}),K=new yt({props:{$$slots:{default:[cs]},$$scope:{ctx:C}}}),Te=new Re({props:{title:"Evaluate",local:"evaluate",headingTag:"h2"}}),$e=new Re({props:{title:"Inference",local:"inference",headingTag:"h2"}}),Ce=new X({props:{code:"cXVlc3Rpb24lMjAlM0QlMjAlMjJIb3clMjBtYW55JTIwcHJvZ3JhbW1pbmclMjBsYW5ndWFnZXMlMjBkb2VzJTIwQkxPT00lMjBzdXBwb3J0JTNGJTIyJTBBY29udGV4dCUyMCUzRCUyMCUyMkJMT09NJTIwaGFzJTIwMTc2JTIwYmlsbGlvbiUyMHBhcmFtZXRlcnMlMjBhbmQlMjBjYW4lMjBnZW5lcmF0ZSUyMHRleHQlMjBpbiUyMDQ2JTIwbGFuZ3VhZ2VzJTIwbmF0dXJhbCUyMGxhbmd1YWdlcyUyMGFuZCUyMDEzJTIwcHJvZ3JhbW1pbmclMjBsYW5ndWFnZXMuJTIy",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>question = <span class="hljs-string">&quot;How many programming languages does BLOOM support?&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>context = <span class="hljs-string">&quot;BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.&quot;</span>`,wrap:!1}}),ke=new X({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBcXVlc3Rpb25fYW5zd2VyZXIlMjAlM0QlMjBwaXBlbGluZSglMjJxdWVzdGlvbi1hbnN3ZXJpbmclMjIlMkMlMjBtb2RlbCUzRCUyMm15X2F3ZXNvbWVfcWFfbW9kZWwlMjIpJTBBcXVlc3Rpb25fYW5zd2VyZXIocXVlc3Rpb24lM0RxdWVzdGlvbiUyQyUyMGNvbnRleHQlM0Rjb250ZXh0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>question_answerer = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>question_answerer(question=question, context=context)
{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.2058267742395401</span>,
 <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">10</span>,
 <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">95</span>,
 <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;176 billion parameters and can generate text in 46 languages natural languages and 13&#x27;</span>}`,wrap:!1}}),O=new jt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Ms],pytorch:[us]},$$scope:{ctx:C}}}),{c(){a=g("meta"),m=p(),s=g("p"),c=p(),h(u.$$.fragment),I=p(),h(W.$$.fragment),R=p(),h(k.$$.fragment),v=p(),$=g("p"),$.textContent=z,B=p(),b=g("ul"),b.innerHTML=A,Z=p(),E=g("p"),E.textContent=G,U=p(),x=g("ol"),x.innerHTML=t,d=p(),h(V.$$.fragment),q=p(),F=g("p"),F.textContent=Xe,Y=p(),h(N.$$.fragment),L=p(),H=g("p"),H.textContent=ve,S=p(),h(o.$$.fragment),_=p(),h(Q.$$.fragment),Ae=p(),te=g("p"),te.textContent=gt,Ge=p(),h(se.$$.fragment),We=p(),ae=g("p"),ae.innerHTML=Tt,Ee=p(),h(le.$$.fragment),Ve=p(),ne=g("p"),ne.textContent=Jt,ze=p(),h(re.$$.fragment),Fe=p(),oe=g("p"),oe.textContent=bt,Ne=p(),pe=g("ul"),pe.innerHTML=$t,He=p(),h(ie.$$.fragment),Qe=p(),h(me.$$.fragment),qe=p(),ce=g("p"),ce.innerHTML=Ut,Ye=p(),h(de.$$.fragment),Le=p(),ue=g("p"),ue.textContent=_t,Se=p(),he=g("ol"),he.innerHTML=Ct,De=p(),Me=g("p"),Me.innerHTML=It,Pe=p(),h(fe.$$.fragment),Ke=p(),we=g("p"),we.innerHTML=kt,Oe=p(),h(ye.$$.fragment),et=p(),je=g("p"),je.innerHTML=Zt,tt=p(),h(D.$$.fragment),st=p(),h(ge.$$.fragment),at=p(),h(P.$$.fragment),lt=p(),h(K.$$.fragment),nt=p(),h(Te.$$.fragment),rt=p(),Je=g("p"),Je.innerHTML=Rt,ot=p(),be=g("p"),be.innerHTML=xt,pt=p(),h($e.$$.fragment),it=p(),Ue=g("p"),Ue.textContent=Xt,mt=p(),_e=g("p"),_e.textContent=vt,ct=p(),h(Ce.$$.fragment),dt=p(),Ie=g("p"),Ie.innerHTML=Bt,ut=p(),h(ke.$$.fragment),ht=p(),Ze=g("p"),Ze.innerHTML=At,Mt=p(),h(O.$$.fragment),ft=p(),Be=g("p"),this.h()},l(e){const r=Pt("svelte-u9bgzb",document.head);a=T(r,"META",{name:!0,content:!0}),r.forEach(l),m=i(e),s=T(e,"P",{}),Ft(s).forEach(l),c=i(e),M(u.$$.fragment,e),I=i(e),M(W.$$.fragment,e),R=i(e),M(k.$$.fragment,e),v=i(e),$=T(e,"P",{"data-svelte-h":!0}),J($)!=="svelte-wddg3q"&&($.textContent=z),B=i(e),b=T(e,"UL",{"data-svelte-h":!0}),J(b)!=="svelte-juxaac"&&(b.innerHTML=A),Z=i(e),E=T(e,"P",{"data-svelte-h":!0}),J(E)!=="svelte-1aff4p7"&&(E.textContent=G),U=i(e),x=T(e,"OL",{"data-svelte-h":!0}),J(x)!=="svelte-1par97w"&&(x.innerHTML=t),d=i(e),M(V.$$.fragment,e),q=i(e),F=T(e,"P",{"data-svelte-h":!0}),J(F)!=="svelte-1c9nexd"&&(F.textContent=Xe),Y=i(e),M(N.$$.fragment,e),L=i(e),H=T(e,"P",{"data-svelte-h":!0}),J(H)!=="svelte-k76o1m"&&(H.textContent=ve),S=i(e),M(o.$$.fragment,e),_=i(e),M(Q.$$.fragment,e),Ae=i(e),te=T(e,"P",{"data-svelte-h":!0}),J(te)!=="svelte-86lsp1"&&(te.textContent=gt),Ge=i(e),M(se.$$.fragment,e),We=i(e),ae=T(e,"P",{"data-svelte-h":!0}),J(ae)!=="svelte-rugbz4"&&(ae.innerHTML=Tt),Ee=i(e),M(le.$$.fragment,e),Ve=i(e),ne=T(e,"P",{"data-svelte-h":!0}),J(ne)!=="svelte-1m91ua0"&&(ne.textContent=Jt),ze=i(e),M(re.$$.fragment,e),Fe=i(e),oe=T(e,"P",{"data-svelte-h":!0}),J(oe)!=="svelte-ixla8d"&&(oe.textContent=bt),Ne=i(e),pe=T(e,"UL",{"data-svelte-h":!0}),J(pe)!=="svelte-13sugm7"&&(pe.innerHTML=$t),He=i(e),M(ie.$$.fragment,e),Qe=i(e),M(me.$$.fragment,e),qe=i(e),ce=T(e,"P",{"data-svelte-h":!0}),J(ce)!=="svelte-1l87utj"&&(ce.innerHTML=Ut),Ye=i(e),M(de.$$.fragment,e),Le=i(e),ue=T(e,"P",{"data-svelte-h":!0}),J(ue)!=="svelte-6fi1jw"&&(ue.textContent=_t),Se=i(e),he=T(e,"OL",{"data-svelte-h":!0}),J(he)!=="svelte-twn3no"&&(he.innerHTML=Ct),De=i(e),Me=T(e,"P",{"data-svelte-h":!0}),J(Me)!=="svelte-1l18kqg"&&(Me.innerHTML=It),Pe=i(e),M(fe.$$.fragment,e),Ke=i(e),we=T(e,"P",{"data-svelte-h":!0}),J(we)!=="svelte-504s7j"&&(we.innerHTML=kt),Oe=i(e),M(ye.$$.fragment,e),et=i(e),je=T(e,"P",{"data-svelte-h":!0}),J(je)!=="svelte-1cisvfs"&&(je.innerHTML=Zt),tt=i(e),M(D.$$.fragment,e),st=i(e),M(ge.$$.fragment,e),at=i(e),M(P.$$.fragment,e),lt=i(e),M(K.$$.fragment,e),nt=i(e),M(Te.$$.fragment,e),rt=i(e),Je=T(e,"P",{"data-svelte-h":!0}),J(Je)!=="svelte-1nnb2lp"&&(Je.innerHTML=Rt),ot=i(e),be=T(e,"P",{"data-svelte-h":!0}),J(be)!=="svelte-ktob7c"&&(be.innerHTML=xt),pt=i(e),M($e.$$.fragment,e),it=i(e),Ue=T(e,"P",{"data-svelte-h":!0}),J(Ue)!=="svelte-633ppb"&&(Ue.textContent=Xt),mt=i(e),_e=T(e,"P",{"data-svelte-h":!0}),J(_e)!=="svelte-1wy7p4p"&&(_e.textContent=vt),ct=i(e),M(Ce.$$.fragment,e),dt=i(e),Ie=T(e,"P",{"data-svelte-h":!0}),J(Ie)!=="svelte-1pyk5cg"&&(Ie.innerHTML=Bt),ut=i(e),M(ke.$$.fragment,e),ht=i(e),Ze=T(e,"P",{"data-svelte-h":!0}),J(Ze)!=="svelte-1njl8vm"&&(Ze.innerHTML=At),Mt=i(e),M(O.$$.fragment,e),ft=i(e),Be=T(e,"P",{}),Ft(Be).forEach(l),this.h()},h(){Nt(a,"name","hf:doc:metadata"),Nt(a,"content",ws)},m(e,r){Kt(document.head,a),n(e,m,r),n(e,s,r),n(e,c,r),f(u,e,r),n(e,I,r),f(W,e,r),n(e,R,r),f(k,e,r),n(e,v,r),n(e,$,r),n(e,B,r),n(e,b,r),n(e,Z,r),n(e,E,r),n(e,U,r),n(e,x,r),n(e,d,r),f(V,e,r),n(e,q,r),n(e,F,r),n(e,Y,r),f(N,e,r),n(e,L,r),n(e,H,r),n(e,S,r),f(o,e,r),n(e,_,r),f(Q,e,r),n(e,Ae,r),n(e,te,r),n(e,Ge,r),f(se,e,r),n(e,We,r),n(e,ae,r),n(e,Ee,r),f(le,e,r),n(e,Ve,r),n(e,ne,r),n(e,ze,r),f(re,e,r),n(e,Fe,r),n(e,oe,r),n(e,Ne,r),n(e,pe,r),n(e,He,r),f(ie,e,r),n(e,Qe,r),f(me,e,r),n(e,qe,r),n(e,ce,r),n(e,Ye,r),f(de,e,r),n(e,Le,r),n(e,ue,r),n(e,Se,r),n(e,he,r),n(e,De,r),n(e,Me,r),n(e,Pe,r),f(fe,e,r),n(e,Ke,r),n(e,we,r),n(e,Oe,r),f(ye,e,r),n(e,et,r),n(e,je,r),n(e,tt,r),f(D,e,r),n(e,st,r),f(ge,e,r),n(e,at,r),f(P,e,r),n(e,lt,r),f(K,e,r),n(e,nt,r),f(Te,e,r),n(e,rt,r),n(e,Je,r),n(e,ot,r),n(e,be,r),n(e,pt,r),f($e,e,r),n(e,it,r),n(e,Ue,r),n(e,mt,r),n(e,_e,r),n(e,ct,r),f(Ce,e,r),n(e,dt,r),n(e,Ie,r),n(e,ut,r),f(ke,e,r),n(e,ht,r),n(e,Ze,r),n(e,Mt,r),f(O,e,r),n(e,ft,r),n(e,Be,r),wt=!0},p(e,[r]){const Gt={};r&2&&(Gt.$$scope={dirty:r,ctx:e}),V.$set(Gt);const Wt={};r&2&&(Wt.$$scope={dirty:r,ctx:e}),D.$set(Wt);const Et={};r&2&&(Et.$$scope={dirty:r,ctx:e}),P.$set(Et);const Vt={};r&2&&(Vt.$$scope={dirty:r,ctx:e}),K.$set(Vt);const zt={};r&2&&(zt.$$scope={dirty:r,ctx:e}),O.$set(zt)},i(e){wt||(w(u.$$.fragment,e),w(W.$$.fragment,e),w(k.$$.fragment,e),w(V.$$.fragment,e),w(N.$$.fragment,e),w(o.$$.fragment,e),w(Q.$$.fragment,e),w(se.$$.fragment,e),w(le.$$.fragment,e),w(re.$$.fragment,e),w(ie.$$.fragment,e),w(me.$$.fragment,e),w(de.$$.fragment,e),w(fe.$$.fragment,e),w(ye.$$.fragment,e),w(D.$$.fragment,e),w(ge.$$.fragment,e),w(P.$$.fragment,e),w(K.$$.fragment,e),w(Te.$$.fragment,e),w($e.$$.fragment,e),w(Ce.$$.fragment,e),w(ke.$$.fragment,e),w(O.$$.fragment,e),wt=!0)},o(e){y(u.$$.fragment,e),y(W.$$.fragment,e),y(k.$$.fragment,e),y(V.$$.fragment,e),y(N.$$.fragment,e),y(o.$$.fragment,e),y(Q.$$.fragment,e),y(se.$$.fragment,e),y(le.$$.fragment,e),y(re.$$.fragment,e),y(ie.$$.fragment,e),y(me.$$.fragment,e),y(de.$$.fragment,e),y(fe.$$.fragment,e),y(ye.$$.fragment,e),y(D.$$.fragment,e),y(ge.$$.fragment,e),y(P.$$.fragment,e),y(K.$$.fragment,e),y(Te.$$.fragment,e),y($e.$$.fragment,e),y(Ce.$$.fragment,e),y(ke.$$.fragment,e),y(O.$$.fragment,e),wt=!1},d(e){e&&(l(m),l(s),l(c),l(I),l(R),l(v),l($),l(B),l(b),l(Z),l(E),l(U),l(x),l(d),l(q),l(F),l(Y),l(L),l(H),l(S),l(_),l(Ae),l(te),l(Ge),l(We),l(ae),l(Ee),l(Ve),l(ne),l(ze),l(Fe),l(oe),l(Ne),l(pe),l(He),l(Qe),l(qe),l(ce),l(Ye),l(Le),l(ue),l(Se),l(he),l(De),l(Me),l(Pe),l(Ke),l(we),l(Oe),l(et),l(je),l(tt),l(st),l(at),l(lt),l(nt),l(rt),l(Je),l(ot),l(be),l(pt),l(it),l(Ue),l(mt),l(_e),l(ct),l(dt),l(Ie),l(ut),l(ht),l(Ze),l(Mt),l(ft),l(Be)),l(a),j(u,e),j(W,e),j(k,e),j(V,e),j(N,e),j(o,e),j(Q,e),j(se,e),j(le,e),j(re,e),j(ie,e),j(me,e),j(de,e),j(fe,e),j(ye,e),j(D,e),j(ge,e),j(P,e),j(K,e),j(Te,e),j($e,e),j(Ce,e),j(ke,e),j(O,e)}}}const ws='{"title":"Question answering","local":"question-answering","sections":[{"title":"Load SQuAD dataset","local":"load-squad-dataset","sections":[],"depth":2},{"title":"Preprocess","local":"preprocess","sections":[],"depth":2},{"title":"Train","local":"train","sections":[],"depth":2},{"title":"Evaluate","local":"evaluate","sections":[],"depth":2},{"title":"Inference","local":"inference","sections":[],"depth":2}],"depth":1}';function ys(C){return Lt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Cs extends St{constructor(a){super(),Dt(this,a,ys,fs,Yt,{})}}export{Cs as component};
