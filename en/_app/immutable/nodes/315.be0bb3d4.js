import{s as al,f as nl,o as sl,n as je}from"../chunks/scheduler.9bc65507.js";import{S as ol,i as rl,g as d,s as o,r as w,A as il,h as c,f as t,c as r,j as kt,u as y,x as $,k as R,y as ml,a,v as b,d as T,t as _,w as M}from"../chunks/index.707bf1b6.js";import{T as pl}from"../chunks/Tip.c2ecdbf4.js";import{Y as ul}from"../chunks/Youtube.e1129c6f.js";import{C as F}from"../chunks/CodeBlock.54a9f38d.js";import{F as ll,M as Ze}from"../chunks/Markdown.fef84341.js";import{H as G}from"../chunks/Heading.342b1fa6.js";function fl(C){let n,p='To share a model with the community, you need an account on <a href="https://huggingface.co/join" rel="nofollow">huggingface.co</a>. You can also join an existing organization or create a new one.';return{c(){n=d("p"),n.innerHTML=p},l(s){n=c(s,"P",{"data-svelte-h":!0}),$(n)!=="svelte-n70tme"&&(n.innerHTML=p)},m(s,i){a(s,n,i)},p:je,d(s){s&&t(n)}}}function dl(C){let n,p="Specify <code>from_tf=True</code> to convert a checkpoint from TensorFlow to PyTorch:",s,i,f;return i=new F({props:{code:"cHRfbW9kZWwlMjAlM0QlMjBEaXN0aWxCZXJ0Rm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIycGF0aCUyRnRvJTJGYXdlc29tZS1uYW1lLXlvdS1waWNrZWQlMjIlMkMlMjBmcm9tX3RmJTNEVHJ1ZSklMEFwdF9tb2RlbC5zYXZlX3ByZXRyYWluZWQoJTIycGF0aCUyRnRvJTJGYXdlc29tZS1uYW1lLXlvdS1waWNrZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = DistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>, from_tf=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>)`,wrap:!1}}),{c(){n=d("p"),n.innerHTML=p,s=o(),w(i.$$.fragment)},l(m){n=c(m,"P",{"data-svelte-h":!0}),$(n)!=="svelte-t2b4fg"&&(n.innerHTML=p),s=r(m),y(i.$$.fragment,m)},m(m,v){a(m,n,v),a(m,s,v),b(i,m,v),f=!0},p:je,i(m){f||(T(i.$$.fragment,m),f=!0)},o(m){_(i.$$.fragment,m),f=!1},d(m){m&&(t(n),t(s)),M(i,m)}}}function cl(C){let n,p;return n=new Ze({props:{$$slots:{default:[dl]},$$scope:{ctx:C}}}),{c(){w(n.$$.fragment)},l(s){y(n.$$.fragment,s)},m(s,i){b(n,s,i),p=!0},p(s,i){const f={};i&2&&(f.$$scope={dirty:i,ctx:s}),n.$set(f)},i(s){p||(T(n.$$.fragment,s),p=!0)},o(s){_(n.$$.fragment,s),p=!1},d(s){M(n,s)}}}function hl(C){let n,p="Specify <code>from_pt=True</code> to convert a checkpoint from PyTorch to TensorFlow:",s,i,f,m,v="Then you can save your new TensorFlow model with its new checkpoint:",W,H,Z;return i=new F({props:{code:"dGZfbW9kZWwlMjAlM0QlMjBURkRpc3RpbEJlcnRGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJwYXRoJTJGdG8lMkZhd2Vzb21lLW5hbWUteW91LXBpY2tlZCUyMiUyQyUyMGZyb21fcHQlM0RUcnVlKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFDistilBertForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>, from_pt=<span class="hljs-literal">True</span>)',wrap:!1}}),H=new F({props:{code:"dGZfbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKCUyMnBhdGglMkZ0byUyRmF3ZXNvbWUtbmFtZS15b3UtcGlja2VkJTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(<span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>)',wrap:!1}}),{c(){n=d("p"),n.innerHTML=p,s=o(),w(i.$$.fragment),f=o(),m=d("p"),m.textContent=v,W=o(),w(H.$$.fragment)},l(h){n=c(h,"P",{"data-svelte-h":!0}),$(n)!=="svelte-17l9qm6"&&(n.innerHTML=p),s=r(h),y(i.$$.fragment,h),f=r(h),m=c(h,"P",{"data-svelte-h":!0}),$(m)!=="svelte-4w3hzs"&&(m.textContent=v),W=r(h),y(H.$$.fragment,h)},m(h,k){a(h,n,k),a(h,s,k),b(i,h,k),a(h,f,k),a(h,m,k),a(h,W,k),b(H,h,k),Z=!0},p:je,i(h){Z||(T(i.$$.fragment,h),T(H.$$.fragment,h),Z=!0)},o(h){_(i.$$.fragment,h),_(H.$$.fragment,h),Z=!1},d(h){h&&(t(n),t(s),t(f),t(m),t(W)),M(i,h),M(H,h)}}}function $l(C){let n,p;return n=new Ze({props:{$$slots:{default:[hl]},$$scope:{ctx:C}}}),{c(){w(n.$$.fragment)},l(s){y(n.$$.fragment,s)},m(s,i){b(n,s,i),p=!0},p(s,i){const f={};i&2&&(f.$$scope={dirty:i,ctx:s}),n.$set(f)},i(s){p||(T(n.$$.fragment,s),p=!0)},o(s){_(n.$$.fragment,s),p=!1},d(s){M(n,s)}}}function gl(C){let n,p="If a model is available in Flax, you can also convert a checkpoint from PyTorch to Flax:",s,i,f;return i=new F({props:{code:"ZmxheF9tb2RlbCUyMCUzRCUyMEZsYXhEaXN0aWxCZXJ0Rm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIycGF0aCUyRnRvJTJGYXdlc29tZS1uYW1lLXlvdS1waWNrZWQlMjIlMkMlMjBmcm9tX3B0JTNEVHJ1ZSUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>flax_model = FlaxDistilBertForSequenceClassification.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;path/to/awesome-name-you-picked&quot;</span>, from_pt=<span class="hljs-literal">True</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){n=d("p"),n.textContent=p,s=o(),w(i.$$.fragment)},l(m){n=c(m,"P",{"data-svelte-h":!0}),$(n)!=="svelte-1wdqh65"&&(n.textContent=p),s=r(m),y(i.$$.fragment,m)},m(m,v){a(m,n,v),a(m,s,v),b(i,m,v),f=!0},p:je,i(m){f||(T(i.$$.fragment,m),f=!0)},o(m){_(i.$$.fragment,m),f=!1},d(m){m&&(t(n),t(s)),M(i,m)}}}function wl(C){let n,p;return n=new Ze({props:{$$slots:{default:[gl]},$$scope:{ctx:C}}}),{c(){w(n.$$.fragment)},l(s){y(n.$$.fragment,s)},m(s,i){b(n,s,i),p=!0},p(s,i){const f={};i&2&&(f.$$scope={dirty:i,ctx:s}),n.$set(f)},i(s){p||(T(n.$$.fragment,s),p=!0)},o(s){_(n.$$.fragment,s),p=!1},d(s){M(n,s)}}}function yl(C){let n,p,s,i='Sharing a model to the Hub is as simple as adding an extra parameter or callback. Remember from the <a href="training">fine-tuning tutorial</a>, the <a href="/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> class is where you specify hyperparameters and additional training options. One of these training options includes the ability to push a model directly to the Hub. Set <code>push_to_hub=True</code> in your <a href="/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>:',f,m,v,W,H='Pass your training arguments as usual to <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a>:',Z,h,k,x,g='After you fine-tune your model, call <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.push_to_hub">push_to_hub()</a> on <a href="/docs/transformers/main/en/main_classes/trainer#transformers.Trainer">Trainer</a> to push the trained model to the Hub. ðŸ¤— Transformers will even automatically add training hyperparameters, training results and framework versions to your model card!',L,j,I;return n=new ul({props:{id:"Z1-XMy-GNLQ"}}),m=new F({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKG91dHB1dF9kaXIlM0QlMjJteS1hd2Vzb21lLW1vZGVsJTIyJTJDJTIwcHVzaF90b19odWIlM0RUcnVlKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(output_dir=<span class="hljs-string">&quot;my-awesome-model&quot;</span>, push_to_hub=<span class="hljs-literal">True</span>)',wrap:!1}}),h=new F({props:{code:"dHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHNtYWxsX3RyYWluX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0RzbWFsbF9ldmFsX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBjb21wdXRlX21ldHJpY3MlM0Rjb21wdXRlX21ldHJpY3MlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=small_train_dataset,
<span class="hljs-meta">... </span>    eval_dataset=small_eval_dataset,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)`,wrap:!1}}),j=new F({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){w(n.$$.fragment),p=o(),s=d("p"),s.innerHTML=i,f=o(),w(m.$$.fragment),v=o(),W=d("p"),W.innerHTML=H,Z=o(),w(h.$$.fragment),k=o(),x=d("p"),x.innerHTML=g,L=o(),w(j.$$.fragment)},l(u){y(n.$$.fragment,u),p=r(u),s=c(u,"P",{"data-svelte-h":!0}),$(s)!=="svelte-56vvq1"&&(s.innerHTML=i),f=r(u),y(m.$$.fragment,u),v=r(u),W=c(u,"P",{"data-svelte-h":!0}),$(W)!=="svelte-uafryp"&&(W.innerHTML=H),Z=r(u),y(h.$$.fragment,u),k=r(u),x=c(u,"P",{"data-svelte-h":!0}),$(x)!=="svelte-f2cbnp"&&(x.innerHTML=g),L=r(u),y(j.$$.fragment,u)},m(u,J){b(n,u,J),a(u,p,J),a(u,s,J),a(u,f,J),b(m,u,J),a(u,v,J),a(u,W,J),a(u,Z,J),b(h,u,J),a(u,k,J),a(u,x,J),a(u,L,J),b(j,u,J),I=!0},p:je,i(u){I||(T(n.$$.fragment,u),T(m.$$.fragment,u),T(h.$$.fragment,u),T(j.$$.fragment,u),I=!0)},o(u){_(n.$$.fragment,u),_(m.$$.fragment,u),_(h.$$.fragment,u),_(j.$$.fragment,u),I=!1},d(u){u&&(t(p),t(s),t(f),t(v),t(W),t(Z),t(k),t(x),t(L)),M(n,u),M(m,u),M(h,u),M(j,u)}}}function bl(C){let n,p;return n=new Ze({props:{$$slots:{default:[yl]},$$scope:{ctx:C}}}),{c(){w(n.$$.fragment)},l(s){y(n.$$.fragment,s)},m(s,i){b(n,s,i),p=!0},p(s,i){const f={};i&2&&(f.$$scope={dirty:i,ctx:s}),n.$set(f)},i(s){p||(T(n.$$.fragment,s),p=!0)},o(s){_(n.$$.fragment,s),p=!1},d(s){M(n,s)}}}function Tl(C){let n,p='Share a model to the Hub with <a href="/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a>. In the <a href="/docs/transformers/main/en/main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a> function, add:',s,i,f="<li>An output directory for your model.</li> <li>A tokenizer.</li> <li>The <code>hub_model_id</code>, which is your Hub username and model name.</li>",m,v,W,H,Z='Add the callback to <a href="https://keras.io/api/models/model_training_apis/" rel="nofollow"><code>fit</code></a>, and ðŸ¤— Transformers will push the trained model to the Hub:',h,k,x;return v=new F({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFB1c2hUb0h1YkNhbGxiYWNrJTBBJTBBcHVzaF90b19odWJfY2FsbGJhY2slMjAlM0QlMjBQdXNoVG9IdWJDYWxsYmFjayglMEElMjAlMjAlMjAlMjBvdXRwdXRfZGlyJTNEJTIyLiUyRnlvdXJfbW9kZWxfc2F2ZV9wYXRoJTIyJTJDJTIwdG9rZW5pemVyJTNEdG9rZW5pemVyJTJDJTIwaHViX21vZGVsX2lkJTNEJTIyeW91ci11c2VybmFtZSUyRm15LWF3ZXNvbWUtbW9kZWwlMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>push_to_hub_callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;./your_model_save_path&quot;</span>, tokenizer=tokenizer, hub_model_id=<span class="hljs-string">&quot;your-username/my-awesome-model&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),k=new F({props:{code:"bW9kZWwuZml0KHRmX3RyYWluX2RhdGFzZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl92YWxpZGF0aW9uX2RhdGFzZXQlMkMlMjBlcG9jaHMlM0QzJTJDJTIwY2FsbGJhY2tzJTNEcHVzaF90b19odWJfY2FsbGJhY2sp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=<span class="hljs-number">3</span>, callbacks=push_to_hub_callback)',wrap:!1}}),{c(){n=d("p"),n.innerHTML=p,s=o(),i=d("ul"),i.innerHTML=f,m=o(),w(v.$$.fragment),W=o(),H=d("p"),H.innerHTML=Z,h=o(),w(k.$$.fragment)},l(g){n=c(g,"P",{"data-svelte-h":!0}),$(n)!=="svelte-13qdlrx"&&(n.innerHTML=p),s=r(g),i=c(g,"UL",{"data-svelte-h":!0}),$(i)!=="svelte-165fubm"&&(i.innerHTML=f),m=r(g),y(v.$$.fragment,g),W=r(g),H=c(g,"P",{"data-svelte-h":!0}),$(H)!=="svelte-1f8ao70"&&(H.innerHTML=Z),h=r(g),y(k.$$.fragment,g)},m(g,L){a(g,n,L),a(g,s,L),a(g,i,L),a(g,m,L),b(v,g,L),a(g,W,L),a(g,H,L),a(g,h,L),b(k,g,L),x=!0},p:je,i(g){x||(T(v.$$.fragment,g),T(k.$$.fragment,g),x=!0)},o(g){_(v.$$.fragment,g),_(k.$$.fragment,g),x=!1},d(g){g&&(t(n),t(s),t(i),t(m),t(W),t(H),t(h)),M(v,g),M(k,g)}}}function _l(C){let n,p;return n=new Ze({props:{$$slots:{default:[Tl]},$$scope:{ctx:C}}}),{c(){w(n.$$.fragment)},l(s){y(n.$$.fragment,s)},m(s,i){b(n,s,i),p=!0},p(s,i){const f={};i&2&&(f.$$scope={dirty:i,ctx:s}),n.$set(f)},i(s){p||(T(n.$$.fragment,s),p=!0)},o(s){_(n.$$.fragment,s),p=!1},d(s){M(n,s)}}}function Ml(C){let n,p,s,i,f,m,v,W="The last two tutorials showed how you can fine-tune a model with PyTorch, Keras, and ðŸ¤— Accelerate for distributed setups. The next step is to share your model with the community! At Hugging Face, we believe in openly sharing knowledge and resources to democratize artificial intelligence for everyone. We encourage you to consider sharing your model with the community to help others save time and resources.",H,Z,h='In this tutorial, you will learn two methods for sharing a trained or fine-tuned model on the <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>:',k,x,g="<li>Programmatically push your files to the Hub.</li> <li>Drag-and-drop your files to the Hub with the web interface.</li>",L,j,I,u,J,xe,P,Le,Y,Ht="Each repository on the Model Hub behaves like a typical GitHub repository. Our repositories offer versioning, commit history, and the ability to visualize differences.",Fe,z,Jt='The Model Hubâ€™s built-in versioning is based on git and <a href="https://git-lfs.github.com/" rel="nofollow">git-lfs</a>. In other words, you can treat one model as one repository, enabling greater access control and scalability. Version control allows <em>revisions</em>, a method for pinning a specific version of a model with a commit hash, tag or branch.',Ue,V,Ct="As a result, you can load a specific model version with the <code>revision</code> parameter:",Xe,S,Re,q,jt="Files are also easily edited in a repository, and you can view the commit history as well as the difference:",Ge,B,Wt='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/vis_diff.png" alt="vis_diff"/>',Ie,E,Pe,Q,Zt="Before sharing a model to the Hub, you will need your Hugging Face credentials. If you have access to a terminal, run the following command in the virtual environment where ðŸ¤— Transformers is installed. This will store your access token in your Hugging Face cache folder (<code>~/.cache/</code> by default):",Ye,A,ze,N,xt='If you are using a notebook like Jupyter or Colaboratory, make sure you have the <a href="https://huggingface.co/docs/hub/adding-a-library" rel="nofollow"><code>huggingface_hub</code></a> library installed. This library allows you to programmatically interact with the Hub.',Ve,D,Se,K,Lt='Then use <code>notebook_login</code> to sign-in to the Hub, and follow the link <a href="https://huggingface.co/settings/token" rel="nofollow">here</a> to generate a token to login with:',qe,O,Be,ee,Ee,te,Ft="To ensure your model can be used by someone working with a different framework, we recommend you convert and upload your model with both PyTorch and TensorFlow checkpoints. While users are still able to load your model from a different framework if you skip this step, it will be slower because ðŸ¤— Transformers will need to convert the checkpoint on-the-fly.",Qe,le,Ut='Converting a checkpoint for another framework is easy. Make sure you have PyTorch and TensorFlow installed (see <a href="installation">here</a> for installation instructions), and then find the specific model for your task in the other framework.',Ae,U,Ne,ae,De,X,Ke,ne,Oe,se,Xt="You can also call <code>push_to_hub</code> directly on your model to upload it to the Hub.",et,oe,Rt="Specify your model name in <code>push_to_hub</code>:",tt,re,lt,ie,Gt="This creates a repository under your username with the model name <code>my-awesome-model</code>. Users can now load your model with the <code>from_pretrained</code> function:",at,me,nt,pe,It="If you belong to an organization and want to push your model under the organization name instead, just add it to the <code>repo_id</code>:",st,ue,ot,fe,Pt="The <code>push_to_hub</code> function can also be used to add other files to a model repository. For example, add a tokenizer to a model repository:",rt,de,it,ce,Yt="Or perhaps youâ€™d like to add the TensorFlow version of your fine-tuned PyTorch model:",mt,he,pt,$e,zt="Now when you navigate to your Hugging Face profile, you should see your newly created model repository. Clicking on the <strong>Files</strong> tab will display all the files youâ€™ve uploaded to the repository.",ut,ge,Vt='For more details on how to create and upload files to a repository, refer to the Hub documentation <a href="https://huggingface.co/docs/hub/how-to-upstream" rel="nofollow">here</a>.',ft,we,dt,ye,St='Users who prefer a no-code approach are able to upload a model through the Hubâ€™s web interface. Visit <a href="https://huggingface.co/new" rel="nofollow">huggingface.co/new</a> to create a new repository:',ct,be,qt='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/new_model_repo.png" alt="new_model_repo"/>',ht,Te,Bt="From here, add some information about your model:",$t,_e,Et="<li>Select the <strong>owner</strong> of the repository. This can be yourself or any of the organizations you belong to.</li> <li>Pick a name for your model, which will also be the repository name.</li> <li>Choose whether your model is public or private.</li> <li>Specify the license usage for your model.</li>",gt,Me,Qt="Now click on the <strong>Files</strong> tab and click on the <strong>Add file</strong> button to upload a new file to your repository. Then drag-and-drop a file to upload and add a commit message.",wt,ve,At='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/upload_file.png" alt="upload_file"/>',yt,ke,bt,He,Nt="To make sure users understand your modelâ€™s capabilities, limitations, potential biases and ethical considerations, please add a model card to your repository. The model card is defined in the <code>README.md</code> file. You can add a model card by:",Tt,Je,Dt="<li>Manually creating and uploading a <code>README.md</code> file.</li> <li>Clicking on the <strong>Edit model card</strong> button in your model repository.</li>",_t,Ce,Kt='Take a look at the DistilBert <a href="https://huggingface.co/distilbert/distilbert-base-uncased" rel="nofollow">model card</a> for a good example of the type of information a model card should include. For more details about other options you can control in the <code>README.md</code> file such as a modelâ€™s carbon footprint or widget examples, refer to the documentation <a href="https://huggingface.co/docs/hub/models-cards" rel="nofollow">here</a>.',Mt,We,vt;return f=new G({props:{title:"Share a model",local:"share-a-model",headingTag:"h1"}}),J=new pl({props:{$$slots:{default:[fl]},$$scope:{ctx:C}}}),P=new G({props:{title:"Repository features",local:"repository-features",headingTag:"h2"}}),S=new F({props:{code:"bW9kZWwlMjAlM0QlMjBBdXRvTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMCUyMmp1bGllbi1jJTJGRXNwZXJCRVJUby1zbWFsbCUyMiUyQyUyMHJldmlzaW9uJTNEJTIydjIuMC4xJTIyJTIwJTIwJTIzJTIwdGFnJTIwbmFtZSUyQyUyMG9yJTIwYnJhbmNoJTIwbmFtZSUyQyUyMG9yJTIwY29tbWl0JTIwaGFzaCUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;julien-c/EsperBERTo-small&quot;</span>, revision=<span class="hljs-string">&quot;v2.0.1&quot;</span>  <span class="hljs-comment"># tag name, or branch name, or commit hash</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),E=new G({props:{title:"Setup",local:"setup",headingTag:"h2"}}),A=new F({props:{code:"aHVnZ2luZ2ZhY2UtY2xpJTIwbG9naW4=",highlighted:"huggingface-cli login",wrap:!1}}),D=new F({props:{code:"cGlwJTIwaW5zdGFsbCUyMGh1Z2dpbmdmYWNlX2h1Yg==",highlighted:"pip install huggingface_hub",wrap:!1}}),O=new F({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),ee=new G({props:{title:"Convert a model for all frameworks",local:"convert-a-model-for-all-frameworks",headingTag:"h2"}}),U=new ll({props:{pytorch:!0,tensorflow:!0,jax:!0,$$slots:{jax:[wl],tensorflow:[$l],pytorch:[cl]},$$scope:{ctx:C}}}),ae=new G({props:{title:"Push a model during training",local:"push-a-model-during-training",headingTag:"h2"}}),X=new ll({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[_l],pytorch:[bl]},$$scope:{ctx:C}}}),ne=new G({props:{title:"Use the push_to_hub function",local:"use-the-pushtohub-function",headingTag:"h2"}}),re=new F({props:{code:"cHRfbW9kZWwucHVzaF90b19odWIoJTIybXktYXdlc29tZS1tb2RlbCUyMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)',wrap:!1}}),me=new F({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsLmZyb21fcHJldHJhaW5lZCglMjJ5b3VyX3VzZXJuYW1lJTJGbXktYXdlc29tZS1tb2RlbCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModel.from_pretrained(<span class="hljs-string">&quot;your_username/my-awesome-model&quot;</span>)`,wrap:!1}}),ue=new F({props:{code:"cHRfbW9kZWwucHVzaF90b19odWIoJTIybXktYXdlc29tZS1vcmclMkZteS1hd2Vzb21lLW1vZGVsJTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.push_to_hub(<span class="hljs-string">&quot;my-awesome-org/my-awesome-model&quot;</span>)',wrap:!1}}),de=new F({props:{code:"dG9rZW5pemVyLnB1c2hfdG9faHViKCUyMm15LWF3ZXNvbWUtbW9kZWwlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)',wrap:!1}}),he=new F({props:{code:"dGZfbW9kZWwucHVzaF90b19odWIoJTIybXktYXdlc29tZS1tb2RlbCUyMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.push_to_hub(<span class="hljs-string">&quot;my-awesome-model&quot;</span>)',wrap:!1}}),we=new G({props:{title:"Upload with the web interface",local:"upload-with-the-web-interface",headingTag:"h2"}}),ke=new G({props:{title:"Add a model card",local:"add-a-model-card",headingTag:"h2"}}),{c(){n=d("meta"),p=o(),s=d("p"),i=o(),w(f.$$.fragment),m=o(),v=d("p"),v.textContent=W,H=o(),Z=d("p"),Z.innerHTML=h,k=o(),x=d("ul"),x.innerHTML=g,L=o(),j=d("iframe"),u=o(),w(J.$$.fragment),xe=o(),w(P.$$.fragment),Le=o(),Y=d("p"),Y.textContent=Ht,Fe=o(),z=d("p"),z.innerHTML=Jt,Ue=o(),V=d("p"),V.innerHTML=Ct,Xe=o(),w(S.$$.fragment),Re=o(),q=d("p"),q.textContent=jt,Ge=o(),B=d("p"),B.innerHTML=Wt,Ie=o(),w(E.$$.fragment),Pe=o(),Q=d("p"),Q.innerHTML=Zt,Ye=o(),w(A.$$.fragment),ze=o(),N=d("p"),N.innerHTML=xt,Ve=o(),w(D.$$.fragment),Se=o(),K=d("p"),K.innerHTML=Lt,qe=o(),w(O.$$.fragment),Be=o(),w(ee.$$.fragment),Ee=o(),te=d("p"),te.textContent=Ft,Qe=o(),le=d("p"),le.innerHTML=Ut,Ae=o(),w(U.$$.fragment),Ne=o(),w(ae.$$.fragment),De=o(),w(X.$$.fragment),Ke=o(),w(ne.$$.fragment),Oe=o(),se=d("p"),se.innerHTML=Xt,et=o(),oe=d("p"),oe.innerHTML=Rt,tt=o(),w(re.$$.fragment),lt=o(),ie=d("p"),ie.innerHTML=Gt,at=o(),w(me.$$.fragment),nt=o(),pe=d("p"),pe.innerHTML=It,st=o(),w(ue.$$.fragment),ot=o(),fe=d("p"),fe.innerHTML=Pt,rt=o(),w(de.$$.fragment),it=o(),ce=d("p"),ce.textContent=Yt,mt=o(),w(he.$$.fragment),pt=o(),$e=d("p"),$e.innerHTML=zt,ut=o(),ge=d("p"),ge.innerHTML=Vt,ft=o(),w(we.$$.fragment),dt=o(),ye=d("p"),ye.innerHTML=St,ct=o(),be=d("p"),be.innerHTML=qt,ht=o(),Te=d("p"),Te.textContent=Bt,$t=o(),_e=d("ul"),_e.innerHTML=Et,gt=o(),Me=d("p"),Me.innerHTML=Qt,wt=o(),ve=d("p"),ve.innerHTML=At,yt=o(),w(ke.$$.fragment),bt=o(),He=d("p"),He.innerHTML=Nt,Tt=o(),Je=d("ul"),Je.innerHTML=Dt,_t=o(),Ce=d("p"),Ce.innerHTML=Kt,Mt=o(),We=d("p"),this.h()},l(e){const l=il("svelte-u9bgzb",document.head);n=c(l,"META",{name:!0,content:!0}),l.forEach(t),p=r(e),s=c(e,"P",{}),kt(s).forEach(t),i=r(e),y(f.$$.fragment,e),m=r(e),v=c(e,"P",{"data-svelte-h":!0}),$(v)!=="svelte-15mf9cm"&&(v.textContent=W),H=r(e),Z=c(e,"P",{"data-svelte-h":!0}),$(Z)!=="svelte-1oy12p9"&&(Z.innerHTML=h),k=r(e),x=c(e,"UL",{"data-svelte-h":!0}),$(x)!=="svelte-1yyi6js"&&(x.innerHTML=g),L=r(e),j=c(e,"IFRAME",{width:!0,height:!0,src:!0,title:!0,frameborder:!0,allow:!0}),kt(j).forEach(t),u=r(e),y(J.$$.fragment,e),xe=r(e),y(P.$$.fragment,e),Le=r(e),Y=c(e,"P",{"data-svelte-h":!0}),$(Y)!=="svelte-1cn28ug"&&(Y.textContent=Ht),Fe=r(e),z=c(e,"P",{"data-svelte-h":!0}),$(z)!=="svelte-1ws64pt"&&(z.innerHTML=Jt),Ue=r(e),V=c(e,"P",{"data-svelte-h":!0}),$(V)!=="svelte-19e11vj"&&(V.innerHTML=Ct),Xe=r(e),y(S.$$.fragment,e),Re=r(e),q=c(e,"P",{"data-svelte-h":!0}),$(q)!=="svelte-1p8nvr9"&&(q.textContent=jt),Ge=r(e),B=c(e,"P",{"data-svelte-h":!0}),$(B)!=="svelte-hnu2bf"&&(B.innerHTML=Wt),Ie=r(e),y(E.$$.fragment,e),Pe=r(e),Q=c(e,"P",{"data-svelte-h":!0}),$(Q)!=="svelte-16kxv5p"&&(Q.innerHTML=Zt),Ye=r(e),y(A.$$.fragment,e),ze=r(e),N=c(e,"P",{"data-svelte-h":!0}),$(N)!=="svelte-tjzd4u"&&(N.innerHTML=xt),Ve=r(e),y(D.$$.fragment,e),Se=r(e),K=c(e,"P",{"data-svelte-h":!0}),$(K)!=="svelte-obyz8o"&&(K.innerHTML=Lt),qe=r(e),y(O.$$.fragment,e),Be=r(e),y(ee.$$.fragment,e),Ee=r(e),te=c(e,"P",{"data-svelte-h":!0}),$(te)!=="svelte-9ao4c4"&&(te.textContent=Ft),Qe=r(e),le=c(e,"P",{"data-svelte-h":!0}),$(le)!=="svelte-kq5z9m"&&(le.innerHTML=Ut),Ae=r(e),y(U.$$.fragment,e),Ne=r(e),y(ae.$$.fragment,e),De=r(e),y(X.$$.fragment,e),Ke=r(e),y(ne.$$.fragment,e),Oe=r(e),se=c(e,"P",{"data-svelte-h":!0}),$(se)!=="svelte-1ajv3us"&&(se.innerHTML=Xt),et=r(e),oe=c(e,"P",{"data-svelte-h":!0}),$(oe)!=="svelte-1k2vywi"&&(oe.innerHTML=Rt),tt=r(e),y(re.$$.fragment,e),lt=r(e),ie=c(e,"P",{"data-svelte-h":!0}),$(ie)!=="svelte-1t06m9y"&&(ie.innerHTML=Gt),at=r(e),y(me.$$.fragment,e),nt=r(e),pe=c(e,"P",{"data-svelte-h":!0}),$(pe)!=="svelte-mi63rk"&&(pe.innerHTML=It),st=r(e),y(ue.$$.fragment,e),ot=r(e),fe=c(e,"P",{"data-svelte-h":!0}),$(fe)!=="svelte-gpmj4u"&&(fe.innerHTML=Pt),rt=r(e),y(de.$$.fragment,e),it=r(e),ce=c(e,"P",{"data-svelte-h":!0}),$(ce)!=="svelte-zov16a"&&(ce.textContent=Yt),mt=r(e),y(he.$$.fragment,e),pt=r(e),$e=c(e,"P",{"data-svelte-h":!0}),$($e)!=="svelte-1j1dvvi"&&($e.innerHTML=zt),ut=r(e),ge=c(e,"P",{"data-svelte-h":!0}),$(ge)!=="svelte-1nvaa8l"&&(ge.innerHTML=Vt),ft=r(e),y(we.$$.fragment,e),dt=r(e),ye=c(e,"P",{"data-svelte-h":!0}),$(ye)!=="svelte-fcl9f1"&&(ye.innerHTML=St),ct=r(e),be=c(e,"P",{"data-svelte-h":!0}),$(be)!=="svelte-ahj3l9"&&(be.innerHTML=qt),ht=r(e),Te=c(e,"P",{"data-svelte-h":!0}),$(Te)!=="svelte-xicbqw"&&(Te.textContent=Bt),$t=r(e),_e=c(e,"UL",{"data-svelte-h":!0}),$(_e)!=="svelte-lokm6g"&&(_e.innerHTML=Et),gt=r(e),Me=c(e,"P",{"data-svelte-h":!0}),$(Me)!=="svelte-zmzt5c"&&(Me.innerHTML=Qt),wt=r(e),ve=c(e,"P",{"data-svelte-h":!0}),$(ve)!=="svelte-32sxm9"&&(ve.innerHTML=At),yt=r(e),y(ke.$$.fragment,e),bt=r(e),He=c(e,"P",{"data-svelte-h":!0}),$(He)!=="svelte-11tnibt"&&(He.innerHTML=Nt),Tt=r(e),Je=c(e,"UL",{"data-svelte-h":!0}),$(Je)!=="svelte-1rmq5mo"&&(Je.innerHTML=Dt),_t=r(e),Ce=c(e,"P",{"data-svelte-h":!0}),$(Ce)!=="svelte-y7wqhm"&&(Ce.innerHTML=Kt),Mt=r(e),We=c(e,"P",{}),kt(We).forEach(t),this.h()},h(){R(n,"name","hf:doc:metadata"),R(n,"content",vl),R(j,"width","560"),R(j,"height","315"),nl(j.src,I="https://www.youtube.com/embed/XvSGPZFEjDY")||R(j,"src",I),R(j,"title","YouTube video player"),R(j,"frameborder","0"),R(j,"allow",`accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
picture-in-picture`),j.allowFullscreen=""},m(e,l){ml(document.head,n),a(e,p,l),a(e,s,l),a(e,i,l),b(f,e,l),a(e,m,l),a(e,v,l),a(e,H,l),a(e,Z,l),a(e,k,l),a(e,x,l),a(e,L,l),a(e,j,l),a(e,u,l),b(J,e,l),a(e,xe,l),b(P,e,l),a(e,Le,l),a(e,Y,l),a(e,Fe,l),a(e,z,l),a(e,Ue,l),a(e,V,l),a(e,Xe,l),b(S,e,l),a(e,Re,l),a(e,q,l),a(e,Ge,l),a(e,B,l),a(e,Ie,l),b(E,e,l),a(e,Pe,l),a(e,Q,l),a(e,Ye,l),b(A,e,l),a(e,ze,l),a(e,N,l),a(e,Ve,l),b(D,e,l),a(e,Se,l),a(e,K,l),a(e,qe,l),b(O,e,l),a(e,Be,l),b(ee,e,l),a(e,Ee,l),a(e,te,l),a(e,Qe,l),a(e,le,l),a(e,Ae,l),b(U,e,l),a(e,Ne,l),b(ae,e,l),a(e,De,l),b(X,e,l),a(e,Ke,l),b(ne,e,l),a(e,Oe,l),a(e,se,l),a(e,et,l),a(e,oe,l),a(e,tt,l),b(re,e,l),a(e,lt,l),a(e,ie,l),a(e,at,l),b(me,e,l),a(e,nt,l),a(e,pe,l),a(e,st,l),b(ue,e,l),a(e,ot,l),a(e,fe,l),a(e,rt,l),b(de,e,l),a(e,it,l),a(e,ce,l),a(e,mt,l),b(he,e,l),a(e,pt,l),a(e,$e,l),a(e,ut,l),a(e,ge,l),a(e,ft,l),b(we,e,l),a(e,dt,l),a(e,ye,l),a(e,ct,l),a(e,be,l),a(e,ht,l),a(e,Te,l),a(e,$t,l),a(e,_e,l),a(e,gt,l),a(e,Me,l),a(e,wt,l),a(e,ve,l),a(e,yt,l),b(ke,e,l),a(e,bt,l),a(e,He,l),a(e,Tt,l),a(e,Je,l),a(e,_t,l),a(e,Ce,l),a(e,Mt,l),a(e,We,l),vt=!0},p(e,[l]){const Ot={};l&2&&(Ot.$$scope={dirty:l,ctx:e}),J.$set(Ot);const el={};l&2&&(el.$$scope={dirty:l,ctx:e}),U.$set(el);const tl={};l&2&&(tl.$$scope={dirty:l,ctx:e}),X.$set(tl)},i(e){vt||(T(f.$$.fragment,e),T(J.$$.fragment,e),T(P.$$.fragment,e),T(S.$$.fragment,e),T(E.$$.fragment,e),T(A.$$.fragment,e),T(D.$$.fragment,e),T(O.$$.fragment,e),T(ee.$$.fragment,e),T(U.$$.fragment,e),T(ae.$$.fragment,e),T(X.$$.fragment,e),T(ne.$$.fragment,e),T(re.$$.fragment,e),T(me.$$.fragment,e),T(ue.$$.fragment,e),T(de.$$.fragment,e),T(he.$$.fragment,e),T(we.$$.fragment,e),T(ke.$$.fragment,e),vt=!0)},o(e){_(f.$$.fragment,e),_(J.$$.fragment,e),_(P.$$.fragment,e),_(S.$$.fragment,e),_(E.$$.fragment,e),_(A.$$.fragment,e),_(D.$$.fragment,e),_(O.$$.fragment,e),_(ee.$$.fragment,e),_(U.$$.fragment,e),_(ae.$$.fragment,e),_(X.$$.fragment,e),_(ne.$$.fragment,e),_(re.$$.fragment,e),_(me.$$.fragment,e),_(ue.$$.fragment,e),_(de.$$.fragment,e),_(he.$$.fragment,e),_(we.$$.fragment,e),_(ke.$$.fragment,e),vt=!1},d(e){e&&(t(p),t(s),t(i),t(m),t(v),t(H),t(Z),t(k),t(x),t(L),t(j),t(u),t(xe),t(Le),t(Y),t(Fe),t(z),t(Ue),t(V),t(Xe),t(Re),t(q),t(Ge),t(B),t(Ie),t(Pe),t(Q),t(Ye),t(ze),t(N),t(Ve),t(Se),t(K),t(qe),t(Be),t(Ee),t(te),t(Qe),t(le),t(Ae),t(Ne),t(De),t(Ke),t(Oe),t(se),t(et),t(oe),t(tt),t(lt),t(ie),t(at),t(nt),t(pe),t(st),t(ot),t(fe),t(rt),t(it),t(ce),t(mt),t(pt),t($e),t(ut),t(ge),t(ft),t(dt),t(ye),t(ct),t(be),t(ht),t(Te),t($t),t(_e),t(gt),t(Me),t(wt),t(ve),t(yt),t(bt),t(He),t(Tt),t(Je),t(_t),t(Ce),t(Mt),t(We)),t(n),M(f,e),M(J,e),M(P,e),M(S,e),M(E,e),M(A,e),M(D,e),M(O,e),M(ee,e),M(U,e),M(ae,e),M(X,e),M(ne,e),M(re,e),M(me,e),M(ue,e),M(de,e),M(he,e),M(we,e),M(ke,e)}}}const vl='{"title":"Share a model","local":"share-a-model","sections":[{"title":"Repository features","local":"repository-features","sections":[],"depth":2},{"title":"Setup","local":"setup","sections":[],"depth":2},{"title":"Convert a model for all frameworks","local":"convert-a-model-for-all-frameworks","sections":[],"depth":2},{"title":"Push a model during training","local":"push-a-model-during-training","sections":[],"depth":2},{"title":"Use the push_to_hub function","local":"use-the-pushtohub-function","sections":[],"depth":2},{"title":"Upload with the web interface","local":"upload-with-the-web-interface","sections":[],"depth":2},{"title":"Add a model card","local":"add-a-model-card","sections":[],"depth":2}],"depth":1}';function kl(C){return sl(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ll extends ol{constructor(n){super(),rl(this,n,kl,Ml,al,{})}}export{Ll as component};
