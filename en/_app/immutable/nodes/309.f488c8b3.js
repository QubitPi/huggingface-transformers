import{s as D,o as Z,n as ee}from"../chunks/scheduler.9bc65507.js";import{S as te,i as ae,g as l,s as i,r as V,A as ne,h as p,f as a,c as s,j as Q,u as W,x as T,k as Y,y as oe,a as n,v as B,d as z,t as U,w as O}from"../chunks/index.707bf1b6.js";import{T as ie}from"../chunks/Tip.c2ecdbf4.js";import{H as j}from"../chunks/Heading.342b1fa6.js";function se(b){let o,f='XLS-R’s architecture is based on the Wav2Vec2 model, refer to <a href="wav2vec2">Wav2Vec2’s documentation page</a> for API reference.';return{c(){o=l("p"),o.innerHTML=f},l(r){o=p(r,"P",{"data-svelte-h":!0}),T(o)!=="svelte-bku3o"&&(o.innerHTML=f)},m(r,_){n(r,o,_)},p:ee,d(r){r&&a(o)}}}function re(b){let o,f,r,_,h,C,c,S,u,q=`The XLS-R model was proposed in <a href="https://arxiv.org/abs/2111.09296" rel="nofollow">XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale</a> by Arun Babu, Changhan Wang, Andros Tjandra, Kushal Lakhotia, Qiantong Xu, Naman
Goyal, Kritika Singh, Patrick von Platen, Yatharth Saraf, Juan Pino, Alexei Baevski, Alexis Conneau, Michael Auli.`,M,g,K="The abstract from the paper is the following:",P,v,F=`<em>This paper presents XLS-R, a large-scale model for cross-lingual speech representation learning based on wav2vec 2.0.
We train models with up to 2B parameters on nearly half a million hours of publicly available speech audio in 128
languages, an order of magnitude more public data than the largest known prior work. Our evaluation covers a wide range
of tasks, domains, data regimes and languages, both high and low-resource. On the CoVoST-2 speech translation
benchmark, we improve the previous state of the art by an average of 7.4 BLEU over 21 translation directions into
English. For speech recognition, XLS-R improves over the best known prior work on BABEL, MLS, CommonVoice as well as
VoxPopuli, lowering error rates by 14-34% relative on average. XLS-R also sets a new state of the art on VoxLingua107
language identification. Moreover, we show that with sufficient model size, cross-lingual pretraining can outperform
English-only pretraining when translating English speech into other languages, a setting which favors monolingual
pretraining. We hope XLS-R can help to improve speech processing tasks for many more languages of the world.</em>`,k,d,G='Relevant checkpoints can be found under <a href="https://huggingface.co/models?other=xls_r" rel="nofollow">https://huggingface.co/models?other=xls_r</a>.',y,w,I='The original code can be found <a href="https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec" rel="nofollow">here</a>.',H,$,R,L,J=`<li>XLS-R is a speech model that accepts a float array corresponding to the raw waveform of the speech signal.</li> <li>XLS-R model was trained using connectionist temporal classification (CTC) so the model output has to be decoded using
<a href="/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer">Wav2Vec2CTCTokenizer</a>.</li>`,X,m,A,x,E;return h=new j({props:{title:"XLS-R",local:"xls-r",headingTag:"h1"}}),c=new j({props:{title:"Overview",local:"overview",headingTag:"h2"}}),$=new j({props:{title:"Usage tips",local:"usage-tips",headingTag:"h2"}}),m=new ie({props:{$$slots:{default:[se]},$$scope:{ctx:b}}}),{c(){o=l("meta"),f=i(),r=l("p"),_=i(),V(h.$$.fragment),C=i(),V(c.$$.fragment),S=i(),u=l("p"),u.innerHTML=q,M=i(),g=l("p"),g.textContent=K,P=i(),v=l("p"),v.innerHTML=F,k=i(),d=l("p"),d.innerHTML=G,y=i(),w=l("p"),w.innerHTML=I,H=i(),V($.$$.fragment),R=i(),L=l("ul"),L.innerHTML=J,X=i(),V(m.$$.fragment),A=i(),x=l("p"),this.h()},l(e){const t=ne("svelte-u9bgzb",document.head);o=p(t,"META",{name:!0,content:!0}),t.forEach(a),f=s(e),r=p(e,"P",{}),Q(r).forEach(a),_=s(e),W(h.$$.fragment,e),C=s(e),W(c.$$.fragment,e),S=s(e),u=p(e,"P",{"data-svelte-h":!0}),T(u)!=="svelte-1nyy59j"&&(u.innerHTML=q),M=s(e),g=p(e,"P",{"data-svelte-h":!0}),T(g)!=="svelte-vfdo9a"&&(g.textContent=K),P=s(e),v=p(e,"P",{"data-svelte-h":!0}),T(v)!=="svelte-ul075o"&&(v.innerHTML=F),k=s(e),d=p(e,"P",{"data-svelte-h":!0}),T(d)!=="svelte-p0mu8e"&&(d.innerHTML=G),y=s(e),w=p(e,"P",{"data-svelte-h":!0}),T(w)!=="svelte-12gzw10"&&(w.innerHTML=I),H=s(e),W($.$$.fragment,e),R=s(e),L=p(e,"UL",{"data-svelte-h":!0}),T(L)!=="svelte-12sorrm"&&(L.innerHTML=J),X=s(e),W(m.$$.fragment,e),A=s(e),x=p(e,"P",{}),Q(x).forEach(a),this.h()},h(){Y(o,"name","hf:doc:metadata"),Y(o,"content",le)},m(e,t){oe(document.head,o),n(e,f,t),n(e,r,t),n(e,_,t),B(h,e,t),n(e,C,t),B(c,e,t),n(e,S,t),n(e,u,t),n(e,M,t),n(e,g,t),n(e,P,t),n(e,v,t),n(e,k,t),n(e,d,t),n(e,y,t),n(e,w,t),n(e,H,t),B($,e,t),n(e,R,t),n(e,L,t),n(e,X,t),B(m,e,t),n(e,A,t),n(e,x,t),E=!0},p(e,[t]){const N={};t&2&&(N.$$scope={dirty:t,ctx:e}),m.$set(N)},i(e){E||(z(h.$$.fragment,e),z(c.$$.fragment,e),z($.$$.fragment,e),z(m.$$.fragment,e),E=!0)},o(e){U(h.$$.fragment,e),U(c.$$.fragment,e),U($.$$.fragment,e),U(m.$$.fragment,e),E=!1},d(e){e&&(a(f),a(r),a(_),a(C),a(S),a(u),a(M),a(g),a(P),a(v),a(k),a(d),a(y),a(w),a(H),a(R),a(L),a(X),a(A),a(x)),a(o),O(h,e),O(c,e),O($,e),O(m,e)}}}const le='{"title":"XLS-R","local":"xls-r","sections":[{"title":"Overview","local":"overview","sections":[],"depth":2},{"title":"Usage tips","local":"usage-tips","sections":[],"depth":2}],"depth":1}';function pe(b){return Z(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ue extends te{constructor(o){super(),ae(this,o,pe,re,D,{})}}export{ue as component};
