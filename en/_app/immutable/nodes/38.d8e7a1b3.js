import{s as wa,o as xa,n as F}from"../chunks/scheduler.9bc65507.js";import{S as Aa,i as Ma,g as i,s as n,r as c,A as ka,h as m,f as o,c as r,j as w,u as g,x as _,k as x,y as t,a as d,v as u,d as f,t as h,w as $}from"../chunks/index.707bf1b6.js";import{T as jr}from"../chunks/Tip.c2ecdbf4.js";import{D as A}from"../chunks/Docstring.17db21ae.js";import{C as Lt}from"../chunks/CodeBlock.54a9f38d.js";import{E as jt}from"../chunks/ExampleCodeBlock.4f515aa9.js";import{H as P}from"../chunks/Heading.342b1fa6.js";function Ia(k){let l,T=`Transformers Agents is an experimental API which is subject to change at any time. Results returned by the agents
can vary as the APIs or underlying models are prone to change.`;return{c(){l=i("p"),l.textContent=T},l(b){l=m(b,"P",{"data-svelte-h":!0}),_(l)!=="svelte-1fgfei3"&&(l.textContent=T)},m(b,p){d(b,l,p)},p:F,d(b){b&&o(l)}}}function Ca(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEhmQWdlbnQlMEElMEFhZ2VudCUyMCUzRCUyMEhmQWdlbnQoJTIyaHR0cHMlM0ElMkYlMkZhcGktaW5mZXJlbmNlLmh1Z2dpbmdmYWNlLmNvJTJGbW9kZWxzJTJGYmlnY29kZSUyRnN0YXJjb2RlciUyMiklMEFhZ2VudC5ydW4oJTIySXMlMjB0aGUlMjBmb2xsb3dpbmclMjAlNjB0ZXh0JTYwJTIwKGluJTIwU3BhbmlzaCklMjBwb3NpdGl2ZSUyMG9yJTIwbmVnYXRpdmUlM0YlMjIlMkMlMjB0ZXh0JTNEJTIyJUMyJUExRXN0ZSUyMGVzJTIwdW4lMjBBUEklMjBtdXklMjBhZ3JhZGFibGUhJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> HfAgent

agent = HfAgent(<span class="hljs-string">&quot;https://api-inference.huggingface.co/models/bigcode/starcoder&quot;</span>)
agent.run(<span class="hljs-string">&quot;Is the following \`text\` (in Spanish) positive or negative?&quot;</span>, text=<span class="hljs-string">&quot;¡Este es un API muy agradable!&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function Pa(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b01vZGVsRm9yQ2F1c2FsTE0lMkMlMjBBdXRvVG9rZW5pemVyJTJDJTIwTG9jYWxBZ2VudCUwQSUwQWNoZWNrcG9pbnQlMjAlM0QlMjAlMjJiaWdjb2RlJTJGc3RhcmNvZGVyJTIyJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoY2hlY2twb2ludCUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChjaGVja3BvaW50KSUwQSUwQWFnZW50JTIwJTNEJTIwTG9jYWxBZ2VudChtb2RlbCUyQyUyMHRva2VuaXplciklMEFhZ2VudC5ydW4oJTIyRHJhdyUyMG1lJTIwYSUyMHBpY3R1cmUlMjBvZiUyMHJpdmVycyUyMGFuZCUyMGxha2VzLiUyMik=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, AutoTokenizer, LocalAgent

checkpoint = <span class="hljs-string">&quot;bigcode/starcoder&quot;</span>
model = AutoModelForCausalLM.from_pretrained(checkpoint, device_map=<span class="hljs-string">&quot;auto&quot;</span>, torch_dtype=torch.bfloat16)
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

agent = LocalAgent(model, tokenizer)
agent.run(<span class="hljs-string">&quot;Draw me a picture of rivers and lakes.&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function Ha(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwTG9jYWxBZ2VudCUwQSUwQWFnZW50JTIwJTNEJTIwTG9jYWxBZ2VudC5mcm9tX3ByZXRyYWluZWQoJTIyYmlnY29kZSUyRnN0YXJjb2RlciUyMiUyQyUyMGRldmljZV9tYXAlM0QlMjJhdXRvJTIyJTJDJTIwdG9yY2hfZHR5cGUlM0R0b3JjaC5iZmxvYXQxNiklMEFhZ2VudC5ydW4oJTIyRHJhdyUyMG1lJTIwYSUyMHBpY3R1cmUlMjBvZiUyMHJpdmVycyUyMGFuZCUyMGxha2VzLiUyMik=",highlighted:`<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> LocalAgent

agent = LocalAgent.from_pretrained(<span class="hljs-string">&quot;bigcode/starcoder&quot;</span>, device_map=<span class="hljs-string">&quot;auto&quot;</span>, torch_dtype=torch.bfloat16)
agent.run(<span class="hljs-string">&quot;Draw me a picture of rivers and lakes.&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function ja(k){let l,T=`The openAI models are used in generation mode, so even for the <code>chat()</code> API, it’s better to use models like
<code>&quot;text-davinci-003&quot;</code> over the chat-GPT variant. Proper support for chat-GPT models will come in a next version.`;return{c(){l=i("p"),l.innerHTML=T},l(b){l=m(b,"P",{"data-svelte-h":!0}),_(l)!=="svelte-3idp4e"&&(l.innerHTML=T)},m(b,p){d(b,l,p)},p:F,d(b){b&&o(l)}}}function La(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyME9wZW5BaUFnZW50JTBBJTBBYWdlbnQlMjAlM0QlMjBPcGVuQWlBZ2VudChtb2RlbCUzRCUyMnRleHQtZGF2aW5jaS0wMDMlMjIlMkMlMjBhcGlfa2V5JTNEeHh4KSUwQWFnZW50LnJ1biglMjJJcyUyMHRoZSUyMGZvbGxvd2luZyUyMCU2MHRleHQlNjAlMjAoaW4lMjBTcGFuaXNoKSUyMHBvc2l0aXZlJTIwb3IlMjBuZWdhdGl2ZSUzRiUyMiUyQyUyMHRleHQlM0QlMjIlQzIlQTFFc3RlJTIwZXMlMjB1biUyMEFQSSUyMG11eSUyMGFncmFkYWJsZSElMjIp",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> OpenAiAgent

agent = OpenAiAgent(model=<span class="hljs-string">&quot;text-davinci-003&quot;</span>, api_key=xxx)
agent.run(<span class="hljs-string">&quot;Is the following \`text\` (in Spanish) positive or negative?&quot;</span>, text=<span class="hljs-string">&quot;¡Este es un API muy agradable!&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function Ja(k){let l,T=`The openAI models are used in generation mode, so even for the <code>chat()</code> API, it’s better to use models like
<code>&quot;text-davinci-003&quot;</code> over the chat-GPT variant. Proper support for chat-GPT models will come in a next version.`;return{c(){l=i("p"),l.innerHTML=T},l(b){l=m(b,"P",{"data-svelte-h":!0}),_(l)!=="svelte-3idp4e"&&(l.innerHTML=T)},m(b,p){d(b,l,p)},p:F,d(b){b&&o(l)}}}function Ua(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF6dXJlT3BlbkFpQWdlbnQlMEElMEFhZ2VudCUyMCUzRCUyMEF6dXJlQWlBZ2VudChkZXBsb3ltZW50X2lkJTNEJTIyRGF2aW5jaS0wMDMlMjIlMkMlMjBhcGlfa2V5JTNEeHh4JTJDJTIwcmVzb3VyY2VfbmFtZSUzRHl5eSklMEFhZ2VudC5ydW4oJTIySXMlMjB0aGUlMjBmb2xsb3dpbmclMjAlNjB0ZXh0JTYwJTIwKGluJTIwU3BhbmlzaCklMjBwb3NpdGl2ZSUyMG9yJTIwbmVnYXRpdmUlM0YlMjIlMkMlMjB0ZXh0JTNEJTIyJUMyJUExRXN0ZSUyMGVzJTIwdW4lMjBBUEklMjBtdXklMjBhZ3JhZGFibGUhJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AzureOpenAiAgent

agent = AzureAiAgent(deployment_id=<span class="hljs-string">&quot;Davinci-003&quot;</span>, api_key=xxx, resource_name=yyy)
agent.run(<span class="hljs-string">&quot;Is the following \`text\` (in Spanish) positive or negative?&quot;</span>, text=<span class="hljs-string">&quot;¡Este es un API muy agradable!&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function qa(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEhmQWdlbnQlMEElMEFhZ2VudCUyMCUzRCUyMEhmQWdlbnQoJTIyaHR0cHMlM0ElMkYlMkZhcGktaW5mZXJlbmNlLmh1Z2dpbmdmYWNlLmNvJTJGbW9kZWxzJTJGYmlnY29kZSUyRnN0YXJjb2RlciUyMiklMEFhZ2VudC5jaGF0KCUyMkRyYXclMjBtZSUyMGElMjBwaWN0dXJlJTIwb2YlMjByaXZlcnMlMjBhbmQlMjBsYWtlcyUyMiklMEElMEFhZ2VudC5jaGF0KCUyMlRyYW5zZm9ybSUyMHRoZSUyMHBpY3R1cmUlMjBzbyUyMHRoYXQlMjB0aGVyZSUyMGlzJTIwYSUyMHJvY2slMjBpbiUyMHRoZXJlJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> HfAgent

agent = HfAgent(<span class="hljs-string">&quot;https://api-inference.huggingface.co/models/bigcode/starcoder&quot;</span>)
agent.chat(<span class="hljs-string">&quot;Draw me a picture of rivers and lakes&quot;</span>)

agent.chat(<span class="hljs-string">&quot;Transform the picture so that there is a rock in there&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function Ea(k){let l,T="Example:",b,p,v;return p=new Lt({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEhmQWdlbnQlMEElMEFhZ2VudCUyMCUzRCUyMEhmQWdlbnQoJTIyaHR0cHMlM0ElMkYlMkZhcGktaW5mZXJlbmNlLmh1Z2dpbmdmYWNlLmNvJTJGbW9kZWxzJTJGYmlnY29kZSUyRnN0YXJjb2RlciUyMiklMEFhZ2VudC5ydW4oJTIyRHJhdyUyMG1lJTIwYSUyMHBpY3R1cmUlMjBvZiUyMHJpdmVycyUyMGFuZCUyMGxha2VzJTIyKQ==",highlighted:`<span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> HfAgent

agent = HfAgent(<span class="hljs-string">&quot;https://api-inference.huggingface.co/models/bigcode/starcoder&quot;</span>)
agent.run(<span class="hljs-string">&quot;Draw me a picture of rivers and lakes&quot;</span>)`,wrap:!1}}),{c(){l=i("p"),l.textContent=T,b=n(),c(p.$$.fragment)},l(a){l=m(a,"P",{"data-svelte-h":!0}),_(l)!=="svelte-11lpom8"&&(l.textContent=T),b=r(a),g(p.$$.fragment,a)},m(a,y){d(a,l,y),d(a,b,y),u(p,a,y),v=!0},p:F,i(a){v||(f(p.$$.fragment,a),v=!0)},o(a){h(p.$$.fragment,a),v=!1},d(a){a&&(o(l),o(b)),$(p,a)}}}function Za(k){let l,T,b,p,v,a,y,yo,Pe,Lr=`To learn more about agents and tools make sure to read the <a href="../transformers_agents">introductory guide</a>. This page
contains the API docs for the underlying classes.`,To,He,wo,je,Jr='We provide three types of agents: <a href="/docs/transformers/main/en/main_classes/agent#transformers.HfAgent">HfAgent</a> uses inference endpoints for opensource models, <a href="/docs/transformers/main/en/main_classes/agent#transformers.LocalAgent">LocalAgent</a> uses a model of your choice locally and <a href="/docs/transformers/main/en/main_classes/agent#transformers.OpenAiAgent">OpenAiAgent</a> uses OpenAI closed models.',xo,Le,Ao,z,Je,vn,Jt,Ur="Agent that uses an inference endpoint to generate code.",yn,ne,Mo,Ue,ko,L,qe,Tn,Ut,qr="Agent that uses a local model and tokenizer to generate code.",wn,re,xn,N,Ee,An,qt,Er="Convenience method to build a <code>LocalAgent</code> from a pretrained checkpoint.",Mn,ae,Io,Ze,Co,J,We,kn,Et,Zr="Agent that uses the openai API to generate code.",In,se,Cn,le,Po,Re,Ho,U,ze,Pn,Zt,Wr=`Agent that uses Azure OpenAI to generate code. See the <a href="https://learn.microsoft.com/en-us/azure/cognitive-services/openai/" rel="nofollow">official
documentation</a> to learn how to deploy an openAI
model on Azure`,Hn,ie,jn,me,jo,Qe,Lo,H,Ge,Ln,Wt,Rr="Base class for all agents which contains the main API methods.",Jn,D,Ve,Un,Rt,zr="Sends a new request to the agent in a chat. Will use the previous ones in its history.",qn,de,En,B,Ne,Zn,zt,Qr="Sends a request to the agent.",Wn,pe,Rn,ce,De,zn,Qt,Gr='Clears the history of prior calls to <a href="/docs/transformers/main/en/main_classes/agent#transformers.Agent.chat">chat()</a>.',Jo,Be,Uo,Ye,qo,S,Fe,Qn,Gt,Vr="Main function to quickly load a tool, be it on the Hub or in the Transformers library.",Eo,Se,Zo,M,Xe,Gn,Vt,Nr=`A base class for the functions used by the agent. Subclass this and implement the <code>__call__</code> method as well as the
following class attributes:`,Vn,Nt,Dr=`<li><strong>description</strong> (<code>str</code>) — A short description of what your tool does, the inputs it expects and the output(s) it
will return. For instance ‘This is a tool that downloads a file from a <code>url</code>. It takes the <code>url</code> as input, and
returns the text contained in the file’.</li> <li><strong>name</strong> (<code>str</code>) — A performative name that will be used for your tool in the prompt to the agent. For instance
<code>&quot;text-classifier&quot;</code> or <code>&quot;image_generator&quot;</code>.</li> <li><strong>inputs</strong> (<code>List[str]</code>) — The list of modalities expected for the inputs (in the same order as in the call).
Modalitiies should be <code>&quot;text&quot;</code>, <code>&quot;image&quot;</code> or <code>&quot;audio&quot;</code>. This is only used by <code>launch_gradio_demo</code> or to make a
nice space from your tool.</li> <li><strong>outputs</strong> (<code>List[str]</code>) — The list of modalities returned but the tool (in the same order as the return of the
call method). Modalitiies should be <code>&quot;text&quot;</code>, <code>&quot;image&quot;</code> or <code>&quot;audio&quot;</code>. This is only used by <code>launch_gradio_demo</code>
or to make a nice space from your tool.</li>`,Nn,Dt,Br=`You can also override the method <a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool.setup">setup()</a> if your tool as an expensive operation to perform before being
usable (such as loading a model). <a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool.setup">setup()</a> will be called the first time you use your tool, but not at
instantiation.`,Dn,ge,Oe,Bn,Bt,Yr='Creates a <a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a> from a gradio tool.',Yn,ue,Ke,Fn,Yt,Fr="Loads a tool defined on the Hub.",Sn,fe,et,Xn,Ft,Sr="Upload the tool to the Hub.",On,R,tt,Kn,St,Xr=`Saves the relevant code files for your tool so it can be pushed to the Hub. This will copy the code of your
tool in <code>output_dir</code> as well as autogenerate:`,er,Xt,Or=`<li>a config file named <code>tool_config.json</code></li> <li>an <code>app.py</code> file so that your tool can be converted to a space</li> <li>a <code>requirements.txt</code> containing the names of the module used by your tool (as detected when inspecting its
code)</li>`,tr,Ot,Kr="You should only use this method to save tools that are defined in a separate module (not <code>__main__</code>).",or,he,ot,nr,Kt,ea=`Overwrite this method here for any operation that is expensive and needs to be executed before you start using
your tool. Such as loading a big model.`,Wo,nt,Ro,I,rt,rr,eo,ta=`A <a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a> tailored towards Transformer models. On top of the class attributes of the base class <a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a>, you will
need to specify:`,ar,to,oa=`<li><strong>model_class</strong> (<code>type</code>) — The class to use to load the model in this tool.</li> <li><strong>default_checkpoint</strong> (<code>str</code>) — The default checkpoint that should be used when the user doesn’t specify one.</li> <li><strong>pre_processor_class</strong> (<code>type</code>, <em>optional</em>, defaults to <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor">AutoProcessor</a>) — The class to use to load the
pre-processor</li> <li><strong>post_processor_class</strong> (<code>type</code>, <em>optional</em>, defaults to <a href="/docs/transformers/main/en/model_doc/auto#transformers.AutoProcessor">AutoProcessor</a>) — The class to use to load the
post-processor (when different from the pre-processor).</li>`,sr,$e,at,lr,oo,na="Uses the <code>post_processor</code> to decode the model output.",ir,be,st,mr,no,ra="Uses the <code>pre_processor</code> to prepare the inputs for the <code>model</code>.",dr,_e,lt,pr,ro,aa="Sends the inputs through the <code>model</code>.",cr,ve,it,gr,ao,sa="Instantiates the <code>pre_processor</code>, <code>model</code> and <code>post_processor</code> if necessary.",zo,mt,Qo,q,dt,ur,so,la='A <a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a> that will make requests to an inference endpoint.',fr,ye,pt,hr,lo,ia=`You can override this method in your custom class of <a href="/docs/transformers/main/en/main_classes/agent#transformers.RemoteTool">RemoteTool</a> to apply some custom post-processing of the
outputs of the endpoint.`,$r,Y,ct,br,io,ma=`Prepare the inputs received for the HTTP client sending data to the endpoint. Positional arguments will be
matched with the signature of the <code>tool_class</code> if it was provided at instantation. Images will be encoded into
bytes.`,_r,mo,da='You can override this method in your custom class of <a href="/docs/transformers/main/en/main_classes/agent#transformers.RemoteTool">RemoteTool</a>.',Go,gt,Vo,X,ut,vr,po,pa=`Launches a gradio demo for a tool. The corresponding tool class needs to properly implement the class attributes
<code>inputs</code> and <code>outputs</code>.`,No,ft,Do,ht,ca=`Agents can handle any type of object in-between tools; tools, being completely multimodal, can accept and return
text, image, audio, video, among other types. In order to increase compatibility between tools, as well as to
correctly render these returns in ipython (jupyter, colab, ipython notebooks, …), we implement wrapper classes
around these types.`,Bo,$t,ga=`The wrapped objects should continue behaving as initially; a text object should still behave as a string, an image
object should still behave as a <code>PIL.Image</code>.`,Yo,bt,ua="These types have three specific purposes:",Fo,_t,fa=`<li>Calling <code>to_raw</code> on the type should return the underlying object</li> <li>Calling <code>to_string</code> on the type should return the object as a string: that can be the string in case of an <code>AgentText</code>
but will be the path of the serialized version of the object in other instances</li> <li>Displaying it in an ipython kernel should display the object correctly</li>`,So,vt,Xo,O,yt,yr,co,ha="Text type returned by the agent. Behaves as a string.",Oo,Tt,Ko,E,wt,Tr,go,$a="Image type returned by the agent. Behaves as a PIL.Image.",wr,Te,xt,xr,uo,ba="Returns the “raw” version of that object. In the case of an AgentImage, it is a PIL.Image.",Ar,we,At,Mr,fo,_a=`Returns the stringified version of that object. In the case of an AgentImage, it is a path to the serialized
version of the image.`,en,Mt,tn,Z,kt,kr,ho,va="Audio type returned by the agent.",Ir,xe,It,Cr,$o,ya="Returns the “raw” version of that object. It is a <code>torch.Tensor</code> object.",Pr,Ae,Ct,Hr,bo,Ta=`Returns the stringified version of that object. In the case of an AgentAudio, it is a path to the serialized
version of the audio.`,on,vo,nn;return v=new P({props:{title:"Agents & Tools",local:"agents--tools",headingTag:"h1"}}),y=new jr({props:{warning:!0,$$slots:{default:[Ia]},$$scope:{ctx:k}}}),He=new P({props:{title:"Agents",local:"agents",headingTag:"h2"}}),Le=new P({props:{title:"HfAgent",local:"transformers.HfAgent",headingTag:"h3"}}),Je=new A({props:{name:"class transformers.HfAgent",anchor:"transformers.HfAgent",parameters:[{name:"url_endpoint",val:""},{name:"token",val:" = None"},{name:"chat_prompt_template",val:" = None"},{name:"run_prompt_template",val:" = None"},{name:"additional_tools",val:" = None"}],parametersDescription:[{anchor:"transformers.HfAgent.url_endpoint",description:`<strong>url_endpoint</strong> (<code>str</code>) &#x2014;
The name of the url endpoint to use.`,name:"url_endpoint"},{anchor:"transformers.HfAgent.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If unset, will use the token generated when
running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"transformers.HfAgent.chat_prompt_template",description:`<strong>chat_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>chat</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>chat_prompt_template.txt</code> in this repo in this case.`,name:"chat_prompt_template"},{anchor:"transformers.HfAgent.run_prompt_template",description:`<strong>run_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>run</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>run_prompt_template.txt</code> in this repo in this case.`,name:"run_prompt_template"},{anchor:"transformers.HfAgent.additional_tools",description:`<strong>additional_tools</strong> (<a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a>, list of tools or dictionary with tool values, <em>optional</em>) &#x2014;
Any additional tools to include on top of the default ones. If you pass along a tool with the same name as
one of the default tools, that default tool will be overridden.`,name:"additional_tools"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L595"}}),ne=new jt({props:{anchor:"transformers.HfAgent.example",$$slots:{default:[Ca]},$$scope:{ctx:k}}}),Ue=new P({props:{title:"LocalAgent",local:"transformers.LocalAgent",headingTag:"h3"}}),qe=new A({props:{name:"class transformers.LocalAgent",anchor:"transformers.LocalAgent",parameters:[{name:"model",val:""},{name:"tokenizer",val:""},{name:"chat_prompt_template",val:" = None"},{name:"run_prompt_template",val:" = None"},{name:"additional_tools",val:" = None"}],parametersDescription:[{anchor:"transformers.LocalAgent.model",description:`<strong>model</strong> (<a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>) &#x2014;
The model to use for the agent.`,name:"model"},{anchor:"transformers.LocalAgent.tokenizer",description:`<strong>tokenizer</strong> (<a href="/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizer">PreTrainedTokenizer</a>) &#x2014;
The tokenizer to use for the agent.`,name:"tokenizer"},{anchor:"transformers.LocalAgent.chat_prompt_template",description:`<strong>chat_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>chat</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>chat_prompt_template.txt</code> in this repo in this case.`,name:"chat_prompt_template"},{anchor:"transformers.LocalAgent.run_prompt_template",description:`<strong>run_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>run</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>run_prompt_template.txt</code> in this repo in this case.`,name:"run_prompt_template"},{anchor:"transformers.LocalAgent.additional_tools",description:`<strong>additional_tools</strong> (<a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a>, list of tools or dictionary with tool values, <em>optional</em>) &#x2014;
Any additional tools to include on top of the default ones. If you pass along a tool with the same name as
one of the default tools, that default tool will be overridden.`,name:"additional_tools"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L666"}}),re=new jt({props:{anchor:"transformers.LocalAgent.example",$$slots:{default:[Pa]},$$scope:{ctx:k}}}),Ee=new A({props:{name:"from_pretrained",anchor:"transformers.LocalAgent.from_pretrained",parameters:[{name:"pretrained_model_name_or_path",val:""},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.LocalAgent.from_pretrained.pretrained_model_name_or_path",description:`<strong>pretrained_model_name_or_path</strong> (<code>str</code> or <code>os.PathLike</code>) &#x2014;
The name of a repo on the Hub or a local path to a folder containing both model and tokenizer.`,name:"pretrained_model_name_or_path"},{anchor:"transformers.LocalAgent.from_pretrained.kwargs",description:`<strong>kwargs</strong> (<code>Dict[str, Any]</code>, <em>optional</em>) &#x2014;
Keyword arguments passed along to <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel.from_pretrained">from_pretrained()</a>.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L711"}}),ae=new jt({props:{anchor:"transformers.LocalAgent.from_pretrained.example",$$slots:{default:[Ha]},$$scope:{ctx:k}}}),Ze=new P({props:{title:"OpenAiAgent",local:"transformers.OpenAiAgent",headingTag:"h3"}}),We=new A({props:{name:"class transformers.OpenAiAgent",anchor:"transformers.OpenAiAgent",parameters:[{name:"model",val:" = 'text-davinci-003'"},{name:"api_key",val:" = None"},{name:"chat_prompt_template",val:" = None"},{name:"run_prompt_template",val:" = None"},{name:"additional_tools",val:" = None"}],parametersDescription:[{anchor:"transformers.OpenAiAgent.model",description:`<strong>model</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;text-davinci-003&quot;</code>) &#x2014;
The name of the OpenAI model to use.`,name:"model"},{anchor:"transformers.OpenAiAgent.api_key",description:`<strong>api_key</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API key to use. If unset, will look for the environment variable <code>&quot;OPENAI_API_KEY&quot;</code>.`,name:"api_key"},{anchor:"transformers.OpenAiAgent.chat_prompt_template",description:`<strong>chat_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>chat</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>chat_prompt_template.txt</code> in this repo in this case.`,name:"chat_prompt_template"},{anchor:"transformers.OpenAiAgent.run_prompt_template",description:`<strong>run_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>run</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>run_prompt_template.txt</code> in this repo in this case.`,name:"run_prompt_template"},{anchor:"transformers.OpenAiAgent.additional_tools",description:`<strong>additional_tools</strong> (<a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a>, list of tools or dictionary with tool values, <em>optional</em>) &#x2014;
Any additional tools to include on top of the default ones. If you pass along a tool with the same name as
one of the default tools, that default tool will be overridden.`,name:"additional_tools"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L371"}}),se=new jr({props:{warning:!0,$$slots:{default:[ja]},$$scope:{ctx:k}}}),le=new jt({props:{anchor:"transformers.OpenAiAgent.example",$$slots:{default:[La]},$$scope:{ctx:k}}}),Re=new P({props:{title:"AzureOpenAiAgent",local:"transformers.AzureOpenAiAgent",headingTag:"h3"}}),ze=new A({props:{name:"class transformers.AzureOpenAiAgent",anchor:"transformers.AzureOpenAiAgent",parameters:[{name:"deployment_id",val:""},{name:"api_key",val:" = None"},{name:"resource_name",val:" = None"},{name:"api_version",val:" = '2022-12-01'"},{name:"is_chat_model",val:" = None"},{name:"chat_prompt_template",val:" = None"},{name:"run_prompt_template",val:" = None"},{name:"additional_tools",val:" = None"}],parametersDescription:[{anchor:"transformers.AzureOpenAiAgent.deployment_id",description:`<strong>deployment_id</strong> (<code>str</code>) &#x2014;
The name of the deployed Azure openAI model to use.`,name:"deployment_id"},{anchor:"transformers.AzureOpenAiAgent.api_key",description:`<strong>api_key</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The API key to use. If unset, will look for the environment variable <code>&quot;AZURE_OPENAI_API_KEY&quot;</code>.`,name:"api_key"},{anchor:"transformers.AzureOpenAiAgent.resource_name",description:`<strong>resource_name</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The name of your Azure OpenAI Resource. If unset, will look for the environment variable
<code>&quot;AZURE_OPENAI_RESOURCE_NAME&quot;</code>.`,name:"resource_name"},{anchor:"transformers.AzureOpenAiAgent.api_version",description:`<strong>api_version</strong> (<code>str</code>, <em>optional</em>, default to <code>&quot;2022-12-01&quot;</code>) &#x2014;
The API version to use for this agent.`,name:"api_version"},{anchor:"transformers.AzureOpenAiAgent.is_chat_mode",description:`<strong>is_chat_mode</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether you are using a completion model or a chat model (see note above, chat models won&#x2019;t be as
efficient). Will default to <code>gpt</code> being in the <code>deployment_id</code> or not.`,name:"is_chat_mode"},{anchor:"transformers.AzureOpenAiAgent.chat_prompt_template",description:`<strong>chat_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>chat</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>chat_prompt_template.txt</code> in this repo in this case.`,name:"chat_prompt_template"},{anchor:"transformers.AzureOpenAiAgent.run_prompt_template",description:`<strong>run_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>run</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>run_prompt_template.txt</code> in this repo in this case.`,name:"run_prompt_template"},{anchor:"transformers.AzureOpenAiAgent.additional_tools",description:`<strong>additional_tools</strong> (<a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a>, list of tools or dictionary with tool values, <em>optional</em>) &#x2014;
Any additional tools to include on top of the default ones. If you pass along a tool with the same name as
one of the default tools, that default tool will be overridden.`,name:"additional_tools"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L469"}}),ie=new jr({props:{warning:!0,$$slots:{default:[Ja]},$$scope:{ctx:k}}}),me=new jt({props:{anchor:"transformers.AzureOpenAiAgent.example",$$slots:{default:[Ua]},$$scope:{ctx:k}}}),Qe=new P({props:{title:"Agent",local:"transformers.Agent",headingTag:"h3"}}),Ge=new A({props:{name:"class transformers.Agent",anchor:"transformers.Agent",parameters:[{name:"chat_prompt_template",val:" = None"},{name:"run_prompt_template",val:" = None"},{name:"additional_tools",val:" = None"}],parametersDescription:[{anchor:"transformers.Agent.chat_prompt_template",description:`<strong>chat_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>chat</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>chat_prompt_template.txt</code> in this repo in this case.`,name:"chat_prompt_template"},{anchor:"transformers.Agent.run_prompt_template",description:`<strong>run_prompt_template</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Pass along your own prompt if you want to override the default template for the <code>run</code> method. Can be the
actual prompt template or a repo ID (on the Hugging Face Hub). The prompt should be in a file named
<code>run_prompt_template.txt</code> in this repo in this case.`,name:"run_prompt_template"},{anchor:"transformers.Agent.additional_tools",description:`<strong>additional_tools</strong> (<a href="/docs/transformers/main/en/main_classes/agent#transformers.Tool">Tool</a>, list of tools or dictionary with tool values, <em>optional</em>) &#x2014;
Any additional tools to include on top of the default ones. If you pass along a tool with the same name as
one of the default tools, that default tool will be overridden.`,name:"additional_tools"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L196"}}),Ve=new A({props:{name:"chat",anchor:"transformers.Agent.chat",parameters:[{name:"task",val:""},{name:"return_code",val:" = False"},{name:"remote",val:" = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.Agent.chat.task",description:"<strong>task</strong> (<code>str</code>) &#x2014; The task to perform",name:"task"},{anchor:"transformers.Agent.chat.return_code",description:`<strong>return_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to just return code and not evaluate it.`,name:"return_code"},{anchor:"transformers.Agent.chat.remote",description:`<strong>remote</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use remote tools (inference endpoints) instead of local ones.`,name:"remote"},{anchor:"transformers.Agent.chat.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Any keyword argument to send to the agent when evaluating the code.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L268"}}),de=new jt({props:{anchor:"transformers.Agent.chat.example",$$slots:{default:[qa]},$$scope:{ctx:k}}}),Ne=new A({props:{name:"run",anchor:"transformers.Agent.run",parameters:[{name:"task",val:""},{name:"return_code",val:" = False"},{name:"remote",val:" = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.Agent.run.task",description:"<strong>task</strong> (<code>str</code>) &#x2014; The task to perform",name:"task"},{anchor:"transformers.Agent.run.return_code",description:`<strong>return_code</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to just return code and not evaluate it.`,name:"return_code"},{anchor:"transformers.Agent.run.remote",description:`<strong>remote</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to use remote tools (inference endpoints) instead of local ones.`,name:"remote"},{anchor:"transformers.Agent.run.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Any keyword argument to send to the agent when evaluating the code.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L325"}}),pe=new jt({props:{anchor:"transformers.Agent.run.example",$$slots:{default:[Ea]},$$scope:{ctx:k}}}),De=new A({props:{name:"prepare_for_new_chat",anchor:"transformers.Agent.prepare_for_new_chat",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agents.py#L310"}}),Be=new P({props:{title:"Tools",local:"tools",headingTag:"h2"}}),Ye=new P({props:{title:"load_tool",local:"transformers.load_tool",headingTag:"h3"}}),Fe=new A({props:{name:"transformers.load_tool",anchor:"transformers.load_tool",parameters:[{name:"task_or_repo_id",val:""},{name:"model_repo_id",val:" = None"},{name:"remote",val:" = False"},{name:"token",val:" = None"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.load_tool.task_or_repo_id",description:`<strong>task_or_repo_id</strong> (<code>str</code>) &#x2014;
The task for which to load the tool or a repo ID of a tool on the Hub. Tasks implemented in Transformers
are:</p>
<ul>
<li><code>&quot;document-question-answering&quot;</code></li>
<li><code>&quot;image-captioning&quot;</code></li>
<li><code>&quot;image-question-answering&quot;</code></li>
<li><code>&quot;image-segmentation&quot;</code></li>
<li><code>&quot;speech-to-text&quot;</code></li>
<li><code>&quot;summarization&quot;</code></li>
<li><code>&quot;text-classification&quot;</code></li>
<li><code>&quot;text-question-answering&quot;</code></li>
<li><code>&quot;text-to-speech&quot;</code></li>
<li><code>&quot;translation&quot;</code></li>
</ul>`,name:"task_or_repo_id"},{anchor:"transformers.load_tool.model_repo_id",description:`<strong>model_repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
Use this argument to use a different model than the default one for the tool you selected.`,name:"model_repo_id"},{anchor:"transformers.load_tool.remote",description:`<strong>remote</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to use your tool by downloading the model or (if it is available) with an inference endpoint.`,name:"remote"},{anchor:"transformers.load_tool.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to identify you on hf.co. If unset, will use the token generated when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"transformers.load_tool.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Additional keyword arguments that will be split in two: all arguments relevant to the Hub (such as
<code>cache_dir</code>, <code>revision</code>, <code>subfolder</code>) will be used when downloading the files for your tool, and the others
will be passed along to its init.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L629"}}),Se=new P({props:{title:"Tool",local:"transformers.Tool",headingTag:"h3"}}),Xe=new A({props:{name:"class transformers.Tool",anchor:"transformers.Tool",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L82"}}),Oe=new A({props:{name:"from_gradio",anchor:"transformers.Tool.from_gradio",parameters:[{name:"gradio_tool",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L333"}}),Ke=new A({props:{name:"from_hub",anchor:"transformers.Tool.from_hub",parameters:[{name:"repo_id",val:": str"},{name:"model_repo_id",val:": Optional = None"},{name:"token",val:": Optional = None"},{name:"remote",val:": bool = False"},{name:"**kwargs",val:""}],parametersDescription:[{anchor:"transformers.Tool.from_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The name of the repo on the Hub where your tool is defined.`,name:"repo_id"},{anchor:"transformers.Tool.from_hub.model_repo_id",description:`<strong>model_repo_id</strong> (<code>str</code>, <em>optional</em>) &#x2014;
If your tool uses a model and you want to use a different model than the default, you can pass a second
repo ID or an endpoint url to this argument.`,name:"model_repo_id"},{anchor:"transformers.Tool.from_hub.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to identify you on hf.co. If unset, will use the token generated when running
<code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"transformers.Tool.from_hub.remote",description:`<strong>remote</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether to use your tool by downloading the model or (if it is available) with an inference endpoint.`,name:"remote"},{anchor:"transformers.Tool.from_hub.kwargs",description:`<strong>kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Additional keyword arguments that will be split in two: all arguments relevant to the Hub (such as
<code>cache_dir</code>, <code>revision</code>, <code>subfolder</code>) will be used when downloading the files for your tool, and the
others will be passed along to its init.`,name:"kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L177"}}),et=new A({props:{name:"push_to_hub",anchor:"transformers.Tool.push_to_hub",parameters:[{name:"repo_id",val:": str"},{name:"commit_message",val:": str = 'Upload tool'"},{name:"private",val:": Optional = None"},{name:"token",val:": Union = None"},{name:"create_pr",val:": bool = False"}],parametersDescription:[{anchor:"transformers.Tool.push_to_hub.repo_id",description:`<strong>repo_id</strong> (<code>str</code>) &#x2014;
The name of the repository you want to push your tool to. It should contain your organization name when
pushing to a given organization.`,name:"repo_id"},{anchor:"transformers.Tool.push_to_hub.commit_message",description:`<strong>commit_message</strong> (<code>str</code>, <em>optional</em>, defaults to <code>&quot;Upload tool&quot;</code>) &#x2014;
Message to commit while pushing.`,name:"commit_message"},{anchor:"transformers.Tool.push_to_hub.private",description:`<strong>private</strong> (<code>bool</code>, <em>optional</em>) &#x2014;
Whether or not the repository created should be private.`,name:"private"},{anchor:"transformers.Tool.push_to_hub.token",description:`<strong>token</strong> (<code>bool</code> or <code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If unset, will use the token generated
when running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"transformers.Tool.push_to_hub.create_pr",description:`<strong>create_pr</strong> (<code>bool</code>, <em>optional</em>, defaults to <code>False</code>) &#x2014;
Whether or not to create a PR with the uploaded files or directly commit.`,name:"create_pr"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L289"}}),tt=new A({props:{name:"save",anchor:"transformers.Tool.save",parameters:[{name:"output_dir",val:""}],parametersDescription:[{anchor:"transformers.Tool.save.output_dir",description:"<strong>output_dir</strong> (<code>str</code>) &#x2014; The folder in which you want to save your tool.",name:"output_dir"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L123"}}),ot=new A({props:{name:"setup",anchor:"transformers.Tool.setup",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L116"}}),nt=new P({props:{title:"PipelineTool",local:"transformers.PipelineTool",headingTag:"h3"}}),rt=new A({props:{name:"class transformers.PipelineTool",anchor:"transformers.PipelineTool",parameters:[{name:"model",val:" = None"},{name:"pre_processor",val:" = None"},{name:"post_processor",val:" = None"},{name:"device",val:" = None"},{name:"device_map",val:" = None"},{name:"model_kwargs",val:" = None"},{name:"token",val:" = None"},{name:"**hub_kwargs",val:""}],parametersDescription:[{anchor:"transformers.PipelineTool.model",description:`<strong>model</strong> (<code>str</code> or <a href="/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel">PreTrainedModel</a>, <em>optional</em>) &#x2014;
The name of the checkpoint to use for the model, or the instantiated model. If unset, will default to the
value of the class attribute <code>default_checkpoint</code>.`,name:"model"},{anchor:"transformers.PipelineTool.pre_processor",description:`<strong>pre_processor</strong> (<code>str</code> or <code>Any</code>, <em>optional</em>) &#x2014;
The name of the checkpoint to use for the pre-processor, or the instantiated pre-processor (can be a
tokenizer, an image processor, a feature extractor or a processor). Will default to the value of <code>model</code> if
unset.`,name:"pre_processor"},{anchor:"transformers.PipelineTool.post_processor",description:`<strong>post_processor</strong> (<code>str</code> or <code>Any</code>, <em>optional</em>) &#x2014;
The name of the checkpoint to use for the post-processor, or the instantiated pre-processor (can be a
tokenizer, an image processor, a feature extractor or a processor). Will default to the <code>pre_processor</code> if
unset.`,name:"post_processor"},{anchor:"transformers.PipelineTool.device",description:`<strong>device</strong> (<code>int</code>, <code>str</code> or <code>torch.device</code>, <em>optional</em>) &#x2014;
The device on which to execute the model. Will default to any accelerator available (GPU, MPS etc&#x2026;), the
CPU otherwise.`,name:"device"},{anchor:"transformers.PipelineTool.device_map",description:`<strong>device_map</strong> (<code>str</code> or <code>dict</code>, <em>optional</em>) &#x2014;
If passed along, will be used to instantiate the model.`,name:"device_map"},{anchor:"transformers.PipelineTool.model_kwargs",description:`<strong>model_kwargs</strong> (<code>dict</code>, <em>optional</em>) &#x2014;
Any keyword argument to send to the model instantiation.`,name:"model_kwargs"},{anchor:"transformers.PipelineTool.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If unset, will use the token generated when
running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"transformers.PipelineTool.hub_kwargs",description:`<strong>hub_kwargs</strong> (additional keyword arguments, <em>optional</em>) &#x2014;
Any additional keyword argument to send to the methods that will load the data from the Hub.`,name:"hub_kwargs"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L436"}}),at=new A({props:{name:"decode",anchor:"transformers.PipelineTool.decode",parameters:[{name:"outputs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L555"}}),st=new A({props:{name:"encode",anchor:"transformers.PipelineTool.encode",parameters:[{name:"raw_inputs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L542"}}),lt=new A({props:{name:"forward",anchor:"transformers.PipelineTool.forward",parameters:[{name:"inputs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L548"}}),it=new A({props:{name:"setup",anchor:"transformers.PipelineTool.setup",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L516"}}),mt=new P({props:{title:"RemoteTool",local:"transformers.RemoteTool",headingTag:"h3"}}),dt=new A({props:{name:"class transformers.RemoteTool",anchor:"transformers.RemoteTool",parameters:[{name:"endpoint_url",val:" = None"},{name:"token",val:" = None"},{name:"tool_class",val:" = None"}],parametersDescription:[{anchor:"transformers.RemoteTool.endpoint_url",description:`<strong>endpoint_url</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The url of the endpoint to use.`,name:"endpoint_url"},{anchor:"transformers.RemoteTool.token",description:`<strong>token</strong> (<code>str</code>, <em>optional</em>) &#x2014;
The token to use as HTTP bearer authorization for remote files. If unset, will use the token generated when
running <code>huggingface-cli login</code> (stored in <code>~/.huggingface</code>).`,name:"token"},{anchor:"transformers.RemoteTool.tool_class",description:`<strong>tool_class</strong> (<code>type</code>, <em>optional</em>) &#x2014;
The corresponding <code>tool_class</code> if this is a remote version of an existing tool. Will help determine when
the output should be converted to another type (like images).`,name:"tool_class"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L349"}}),pt=new A({props:{name:"extract_outputs",anchor:"transformers.RemoteTool.extract_outputs",parameters:[{name:"outputs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L412"}}),ct=new A({props:{name:"prepare_inputs",anchor:"transformers.RemoteTool.prepare_inputs",parameters:[{name:"*args",val:""},{name:"**kwargs",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L369"}}),gt=new P({props:{title:"launch_gradio_demo",local:"transformers.launch_gradio_demo",headingTag:"h3"}}),ut=new A({props:{name:"transformers.launch_gradio_demo",anchor:"transformers.launch_gradio_demo",parameters:[{name:"tool_class",val:": Tool"}],parametersDescription:[{anchor:"transformers.launch_gradio_demo.tool_class",description:"<strong>tool_class</strong> (<code>type</code>) &#x2014; The class of the tool for which to launch the demo.",name:"tool_class"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/base.py#L576"}}),ft=new P({props:{title:"Agent Types",local:"agent-types",headingTag:"h2"}}),vt=new P({props:{title:"AgentText",local:"transformers.tools.agent_types.AgentText",headingTag:"h3"}}),yt=new A({props:{name:"class transformers.tools.agent_types.AgentText",anchor:"transformers.tools.agent_types.AgentText",parameters:[{name:"value",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L71"}}),Tt=new P({props:{title:"AgentImage",local:"transformers.tools.agent_types.AgentImage",headingTag:"h3"}}),wt=new A({props:{name:"class transformers.tools.agent_types.AgentImage",anchor:"transformers.tools.agent_types.AgentImage",parameters:[{name:"value",val:""}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L83"}}),xt=new A({props:{name:"to_raw",anchor:"transformers.tools.agent_types.AgentImage.to_raw",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L115"}}),At=new A({props:{name:"to_string",anchor:"transformers.tools.agent_types.AgentImage.to_string",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L126"}}),Mt=new P({props:{title:"AgentAudio",local:"transformers.tools.agent_types.AgentAudio",headingTag:"h3"}}),kt=new A({props:{name:"class transformers.tools.agent_types.AgentAudio",anchor:"transformers.tools.agent_types.AgentAudio",parameters:[{name:"value",val:""},{name:"samplerate",val:" = 16000"}],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L155"}}),It=new A({props:{name:"to_raw",anchor:"transformers.tools.agent_types.AgentAudio.to_raw",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L186"}}),Ct=new A({props:{name:"to_string",anchor:"transformers.tools.agent_types.AgentAudio.to_string",parameters:[],source:"https://github.com/QubitPi/huggingface-transformers/blob/main/src/transformers/tools/agent_types.py#L198"}}),{c(){l=i("meta"),T=n(),b=i("p"),p=n(),c(v.$$.fragment),a=n(),c(y.$$.fragment),yo=n(),Pe=i("p"),Pe.innerHTML=Lr,To=n(),c(He.$$.fragment),wo=n(),je=i("p"),je.innerHTML=Jr,xo=n(),c(Le.$$.fragment),Ao=n(),z=i("div"),c(Je.$$.fragment),vn=n(),Jt=i("p"),Jt.textContent=Ur,yn=n(),c(ne.$$.fragment),Mo=n(),c(Ue.$$.fragment),ko=n(),L=i("div"),c(qe.$$.fragment),Tn=n(),Ut=i("p"),Ut.textContent=qr,wn=n(),c(re.$$.fragment),xn=n(),N=i("div"),c(Ee.$$.fragment),An=n(),qt=i("p"),qt.innerHTML=Er,Mn=n(),c(ae.$$.fragment),Io=n(),c(Ze.$$.fragment),Co=n(),J=i("div"),c(We.$$.fragment),kn=n(),Et=i("p"),Et.textContent=Zr,In=n(),c(se.$$.fragment),Cn=n(),c(le.$$.fragment),Po=n(),c(Re.$$.fragment),Ho=n(),U=i("div"),c(ze.$$.fragment),Pn=n(),Zt=i("p"),Zt.innerHTML=Wr,Hn=n(),c(ie.$$.fragment),jn=n(),c(me.$$.fragment),jo=n(),c(Qe.$$.fragment),Lo=n(),H=i("div"),c(Ge.$$.fragment),Ln=n(),Wt=i("p"),Wt.textContent=Rr,Jn=n(),D=i("div"),c(Ve.$$.fragment),Un=n(),Rt=i("p"),Rt.textContent=zr,qn=n(),c(de.$$.fragment),En=n(),B=i("div"),c(Ne.$$.fragment),Zn=n(),zt=i("p"),zt.textContent=Qr,Wn=n(),c(pe.$$.fragment),Rn=n(),ce=i("div"),c(De.$$.fragment),zn=n(),Qt=i("p"),Qt.innerHTML=Gr,Jo=n(),c(Be.$$.fragment),Uo=n(),c(Ye.$$.fragment),qo=n(),S=i("div"),c(Fe.$$.fragment),Qn=n(),Gt=i("p"),Gt.textContent=Vr,Eo=n(),c(Se.$$.fragment),Zo=n(),M=i("div"),c(Xe.$$.fragment),Gn=n(),Vt=i("p"),Vt.innerHTML=Nr,Vn=n(),Nt=i("ul"),Nt.innerHTML=Dr,Nn=n(),Dt=i("p"),Dt.innerHTML=Br,Dn=n(),ge=i("div"),c(Oe.$$.fragment),Bn=n(),Bt=i("p"),Bt.innerHTML=Yr,Yn=n(),ue=i("div"),c(Ke.$$.fragment),Fn=n(),Yt=i("p"),Yt.textContent=Fr,Sn=n(),fe=i("div"),c(et.$$.fragment),Xn=n(),Ft=i("p"),Ft.textContent=Sr,On=n(),R=i("div"),c(tt.$$.fragment),Kn=n(),St=i("p"),St.innerHTML=Xr,er=n(),Xt=i("ul"),Xt.innerHTML=Or,tr=n(),Ot=i("p"),Ot.innerHTML=Kr,or=n(),he=i("div"),c(ot.$$.fragment),nr=n(),Kt=i("p"),Kt.textContent=ea,Wo=n(),c(nt.$$.fragment),Ro=n(),I=i("div"),c(rt.$$.fragment),rr=n(),eo=i("p"),eo.innerHTML=ta,ar=n(),to=i("ul"),to.innerHTML=oa,sr=n(),$e=i("div"),c(at.$$.fragment),lr=n(),oo=i("p"),oo.innerHTML=na,ir=n(),be=i("div"),c(st.$$.fragment),mr=n(),no=i("p"),no.innerHTML=ra,dr=n(),_e=i("div"),c(lt.$$.fragment),pr=n(),ro=i("p"),ro.innerHTML=aa,cr=n(),ve=i("div"),c(it.$$.fragment),gr=n(),ao=i("p"),ao.innerHTML=sa,zo=n(),c(mt.$$.fragment),Qo=n(),q=i("div"),c(dt.$$.fragment),ur=n(),so=i("p"),so.innerHTML=la,fr=n(),ye=i("div"),c(pt.$$.fragment),hr=n(),lo=i("p"),lo.innerHTML=ia,$r=n(),Y=i("div"),c(ct.$$.fragment),br=n(),io=i("p"),io.innerHTML=ma,_r=n(),mo=i("p"),mo.innerHTML=da,Go=n(),c(gt.$$.fragment),Vo=n(),X=i("div"),c(ut.$$.fragment),vr=n(),po=i("p"),po.innerHTML=pa,No=n(),c(ft.$$.fragment),Do=n(),ht=i("p"),ht.textContent=ca,Bo=n(),$t=i("p"),$t.innerHTML=ga,Yo=n(),bt=i("p"),bt.textContent=ua,Fo=n(),_t=i("ul"),_t.innerHTML=fa,So=n(),c(vt.$$.fragment),Xo=n(),O=i("div"),c(yt.$$.fragment),yr=n(),co=i("p"),co.textContent=ha,Oo=n(),c(Tt.$$.fragment),Ko=n(),E=i("div"),c(wt.$$.fragment),Tr=n(),go=i("p"),go.textContent=$a,wr=n(),Te=i("div"),c(xt.$$.fragment),xr=n(),uo=i("p"),uo.textContent=ba,Ar=n(),we=i("div"),c(At.$$.fragment),Mr=n(),fo=i("p"),fo.textContent=_a,en=n(),c(Mt.$$.fragment),tn=n(),Z=i("div"),c(kt.$$.fragment),kr=n(),ho=i("p"),ho.textContent=va,Ir=n(),xe=i("div"),c(It.$$.fragment),Cr=n(),$o=i("p"),$o.innerHTML=ya,Pr=n(),Ae=i("div"),c(Ct.$$.fragment),Hr=n(),bo=i("p"),bo.textContent=Ta,on=n(),vo=i("p"),this.h()},l(e){const s=ka("svelte-u9bgzb",document.head);l=m(s,"META",{name:!0,content:!0}),s.forEach(o),T=r(e),b=m(e,"P",{}),w(b).forEach(o),p=r(e),g(v.$$.fragment,e),a=r(e),g(y.$$.fragment,e),yo=r(e),Pe=m(e,"P",{"data-svelte-h":!0}),_(Pe)!=="svelte-7mj07q"&&(Pe.innerHTML=Lr),To=r(e),g(He.$$.fragment,e),wo=r(e),je=m(e,"P",{"data-svelte-h":!0}),_(je)!=="svelte-1a0fuyi"&&(je.innerHTML=Jr),xo=r(e),g(Le.$$.fragment,e),Ao=r(e),z=m(e,"DIV",{class:!0});var K=w(z);g(Je.$$.fragment,K),vn=r(K),Jt=m(K,"P",{"data-svelte-h":!0}),_(Jt)!=="svelte-1uej11q"&&(Jt.textContent=Ur),yn=r(K),g(ne.$$.fragment,K),K.forEach(o),Mo=r(e),g(Ue.$$.fragment,e),ko=r(e),L=m(e,"DIV",{class:!0});var Q=w(L);g(qe.$$.fragment,Q),Tn=r(Q),Ut=m(Q,"P",{"data-svelte-h":!0}),_(Ut)!=="svelte-1q3iegi"&&(Ut.textContent=qr),wn=r(Q),g(re.$$.fragment,Q),xn=r(Q),N=m(Q,"DIV",{class:!0});var ee=w(N);g(Ee.$$.fragment,ee),An=r(ee),qt=m(ee,"P",{"data-svelte-h":!0}),_(qt)!=="svelte-1qh3hl2"&&(qt.innerHTML=Er),Mn=r(ee),g(ae.$$.fragment,ee),ee.forEach(o),Q.forEach(o),Io=r(e),g(Ze.$$.fragment,e),Co=r(e),J=m(e,"DIV",{class:!0});var G=w(J);g(We.$$.fragment,G),kn=r(G),Et=m(G,"P",{"data-svelte-h":!0}),_(Et)!=="svelte-182hy5g"&&(Et.textContent=Zr),In=r(G),g(se.$$.fragment,G),Cn=r(G),g(le.$$.fragment,G),G.forEach(o),Po=r(e),g(Re.$$.fragment,e),Ho=r(e),U=m(e,"DIV",{class:!0});var V=w(U);g(ze.$$.fragment,V),Pn=r(V),Zt=m(V,"P",{"data-svelte-h":!0}),_(Zt)!=="svelte-1eoncpw"&&(Zt.innerHTML=Wr),Hn=r(V),g(ie.$$.fragment,V),jn=r(V),g(me.$$.fragment,V),V.forEach(o),jo=r(e),g(Qe.$$.fragment,e),Lo=r(e),H=m(e,"DIV",{class:!0});var W=w(H);g(Ge.$$.fragment,W),Ln=r(W),Wt=m(W,"P",{"data-svelte-h":!0}),_(Wt)!=="svelte-1phtukb"&&(Wt.textContent=Rr),Jn=r(W),D=m(W,"DIV",{class:!0});var te=w(D);g(Ve.$$.fragment,te),Un=r(te),Rt=m(te,"P",{"data-svelte-h":!0}),_(Rt)!=="svelte-1s1qxmr"&&(Rt.textContent=zr),qn=r(te),g(de.$$.fragment,te),te.forEach(o),En=r(W),B=m(W,"DIV",{class:!0});var oe=w(B);g(Ne.$$.fragment,oe),Zn=r(oe),zt=m(oe,"P",{"data-svelte-h":!0}),_(zt)!=="svelte-1685qxi"&&(zt.textContent=Qr),Wn=r(oe),g(pe.$$.fragment,oe),oe.forEach(o),Rn=r(W),ce=m(W,"DIV",{class:!0});var Pt=w(ce);g(De.$$.fragment,Pt),zn=r(Pt),Qt=m(Pt,"P",{"data-svelte-h":!0}),_(Qt)!=="svelte-5wa3vi"&&(Qt.innerHTML=Gr),Pt.forEach(o),W.forEach(o),Jo=r(e),g(Be.$$.fragment,e),Uo=r(e),g(Ye.$$.fragment,e),qo=r(e),S=m(e,"DIV",{class:!0});var Ht=w(S);g(Fe.$$.fragment,Ht),Qn=r(Ht),Gt=m(Ht,"P",{"data-svelte-h":!0}),_(Gt)!=="svelte-16uh3p8"&&(Gt.textContent=Vr),Ht.forEach(o),Eo=r(e),g(Se.$$.fragment,e),Zo=r(e),M=m(e,"DIV",{class:!0});var C=w(M);g(Xe.$$.fragment,C),Gn=r(C),Vt=m(C,"P",{"data-svelte-h":!0}),_(Vt)!=="svelte-cca4c5"&&(Vt.innerHTML=Nr),Vn=r(C),Nt=m(C,"UL",{"data-svelte-h":!0}),_(Nt)!=="svelte-1lb1si5"&&(Nt.innerHTML=Dr),Nn=r(C),Dt=m(C,"P",{"data-svelte-h":!0}),_(Dt)!=="svelte-10s049q"&&(Dt.innerHTML=Br),Dn=r(C),ge=m(C,"DIV",{class:!0});var rn=w(ge);g(Oe.$$.fragment,rn),Bn=r(rn),Bt=m(rn,"P",{"data-svelte-h":!0}),_(Bt)!=="svelte-548oc7"&&(Bt.innerHTML=Yr),rn.forEach(o),Yn=r(C),ue=m(C,"DIV",{class:!0});var an=w(ue);g(Ke.$$.fragment,an),Fn=r(an),Yt=m(an,"P",{"data-svelte-h":!0}),_(Yt)!=="svelte-yy7b2c"&&(Yt.textContent=Fr),an.forEach(o),Sn=r(C),fe=m(C,"DIV",{class:!0});var sn=w(fe);g(et.$$.fragment,sn),Xn=r(sn),Ft=m(sn,"P",{"data-svelte-h":!0}),_(Ft)!=="svelte-1u3gku9"&&(Ft.textContent=Sr),sn.forEach(o),On=r(C),R=m(C,"DIV",{class:!0});var Me=w(R);g(tt.$$.fragment,Me),Kn=r(Me),St=m(Me,"P",{"data-svelte-h":!0}),_(St)!=="svelte-19evuwa"&&(St.innerHTML=Xr),er=r(Me),Xt=m(Me,"UL",{"data-svelte-h":!0}),_(Xt)!=="svelte-15of9ze"&&(Xt.innerHTML=Or),tr=r(Me),Ot=m(Me,"P",{"data-svelte-h":!0}),_(Ot)!=="svelte-msa4ge"&&(Ot.innerHTML=Kr),Me.forEach(o),or=r(C),he=m(C,"DIV",{class:!0});var ln=w(he);g(ot.$$.fragment,ln),nr=r(ln),Kt=m(ln,"P",{"data-svelte-h":!0}),_(Kt)!=="svelte-63kthh"&&(Kt.textContent=ea),ln.forEach(o),C.forEach(o),Wo=r(e),g(nt.$$.fragment,e),Ro=r(e),I=m(e,"DIV",{class:!0});var j=w(I);g(rt.$$.fragment,j),rr=r(j),eo=m(j,"P",{"data-svelte-h":!0}),_(eo)!=="svelte-1tqfigx"&&(eo.innerHTML=ta),ar=r(j),to=m(j,"UL",{"data-svelte-h":!0}),_(to)!=="svelte-n6zm2g"&&(to.innerHTML=oa),sr=r(j),$e=m(j,"DIV",{class:!0});var mn=w($e);g(at.$$.fragment,mn),lr=r(mn),oo=m(mn,"P",{"data-svelte-h":!0}),_(oo)!=="svelte-zkjq4t"&&(oo.innerHTML=na),mn.forEach(o),ir=r(j),be=m(j,"DIV",{class:!0});var dn=w(be);g(st.$$.fragment,dn),mr=r(dn),no=m(dn,"P",{"data-svelte-h":!0}),_(no)!=="svelte-1vxzk80"&&(no.innerHTML=ra),dn.forEach(o),dr=r(j),_e=m(j,"DIV",{class:!0});var pn=w(_e);g(lt.$$.fragment,pn),pr=r(pn),ro=m(pn,"P",{"data-svelte-h":!0}),_(ro)!=="svelte-1qgsi13"&&(ro.innerHTML=aa),pn.forEach(o),cr=r(j),ve=m(j,"DIV",{class:!0});var cn=w(ve);g(it.$$.fragment,cn),gr=r(cn),ao=m(cn,"P",{"data-svelte-h":!0}),_(ao)!=="svelte-1ojxz66"&&(ao.innerHTML=sa),cn.forEach(o),j.forEach(o),zo=r(e),g(mt.$$.fragment,e),Qo=r(e),q=m(e,"DIV",{class:!0});var ke=w(q);g(dt.$$.fragment,ke),ur=r(ke),so=m(ke,"P",{"data-svelte-h":!0}),_(so)!=="svelte-13bxbpc"&&(so.innerHTML=la),fr=r(ke),ye=m(ke,"DIV",{class:!0});var gn=w(ye);g(pt.$$.fragment,gn),hr=r(gn),lo=m(gn,"P",{"data-svelte-h":!0}),_(lo)!=="svelte-tdzm29"&&(lo.innerHTML=ia),gn.forEach(o),$r=r(ke),Y=m(ke,"DIV",{class:!0});var _o=w(Y);g(ct.$$.fragment,_o),br=r(_o),io=m(_o,"P",{"data-svelte-h":!0}),_(io)!=="svelte-14yhe1"&&(io.innerHTML=ma),_r=r(_o),mo=m(_o,"P",{"data-svelte-h":!0}),_(mo)!=="svelte-mygv4m"&&(mo.innerHTML=da),_o.forEach(o),ke.forEach(o),Go=r(e),g(gt.$$.fragment,e),Vo=r(e),X=m(e,"DIV",{class:!0});var un=w(X);g(ut.$$.fragment,un),vr=r(un),po=m(un,"P",{"data-svelte-h":!0}),_(po)!=="svelte-78dinl"&&(po.innerHTML=pa),un.forEach(o),No=r(e),g(ft.$$.fragment,e),Do=r(e),ht=m(e,"P",{"data-svelte-h":!0}),_(ht)!=="svelte-jsq4jz"&&(ht.textContent=ca),Bo=r(e),$t=m(e,"P",{"data-svelte-h":!0}),_($t)!=="svelte-1ixcu88"&&($t.innerHTML=ga),Yo=r(e),bt=m(e,"P",{"data-svelte-h":!0}),_(bt)!=="svelte-1nfvcwf"&&(bt.textContent=ua),Fo=r(e),_t=m(e,"UL",{"data-svelte-h":!0}),_(_t)!=="svelte-ysem30"&&(_t.innerHTML=fa),So=r(e),g(vt.$$.fragment,e),Xo=r(e),O=m(e,"DIV",{class:!0});var fn=w(O);g(yt.$$.fragment,fn),yr=r(fn),co=m(fn,"P",{"data-svelte-h":!0}),_(co)!=="svelte-57fhj7"&&(co.textContent=ha),fn.forEach(o),Oo=r(e),g(Tt.$$.fragment,e),Ko=r(e),E=m(e,"DIV",{class:!0});var Ie=w(E);g(wt.$$.fragment,Ie),Tr=r(Ie),go=m(Ie,"P",{"data-svelte-h":!0}),_(go)!=="svelte-1hsb0qs"&&(go.textContent=$a),wr=r(Ie),Te=m(Ie,"DIV",{class:!0});var hn=w(Te);g(xt.$$.fragment,hn),xr=r(hn),uo=m(hn,"P",{"data-svelte-h":!0}),_(uo)!=="svelte-ybie7i"&&(uo.textContent=ba),hn.forEach(o),Ar=r(Ie),we=m(Ie,"DIV",{class:!0});var $n=w(we);g(At.$$.fragment,$n),Mr=r($n),fo=m($n,"P",{"data-svelte-h":!0}),_(fo)!=="svelte-chc6sp"&&(fo.textContent=_a),$n.forEach(o),Ie.forEach(o),en=r(e),g(Mt.$$.fragment,e),tn=r(e),Z=m(e,"DIV",{class:!0});var Ce=w(Z);g(kt.$$.fragment,Ce),kr=r(Ce),ho=m(Ce,"P",{"data-svelte-h":!0}),_(ho)!=="svelte-ckiqb6"&&(ho.textContent=va),Ir=r(Ce),xe=m(Ce,"DIV",{class:!0});var bn=w(xe);g(It.$$.fragment,bn),Cr=r(bn),$o=m(bn,"P",{"data-svelte-h":!0}),_($o)!=="svelte-10rnn1x"&&($o.innerHTML=ya),bn.forEach(o),Pr=r(Ce),Ae=m(Ce,"DIV",{class:!0});var _n=w(Ae);g(Ct.$$.fragment,_n),Hr=r(_n),bo=m(_n,"P",{"data-svelte-h":!0}),_(bo)!=="svelte-1xu9o93"&&(bo.textContent=Ta),_n.forEach(o),Ce.forEach(o),on=r(e),vo=m(e,"P",{}),w(vo).forEach(o),this.h()},h(){x(l,"name","hf:doc:metadata"),x(l,"content",Wa),x(z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(N,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(L,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(J,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(U,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(D,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(B,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(ce,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(H,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(S,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(ge,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(ue,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(fe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(R,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(he,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(M,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x($e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(be,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(_e,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(ve,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(I,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(ye,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(Y,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(q,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(X,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(O,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(Te,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(we,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(E,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(xe,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(Ae,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8"),x(Z,"class","docstring border-l-2 border-t-2 pl-4 pt-3.5 border-gray-100 rounded-tl-xl mb-6 mt-8")},m(e,s){t(document.head,l),d(e,T,s),d(e,b,s),d(e,p,s),u(v,e,s),d(e,a,s),u(y,e,s),d(e,yo,s),d(e,Pe,s),d(e,To,s),u(He,e,s),d(e,wo,s),d(e,je,s),d(e,xo,s),u(Le,e,s),d(e,Ao,s),d(e,z,s),u(Je,z,null),t(z,vn),t(z,Jt),t(z,yn),u(ne,z,null),d(e,Mo,s),u(Ue,e,s),d(e,ko,s),d(e,L,s),u(qe,L,null),t(L,Tn),t(L,Ut),t(L,wn),u(re,L,null),t(L,xn),t(L,N),u(Ee,N,null),t(N,An),t(N,qt),t(N,Mn),u(ae,N,null),d(e,Io,s),u(Ze,e,s),d(e,Co,s),d(e,J,s),u(We,J,null),t(J,kn),t(J,Et),t(J,In),u(se,J,null),t(J,Cn),u(le,J,null),d(e,Po,s),u(Re,e,s),d(e,Ho,s),d(e,U,s),u(ze,U,null),t(U,Pn),t(U,Zt),t(U,Hn),u(ie,U,null),t(U,jn),u(me,U,null),d(e,jo,s),u(Qe,e,s),d(e,Lo,s),d(e,H,s),u(Ge,H,null),t(H,Ln),t(H,Wt),t(H,Jn),t(H,D),u(Ve,D,null),t(D,Un),t(D,Rt),t(D,qn),u(de,D,null),t(H,En),t(H,B),u(Ne,B,null),t(B,Zn),t(B,zt),t(B,Wn),u(pe,B,null),t(H,Rn),t(H,ce),u(De,ce,null),t(ce,zn),t(ce,Qt),d(e,Jo,s),u(Be,e,s),d(e,Uo,s),u(Ye,e,s),d(e,qo,s),d(e,S,s),u(Fe,S,null),t(S,Qn),t(S,Gt),d(e,Eo,s),u(Se,e,s),d(e,Zo,s),d(e,M,s),u(Xe,M,null),t(M,Gn),t(M,Vt),t(M,Vn),t(M,Nt),t(M,Nn),t(M,Dt),t(M,Dn),t(M,ge),u(Oe,ge,null),t(ge,Bn),t(ge,Bt),t(M,Yn),t(M,ue),u(Ke,ue,null),t(ue,Fn),t(ue,Yt),t(M,Sn),t(M,fe),u(et,fe,null),t(fe,Xn),t(fe,Ft),t(M,On),t(M,R),u(tt,R,null),t(R,Kn),t(R,St),t(R,er),t(R,Xt),t(R,tr),t(R,Ot),t(M,or),t(M,he),u(ot,he,null),t(he,nr),t(he,Kt),d(e,Wo,s),u(nt,e,s),d(e,Ro,s),d(e,I,s),u(rt,I,null),t(I,rr),t(I,eo),t(I,ar),t(I,to),t(I,sr),t(I,$e),u(at,$e,null),t($e,lr),t($e,oo),t(I,ir),t(I,be),u(st,be,null),t(be,mr),t(be,no),t(I,dr),t(I,_e),u(lt,_e,null),t(_e,pr),t(_e,ro),t(I,cr),t(I,ve),u(it,ve,null),t(ve,gr),t(ve,ao),d(e,zo,s),u(mt,e,s),d(e,Qo,s),d(e,q,s),u(dt,q,null),t(q,ur),t(q,so),t(q,fr),t(q,ye),u(pt,ye,null),t(ye,hr),t(ye,lo),t(q,$r),t(q,Y),u(ct,Y,null),t(Y,br),t(Y,io),t(Y,_r),t(Y,mo),d(e,Go,s),u(gt,e,s),d(e,Vo,s),d(e,X,s),u(ut,X,null),t(X,vr),t(X,po),d(e,No,s),u(ft,e,s),d(e,Do,s),d(e,ht,s),d(e,Bo,s),d(e,$t,s),d(e,Yo,s),d(e,bt,s),d(e,Fo,s),d(e,_t,s),d(e,So,s),u(vt,e,s),d(e,Xo,s),d(e,O,s),u(yt,O,null),t(O,yr),t(O,co),d(e,Oo,s),u(Tt,e,s),d(e,Ko,s),d(e,E,s),u(wt,E,null),t(E,Tr),t(E,go),t(E,wr),t(E,Te),u(xt,Te,null),t(Te,xr),t(Te,uo),t(E,Ar),t(E,we),u(At,we,null),t(we,Mr),t(we,fo),d(e,en,s),u(Mt,e,s),d(e,tn,s),d(e,Z,s),u(kt,Z,null),t(Z,kr),t(Z,ho),t(Z,Ir),t(Z,xe),u(It,xe,null),t(xe,Cr),t(xe,$o),t(Z,Pr),t(Z,Ae),u(Ct,Ae,null),t(Ae,Hr),t(Ae,bo),d(e,on,s),d(e,vo,s),nn=!0},p(e,[s]){const K={};s&2&&(K.$$scope={dirty:s,ctx:e}),y.$set(K);const Q={};s&2&&(Q.$$scope={dirty:s,ctx:e}),ne.$set(Q);const ee={};s&2&&(ee.$$scope={dirty:s,ctx:e}),re.$set(ee);const G={};s&2&&(G.$$scope={dirty:s,ctx:e}),ae.$set(G);const V={};s&2&&(V.$$scope={dirty:s,ctx:e}),se.$set(V);const W={};s&2&&(W.$$scope={dirty:s,ctx:e}),le.$set(W);const te={};s&2&&(te.$$scope={dirty:s,ctx:e}),ie.$set(te);const oe={};s&2&&(oe.$$scope={dirty:s,ctx:e}),me.$set(oe);const Pt={};s&2&&(Pt.$$scope={dirty:s,ctx:e}),de.$set(Pt);const Ht={};s&2&&(Ht.$$scope={dirty:s,ctx:e}),pe.$set(Ht)},i(e){nn||(f(v.$$.fragment,e),f(y.$$.fragment,e),f(He.$$.fragment,e),f(Le.$$.fragment,e),f(Je.$$.fragment,e),f(ne.$$.fragment,e),f(Ue.$$.fragment,e),f(qe.$$.fragment,e),f(re.$$.fragment,e),f(Ee.$$.fragment,e),f(ae.$$.fragment,e),f(Ze.$$.fragment,e),f(We.$$.fragment,e),f(se.$$.fragment,e),f(le.$$.fragment,e),f(Re.$$.fragment,e),f(ze.$$.fragment,e),f(ie.$$.fragment,e),f(me.$$.fragment,e),f(Qe.$$.fragment,e),f(Ge.$$.fragment,e),f(Ve.$$.fragment,e),f(de.$$.fragment,e),f(Ne.$$.fragment,e),f(pe.$$.fragment,e),f(De.$$.fragment,e),f(Be.$$.fragment,e),f(Ye.$$.fragment,e),f(Fe.$$.fragment,e),f(Se.$$.fragment,e),f(Xe.$$.fragment,e),f(Oe.$$.fragment,e),f(Ke.$$.fragment,e),f(et.$$.fragment,e),f(tt.$$.fragment,e),f(ot.$$.fragment,e),f(nt.$$.fragment,e),f(rt.$$.fragment,e),f(at.$$.fragment,e),f(st.$$.fragment,e),f(lt.$$.fragment,e),f(it.$$.fragment,e),f(mt.$$.fragment,e),f(dt.$$.fragment,e),f(pt.$$.fragment,e),f(ct.$$.fragment,e),f(gt.$$.fragment,e),f(ut.$$.fragment,e),f(ft.$$.fragment,e),f(vt.$$.fragment,e),f(yt.$$.fragment,e),f(Tt.$$.fragment,e),f(wt.$$.fragment,e),f(xt.$$.fragment,e),f(At.$$.fragment,e),f(Mt.$$.fragment,e),f(kt.$$.fragment,e),f(It.$$.fragment,e),f(Ct.$$.fragment,e),nn=!0)},o(e){h(v.$$.fragment,e),h(y.$$.fragment,e),h(He.$$.fragment,e),h(Le.$$.fragment,e),h(Je.$$.fragment,e),h(ne.$$.fragment,e),h(Ue.$$.fragment,e),h(qe.$$.fragment,e),h(re.$$.fragment,e),h(Ee.$$.fragment,e),h(ae.$$.fragment,e),h(Ze.$$.fragment,e),h(We.$$.fragment,e),h(se.$$.fragment,e),h(le.$$.fragment,e),h(Re.$$.fragment,e),h(ze.$$.fragment,e),h(ie.$$.fragment,e),h(me.$$.fragment,e),h(Qe.$$.fragment,e),h(Ge.$$.fragment,e),h(Ve.$$.fragment,e),h(de.$$.fragment,e),h(Ne.$$.fragment,e),h(pe.$$.fragment,e),h(De.$$.fragment,e),h(Be.$$.fragment,e),h(Ye.$$.fragment,e),h(Fe.$$.fragment,e),h(Se.$$.fragment,e),h(Xe.$$.fragment,e),h(Oe.$$.fragment,e),h(Ke.$$.fragment,e),h(et.$$.fragment,e),h(tt.$$.fragment,e),h(ot.$$.fragment,e),h(nt.$$.fragment,e),h(rt.$$.fragment,e),h(at.$$.fragment,e),h(st.$$.fragment,e),h(lt.$$.fragment,e),h(it.$$.fragment,e),h(mt.$$.fragment,e),h(dt.$$.fragment,e),h(pt.$$.fragment,e),h(ct.$$.fragment,e),h(gt.$$.fragment,e),h(ut.$$.fragment,e),h(ft.$$.fragment,e),h(vt.$$.fragment,e),h(yt.$$.fragment,e),h(Tt.$$.fragment,e),h(wt.$$.fragment,e),h(xt.$$.fragment,e),h(At.$$.fragment,e),h(Mt.$$.fragment,e),h(kt.$$.fragment,e),h(It.$$.fragment,e),h(Ct.$$.fragment,e),nn=!1},d(e){e&&(o(T),o(b),o(p),o(a),o(yo),o(Pe),o(To),o(wo),o(je),o(xo),o(Ao),o(z),o(Mo),o(ko),o(L),o(Io),o(Co),o(J),o(Po),o(Ho),o(U),o(jo),o(Lo),o(H),o(Jo),o(Uo),o(qo),o(S),o(Eo),o(Zo),o(M),o(Wo),o(Ro),o(I),o(zo),o(Qo),o(q),o(Go),o(Vo),o(X),o(No),o(Do),o(ht),o(Bo),o($t),o(Yo),o(bt),o(Fo),o(_t),o(So),o(Xo),o(O),o(Oo),o(Ko),o(E),o(en),o(tn),o(Z),o(on),o(vo)),o(l),$(v,e),$(y,e),$(He,e),$(Le,e),$(Je),$(ne),$(Ue,e),$(qe),$(re),$(Ee),$(ae),$(Ze,e),$(We),$(se),$(le),$(Re,e),$(ze),$(ie),$(me),$(Qe,e),$(Ge),$(Ve),$(de),$(Ne),$(pe),$(De),$(Be,e),$(Ye,e),$(Fe),$(Se,e),$(Xe),$(Oe),$(Ke),$(et),$(tt),$(ot),$(nt,e),$(rt),$(at),$(st),$(lt),$(it),$(mt,e),$(dt),$(pt),$(ct),$(gt,e),$(ut),$(ft,e),$(vt,e),$(yt),$(Tt,e),$(wt),$(xt),$(At),$(Mt,e),$(kt),$(It),$(Ct)}}}const Wa='{"title":"Agents & Tools","local":"agents--tools","sections":[{"title":"Agents","local":"agents","sections":[{"title":"HfAgent","local":"transformers.HfAgent","sections":[],"depth":3},{"title":"LocalAgent","local":"transformers.LocalAgent","sections":[],"depth":3},{"title":"OpenAiAgent","local":"transformers.OpenAiAgent","sections":[],"depth":3},{"title":"AzureOpenAiAgent","local":"transformers.AzureOpenAiAgent","sections":[],"depth":3},{"title":"Agent","local":"transformers.Agent","sections":[],"depth":3}],"depth":2},{"title":"Tools","local":"tools","sections":[{"title":"load_tool","local":"transformers.load_tool","sections":[],"depth":3},{"title":"Tool","local":"transformers.Tool","sections":[],"depth":3},{"title":"PipelineTool","local":"transformers.PipelineTool","sections":[],"depth":3},{"title":"RemoteTool","local":"transformers.RemoteTool","sections":[],"depth":3},{"title":"launch_gradio_demo","local":"transformers.launch_gradio_demo","sections":[],"depth":3}],"depth":2},{"title":"Agent Types","local":"agent-types","sections":[{"title":"AgentText","local":"transformers.tools.agent_types.AgentText","sections":[],"depth":3},{"title":"AgentImage","local":"transformers.tools.agent_types.AgentImage","sections":[],"depth":3},{"title":"AgentAudio","local":"transformers.tools.agent_types.AgentAudio","sections":[],"depth":3}],"depth":2}],"depth":1}';function Ra(k){return xa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ya extends Aa{constructor(l){super(),Ma(this,l,Ra,Za,wa,{})}}export{Ya as component};
