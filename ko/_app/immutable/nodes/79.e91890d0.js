import{s as zt,o as St,n as Pt}from"../chunks/scheduler.56730f09.js";import{S as Yt,i as Dt,g as p,s as n,r as o,A as qt,h as r,f as s,c as a,j as Lt,u as i,x as d,k as $t,y as Kt,a as l,v as m,d as u,t as c,w as f}from"../chunks/index.1f144517.js";import{T as Nt}from"../chunks/Tip.41e845e5.js";import{Y as Xt}from"../chunks/Youtube.62e0f062.js";import{C as M}from"../chunks/CodeBlock.738eeccb.js";import{H as T}from"../chunks/Heading.57d46534.js";function Ot(Me){let g,h='메모리 절약 기술에 대한 자세한 내용은 성능 <a href="performance">가이드</a>를 참조하세요.';return{c(){g=p("p"),g.innerHTML=h},l($){g=r($,"P",{"data-svelte-h":!0}),d(g)!=="svelte-74wrmh"&&(g.innerHTML=h)},m($,j){l($,g,j)},p:Pt,d($){$&&s(g)}}}function es(Me){let g,h="일반적으로 토크나이저는 특정 토크나이저의 기본 값을 기준으로 사용자에 대한 ‘attention_mask’를 만듭니다.";return{c(){g=p("p"),g.textContent=h},l($){g=r($,"P",{"data-svelte-h":!0}),d(g)!=="svelte-1afkfxz"&&(g.textContent=h)},m($,j){l($,g,j)},p:Pt,d($){$&&s(g)}}}function ts(Me){let g,h,$,j,U,je,C,Mt="때때로 오류가 발생할 수 있지만, 저희가 도와드리겠습니다! 이 가이드는 현재까지 확인된 가장 일반적인 문제 몇 가지와 그것들을 해결하는 방법에 대해 다룹니다. 그러나 이 가이드는 모든 🤗 Transformers 문제를 포괄적으로 다루고 있지 않습니다. 문제 해결에 더 많은 도움을 받으려면 다음을 시도해보세요:",ye,v,be,J,ht='<li><a href="https://discuss.huggingface.co/" rel="nofollow">포럼</a>에서 도움을 요청하세요. <a href="https://discuss.huggingface.co/c/beginners/5" rel="nofollow">Beginners</a> 또는 <a href="https://discuss.huggingface.co/c/transformers/9" rel="nofollow">🤗 Transformers</a>와 같은 특정 카테고리에 질문을 게시할 수 있습니다. 재현 가능한 코드와 함께 잘 서술된 포럼 게시물을 작성하여 여러분의 문제가 해결될 가능성을 극대화하세요!</li>',we,_,Te,y,jt='<li><p>라이브러리와 관련된 버그이면 🤗 Transformers 저장소에서 <a href="https://github.com/huggingface/transformers/issues/new/choose" rel="nofollow">이슈</a>를 생성하세요. 버그에 대해 설명하는 정보를 가능한 많이 포함하려고 노력하여, 무엇이 잘못 되었는지와 어떻게 수정할 수 있는지 더 잘 파악할 수 있도록 도와주세요.</p></li> <li><p>이전 버전의 🤗 Transformers을 사용하는 경우 중요한 변경 사항이 버전 사이에 도입되었기 때문에 <a href="migration">마이그레이션</a> 가이드를 확인하세요.</p></li>',Ue,k,yt='문제 해결 및 도움 매뉴얼에 대한 자세한 내용은 Hugging Face 강좌의 <a href="https://huggingface.co/course/chapter8/1?fw=pt" rel="nofollow">8장</a>을 참조하세요.',Ce,V,ve,Z,bt="클라우드 및 내부망(intranet) 설정의 일부 GPU 인스턴스는 외부 연결에 대한 방화벽으로 차단되어 연결 오류가 발생할 수 있습니다. 스크립트가 모델 가중치나 데이터를 다운로드하려고 할 때, 다운로드가 중단되고 다음 메시지와 함께 시간 초과됩니다:",Je,G,_e,W,wt='이 경우에는 연결 오류를 피하기 위해 🤗 Transformers를 <a href="installation#offline-mode">오프라인 모드</a>로 실행해야 합니다.',ke,x,Ve,I,Tt="수백만 개의 매개변수로 대규모 모델을 훈련하는 것은 적절한 하드웨어 없이 어려울 수 있습니다. GPU 메모리가 부족한 경우 발생할 수 있는 일반적인 오류는 다음과 같습니다:",Ze,Q,Ge,B,Ut="다음은 메모리 사용을 줄이기 위해 시도해 볼 수 있는 몇 가지 잠재적인 해결책입니다:",We,H,Ct='<li><code>TrainingArguments</code>의 <a href="main_classes/trainer#transformers.TrainingArguments.per_device_train_batch_size"><code>per_device_train_batch_size</code></a> 값을 줄이세요.</li> <li><code>TrainingArguments</code>의 <a href="main_classes/trainer#transformers.TrainingArguments.gradient_accumulation_steps"><code>gradient_accumulation_steps</code></a>은 전체 배치 크기를 효과적으로 늘리세요.</li>',xe,b,Ie,E,Qe,F,vt='TensorFlow의 <a href="https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model" rel="nofollow">model.save</a> 메소드는 아키텍처, 가중치, 훈련 구성 등 전체 모델을 단일 파일에 저장합니다. 그러나 모델 파일을 다시 가져올 때 🤗 Transformers는 모델 파일에 있는 모든 TensorFlow 관련 객체를 가져오지 않을 수 있기 때문에 오류가 발생할 수 있습니다. TensorFlow 모델 저장 및 가져오기 문제를 피하려면 다음을 권장합니다:',Be,R,Jt='<li>모델 가중치를 <code>h5</code> 파일 확장자로 <a href="https://www.tensorflow.org/tutorials/keras/save_and_load#save_the_entire_model" rel="nofollow"><code>model.save_weights</code></a>로 저장한 다음 <code>from_pretrained()</code>로 모델을 다시 가져옵니다:</li>',He,A,Ee,L,_t="<li>모델을 <code>~TFPretrainedModel.save_pretrained</code>로 저장하고 <code>from_pretrained()</code>로 다시 가져옵니다:</li>",Fe,N,Re,X,Ae,P,kt="특히 최신 모델인 경우 만날 수 있는 다른 일반적인 오류는 <code>ImportError</code>입니다:",Le,z,Ne,S,Vt="이러한 오류 유형의 경우 최신 모델에 액세스할 수 있도록 최신 버전의 🤗 Transformers가 설치되어 있는지 확인하세요:",Xe,Y,Pe,D,ze,q,Zt="때때로 장치 코드 오류에 대한 일반적인 CUDA 오류가 발생할 수 있습니다.",Se,K,Ye,O,Gt="더 자세한 오류 메시지를 얻으려면 우선 코드를 CPU에서 실행합니다. 다음 환경 변수를 코드의 시작 부분에 추가하여 CPU로 전환하세요:",De,ee,qe,te,Wt="또 다른 옵션은 GPU에서 더 나은 역추적(traceback)을 얻는 것입니다. 다음 환경 변수를 코드의 시작 부분에 추가하여 역추적이 오류가 발생한 소스를 가리키도록 하세요:",Ke,se,Oe,le,et,ne,xt="경우에 따라 <code>input_ids</code>에 패딩 토큰이 포함된 경우 <code>hidden_state</code> 출력이 올바르지 않을 수 있습니다. 데모를 위해 모델과 토크나이저를 가져오세요. 모델의 <code>pad_token_id</code>에 액세스하여 해당 값을 확인할 수 있습니다. 일부 모델의 경우 <code>pad_token_id</code>가 <code>None</code>일 수 있지만 언제든지 수동으로 설정할 수 있습니다.",tt,ae,st,pe,It="다음 예제는 패딩 토큰을 마스킹하지 않은 출력을 보여줍니다:",lt,re,nt,oe,Qt="다음은 두 번째 시퀀스의 실제 출력입니다:",at,ie,pt,me,Bt="대부분의 경우 모델에 <code>attention_mask</code>를 제공하여 패딩 토큰을 무시해야 이러한 조용한 오류를 방지할 수 있습니다. 이제 두 번째 시퀀스의 출력이 실제 출력과 일치합니다:",rt,w,ot,ue,it,ce,Ht="🤗 Transformers는 패딩 토큰이 제공된 경우 패딩 토큰을 마스킹하기 위한 <code>attention_mask</code>를 자동으로 생성하지 않습니다. 그 이유는 다음과 같습니다:",mt,fe,Et="<li>일부 모델에는 패딩 토큰이 없습니다.</li> <li>일부 사용 사례의 경우 사용자가 모델이 패딩 토큰을 관리하기를 원합니다.</li>",ut,de,ct,ge,Ft=`일반적으로, 사전 학습된 모델의 인스턴스를 가져오기 위해 <code>AutoModel</code> 클래스를 사용하는 것이 좋습니다.
이 클래스는 구성에 따라 주어진 체크포인트에서 올바른 아키텍처를 자동으로 추론하고 가져올 수 있습니다.
모델을 체크포인트에서 가져올 때 이 <code>ValueError</code>가 발생하면, 이는 Auto 클래스가 주어진 체크포인트의 구성에서
가져오려는 모델 유형과 매핑을 찾을 수 없다는 것을 의미합니다. 가장 흔하게 발생하는 경우는
체크포인트가 주어진 태스크를 지원하지 않을 때입니다.
예를 들어, 다음 예제에서 질의응답에 대한 GPT2가 없기 때문에 오류가 발생합니다:`,ft,$e,dt,he,gt;return U=new T({props:{title:"문제 해결",local:"troubleshoot",headingTag:"h1"}}),v=new Xt({props:{id:"S2EEG3JIt2A"}}),_=new Xt({props:{id:"_PAli-V4wj0"}}),V=new T({props:{title:"방화벽 환경",local:"firewalled-environments",headingTag:"h2"}}),G=new M({props:{code:"VmFsdWVFcnJvciUzQSUyMENvbm5lY3Rpb24lMjBlcnJvciUyQyUyMGFuZCUyMHdlJTIwY2Fubm90JTIwZmluZCUyMHRoZSUyMHJlcXVlc3RlZCUyMGZpbGVzJTIwaW4lMjB0aGUlMjBjYWNoZWQlMjBwYXRoLiUwQVBsZWFzZSUyMHRyeSUyMGFnYWluJTIwb3IlMjBtYWtlJTIwc3VyZSUyMHlvdXIlMjBJbnRlcm5ldCUyMGNvbm5lY3Rpb24lMjBpcyUyMG9uLg==",highlighted:`ValueError: Connection error, <span class="hljs-built_in">and</span> we cannot <span class="hljs-keyword">find</span> the requested <span class="hljs-keyword">files</span> in the cached path.
Please <span class="hljs-keyword">try</span> again <span class="hljs-built_in">or</span> <span class="hljs-keyword">make</span> sure your Internet connection <span class="hljs-keyword">is</span> <span class="hljs-keyword">on</span>.`,wrap:!1}}),x=new T({props:{title:"CUDA 메모리 부족(CUDA out of memory)",local:"cuda-out-of-memory",headingTag:"h2"}}),Q=new M({props:{code:"Q1VEQSUyMG91dCUyMG9mJTIwbWVtb3J5LiUyMFRyaWVkJTIwdG8lMjBhbGxvY2F0ZSUyMDI1Ni4wMCUyME1pQiUyMChHUFUlMjAwJTNCJTIwMTEuMTclMjBHaUIlMjB0b3RhbCUyMGNhcGFjaXR5JTNCJTIwOS43MCUyMEdpQiUyMGFscmVhZHklMjBhbGxvY2F0ZWQlM0IlMjAxNzkuODElMjBNaUIlMjBmcmVlJTNCJTIwOS44NSUyMEdpQiUyMHJlc2VydmVkJTIwaW4lMjB0b3RhbCUyMGJ5JTIwUHlUb3JjaCk=",highlighted:'<span class="hljs-attribute">CUDA</span> out of memory. Tried to allocate <span class="hljs-number">256</span>.<span class="hljs-number">00</span> MiB (GPU <span class="hljs-number">0</span>; <span class="hljs-number">11</span>.<span class="hljs-number">17</span> GiB total capacity; <span class="hljs-number">9</span>.<span class="hljs-number">70</span> GiB already allocated; <span class="hljs-number">179</span>.<span class="hljs-number">81</span> MiB free; <span class="hljs-number">9</span>.<span class="hljs-number">85</span> GiB reserved in total by PyTorch)',wrap:!1}}),b=new Nt({props:{$$slots:{default:[Ot]},$$scope:{ctx:Me}}}),E=new T({props:{title:"저장된 TensorFlow 모델을 가져올 수 없습니다(Unable to load a saved TensorFlow model)",local:"unable-to-load-a-saved-uensorFlow-model",headingTag:"h2"}}),A=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGUHJlVHJhaW5lZE1vZGVsJTBBZnJvbSUyMHRlbnNvcmZsb3clMjBpbXBvcnQlMjBrZXJhcyUwQSUwQW1vZGVsLnNhdmVfd2VpZ2h0cyglMjJzb21lX2ZvbGRlciUyRnRmX21vZGVsLmg1JTIyKSUwQW1vZGVsJTIwJTNEJTIwVEZQcmVUcmFpbmVkTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMnNvbWVfZm9sZGVyJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFPreTrainedModel
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras

<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_weights(<span class="hljs-string">&quot;some_folder/tf_model.h5&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFPreTrainedModel.from_pretrained(<span class="hljs-string">&quot;some_folder&quot;</span>)`,wrap:!1}}),N=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGUHJlVHJhaW5lZE1vZGVsJTBBJTBBbW9kZWwuc2F2ZV9wcmV0cmFpbmVkKCUyMnBhdGhfdG8lMkZtb2RlbCUyMiklMEFtb2RlbCUyMCUzRCUyMFRGUHJlVHJhaW5lZE1vZGVsLmZyb21fcHJldHJhaW5lZCglMjJwYXRoX3RvJTJGbW9kZWwlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFPreTrainedModel

<span class="hljs-meta">&gt;&gt;&gt; </span>model.save_pretrained(<span class="hljs-string">&quot;path_to/model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFPreTrainedModel.from_pretrained(<span class="hljs-string">&quot;path_to/model&quot;</span>)`,wrap:!1}}),X=new T({props:{title:"ImportError",local:"importerror",headingTag:"h2"}}),z=new M({props:{code:"SW1wb3J0RXJyb3IlM0ElMjBjYW5ub3QlMjBpbXBvcnQlMjBuYW1lJTIwJ0ltYWdlR1BUSW1hZ2VQcm9jZXNzb3InJTIwZnJvbSUyMCd0cmFuc2Zvcm1lcnMnJTIwKHVua25vd24lMjBsb2NhdGlvbik=",highlighted:'ImportError: cannot <span class="hljs-keyword">import</span> <span class="hljs-type">name</span> <span class="hljs-string">&#x27;ImageGPTImageProcessor&#x27;</span> <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;transformers&#x27;</span> (<span class="hljs-type">unknown</span> <span class="hljs-keyword">location</span>)',wrap:!1}}),Y=new M({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMC0tdXBncmFkZQ==",highlighted:"pip install transformers --upgrade",wrap:!1}}),D=new T({props:{title:"CUDA error: device-side assert triggered",local:"cuda-error-deviceside-assert-triggered",headingTag:"h2"}}),K=new M({props:{code:"UnVudGltZUVycm9yJTNBJTIwQ1VEQSUyMGVycm9yJTNBJTIwZGV2aWNlLXNpZGUlMjBhc3NlcnQlMjB0cmlnZ2VyZWQ=",highlighted:'RuntimeError: CUDA <span class="hljs-literal">error</span>: device-<span class="hljs-literal">side</span> <span class="hljs-keyword">assert</span> triggered',wrap:!1}}),ee=new M({props:{code:"aW1wb3J0JTIwb3MlMEElMEFvcy5lbnZpcm9uJTVCJTIyQ1VEQV9WSVNJQkxFX0RFVklDRVMlMjIlNUQlMjAlM0QlMjAlMjIlMjI=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os

<span class="hljs-meta">&gt;&gt;&gt; </span>os.environ[<span class="hljs-string">&quot;CUDA_VISIBLE_DEVICES&quot;</span>] = <span class="hljs-string">&quot;&quot;</span>`,wrap:!1}}),se=new M({props:{code:"aW1wb3J0JTIwb3MlMEElMEFvcy5lbnZpcm9uJTVCJTIyQ1VEQV9MQVVOQ0hfQkxPQ0tJTkclMjIlNUQlMjAlM0QlMjAlMjIxJTIy",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> os

<span class="hljs-meta">&gt;&gt;&gt; </span>os.environ[<span class="hljs-string">&quot;CUDA_LAUNCH_BLOCKING&quot;</span>] = <span class="hljs-string">&quot;1&quot;</span>`,wrap:!1}}),le=new T({props:{title:"패딩 토큰이 마스킹되지 않은 경우 잘못된 출력(Incorrect output when padding tokens aren’t masked)",local:"incorrect-output-when-padding-tokens-arent-masked",headingTag:"h2"}}),ae=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEFpbXBvcnQlMjB0b3JjaCUwQSUwQW1vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlLWJlcnQlMkZiZXJ0LWJhc2UtdW5jYXNlZCUyMiklMEFtb2RlbC5jb25maWcucGFkX3Rva2VuX2lk",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.pad_token_id
<span class="hljs-number">0</span>`,wrap:!1}}),re=new M({props:{code:"aW5wdXRfaWRzJTIwJTNEJTIwdG9yY2gudGVuc29yKCU1QiU1Qjc1OTIlMkMlMjAyMDU3JTJDJTIwMjA5NyUyQyUyMDIzOTMlMkMlMjA5NjExJTJDJTIwMjExNSU1RCUyQyUyMCU1Qjc1OTIlMkMlMjAwJTJDJTIwMCUyQyUyMDAlMkMlMjAwJTJDJTIwMCU1RCU1RCklMEFvdXRwdXQlMjAlM0QlMjBtb2RlbChpbnB1dF9pZHMpJTBBcHJpbnQob3V0cHV0LmxvZ2l0cyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([[<span class="hljs-number">7592</span>, <span class="hljs-number">2057</span>, <span class="hljs-number">2097</span>, <span class="hljs-number">2393</span>, <span class="hljs-number">9611</span>, <span class="hljs-number">2115</span>], [<span class="hljs-number">7592</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[ <span class="hljs-number">0.0082</span>, -<span class="hljs-number">0.2307</span>],
        [ <span class="hljs-number">0.1317</span>, -<span class="hljs-number">0.1683</span>]], grad_fn=&lt;AddmmBackward0&gt;)`,wrap:!1}}),ie=new M({props:{code:"aW5wdXRfaWRzJTIwJTNEJTIwdG9yY2gudGVuc29yKCU1QiU1Qjc1OTIlNUQlNUQpJTBBb3V0cHV0JTIwJTNEJTIwbW9kZWwoaW5wdXRfaWRzKSUwQXByaW50KG91dHB1dC5sb2dpdHMp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([[<span class="hljs-number">7592</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[-<span class="hljs-number">0.1008</span>, -<span class="hljs-number">0.4061</span>]], grad_fn=&lt;AddmmBackward0&gt;)`,wrap:!1}}),w=new Nt({props:{$$slots:{default:[es]},$$scope:{ctx:Me}}}),ue=new M({props:{code:"YXR0ZW50aW9uX21hc2slMjAlM0QlMjB0b3JjaC50ZW5zb3IoJTVCJTVCMSUyQyUyMDElMkMlMjAxJTJDJTIwMSUyQyUyMDElMkMlMjAxJTVEJTJDJTIwJTVCMSUyQyUyMDAlMkMlMjAwJTJDJTIwMCUyQyUyMDAlMkMlMjAwJTVEJTVEKSUwQW91dHB1dCUyMCUzRCUyMG1vZGVsKGlucHV0X2lkcyUyQyUyMGF0dGVudGlvbl9tYXNrJTNEYXR0ZW50aW9uX21hc2spJTBBcHJpbnQob3V0cHV0LmxvZ2l0cyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>attention_mask = torch.tensor([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>]])
<span class="hljs-meta">&gt;&gt;&gt; </span>output = model(input_ids, attention_mask=attention_mask)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(output.logits)
tensor([[ <span class="hljs-number">0.0082</span>, -<span class="hljs-number">0.2307</span>],
        [-<span class="hljs-number">0.1008</span>, -<span class="hljs-number">0.4061</span>]], grad_fn=&lt;AddmmBackward0&gt;)`,wrap:!1}}),de=new T({props:{title:"ValueError: 이 유형의 AutoModel에 대해 인식할 수 없는 XYZ 구성 클래스(ValueError: Unrecognized configuration class XYZ for this kind of AutoModel)",local:"valueerror-unrecognized-configuration-class-xyz-for-this-kind-of-automodel",headingTag:"h2"}}),$e=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMkMlMjBBdXRvTW9kZWxGb3JRdWVzdGlvbkFuc3dlcmluZyUwQSUwQXByb2Nlc3NvciUyMCUzRCUyMEF1dG9Qcm9jZXNzb3IuZnJvbV9wcmV0cmFpbmVkKCUyMm9wZW5haS1jb21tdW5pdHklMkZncHQyLW1lZGl1bSUyMiklMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclF1ZXN0aW9uQW5zd2VyaW5nLmZyb21fcHJldHJhaW5lZCglMjJvcGVuYWktY29tbXVuaXR5JTJGZ3B0Mi1tZWRpdW0lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor, AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;openai-community/gpt2-medium&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;openai-community/gpt2-medium&quot;</span>)
ValueError: Unrecognized configuration <span class="hljs-keyword">class</span> &lt;<span class="hljs-keyword">class</span> <span class="hljs-string">&#x27;transformers.models.gpt2.configuration_gpt2.GPT2Config&#x27;</span>&gt; <span class="hljs-keyword">for</span> this kind of AutoModel: AutoModelForQuestionAnswering.
Model <span class="hljs-built_in">type</span> should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BloomConfig, ...`,wrap:!1}}),{c(){g=p("meta"),h=n(),$=p("p"),j=n(),o(U.$$.fragment),je=n(),C=p("p"),C.textContent=Mt,ye=n(),o(v.$$.fragment),be=n(),J=p("ol"),J.innerHTML=ht,we=n(),o(_.$$.fragment),Te=n(),y=p("ol"),y.innerHTML=jt,Ue=n(),k=p("p"),k.innerHTML=yt,Ce=n(),o(V.$$.fragment),ve=n(),Z=p("p"),Z.textContent=bt,Je=n(),o(G.$$.fragment),_e=n(),W=p("p"),W.innerHTML=wt,ke=n(),o(x.$$.fragment),Ve=n(),I=p("p"),I.textContent=Tt,Ze=n(),o(Q.$$.fragment),Ge=n(),B=p("p"),B.textContent=Ut,We=n(),H=p("ul"),H.innerHTML=Ct,xe=n(),o(b.$$.fragment),Ie=n(),o(E.$$.fragment),Qe=n(),F=p("p"),F.innerHTML=vt,Be=n(),R=p("ul"),R.innerHTML=Jt,He=n(),o(A.$$.fragment),Ee=n(),L=p("ul"),L.innerHTML=_t,Fe=n(),o(N.$$.fragment),Re=n(),o(X.$$.fragment),Ae=n(),P=p("p"),P.innerHTML=kt,Le=n(),o(z.$$.fragment),Ne=n(),S=p("p"),S.textContent=Vt,Xe=n(),o(Y.$$.fragment),Pe=n(),o(D.$$.fragment),ze=n(),q=p("p"),q.textContent=Zt,Se=n(),o(K.$$.fragment),Ye=n(),O=p("p"),O.textContent=Gt,De=n(),o(ee.$$.fragment),qe=n(),te=p("p"),te.textContent=Wt,Ke=n(),o(se.$$.fragment),Oe=n(),o(le.$$.fragment),et=n(),ne=p("p"),ne.innerHTML=xt,tt=n(),o(ae.$$.fragment),st=n(),pe=p("p"),pe.textContent=It,lt=n(),o(re.$$.fragment),nt=n(),oe=p("p"),oe.textContent=Qt,at=n(),o(ie.$$.fragment),pt=n(),me=p("p"),me.innerHTML=Bt,rt=n(),o(w.$$.fragment),ot=n(),o(ue.$$.fragment),it=n(),ce=p("p"),ce.innerHTML=Ht,mt=n(),fe=p("ul"),fe.innerHTML=Et,ut=n(),o(de.$$.fragment),ct=n(),ge=p("p"),ge.innerHTML=Ft,ft=n(),o($e.$$.fragment),dt=n(),he=p("p"),this.h()},l(e){const t=qt("svelte-u9bgzb",document.head);g=r(t,"META",{name:!0,content:!0}),t.forEach(s),h=a(e),$=r(e,"P",{}),Lt($).forEach(s),j=a(e),i(U.$$.fragment,e),je=a(e),C=r(e,"P",{"data-svelte-h":!0}),d(C)!=="svelte-lsu3nl"&&(C.textContent=Mt),ye=a(e),i(v.$$.fragment,e),be=a(e),J=r(e,"OL",{"data-svelte-h":!0}),d(J)!=="svelte-ucur6z"&&(J.innerHTML=ht),we=a(e),i(_.$$.fragment,e),Te=a(e),y=r(e,"OL",{start:!0,"data-svelte-h":!0}),d(y)!=="svelte-uo4aew"&&(y.innerHTML=jt),Ue=a(e),k=r(e,"P",{"data-svelte-h":!0}),d(k)!=="svelte-1uhar05"&&(k.innerHTML=yt),Ce=a(e),i(V.$$.fragment,e),ve=a(e),Z=r(e,"P",{"data-svelte-h":!0}),d(Z)!=="svelte-12ucoaj"&&(Z.textContent=bt),Je=a(e),i(G.$$.fragment,e),_e=a(e),W=r(e,"P",{"data-svelte-h":!0}),d(W)!=="svelte-11zq317"&&(W.innerHTML=wt),ke=a(e),i(x.$$.fragment,e),Ve=a(e),I=r(e,"P",{"data-svelte-h":!0}),d(I)!=="svelte-1c8hb26"&&(I.textContent=Tt),Ze=a(e),i(Q.$$.fragment,e),Ge=a(e),B=r(e,"P",{"data-svelte-h":!0}),d(B)!=="svelte-15g2fcx"&&(B.textContent=Ut),We=a(e),H=r(e,"UL",{"data-svelte-h":!0}),d(H)!=="svelte-meem4b"&&(H.innerHTML=Ct),xe=a(e),i(b.$$.fragment,e),Ie=a(e),i(E.$$.fragment,e),Qe=a(e),F=r(e,"P",{"data-svelte-h":!0}),d(F)!=="svelte-1v88cop"&&(F.innerHTML=vt),Be=a(e),R=r(e,"UL",{"data-svelte-h":!0}),d(R)!=="svelte-colwgc"&&(R.innerHTML=Jt),He=a(e),i(A.$$.fragment,e),Ee=a(e),L=r(e,"UL",{"data-svelte-h":!0}),d(L)!=="svelte-15oz86s"&&(L.innerHTML=_t),Fe=a(e),i(N.$$.fragment,e),Re=a(e),i(X.$$.fragment,e),Ae=a(e),P=r(e,"P",{"data-svelte-h":!0}),d(P)!=="svelte-1ujp2u8"&&(P.innerHTML=kt),Le=a(e),i(z.$$.fragment,e),Ne=a(e),S=r(e,"P",{"data-svelte-h":!0}),d(S)!=="svelte-m1x930"&&(S.textContent=Vt),Xe=a(e),i(Y.$$.fragment,e),Pe=a(e),i(D.$$.fragment,e),ze=a(e),q=r(e,"P",{"data-svelte-h":!0}),d(q)!=="svelte-1tlsczl"&&(q.textContent=Zt),Se=a(e),i(K.$$.fragment,e),Ye=a(e),O=r(e,"P",{"data-svelte-h":!0}),d(O)!=="svelte-17874yl"&&(O.textContent=Gt),De=a(e),i(ee.$$.fragment,e),qe=a(e),te=r(e,"P",{"data-svelte-h":!0}),d(te)!=="svelte-eyhzxh"&&(te.textContent=Wt),Ke=a(e),i(se.$$.fragment,e),Oe=a(e),i(le.$$.fragment,e),et=a(e),ne=r(e,"P",{"data-svelte-h":!0}),d(ne)!=="svelte-1wwur9b"&&(ne.innerHTML=xt),tt=a(e),i(ae.$$.fragment,e),st=a(e),pe=r(e,"P",{"data-svelte-h":!0}),d(pe)!=="svelte-1qlewzi"&&(pe.textContent=It),lt=a(e),i(re.$$.fragment,e),nt=a(e),oe=r(e,"P",{"data-svelte-h":!0}),d(oe)!=="svelte-16yb6is"&&(oe.textContent=Qt),at=a(e),i(ie.$$.fragment,e),pt=a(e),me=r(e,"P",{"data-svelte-h":!0}),d(me)!=="svelte-jqbu9"&&(me.innerHTML=Bt),rt=a(e),i(w.$$.fragment,e),ot=a(e),i(ue.$$.fragment,e),it=a(e),ce=r(e,"P",{"data-svelte-h":!0}),d(ce)!=="svelte-2020ti"&&(ce.innerHTML=Ht),mt=a(e),fe=r(e,"UL",{"data-svelte-h":!0}),d(fe)!=="svelte-iyjkil"&&(fe.innerHTML=Et),ut=a(e),i(de.$$.fragment,e),ct=a(e),ge=r(e,"P",{"data-svelte-h":!0}),d(ge)!=="svelte-psmtvy"&&(ge.innerHTML=Ft),ft=a(e),i($e.$$.fragment,e),dt=a(e),he=r(e,"P",{}),Lt(he).forEach(s),this.h()},h(){$t(g,"name","hf:doc:metadata"),$t(g,"content",ss),$t(y,"start","2")},m(e,t){Kt(document.head,g),l(e,h,t),l(e,$,t),l(e,j,t),m(U,e,t),l(e,je,t),l(e,C,t),l(e,ye,t),m(v,e,t),l(e,be,t),l(e,J,t),l(e,we,t),m(_,e,t),l(e,Te,t),l(e,y,t),l(e,Ue,t),l(e,k,t),l(e,Ce,t),m(V,e,t),l(e,ve,t),l(e,Z,t),l(e,Je,t),m(G,e,t),l(e,_e,t),l(e,W,t),l(e,ke,t),m(x,e,t),l(e,Ve,t),l(e,I,t),l(e,Ze,t),m(Q,e,t),l(e,Ge,t),l(e,B,t),l(e,We,t),l(e,H,t),l(e,xe,t),m(b,e,t),l(e,Ie,t),m(E,e,t),l(e,Qe,t),l(e,F,t),l(e,Be,t),l(e,R,t),l(e,He,t),m(A,e,t),l(e,Ee,t),l(e,L,t),l(e,Fe,t),m(N,e,t),l(e,Re,t),m(X,e,t),l(e,Ae,t),l(e,P,t),l(e,Le,t),m(z,e,t),l(e,Ne,t),l(e,S,t),l(e,Xe,t),m(Y,e,t),l(e,Pe,t),m(D,e,t),l(e,ze,t),l(e,q,t),l(e,Se,t),m(K,e,t),l(e,Ye,t),l(e,O,t),l(e,De,t),m(ee,e,t),l(e,qe,t),l(e,te,t),l(e,Ke,t),m(se,e,t),l(e,Oe,t),m(le,e,t),l(e,et,t),l(e,ne,t),l(e,tt,t),m(ae,e,t),l(e,st,t),l(e,pe,t),l(e,lt,t),m(re,e,t),l(e,nt,t),l(e,oe,t),l(e,at,t),m(ie,e,t),l(e,pt,t),l(e,me,t),l(e,rt,t),m(w,e,t),l(e,ot,t),m(ue,e,t),l(e,it,t),l(e,ce,t),l(e,mt,t),l(e,fe,t),l(e,ut,t),m(de,e,t),l(e,ct,t),l(e,ge,t),l(e,ft,t),m($e,e,t),l(e,dt,t),l(e,he,t),gt=!0},p(e,[t]){const Rt={};t&2&&(Rt.$$scope={dirty:t,ctx:e}),b.$set(Rt);const At={};t&2&&(At.$$scope={dirty:t,ctx:e}),w.$set(At)},i(e){gt||(u(U.$$.fragment,e),u(v.$$.fragment,e),u(_.$$.fragment,e),u(V.$$.fragment,e),u(G.$$.fragment,e),u(x.$$.fragment,e),u(Q.$$.fragment,e),u(b.$$.fragment,e),u(E.$$.fragment,e),u(A.$$.fragment,e),u(N.$$.fragment,e),u(X.$$.fragment,e),u(z.$$.fragment,e),u(Y.$$.fragment,e),u(D.$$.fragment,e),u(K.$$.fragment,e),u(ee.$$.fragment,e),u(se.$$.fragment,e),u(le.$$.fragment,e),u(ae.$$.fragment,e),u(re.$$.fragment,e),u(ie.$$.fragment,e),u(w.$$.fragment,e),u(ue.$$.fragment,e),u(de.$$.fragment,e),u($e.$$.fragment,e),gt=!0)},o(e){c(U.$$.fragment,e),c(v.$$.fragment,e),c(_.$$.fragment,e),c(V.$$.fragment,e),c(G.$$.fragment,e),c(x.$$.fragment,e),c(Q.$$.fragment,e),c(b.$$.fragment,e),c(E.$$.fragment,e),c(A.$$.fragment,e),c(N.$$.fragment,e),c(X.$$.fragment,e),c(z.$$.fragment,e),c(Y.$$.fragment,e),c(D.$$.fragment,e),c(K.$$.fragment,e),c(ee.$$.fragment,e),c(se.$$.fragment,e),c(le.$$.fragment,e),c(ae.$$.fragment,e),c(re.$$.fragment,e),c(ie.$$.fragment,e),c(w.$$.fragment,e),c(ue.$$.fragment,e),c(de.$$.fragment,e),c($e.$$.fragment,e),gt=!1},d(e){e&&(s(h),s($),s(j),s(je),s(C),s(ye),s(be),s(J),s(we),s(Te),s(y),s(Ue),s(k),s(Ce),s(ve),s(Z),s(Je),s(_e),s(W),s(ke),s(Ve),s(I),s(Ze),s(Ge),s(B),s(We),s(H),s(xe),s(Ie),s(Qe),s(F),s(Be),s(R),s(He),s(Ee),s(L),s(Fe),s(Re),s(Ae),s(P),s(Le),s(Ne),s(S),s(Xe),s(Pe),s(ze),s(q),s(Se),s(Ye),s(O),s(De),s(qe),s(te),s(Ke),s(Oe),s(et),s(ne),s(tt),s(st),s(pe),s(lt),s(nt),s(oe),s(at),s(pt),s(me),s(rt),s(ot),s(it),s(ce),s(mt),s(fe),s(ut),s(ct),s(ge),s(ft),s(dt),s(he)),s(g),f(U,e),f(v,e),f(_,e),f(V,e),f(G,e),f(x,e),f(Q,e),f(b,e),f(E,e),f(A,e),f(N,e),f(X,e),f(z,e),f(Y,e),f(D,e),f(K,e),f(ee,e),f(se,e),f(le,e),f(ae,e),f(re,e),f(ie,e),f(w,e),f(ue,e),f(de,e),f($e,e)}}}const ss='{"title":"문제 해결","local":"troubleshoot","sections":[{"title":"방화벽 환경","local":"firewalled-environments","sections":[],"depth":2},{"title":"CUDA 메모리 부족(CUDA out of memory)","local":"cuda-out-of-memory","sections":[],"depth":2},{"title":"저장된 TensorFlow 모델을 가져올 수 없습니다(Unable to load a saved TensorFlow model)","local":"unable-to-load-a-saved-uensorFlow-model","sections":[],"depth":2},{"title":"ImportError","local":"importerror","sections":[],"depth":2},{"title":"CUDA error: device-side assert triggered","local":"cuda-error-deviceside-assert-triggered","sections":[],"depth":2},{"title":"패딩 토큰이 마스킹되지 않은 경우 잘못된 출력(Incorrect output when padding tokens aren’t masked)","local":"incorrect-output-when-padding-tokens-arent-masked","sections":[],"depth":2},{"title":"ValueError: 이 유형의 AutoModel에 대해 인식할 수 없는 XYZ 구성 클래스(ValueError: Unrecognized configuration class XYZ for this kind of AutoModel)","local":"valueerror-unrecognized-configuration-class-xyz-for-this-kind-of-automodel","sections":[],"depth":2}],"depth":1}';function ls(Me){return St(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ms extends Yt{constructor(g){super(),Dt(this,g,ls,ts,zt,{})}}export{ms as component};
