import{s as Va,o as Xa,n as I}from"../chunks/scheduler.56730f09.js";import{S as Fa,i as xa,g as y,s as o,r as d,A as Na,h as b,f as a,c as i,j as x,u as $,x as T,k as Ia,y as k,a as r,v as u,d as g,t as h,w as M}from"../chunks/index.1f144517.js";import{T as De}from"../chunks/Tip.41e845e5.js";import{Y as Ha}from"../chunks/Youtube.62e0f062.js";import{C as J}from"../chunks/CodeBlock.738eeccb.js";import{D as za}from"../chunks/DocNotebookDropdown.243c3df7.js";import{F as xe,M as E}from"../chunks/Markdown.c541024b.js";import{H as A}from"../chunks/Heading.57d46534.js";function Ea(w){let s,p;return s=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRvcmNo",highlighted:"pip install torch",wrap:!1}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p:I,i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Ya(w){let s,p;return s=new E({props:{$$slots:{default:[Ea]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Ba(w){let s,p;return s=new J({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRlbnNvcmZsb3c=",highlighted:"pip install tensorflow",wrap:!1}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p:I,i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function La(w){let s,p;return s=new E({props:{$$slots:{default:[Ba]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Aa(w){let s,p='사용 가능한 작업의 전체 목록은 <a href="./main_classes/pipelines">Pipelines API 참조</a>를 확인하세요.';return{c(){s=y("p"),s.innerHTML=p},l(e){s=b(e,"P",{"data-svelte-h":!0}),T(s)!=="svelte-jc1org"&&(s.innerHTML=p)},m(e,n){r(e,s,n)},p:I,d(e){e&&a(s)}}}function Qa(w){let s,p="<code>AutoModelForSequenceClassification</code>과 <code>AutoTokenizer</code>를 사용하여 사전 훈련된 모델과 관련된 토크나이저를 로드하세요 (다음 섹션에서 <code>AutoClass</code>에 대해 더 자세히 알아보겠습니다):",e,n,f;return n=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment)},l(m){s=b(m,"P",{"data-svelte-h":!0}),T(s)!=="svelte-2p9zoo"&&(s.innerHTML=p),e=i(m),$(n.$$.fragment,m)},m(m,_){r(m,s,_),r(m,e,_),u(n,m,_),f=!0},p:I,i(m){f||(g(n.$$.fragment,m),f=!0)},o(m){h(n.$$.fragment,m),f=!1},d(m){m&&(a(s),a(e)),M(n,m)}}}function qa(w){let s,p;return s=new E({props:{$$slots:{default:[Qa]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Sa(w){let s,p="<code>TFAutoModelForSequenceClassification</code>과 <code>AutoTokenizer</code>를 사용하여 사전 훈련된 모델과 관련된 토크나이저를 로드하세요 (다음 섹션에서 <code>TFAutoClass</code>에 대해 더 자세히 알아보겠습니다):",e,n,f;return n=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQobW9kZWxfbmFtZSklMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(model_name)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment)},l(m){s=b(m,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1kci4ds"&&(s.innerHTML=p),e=i(m),$(n.$$.fragment,m)},m(m,_){r(m,s,_),r(m,e,_),u(n,m,_),f=!0},p:I,i(m){f||(g(n.$$.fragment,m),f=!0)},o(m){h(n.$$.fragment,m),f=!1},d(m){m&&(a(s),a(e)),M(n,m)}}}function Pa(w){let s,p;return s=new E({props:{$$slots:{default:[Sa]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Oa(w){let s,p;return s=new J({props:{code:"cHRfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;pt&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p:I,i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Da(w){let s,p;return s=new E({props:{$$slots:{default:[Oa]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Ka(w){let s,p;return s=new J({props:{code:"dGZfYmF0Y2glMjAlM0QlMjB0b2tlbml6ZXIoJTBBJTIwJTIwJTIwJTIwJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHBhZGRpbmclM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwdHJ1bmNhdGlvbiUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtYXhfbGVuZ3RoJTNENTEyJTJDJTBBJTIwJTIwJTIwJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJ0ZiUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_batch = tokenizer(
<span class="hljs-meta">... </span>    [<span class="hljs-string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>],
<span class="hljs-meta">... </span>    padding=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    truncation=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    max_length=<span class="hljs-number">512</span>,
<span class="hljs-meta">... </span>    return_tensors=<span class="hljs-string">&quot;tf&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p:I,i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function tn(w){let s,p;return s=new E({props:{$$slots:{default:[Ka]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function en(w){let s,p='<a href="./preprocessing">전처리</a> 튜토리얼을 참조하시면 토큰화에 대한 자세한 설명과 함께 이미지, 오디오와 멀티모달 입력을 전처리하기 위한 <code>AutoImageProcessor</code>와 <code>AutoFeatureExtractor</code>, <code>AutoProcessor</code>의 사용방법도 알 수 있습니다.';return{c(){s=y("p"),s.innerHTML=p},l(e){s=b(e,"P",{"data-svelte-h":!0}),T(s)!=="svelte-7pesi2"&&(s.innerHTML=p)},m(e,n){r(e,s,n)},p:I,d(e){e&&a(s)}}}function sn(w){let s,p='<code>AutoModel</code> 클래스에서 지원하는 과업에 대해서는 <a href="./task_summary">과업 요약</a>을 참조하세요.';return{c(){s=y("p"),s.innerHTML=p},l(e){s=b(e,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1xki2u8"&&(s.innerHTML=p)},m(e,n){r(e,s,n)},p:I,d(e){e&&a(s)}}}function ln(w){let s,p="🤗 Transformers는 사전 훈련된 인스턴스를 간단하고 통합된 방법으로 로드할 수 있습니다. 즉, <code>AutoTokenizer</code>처럼 <code>AutoModel</code>을 로드할 수 있습니다. 유일한 차이점은 과업에 알맞은 <code>AutoModel</code>을 선택해야 한다는 점입니다. 텍스트 (또는 시퀀스) 분류의 경우 <code>AutoModelForSequenceClassification</code>을 로드해야 합니다:",e,n,f,m,_,C,v="이제 전처리된 입력 묶음을 직접 모델에 전달해야 합니다. 아래처럼 <code>**</code>를 앞에 붙여 딕셔너리를 풀어주면 됩니다:",G,j,Z,W,Q="모델의 최종 활성화 함수 출력은 <code>logits</code> 속성에 담겨있습니다. <code>logits</code>에 softmax 함수를 적용하여 확률을 얻을 수 있습니다:",H,R,V;return n=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEFwdF9tb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX25hbWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),m=new De({props:{$$slots:{default:[sn]},$$scope:{ctx:w}}}),j=new J({props:{code:"cHRfb3V0cHV0cyUyMCUzRCUyMHB0X21vZGVsKCoqcHRfYmF0Y2gp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_outputs = pt_model(**pt_batch)',wrap:!1}}),R=new J({props:{code:"ZnJvbSUyMHRvcmNoJTIwaW1wb3J0JTIwbm4lMEElMEFwdF9wcmVkaWN0aW9ucyUyMCUzRCUyMG5uLmZ1bmN0aW9uYWwuc29mdG1heChwdF9vdXRwdXRzLmxvZ2l0cyUyQyUyMGRpbSUzRC0xKSUwQXByaW50KHB0X3ByZWRpY3Rpb25zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span>pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(pt_predictions)
tensor([[<span class="hljs-number">0.0021</span>, <span class="hljs-number">0.0018</span>, <span class="hljs-number">0.0115</span>, <span class="hljs-number">0.2121</span>, <span class="hljs-number">0.7725</span>],
        [<span class="hljs-number">0.2084</span>, <span class="hljs-number">0.1826</span>, <span class="hljs-number">0.1969</span>, <span class="hljs-number">0.1755</span>, <span class="hljs-number">0.2365</span>]], grad_fn=&lt;SoftmaxBackward0&gt;)`,wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment),f=o(),d(m.$$.fragment),_=o(),C=y("p"),C.innerHTML=v,G=o(),d(j.$$.fragment),Z=o(),W=y("p"),W.innerHTML=Q,H=o(),d(R.$$.fragment)},l(c){s=b(c,"P",{"data-svelte-h":!0}),T(s)!=="svelte-xkn7yr"&&(s.innerHTML=p),e=i(c),$(n.$$.fragment,c),f=i(c),$(m.$$.fragment,c),_=i(c),C=b(c,"P",{"data-svelte-h":!0}),T(C)!=="svelte-1t6qist"&&(C.innerHTML=v),G=i(c),$(j.$$.fragment,c),Z=i(c),W=b(c,"P",{"data-svelte-h":!0}),T(W)!=="svelte-yhe83l"&&(W.innerHTML=Q),H=i(c),$(R.$$.fragment,c)},m(c,U){r(c,s,U),r(c,e,U),u(n,c,U),r(c,f,U),u(m,c,U),r(c,_,U),r(c,C,U),r(c,G,U),u(j,c,U),r(c,Z,U),r(c,W,U),r(c,H,U),u(R,c,U),V=!0},p(c,U){const N={};U&2&&(N.$$scope={dirty:U,ctx:c}),m.$set(N)},i(c){V||(g(n.$$.fragment,c),g(m.$$.fragment,c),g(j.$$.fragment,c),g(R.$$.fragment,c),V=!0)},o(c){h(n.$$.fragment,c),h(m.$$.fragment,c),h(j.$$.fragment,c),h(R.$$.fragment,c),V=!1},d(c){c&&(a(s),a(e),a(f),a(_),a(C),a(G),a(Z),a(W),a(H)),M(n,c),M(m,c),M(j,c),M(R,c)}}}function an(w){let s,p;return s=new E({props:{$$slots:{default:[ln]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function nn(w){let s,p='<code>AutoModel</code> 클래스에서 지원하는 과업에 대해서는 <a href="./task_summary">과업 요약</a>을 참조하세요.';return{c(){s=y("p"),s.innerHTML=p},l(e){s=b(e,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1xki2u8"&&(s.innerHTML=p)},m(e,n){r(e,s,n)},p:I,d(e){e&&a(s)}}}function rn(w){let s,p="🤗 Transformers는 사전 훈련된 인스턴스를 간단하고 통합된 방법으로 로드할 수 있습니다. 즉, <code>AutoTokenizer</code>처럼 <code>TFAutoModel</code>을 로드할 수 있습니다. 유일한 차이점은 과업에 알맞은 <code>TFAutoModel</code>을 선택해야 한다는 점입니다. 텍스트 (또는 시퀀스) 분류의 경우 <code>TFAutoModelForSequenceClassification</code>을 로드해야 합니다:",e,n,f,m,_,C,v="이제 전처리된 입력 묶음을 직접 모델에 전달해야 합니다. 아래처럼 그대로 텐서를 전달하면 됩니다:",G,j,Z,W,Q="모델의 최종 활성화 함수 출력은 <code>logits</code> 속성에 담겨있습니다. <code>logits</code>에 softmax 함수를 적용하여 확률을 얻을 수 있습니다:",H,R,V;return n=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsX25hbWUlMjAlM0QlMjAlMjJubHB0b3duJTJGYmVydC1iYXNlLW11bHRpbGluZ3VhbC11bmNhc2VkLXNlbnRpbWVudCUyMiUwQXRmX21vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(model_name)`,wrap:!1}}),m=new De({props:{$$slots:{default:[nn]},$$scope:{ctx:w}}}),j=new J({props:{code:"dGZfb3V0cHV0cyUyMCUzRCUyMHRmX21vZGVsKHRmX2JhdGNoKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_outputs = tf_model(tf_batch)',wrap:!1}}),R=new J({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEF0Zl9wcmVkaWN0aW9ucyUyMCUzRCUyMHRmLm5uLnNvZnRtYXgodGZfb3V0cHV0cy5sb2dpdHMlMkMlMjBheGlzJTNELTEpJTBBdGZfcHJlZGljdGlvbnM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions = tf.nn.softmax(tf_outputs.logits, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_predictions`,wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment),f=o(),d(m.$$.fragment),_=o(),C=y("p"),C.textContent=v,G=o(),d(j.$$.fragment),Z=o(),W=y("p"),W.innerHTML=Q,H=o(),d(R.$$.fragment)},l(c){s=b(c,"P",{"data-svelte-h":!0}),T(s)!=="svelte-18fnh6p"&&(s.innerHTML=p),e=i(c),$(n.$$.fragment,c),f=i(c),$(m.$$.fragment,c),_=i(c),C=b(c,"P",{"data-svelte-h":!0}),T(C)!=="svelte-iofx68"&&(C.textContent=v),G=i(c),$(j.$$.fragment,c),Z=i(c),W=b(c,"P",{"data-svelte-h":!0}),T(W)!=="svelte-yhe83l"&&(W.innerHTML=Q),H=i(c),$(R.$$.fragment,c)},m(c,U){r(c,s,U),r(c,e,U),u(n,c,U),r(c,f,U),u(m,c,U),r(c,_,U),r(c,C,U),r(c,G,U),u(j,c,U),r(c,Z,U),r(c,W,U),r(c,H,U),u(R,c,U),V=!0},p(c,U){const N={};U&2&&(N.$$scope={dirty:U,ctx:c}),m.$set(N)},i(c){V||(g(n.$$.fragment,c),g(m.$$.fragment,c),g(j.$$.fragment,c),g(R.$$.fragment,c),V=!0)},o(c){h(n.$$.fragment,c),h(m.$$.fragment,c),h(j.$$.fragment,c),h(R.$$.fragment,c),V=!1},d(c){c&&(a(s),a(e),a(f),a(_),a(C),a(G),a(Z),a(W),a(H)),M(n,c),M(m,c),M(j,c),M(R,c)}}}function pn(w){let s,p;return s=new E({props:{$$slots:{default:[rn]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function on(w){let s,p="모든 🤗 Transformers 모델(PyTorch 또는 TensorFlow)은 (softmax와 같은) 최종 활성화 함수 <em>이전에</em> 텐서를 출력합니다. 왜냐하면 최종 활성화 함수의 출력은 종종 손실 함수 출력과 결합되기 때문입니다. 모델 출력은 특수한 데이터 클래스이므로 IDE에서 자동 완성됩니다. 모델 출력은 튜플이나 딕셔너리처럼 동작하며 (정수, 슬라이스 또는 문자열로 인덱싱 가능), None인 속성은 무시됩니다.";return{c(){s=y("p"),s.innerHTML=p},l(e){s=b(e,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1hw7pec"&&(s.innerHTML=p)},m(e,n){r(e,s,n)},p:I,d(e){e&&a(s)}}}function mn(w){let s,p="미세조정된 모델을 토크나이저와 함께 저장하려면 <code>PreTrainedModel.save_pretrained()</code>를 사용하세요:",e,n,f,m,_="모델을 다시 사용하려면 <code>PreTrainedModel.from_pretrained()</code>로 모델을 다시 로드하세요:",C,v,G;return n=new J({props:{code:"cHRfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZChwdF9zYXZlX2RpcmVjdG9yeSklMEFwdF9tb2RlbC5zYXZlX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>pt_save_directory = <span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model.save_pretrained(pt_save_directory)`,wrap:!1}}),v=new J({props:{code:"cHRfbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjIuJTJGcHRfc2F2ZV9wcmV0cmFpbmVkJTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./pt_save_pretrained&quot;</span>)',wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment),f=o(),m=y("p"),m.innerHTML=_,C=o(),d(v.$$.fragment)},l(j){s=b(j,"P",{"data-svelte-h":!0}),T(s)!=="svelte-17ceysc"&&(s.innerHTML=p),e=i(j),$(n.$$.fragment,j),f=i(j),m=b(j,"P",{"data-svelte-h":!0}),T(m)!=="svelte-1gryll9"&&(m.innerHTML=_),C=i(j),$(v.$$.fragment,j)},m(j,Z){r(j,s,Z),r(j,e,Z),u(n,j,Z),r(j,f,Z),r(j,m,Z),r(j,C,Z),u(v,j,Z),G=!0},p:I,i(j){G||(g(n.$$.fragment,j),g(v.$$.fragment,j),G=!0)},o(j){h(n.$$.fragment,j),h(v.$$.fragment,j),G=!1},d(j){j&&(a(s),a(e),a(f),a(m),a(C)),M(n,j),M(v,j)}}}function cn(w){let s,p;return s=new E({props:{$$slots:{default:[mn]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function fn(w){let s,p="미세조정된 모델을 토크나이저와 함께 저장하려면 <code>TFPreTrainedModel.save_pretrained()</code>를 사용하세요:",e,n,f,m,_="모델을 다시 사용하려면 <code>TFPreTrainedModel.from_pretrained()</code>로 모델을 다시 로드하세요:",C,v,G;return n=new J({props:{code:"dGZfc2F2ZV9kaXJlY3RvcnklMjAlM0QlMjAlMjIuJTJGdGZfc2F2ZV9wcmV0cmFpbmVkJTIyJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZCh0Zl9zYXZlX2RpcmVjdG9yeSklMEF0Zl9tb2RlbC5zYXZlX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3Rvcnkp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_save_directory = <span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model.save_pretrained(tf_save_directory)`,wrap:!1}}),v=new J({props:{code:"dGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMi4lMkZ0Zl9zYXZlX3ByZXRyYWluZWQlMjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;./tf_save_pretrained&quot;</span>)',wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment),f=o(),m=y("p"),m.innerHTML=_,C=o(),d(v.$$.fragment)},l(j){s=b(j,"P",{"data-svelte-h":!0}),T(s)!=="svelte-8fihd2"&&(s.innerHTML=p),e=i(j),$(n.$$.fragment,j),f=i(j),m=b(j,"P",{"data-svelte-h":!0}),T(m)!=="svelte-1kduch3"&&(m.innerHTML=_),C=i(j),$(v.$$.fragment,j)},m(j,Z){r(j,s,Z),r(j,e,Z),u(n,j,Z),r(j,f,Z),r(j,m,Z),r(j,C,Z),u(v,j,Z),G=!0},p:I,i(j){G||(g(n.$$.fragment,j),g(v.$$.fragment,j),G=!0)},o(j){h(n.$$.fragment,j),h(v.$$.fragment,j),G=!1},d(j){j&&(a(s),a(e),a(f),a(m),a(C)),M(n,j),M(v,j)}}}function dn(w){let s,p;return s=new E({props:{$$slots:{default:[fn]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function $n(w){let s,p;return s=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKHRmX3NhdmVfZGlyZWN0b3J5KSUwQXB0X21vZGVsJTIwJTNEJTIwQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbi5mcm9tX3ByZXRyYWluZWQodGZfc2F2ZV9kaXJlY3RvcnklMkMlMjBmcm9tX3RmJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(tf_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>pt_model = AutoModelForSequenceClassification.from_pretrained(tf_save_directory, from_tf=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p:I,i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function un(w){let s,p;return s=new E({props:{$$slots:{default:[$n]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function gn(w){let s,p;return s=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQocHRfc2F2ZV9kaXJlY3RvcnkpJTBBdGZfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKHB0X3NhdmVfZGlyZWN0b3J5JTJDJTIwZnJvbV9wdCUzRFRydWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=<span class="hljs-literal">True</span>)`,wrap:!1}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p:I,i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function hn(w){let s,p;return s=new E({props:{$$slots:{default:[gn]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Mn(w){let s,p="<code>AutoModel.from_config()</code>를 사용하여 바꾼 구성대로 모델을 생성하세요:",e,n,f;return n=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbCUwQSUwQW15X21vZGVsJTIwJTNEJTIwQXV0b01vZGVsLmZyb21fY29uZmlnKG15X2NvbmZpZyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = AutoModel.from_config(my_config)`,wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment)},l(m){s=b(m,"P",{"data-svelte-h":!0}),T(s)!=="svelte-e2zo3n"&&(s.innerHTML=p),e=i(m),$(n.$$.fragment,m)},m(m,_){r(m,s,_),r(m,e,_),u(n,m,_),f=!0},p:I,i(m){f||(g(n.$$.fragment,m),f=!0)},o(m){h(n.$$.fragment,m),f=!1},d(m){m&&(a(s),a(e)),M(n,m)}}}function yn(w){let s,p;return s=new E({props:{$$slots:{default:[Mn]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function bn(w){let s,p="<code>TFAutoModel.from_config()</code>를 사용하여 바꾼 구성대로 모델을 생성하세요:",e,n,f;return n=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsJTBBJTBBbXlfbW9kZWwlMjAlM0QlMjBURkF1dG9Nb2RlbC5mcm9tX2NvbmZpZyhteV9jb25maWcp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModel

<span class="hljs-meta">&gt;&gt;&gt; </span>my_model = TFAutoModel.from_config(my_config)`,wrap:!1}}),{c(){s=y("p"),s.innerHTML=p,e=o(),d(n.$$.fragment)},l(m){s=b(m,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1j96frd"&&(s.innerHTML=p),e=i(m),$(n.$$.fragment,m)},m(m,_){r(m,s,_),r(m,e,_),u(n,m,_),f=!0},p:I,i(m){f||(g(n.$$.fragment,m),f=!0)},o(m){h(n.$$.fragment,m),f=!1},d(m){m&&(a(s),a(e)),M(n,m)}}}function jn(w){let s,p;return s=new E({props:{$$slots:{default:[bn]},$$scope:{ctx:w}}}),{c(){d(s.$$.fragment)},l(e){$(s.$$.fragment,e)},m(e,n){u(s,e,n),p=!0},p(e,n){const f={};n&2&&(f.$$scope={dirty:n,ctx:e}),s.$set(f)},i(e){p||(g(s.$$.fragment,e),p=!0)},o(e){h(s.$$.fragment,e),p=!1},d(e){M(s,e)}}}function Tn(w){let s,p="번역이나 요약과 같이 시퀀스-시퀀스 모델을 사용하는 과업에는 <code>Seq2SeqTrainer</code> 및 <code>Seq2SeqTrainingArguments</code> 클래스를 사용하세요.";return{c(){s=y("p"),s.innerHTML=p},l(e){s=b(e,"P",{"data-svelte-h":!0}),T(s)!=="svelte-82jwth"&&(s.innerHTML=p)},m(e,n){r(e,s,n)},p:I,d(e){e&&a(s)}}}function wn(w){let s,p,e,n,f,m,_,C,v,G='🤗 Transformers를 시작해보세요! 개발해본 적이 없더라도 쉽게 읽을 수 있도록 쓰인 이 글은 <a href="./main_classes/pipelines"><code>pipeline</code></a>을 사용하여 추론하고, 사전학습된 모델과 전처리기를 <a href="./model_doc/auto">AutoClass</a>로 로드하고, PyTorch 또는 TensorFlow로 모델을 빠르게 학습시키는 방법을 소개해 드릴 것입니다. 본 가이드에서 소개되는 개념을 (특히 초보자의 관점으로) 더 친절하게 접하고 싶다면, 튜토리얼이나 <a href="https://huggingface.co/course/chapter1/1" rel="nofollow">코스</a>를 참조하기를 권장합니다.',j,Z,W="시작하기 전에 필요한 라이브러리가 모두 설치되어 있는지 확인하세요:",Q,H,R,V,c="또한 선호하는 머신 러닝 프레임워크를 설치해야 합니다:",U,N,ts,at,es,nt,ss,rt,Yl='<a href="./main_classes/pipelines"><code>pipeline</code></a>은 사전 훈련된 모델로 추론하기에 가장 쉽고 빠른 방법입니다. <code>pipeline()</code>은 여러 모달리티에서 다양한 과업을 쉽게 처리할 수 있으며, 아래 표에 표시된 몇 가지 과업을 기본적으로 지원합니다:',ls,q,as,pt,Bl="<thead><tr><th><strong>태스크</strong></th> <th><strong>설명</strong></th> <th><strong>모달리티</strong></th> <th><strong>파이프라인 ID</strong></th></tr></thead> <tbody><tr><td>텍스트 분류</td> <td>텍스트에 알맞은 레이블 붙이기</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“sentiment-analysis”)</td></tr> <tr><td>텍스트 생성</td> <td>주어진 문자열 입력과 이어지는 텍스트 생성하기</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“text-generation”)</td></tr> <tr><td>개체명 인식</td> <td>문자열의 각 토큰마다 알맞은 레이블 붙이기 (인물, 조직, 장소 등등)</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“ner”)</td></tr> <tr><td>질의응답</td> <td>주어진 문맥과 질문에 따라 올바른 대답하기</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“question-answering”)</td></tr> <tr><td>빈칸 채우기</td> <td>문자열의 빈칸에 알맞은 토큰 맞추기</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“fill-mask”)</td></tr> <tr><td>요약</td> <td>텍스트나 문서를 요약하기</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“summarization”)</td></tr> <tr><td>번역</td> <td>텍스트를 한 언어에서 다른 언어로 번역하기</td> <td>자연어 처리(NLP)</td> <td>pipeline(task=“translation”)</td></tr> <tr><td>이미지 분류</td> <td>이미지에 알맞은 레이블 붙이기</td> <td>컴퓨터 비전(CV)</td> <td>pipeline(task=“image-classification”)</td></tr> <tr><td>이미지 분할</td> <td>이미지의 픽셀마다 레이블 붙이기(시맨틱, 파놉틱 및 인스턴스 분할 포함)</td> <td>컴퓨터 비전(CV)</td> <td>pipeline(task=“image-segmentation”)</td></tr> <tr><td>객체 탐지</td> <td>이미지 속 객체의 경계 상자를 그리고 클래스를 예측하기</td> <td>컴퓨터 비전(CV)</td> <td>pipeline(task=“object-detection”)</td></tr> <tr><td>오디오 분류</td> <td>오디오 파일에 알맞은 레이블 붙이기</td> <td>오디오</td> <td>pipeline(task=“audio-classification”)</td></tr> <tr><td>자동 음성 인식</td> <td>오디오 파일 속 음성을 텍스트로 바꾸기</td> <td>오디오</td> <td>pipeline(task=“automatic-speech-recognition”)</td></tr> <tr><td>시각 질의응답</td> <td>주어진 이미지와 질문에 대해 올바르게 대답하기</td> <td>멀티모달</td> <td>pipeline(task=“vqa”)</td></tr> <tr><td>문서 질의응답</td> <td>주어진 문서와 질문에 대해 올바르게 대답하기</td> <td>멀티모달</td> <td>pipeline(task=“document-question-answering”)</td></tr> <tr><td>이미지 캡션 달기</td> <td>주어진 이미지의 캡션 생성하기</td> <td>멀티모달</td> <td>pipeline(task=“image-to-text”)</td></tr></tbody>",ns,ot,Ll="먼저 <code>pipeline()</code>의 인스턴스를 생성하고 사용할 작업을 지정합니다. 이 가이드에서는 감정 분석을 위해 <code>pipeline()</code>을 사용하는 예제를 보여드리겠습니다:",rs,it,ps,mt,Al='<code>pipeline()</code>은 감정 분석을 위한 <a href="https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english" rel="nofollow">사전 훈련된 모델</a>과 토크나이저를 자동으로 다운로드하고 캐시합니다. 이제 <code>classifier</code>를 대상 텍스트에 사용할 수 있습니다:',os,ct,is,ft,Ql="만약 입력이 여러 개 있는 경우, 입력을 리스트로 <code>pipeline()</code>에 전달하여, 사전 훈련된 모델의 출력을 딕셔너리로 이루어진 리스트 형태로 받을 수 있습니다:",ms,dt,cs,$t,ql="<code>pipeline()</code>은 주어진 과업에 관계없이 데이터셋 전부를 순회할 수도 있습니다. 이 예제에서는 자동 음성 인식을 과업으로 선택해 보겠습니다:",fs,ut,ds,gt,Sl='데이터셋을 로드할 차례입니다. (자세한 내용은 🤗 Datasets <a href="https://huggingface.co/docs/datasets/quickstart#audio" rel="nofollow">시작하기</a>을 참조하세요) 여기에서는 <a href="https://huggingface.co/datasets/PolyAI/minds14" rel="nofollow">MInDS-14</a> 데이터셋을 로드하겠습니다:',$s,ht,us,Mt,Pl='데이터셋의 샘플링 레이트가 기존 모델인 <a href="https://huggingface.co/facebook/wav2vec2-base-960h" rel="nofollow"><code>facebook/wav2vec2-base-960h</code></a>의 훈련 당시 샘플링 레이트와 일치하는지 확인해야 합니다:',gs,yt,hs,bt,Ol="<code>&quot;audio&quot;</code> 열을 호출하면 자동으로 오디오 파일을 가져와서 리샘플링합니다. 첫 4개 샘플에서 원시 웨이브폼 배열을 추출하고 파이프라인에 리스트로 전달하세요:",Ms,jt,ys,Tt,Dl='음성이나 비전과 같이 입력이 큰 대규모 데이터셋의 경우, 모든 입력을 메모리에 로드하려면 리스트 대신 제너레이터 형태로 전달해야 합니다. 자세한 내용은 <a href="./main_classes/pipelines">Pipelines API 참조</a>를 확인하세요.',bs,wt,js,Jt,Kl='<code>pipeline()</code>은 <a href="https://huggingface.co/models" rel="nofollow">Hub</a>의 모든 모델을 사용할 수 있기 때문에, <code>pipeline()</code>을 다른 용도에 맞게 쉽게 수정할 수 있습니다. 예를 들어, 프랑스어 텍스트를 처리할 수 있는 모델을 사용하기 위해선 Hub의 태그를 사용하여 적절한 모델을 필터링하면 됩니다. 필터링된 결과의 상위 항목으로는 프랑스어 텍스트에 사용할 수 있는 다국어 <a href="https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment" rel="nofollow">BERT 모델</a>이 반환됩니다:',Ts,kt,ws,S,Js,_t,ta="<code>pipeline()</code>에서 모델과 토크나이저를 지정하면, 이제 <code>classifier</code>를 프랑스어 텍스트에 적용할 수 있습니다:",ks,Ut,_s,Zt,ea='마땅한 모델을 찾을 수 없는 경우 데이터를 기반으로 사전 훈련된 모델을 미세조정해야 합니다. 미세조정 방법에 대한 자세한 내용은 <a href="./training">미세조정 튜토리얼</a>을 참조하세요. 사전 훈련된 모델을 미세조정한 후에는 모델을 Hub의 커뮤니티와 공유하여 머신러닝 민주화에 기여해주세요! 🤗',Us,Ct,Zs,vt,Cs,Gt,sa='<code>AutoModelForSequenceClassification</code>과 <code>AutoTokenizer</code> 클래스는 위에서 다룬 <code>pipeline()</code>의 기능을 구현하는 데 사용됩니다. <a href="./model_doc/auto">AutoClass</a>는 사전 훈련된 모델의 아키텍처를 이름이나 경로에서 자동으로 가져오는 ‘바로가기’입니다. 과업에 적합한 <code>AutoClass</code>를 선택하고 해당 전처리 클래스를 선택하기만 하면 됩니다.',vs,Rt,la="이전 섹션의 예제로 돌아가서 <code>pipeline()</code>의 결과를 <code>AutoClass</code>를 활용해 복제하는 방법을 살펴보겠습니다.",Gs,Wt,Rs,It,aa='토크나이저는 텍스트를 모델의 입력으로 사용하기 위해 숫자 배열 형태로 전처리하는 역할을 담당합니다. 토큰화 과정에는 단어를 어디에서 끊을지, 어느 수준까지 나눌지와 같은 여러 규칙들이 있습니다 (토큰화에 대한 자세한 내용은 <a href="./tokenizer_summary">토크나이저 요약</a>을 참조하세요). 가장 중요한 점은 모델이 사전 훈련된 모델과 동일한 토큰화 규칙을 사용하도록 동일한 모델 이름으로 토크나이저를 인스턴스화해야 한다는 것입니다.',Ws,Ht,na="<code>AutoTokenizer</code>로 토크나이저를 로드하세요:",Is,Vt,Hs,Xt,ra="텍스트를 토크나이저에 전달하세요:",Vs,Ft,Xs,xt,pa="토크나이저는 다음을 포함한 딕셔너리를 반환합니다:",Fs,Nt,oa='<li><a href="./glossary#input-ids">input_ids</a>: 토큰의 숫자 표현.</li> <li><a href=".glossary#attention-mask">attention_mask</a>: 어떤 토큰에 주의를 기울여야 하는지를 나타냅니다.</li>',xs,zt,ia="토크나이저는 입력을 리스트 형태로도 받을 수 있으며, 텍스트를 패딩하고 잘라내어 일정한 길이의 묶음을 반환할 수도 있습니다:",Ns,P,zs,O,Es,Et,Ys,D,Bs,K,Ls,Yt,As,tt,Qs,Bt,ma="🤗 Transformers의 멋진 기능 중 하나는 모델을 PyTorch 또는 TensorFlow 모델로 저장해뒀다가 다른 프레임워크로 다시 로드할 수 있는 점입니다. <code>from_pt</code> 또는 <code>from_tf</code> 매개변수를 사용하여 모델을 한 프레임워크에서 다른 프레임워크로 변환할 수 있습니다:",qs,et,Ss,Lt,Ps,At,ca="모델의 구성 클래스를 수정하여 모델의 구조를 바꿀 수 있습니다. (은닉층이나 어텐션 헤드의 수와 같은) 모델의 속성은 구성에서 지정되기 때문입니다. 커스텀 구성 클래스로 모델을 만들면 처음부터 시작해야 합니다. 모델 속성은 무작위로 초기화되므로 의미 있는 결과를 얻으려면 먼저 모델을 훈련시켜야 합니다.",Os,Qt,fa="먼저 <code>AutoConfig</code>를 가져오고 수정하고 싶은 사전학습된 모델을 로드하세요. <code>AutoConfig.from_pretrained()</code> 내부에서 (어텐션 헤드 수와 같이) 변경하려는 속성를 지정할 수 있습니다:",Ds,qt,Ks,st,tl,St,da='커스텀 구성에 대한 자세한 내용은 <a href="./create_a_model">커스텀 아키텍처 만들기</a> 가이드를 확인하세요.',el,Pt,sl,Ot,$a='모든 모델은 <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow"><code>torch.nn.Module</code></a>이므로 일반적인 훈련 루프에서 사용할 수 있습니다. 직접 훈련 루프를 작성할 수도 있지만, 🤗 Transformers는 PyTorch를 위한 <code>Trainer</code> 클래스를 제공합니다. 이 클래스에는 기본 훈련 루프가 포함되어 있으며 분산 훈련, 혼합 정밀도 등과 같은 기능을 추가로 제공합니다.',ll,Dt,ua="과업에 따라 다르지만 일반적으로 <code>Trainer</code>에 다음 매개변수를 전달합니다:",al,X,Kt,Ne,ga='<code>PreTrainedModel</code> 또는 <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow"><code>torch.nn.Module</code></a>로 시작합니다:',jl,te,Tl,ee,ze,ha="<code>TrainingArguments</code>는 학습률, 배치 크기, 훈련할 에포크 수와 같은 모델 하이퍼파라미터를 포함합니다. 훈련 인자를 지정하지 않으면 기본값이 사용됩니다:",wl,se,Jl,le,Ee,Ma="토크나이저, 이미지 프로세서, 특징 추출기(feature extractor) 또는 프로세서와 전처리 클래스를 로드하세요:",kl,ae,_l,ne,Ye,ya="데이터셋을 로드하세요:",Ul,re,Zl,B,Be,ba="데이터셋을 토큰화하는 함수를 생성하세요:",Cl,pe,vl,Le,ja="그리고 <code>map</code>로 데이터셋 전체에 적용하세요:",Gl,oe,Rl,ie,Ae,Ta="<code>DataCollatorWithPadding</code>을 사용하여 데이터셋의 표본 묶음을 만드세요:",Wl,me,nl,ce,wa="이제 위의 모든 클래스를 <code>Trainer</code>로 모으세요:",rl,fe,pl,de,Ja="준비가 되었으면 <code>train()</code>을 호출하여 훈련을 시작하세요:",ol,$e,il,lt,ml,ue,ka="<code>Trainer</code> 내의 메서드를 서브클래스화하여 훈련 루프를 바꿀 수도 있습니다. 이러면 손실 함수, 옵티마이저, 스케줄러와 같은 기능 또한 바꿀 수 있게 됩니다. 변경 가능한 메소드에 대해서는 <code>Trainer</code> 문서를 참고하세요.",cl,ge,_a='훈련 루프를 수정하는 다른 방법은 <a href="./main_classes/callbacks">Callbacks</a>를 사용하는 것입니다. Callbacks로 다른 라이브러리와 통합하고, 훈련 루프를 체크하여 진행 상황을 보고받거나, 훈련을 조기에 중단할 수 있습니다. Callbacks은 훈련 루프 자체를 바꾸지는 않습니다. 손실 함수와 같은 것을 바꾸려면 <code>Trainer</code>를 서브클래스화해야 합니다.',fl,he,dl,Me,Ua='모든 모델은 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow"><code>tf.keras.Model</code></a>이므로 <a href="https://keras.io/" rel="nofollow">Keras</a> API를 통해 TensorFlow에서 훈련시킬 수 있습니다. 🤗 Transformers는 데이터셋을 쉽게 <code>tf.data.Dataset</code> 형태로 쉽게 로드할 수 있는 <code>prepare_tf_dataset()</code> 메소드를 제공하기 때문에, Keras의 <a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a> 및 <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a> 메소드로 바로 훈련을 시작할 수 있습니다.',$l,z,ye,Qe,Za='<code>TFPreTrainedModel</code> 또는 <a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow"><code>tf.keras.Model</code></a>로 시작합니다:',Il,be,Hl,je,qe,Ca="토크나이저, 이미지 프로세서, 특징 추출기(feature extractor) 또는 프로세서와 같은 전처리 클래스를 로드하세요:",Vl,Te,Xl,we,Se,va="데이터셋을 토큰화하는 함수를 생성하세요:",Fl,Je,xl,ke,Pe,Ga="<code>map</code>을 사용하여 전체 데이터셋에 토큰화 함수를 적용하고, 데이터셋과 토크나이저를 <code>prepare_tf_dataset()</code>에 전달하세요. 배치 크기를 변경하거나 데이터셋을 섞을 수도 있습니다:",Nl,_e,zl,Ue,Oe,Ra="준비되었으면 <code>compile</code> 및 <code>fit</code>를 호출하여 훈련을 시작하세요. 🤗 Transformers의 모든 모델은 과업과 관련된 기본 손실 함수를 가지고 있으므로 명시적으로 지정하지 않아도 됩니다:",El,Ze,ul,Ce,gl,ve,Wa="🤗 Transformers 둘러보기를 모두 읽으셨다면, 가이드를 살펴보고 더 구체적인 것을 수행하는 방법을 알아보세요. 이를테면 커스텀 모델 구축하는 방법, 과업에 알맞게 모델을 미세조정하는 방법, 스크립트로 모델 훈련하는 방법 등이 있습니다. 🤗 Transformers 핵심 개념에 대해 더 알아보려면 커피 한 잔 들고 개념 가이드를 살펴보세요!",hl,Ke,Ml;return f=new A({props:{title:"둘러보기",local:"quick-tour",headingTag:"h1"}}),_=new za({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/quicktour.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/quicktour.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/quicktour.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/quicktour.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/quicktour.ipynb"}]}}),H=new J({props:{code:"IXBpcCUyMGluc3RhbGwlMjB0cmFuc2Zvcm1lcnMlMjBkYXRhc2V0cw==",highlighted:"!pip install transformers datasets",wrap:!1}}),N=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[La],pytorch:[Ya]},$$scope:{ctx:w}}}),at=new A({props:{title:"파이프라인",local:"pipeline",headingTag:"h2"}}),nt=new Ha({props:{id:"tiZFewofSLM"}}),q=new De({props:{$$slots:{default:[Aa]},$$scope:{ctx:w}}}),it=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnNlbnRpbWVudC1hbmFseXNpcyUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>)`,wrap:!1}}),ct=new J({props:{code:"Y2xhc3NpZmllciglMjJXZSUyMGFyZSUyMHZlcnklMjBoYXBweSUyMHRvJTIwc2hvdyUyMHlvdSUyMHRoZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycyUyMGxpYnJhcnkuJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;POSITIVE&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.9998</span>}]`,wrap:!1}}),dt=new J({props:{code:"cmVzdWx0cyUyMCUzRCUyMGNsYXNzaWZpZXIoJTVCJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiUyQyUyMCUyMldlJTIwaG9wZSUyMHlvdSUyMGRvbid0JTIwaGF0ZSUyMGl0LiUyMiU1RCklMEFmb3IlMjByZXN1bHQlMjBpbiUyMHJlc3VsdHMlM0ElMEElMjAlMjAlMjAlMjBwcmludChmJTIybGFiZWwlM0ElMjAlN0JyZXN1bHQlNUInbGFiZWwnJTVEJTdEJTJDJTIwd2l0aCUyMHNjb3JlJTNBJTIwJTdCcm91bmQocmVzdWx0JTVCJ3Njb3JlJyU1RCUyQyUyMDQpJTdEJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>results = classifier([<span class="hljs-string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>, <span class="hljs-string">&quot;We hope you don&#x27;t hate it.&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> result <span class="hljs-keyword">in</span> results:
<span class="hljs-meta">... </span>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;label: <span class="hljs-subst">{result[<span class="hljs-string">&#x27;label&#x27;</span>]}</span>, with score: <span class="hljs-subst">{<span class="hljs-built_in">round</span>(result[<span class="hljs-string">&#x27;score&#x27;</span>], <span class="hljs-number">4</span>)}</span>&quot;</span>)
label: POSITIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.9998</span>
label: NEGATIVE, <span class="hljs-keyword">with</span> score: <span class="hljs-number">0.5309</span>`,wrap:!1}}),ut=new J({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwcGlwZWxpbmUlMEElMEFzcGVlY2hfcmVjb2duaXplciUyMCUzRCUyMHBpcGVsaW5lKCUyMmF1dG9tYXRpYy1zcGVlY2gtcmVjb2duaXRpb24lMjIlMkMlMjBtb2RlbCUzRCUyMmZhY2Vib29rJTJGd2F2MnZlYzItYmFzZS05NjBoJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>speech_recognizer = pipeline(<span class="hljs-string">&quot;automatic-speech-recognition&quot;</span>, model=<span class="hljs-string">&quot;facebook/wav2vec2-base-960h&quot;</span>)`,wrap:!1}}),ht=new J({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTJDJTIwQXVkaW8lMEElMEFkYXRhc2V0JTIwJTNEJTIwbG9hZF9kYXRhc2V0KCUyMlBvbHlBSSUyRm1pbmRzMTQlMjIlMkMlMjBuYW1lJTNEJTIyZW4tVVMlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, Audio

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;PolyAI/minds14&quot;</span>, name=<span class="hljs-string">&quot;en-US&quot;</span>, split=<span class="hljs-string">&quot;train&quot;</span>)`,wrap:!1}}),yt=new J({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQuY2FzdF9jb2x1bW4oJTIyYXVkaW8lMjIlMkMlMjBBdWRpbyhzYW1wbGluZ19yYXRlJTNEc3BlZWNoX3JlY29nbml6ZXIuZmVhdHVyZV9leHRyYWN0b3Iuc2FtcGxpbmdfcmF0ZSkp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.cast_column(<span class="hljs-string">&quot;audio&quot;</span>, Audio(sampling_rate=speech_recognizer.feature_extractor.sampling_rate))',wrap:!1}}),jt=new J({props:{code:"cmVzdWx0JTIwJTNEJTIwc3BlZWNoX3JlY29nbml6ZXIoZGF0YXNldCU1QiUzQTQlNUQlNUIlMjJhdWRpbyUyMiU1RCklMEFwcmludCglNUJkJTVCJTIydGV4dCUyMiU1RCUyMGZvciUyMGQlMjBpbiUyMHJlc3VsdCU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>result = speech_recognizer(dataset[:<span class="hljs-number">4</span>][<span class="hljs-string">&quot;audio&quot;</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>([d[<span class="hljs-string">&quot;text&quot;</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> result])
[<span class="hljs-string">&#x27;I WOULD LIKE TO SET UP A JOINT ACCOUNT WITH MY PARTNER HOW DO I PROCEED WITH DOING THAT&#x27;</span>, <span class="hljs-string">&quot;FONDERING HOW I&#x27;D SET UP A JOIN TO HELL T WITH MY WIFE AND WHERE THE AP MIGHT BE&quot;</span>, <span class="hljs-string">&quot;I I&#x27;D LIKE TOY SET UP A JOINT ACCOUNT WITH MY PARTNER I&#x27;M NOT SEEING THE OPTION TO DO IT ON THE APSO I CALLED IN TO GET SOME HELP CAN I JUST DO IT OVER THE PHONE WITH YOU AND GIVE YOU THE INFORMATION OR SHOULD I DO IT IN THE AP AN I&#x27;M MISSING SOMETHING UQUETTE HAD PREFERRED TO JUST DO IT OVER THE PHONE OF POSSIBLE THINGS&quot;</span>, <span class="hljs-string">&#x27;HOW DO I FURN A JOINA COUT&#x27;</span>]`,wrap:!1}}),wt=new A({props:{title:"파이프라인에서 다른 모델과 토크나이저 사용하기",local:"use-another-model-and-tokenizer-in-the-pipeline",headingTag:"h3"}}),kt=new J({props:{code:"bW9kZWxfbmFtZSUyMCUzRCUyMCUyMm5scHRvd24lMkZiZXJ0LWJhc2UtbXVsdGlsaW5ndWFsLXVuY2FzZWQtc2VudGltZW50JTIy",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>',wrap:!1}}),S=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Pa],pytorch:[qa]},$$scope:{ctx:w}}}),Ut=new J({props:{code:"Y2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMnNlbnRpbWVudC1hbmFseXNpcyUyMiUyQyUyMG1vZGVsJTNEbW9kZWwlMkMlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIpJTBBY2xhc3NpZmllciglMjJOb3VzJTIwc29tbWVzJTIwdHIlQzMlQThzJTIwaGV1cmV1eCUyMGRlJTIwdm91cyUyMHByJUMzJUE5c2VudGVyJTIwbGElMjBiaWJsaW90aCVDMyVBOHF1ZSUyMCVGMCU5RiVBNCU5NyUyMFRyYW5zZm9ybWVycy4lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;sentiment-analysis&quot;</span>, model=model, tokenizer=tokenizer)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(<span class="hljs-string">&quot;Nous sommes très heureux de vous présenter la bibliothèque 🤗 Transformers.&quot;</span>)
[{<span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;5 stars&#x27;</span>, <span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.7273</span>}]`,wrap:!1}}),Ct=new A({props:{title:"AutoClass",local:"autoclass",headingTag:"h2"}}),vt=new Ha({props:{id:"AhChOFRegn4"}}),Wt=new A({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h3"}}),Vt=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEFtb2RlbF9uYW1lJTIwJTNEJTIwJTIybmxwdG93biUyRmJlcnQtYmFzZS1tdWx0aWxpbmd1YWwtdW5jYXNlZC1zZW50aW1lbnQlMjIlMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZChtb2RlbF9uYW1lKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_name = <span class="hljs-string">&quot;nlptown/bert-base-multilingual-uncased-sentiment&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_name)`,wrap:!1}}),Ft=new J({props:{code:"ZW5jb2RpbmclMjAlM0QlMjB0b2tlbml6ZXIoJTIyV2UlMjBhcmUlMjB2ZXJ5JTIwaGFwcHklMjB0byUyMHNob3clMjB5b3UlMjB0aGUlMjAlRjAlOUYlQTQlOTclMjBUcmFuc2Zvcm1lcnMlMjBsaWJyYXJ5LiUyMiklMEFwcmludChlbmNvZGluZyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = tokenizer(<span class="hljs-string">&quot;We are very happy to show you the 🤗 Transformers library.&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(encoding)
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">11312</span>, <span class="hljs-number">10320</span>, <span class="hljs-number">12495</span>, <span class="hljs-number">19308</span>, <span class="hljs-number">10114</span>, <span class="hljs-number">11391</span>, <span class="hljs-number">10855</span>, <span class="hljs-number">10103</span>, <span class="hljs-number">100</span>, <span class="hljs-number">58263</span>, <span class="hljs-number">13299</span>, <span class="hljs-number">119</span>, <span class="hljs-number">102</span>],
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>],
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),P=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[tn],pytorch:[Da]},$$scope:{ctx:w}}}),O=new De({props:{$$slots:{default:[en]},$$scope:{ctx:w}}}),Et=new A({props:{title:"AutoModel",local:"automodel",headingTag:"h3"}}),D=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pn],pytorch:[an]},$$scope:{ctx:w}}}),K=new De({props:{$$slots:{default:[on]},$$scope:{ctx:w}}}),Yt=new A({props:{title:"모델 저장하기",local:"save-a-model",headingTag:"h3"}}),tt=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[dn],pytorch:[cn]},$$scope:{ctx:w}}}),et=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[hn],pytorch:[un]},$$scope:{ctx:w}}}),Lt=new A({props:{title:"커스텀 모델 구축하기",local:"custom-model-builds",headingTag:"h2"}}),qt=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Db25maWclMEElMEFteV9jb25maWclMjAlM0QlMjBBdXRvQ29uZmlnLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIlMkMlMjBuX2hlYWRzJTNEMTIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>my_config = AutoConfig.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>, n_heads=<span class="hljs-number">12</span>)`,wrap:!1}}),st=new xe({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[jn],pytorch:[yn]},$$scope:{ctx:w}}}),Pt=new A({props:{title:"Trainer - PyTorch에 최적화된 훈련 루프",local:"trainer-a-pytorch-optimized-training-loop",headingTag:"h2"}}),te=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),se=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluaW5nQXJndW1lbnRzJTBBJTBBdHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJwYXRoJTJGdG8lMkZzYXZlJTJGZm9sZGVyJTJGJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0Q4JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0Q4JTJDJTBBJTIwJTIwJTIwJTIwbnVtX3RyYWluX2Vwb2NocyUzRDIlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TrainingArguments

<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;path/to/save/folder/&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">8</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),ae=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),re=new J({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZGF0YXNldCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJyb3R0ZW5fdG9tYXRvZXMlMjIpJTIwJTIwJTIzJTIwZG9jdGVzdCUzQSUyMCUyQklHTk9SRV9SRVNVTFQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = load_dataset(<span class="hljs-string">&quot;rotten_tomatoes&quot;</span>)  <span class="hljs-comment"># doctest: +IGNORE_RESULT</span>`,wrap:!1}}),pe=new J({props:{code:"ZGVmJTIwdG9rZW5pemVfZGF0YXNldChkYXRhc2V0KSUzQSUwQSUyMCUyMCUyMCUyMHJldHVybiUyMHRva2VuaXplcihkYXRhc2V0JTVCJTIydGV4dCUyMiU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_dataset</span>(<span class="hljs-params">dataset</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(dataset[<span class="hljs-string">&quot;text&quot;</span>])`,wrap:!1}}),oe=new J({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKHRva2VuaXplX2RhdGFzZXQlMkMlMjBiYXRjaGVkJTNEVHJ1ZSk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(tokenize_dataset, batched=<span class="hljs-literal">True</span>)',wrap:!1}}),me=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvcldpdGhQYWRkaW5nJTBBJTBBZGF0YV9jb2xsYXRvciUyMCUzRCUyMERhdGFDb2xsYXRvcldpdGhQYWRkaW5nKHRva2VuaXplciUzRHRva2VuaXplcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorWithPadding

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorWithPadding(tokenizer=tokenizer)`,wrap:!1}}),fe=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRyYWluZXIlMEElMEF0cmFpbmVyJTIwJTNEJTIwVHJhaW5lciglMEElMjAlMjAlMjAlMjBtb2RlbCUzRG1vZGVsJTJDJTBBJTIwJTIwJTIwJTIwYXJncyUzRHRyYWluaW5nX2FyZ3MlMkMlMEElMjAlMjAlMjAlMjB0cmFpbl9kYXRhc2V0JTNEZGF0YXNldCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEZGF0YXNldCU1QiUyMnRlc3QlMjIlNUQlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMEElMjAlMjAlMjAlMjBkYXRhX2NvbGxhdG9yJTNEZGF0YV9jb2xsYXRvciUyQyUwQSklMjAlMjAlMjMlMjBkb2N0ZXN0JTNBJTIwJTJCU0tJUA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`,wrap:!1}}),$e=new J({props:{code:"dHJhaW5lci50cmFpbigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()',wrap:!1}}),lt=new De({props:{$$slots:{default:[Tn]},$$scope:{ctx:w}}}),he=new A({props:{title:"TensorFlow로 훈련시키기",local:"train-with-tensorflow",headingTag:"h2"}}),be=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),Te=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),Je=new J({props:{code:"ZGVmJTIwdG9rZW5pemVfZGF0YXNldChkYXRhc2V0KSUzQSUwQSUyMCUyMCUyMCUyMHJldHVybiUyMHRva2VuaXplcihkYXRhc2V0JTVCJTIydGV4dCUyMiU1RCklMjAlMjAlMjMlMjBkb2N0ZXN0JTNBJTIwJTJCU0tJUA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_dataset</span>(<span class="hljs-params">dataset</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer(dataset[<span class="hljs-string">&quot;text&quot;</span>])  <span class="hljs-comment"># doctest: +SKIP</span>`,wrap:!1}}),_e=new J({props:{code:"ZGF0YXNldCUyMCUzRCUyMGRhdGFzZXQubWFwKHRva2VuaXplX2RhdGFzZXQpJTIwJTIwJTIzJTIwZG9jdGVzdCUzQSUyMCUyQlNLSVAlMEF0Zl9kYXRhc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGRhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUyMGJhdGNoX3NpemUlM0QxNiUyQyUyMHNodWZmbGUlM0RUcnVlJTJDJTIwdG9rZW5pemVyJTNEdG9rZW5pemVyJTBBKSUyMCUyMCUyMyUyMGRvY3Rlc3QlM0ElMjAlMkJTS0lQ",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>dataset = dataset.<span class="hljs-built_in">map</span>(tokenize_dataset)  <span class="hljs-comment"># doctest: +SKIP</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_dataset = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    dataset[<span class="hljs-string">&quot;train&quot;</span>], batch_size=<span class="hljs-number">16</span>, shuffle=<span class="hljs-literal">True</span>, tokenizer=tokenizer
<span class="hljs-meta">... </span>)  <span class="hljs-comment"># doctest: +SKIP</span>`,wrap:!1}}),Ze=new J({props:{code:"ZnJvbSUyMHRlbnNvcmZsb3cua2VyYXMub3B0aW1pemVycyUyMGltcG9ydCUyMEFkYW0lMEElMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzREFkYW0oM2UtNSkpJTIwJTIwJTIzJTIwTm8lMjBsb3NzJTIwYXJndW1lbnQhJTBBbW9kZWwuZml0KHRmX2RhdGFzZXQpJTIwJTIwJTIzJTIwZG9jdGVzdCUzQSUyMCUyQlNLSVA=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow.keras.optimizers <span class="hljs-keyword">import</span> Adam

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=Adam(<span class="hljs-number">3e-5</span>))  <span class="hljs-comment"># No loss argument!</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_dataset)  <span class="hljs-comment"># doctest: +SKIP</span>`,wrap:!1}}),Ce=new A({props:{title:"다음 단계는 무엇인가요?",local:"whats-next",headingTag:"h2"}}),{c(){s=y("meta"),p=o(),e=y("p"),n=o(),d(f.$$.fragment),m=o(),d(_.$$.fragment),C=o(),v=y("p"),v.innerHTML=G,j=o(),Z=y("p"),Z.textContent=W,Q=o(),d(H.$$.fragment),R=o(),V=y("p"),V.textContent=c,U=o(),d(N.$$.fragment),ts=o(),d(at.$$.fragment),es=o(),d(nt.$$.fragment),ss=o(),rt=y("p"),rt.innerHTML=Yl,ls=o(),d(q.$$.fragment),as=o(),pt=y("table"),pt.innerHTML=Bl,ns=o(),ot=y("p"),ot.innerHTML=Ll,rs=o(),d(it.$$.fragment),ps=o(),mt=y("p"),mt.innerHTML=Al,os=o(),d(ct.$$.fragment),is=o(),ft=y("p"),ft.innerHTML=Ql,ms=o(),d(dt.$$.fragment),cs=o(),$t=y("p"),$t.innerHTML=ql,fs=o(),d(ut.$$.fragment),ds=o(),gt=y("p"),gt.innerHTML=Sl,$s=o(),d(ht.$$.fragment),us=o(),Mt=y("p"),Mt.innerHTML=Pl,gs=o(),d(yt.$$.fragment),hs=o(),bt=y("p"),bt.innerHTML=Ol,Ms=o(),d(jt.$$.fragment),ys=o(),Tt=y("p"),Tt.innerHTML=Dl,bs=o(),d(wt.$$.fragment),js=o(),Jt=y("p"),Jt.innerHTML=Kl,Ts=o(),d(kt.$$.fragment),ws=o(),d(S.$$.fragment),Js=o(),_t=y("p"),_t.innerHTML=ta,ks=o(),d(Ut.$$.fragment),_s=o(),Zt=y("p"),Zt.innerHTML=ea,Us=o(),d(Ct.$$.fragment),Zs=o(),d(vt.$$.fragment),Cs=o(),Gt=y("p"),Gt.innerHTML=sa,vs=o(),Rt=y("p"),Rt.innerHTML=la,Gs=o(),d(Wt.$$.fragment),Rs=o(),It=y("p"),It.innerHTML=aa,Ws=o(),Ht=y("p"),Ht.innerHTML=na,Is=o(),d(Vt.$$.fragment),Hs=o(),Xt=y("p"),Xt.textContent=ra,Vs=o(),d(Ft.$$.fragment),Xs=o(),xt=y("p"),xt.textContent=pa,Fs=o(),Nt=y("ul"),Nt.innerHTML=oa,xs=o(),zt=y("p"),zt.textContent=ia,Ns=o(),d(P.$$.fragment),zs=o(),d(O.$$.fragment),Es=o(),d(Et.$$.fragment),Ys=o(),d(D.$$.fragment),Bs=o(),d(K.$$.fragment),Ls=o(),d(Yt.$$.fragment),As=o(),d(tt.$$.fragment),Qs=o(),Bt=y("p"),Bt.innerHTML=ma,qs=o(),d(et.$$.fragment),Ss=o(),d(Lt.$$.fragment),Ps=o(),At=y("p"),At.textContent=ca,Os=o(),Qt=y("p"),Qt.innerHTML=fa,Ds=o(),d(qt.$$.fragment),Ks=o(),d(st.$$.fragment),tl=o(),St=y("p"),St.innerHTML=da,el=o(),d(Pt.$$.fragment),sl=o(),Ot=y("p"),Ot.innerHTML=$a,ll=o(),Dt=y("p"),Dt.innerHTML=ua,al=o(),X=y("ol"),Kt=y("li"),Ne=y("p"),Ne.innerHTML=ga,jl=o(),d(te.$$.fragment),Tl=o(),ee=y("li"),ze=y("p"),ze.innerHTML=ha,wl=o(),d(se.$$.fragment),Jl=o(),le=y("li"),Ee=y("p"),Ee.textContent=Ma,kl=o(),d(ae.$$.fragment),_l=o(),ne=y("li"),Ye=y("p"),Ye.textContent=ya,Ul=o(),d(re.$$.fragment),Zl=o(),B=y("li"),Be=y("p"),Be.textContent=ba,Cl=o(),d(pe.$$.fragment),vl=o(),Le=y("p"),Le.innerHTML=ja,Gl=o(),d(oe.$$.fragment),Rl=o(),ie=y("li"),Ae=y("p"),Ae.innerHTML=Ta,Wl=o(),d(me.$$.fragment),nl=o(),ce=y("p"),ce.innerHTML=wa,rl=o(),d(fe.$$.fragment),pl=o(),de=y("p"),de.innerHTML=Ja,ol=o(),d($e.$$.fragment),il=o(),d(lt.$$.fragment),ml=o(),ue=y("p"),ue.innerHTML=ka,cl=o(),ge=y("p"),ge.innerHTML=_a,fl=o(),d(he.$$.fragment),dl=o(),Me=y("p"),Me.innerHTML=Ua,$l=o(),z=y("ol"),ye=y("li"),Qe=y("p"),Qe.innerHTML=Za,Il=o(),d(be.$$.fragment),Hl=o(),je=y("li"),qe=y("p"),qe.textContent=Ca,Vl=o(),d(Te.$$.fragment),Xl=o(),we=y("li"),Se=y("p"),Se.textContent=va,Fl=o(),d(Je.$$.fragment),xl=o(),ke=y("li"),Pe=y("p"),Pe.innerHTML=Ga,Nl=o(),d(_e.$$.fragment),zl=o(),Ue=y("li"),Oe=y("p"),Oe.innerHTML=Ra,El=o(),d(Ze.$$.fragment),ul=o(),d(Ce.$$.fragment),gl=o(),ve=y("p"),ve.textContent=Wa,hl=o(),Ke=y("p"),this.h()},l(t){const l=Na("svelte-u9bgzb",document.head);s=b(l,"META",{name:!0,content:!0}),l.forEach(a),p=i(t),e=b(t,"P",{}),x(e).forEach(a),n=i(t),$(f.$$.fragment,t),m=i(t),$(_.$$.fragment,t),C=i(t),v=b(t,"P",{"data-svelte-h":!0}),T(v)!=="svelte-6mg9x4"&&(v.innerHTML=G),j=i(t),Z=b(t,"P",{"data-svelte-h":!0}),T(Z)!=="svelte-1k0z9pm"&&(Z.textContent=W),Q=i(t),$(H.$$.fragment,t),R=i(t),V=b(t,"P",{"data-svelte-h":!0}),T(V)!=="svelte-15tdirm"&&(V.textContent=c),U=i(t),$(N.$$.fragment,t),ts=i(t),$(at.$$.fragment,t),es=i(t),$(nt.$$.fragment,t),ss=i(t),rt=b(t,"P",{"data-svelte-h":!0}),T(rt)!=="svelte-1w7vzh3"&&(rt.innerHTML=Yl),ls=i(t),$(q.$$.fragment,t),as=i(t),pt=b(t,"TABLE",{"data-svelte-h":!0}),T(pt)!=="svelte-1hgozun"&&(pt.innerHTML=Bl),ns=i(t),ot=b(t,"P",{"data-svelte-h":!0}),T(ot)!=="svelte-azyw3l"&&(ot.innerHTML=Ll),rs=i(t),$(it.$$.fragment,t),ps=i(t),mt=b(t,"P",{"data-svelte-h":!0}),T(mt)!=="svelte-ijc3e4"&&(mt.innerHTML=Al),os=i(t),$(ct.$$.fragment,t),is=i(t),ft=b(t,"P",{"data-svelte-h":!0}),T(ft)!=="svelte-1ojxldp"&&(ft.innerHTML=Ql),ms=i(t),$(dt.$$.fragment,t),cs=i(t),$t=b(t,"P",{"data-svelte-h":!0}),T($t)!=="svelte-1j1fqr5"&&($t.innerHTML=ql),fs=i(t),$(ut.$$.fragment,t),ds=i(t),gt=b(t,"P",{"data-svelte-h":!0}),T(gt)!=="svelte-1h4e9f5"&&(gt.innerHTML=Sl),$s=i(t),$(ht.$$.fragment,t),us=i(t),Mt=b(t,"P",{"data-svelte-h":!0}),T(Mt)!=="svelte-14oiedi"&&(Mt.innerHTML=Pl),gs=i(t),$(yt.$$.fragment,t),hs=i(t),bt=b(t,"P",{"data-svelte-h":!0}),T(bt)!=="svelte-1yaj65v"&&(bt.innerHTML=Ol),Ms=i(t),$(jt.$$.fragment,t),ys=i(t),Tt=b(t,"P",{"data-svelte-h":!0}),T(Tt)!=="svelte-1r53z39"&&(Tt.innerHTML=Dl),bs=i(t),$(wt.$$.fragment,t),js=i(t),Jt=b(t,"P",{"data-svelte-h":!0}),T(Jt)!=="svelte-1r35uy"&&(Jt.innerHTML=Kl),Ts=i(t),$(kt.$$.fragment,t),ws=i(t),$(S.$$.fragment,t),Js=i(t),_t=b(t,"P",{"data-svelte-h":!0}),T(_t)!=="svelte-94oea8"&&(_t.innerHTML=ta),ks=i(t),$(Ut.$$.fragment,t),_s=i(t),Zt=b(t,"P",{"data-svelte-h":!0}),T(Zt)!=="svelte-q9e5jp"&&(Zt.innerHTML=ea),Us=i(t),$(Ct.$$.fragment,t),Zs=i(t),$(vt.$$.fragment,t),Cs=i(t),Gt=b(t,"P",{"data-svelte-h":!0}),T(Gt)!=="svelte-14dotb2"&&(Gt.innerHTML=sa),vs=i(t),Rt=b(t,"P",{"data-svelte-h":!0}),T(Rt)!=="svelte-1jdzkyq"&&(Rt.innerHTML=la),Gs=i(t),$(Wt.$$.fragment,t),Rs=i(t),It=b(t,"P",{"data-svelte-h":!0}),T(It)!=="svelte-ec7bh3"&&(It.innerHTML=aa),Ws=i(t),Ht=b(t,"P",{"data-svelte-h":!0}),T(Ht)!=="svelte-zox7f"&&(Ht.innerHTML=na),Is=i(t),$(Vt.$$.fragment,t),Hs=i(t),Xt=b(t,"P",{"data-svelte-h":!0}),T(Xt)!=="svelte-1jksv9d"&&(Xt.textContent=ra),Vs=i(t),$(Ft.$$.fragment,t),Xs=i(t),xt=b(t,"P",{"data-svelte-h":!0}),T(xt)!=="svelte-1c10jmq"&&(xt.textContent=pa),Fs=i(t),Nt=b(t,"UL",{"data-svelte-h":!0}),T(Nt)!=="svelte-99hc5f"&&(Nt.innerHTML=oa),xs=i(t),zt=b(t,"P",{"data-svelte-h":!0}),T(zt)!=="svelte-jype1g"&&(zt.textContent=ia),Ns=i(t),$(P.$$.fragment,t),zs=i(t),$(O.$$.fragment,t),Es=i(t),$(Et.$$.fragment,t),Ys=i(t),$(D.$$.fragment,t),Bs=i(t),$(K.$$.fragment,t),Ls=i(t),$(Yt.$$.fragment,t),As=i(t),$(tt.$$.fragment,t),Qs=i(t),Bt=b(t,"P",{"data-svelte-h":!0}),T(Bt)!=="svelte-olv60e"&&(Bt.innerHTML=ma),qs=i(t),$(et.$$.fragment,t),Ss=i(t),$(Lt.$$.fragment,t),Ps=i(t),At=b(t,"P",{"data-svelte-h":!0}),T(At)!=="svelte-pasr7c"&&(At.textContent=ca),Os=i(t),Qt=b(t,"P",{"data-svelte-h":!0}),T(Qt)!=="svelte-1dwc4qs"&&(Qt.innerHTML=fa),Ds=i(t),$(qt.$$.fragment,t),Ks=i(t),$(st.$$.fragment,t),tl=i(t),St=b(t,"P",{"data-svelte-h":!0}),T(St)!=="svelte-1glm9pk"&&(St.innerHTML=da),el=i(t),$(Pt.$$.fragment,t),sl=i(t),Ot=b(t,"P",{"data-svelte-h":!0}),T(Ot)!=="svelte-1ximgfp"&&(Ot.innerHTML=$a),ll=i(t),Dt=b(t,"P",{"data-svelte-h":!0}),T(Dt)!=="svelte-1fcrkl9"&&(Dt.innerHTML=ua),al=i(t),X=b(t,"OL",{});var F=x(X);Kt=b(F,"LI",{});var Ge=x(Kt);Ne=b(Ge,"P",{"data-svelte-h":!0}),T(Ne)!=="svelte-1ndluax"&&(Ne.innerHTML=ga),jl=i(Ge),$(te.$$.fragment,Ge),Ge.forEach(a),Tl=i(F),ee=b(F,"LI",{});var Re=x(ee);ze=b(Re,"P",{"data-svelte-h":!0}),T(ze)!=="svelte-18oxlfo"&&(ze.innerHTML=ha),wl=i(Re),$(se.$$.fragment,Re),Re.forEach(a),Jl=i(F),le=b(F,"LI",{});var We=x(le);Ee=b(We,"P",{"data-svelte-h":!0}),T(Ee)!=="svelte-1v961uv"&&(Ee.textContent=Ma),kl=i(We),$(ae.$$.fragment,We),We.forEach(a),_l=i(F),ne=b(F,"LI",{});var Ie=x(ne);Ye=b(Ie,"P",{"data-svelte-h":!0}),T(Ye)!=="svelte-1pb52rt"&&(Ye.textContent=ya),Ul=i(Ie),$(re.$$.fragment,Ie),Ie.forEach(a),Zl=i(F),B=b(F,"LI",{});var L=x(B);Be=b(L,"P",{"data-svelte-h":!0}),T(Be)!=="svelte-1vmtcn7"&&(Be.textContent=ba),Cl=i(L),$(pe.$$.fragment,L),vl=i(L),Le=b(L,"P",{"data-svelte-h":!0}),T(Le)!=="svelte-1c5wtqo"&&(Le.innerHTML=ja),Gl=i(L),$(oe.$$.fragment,L),L.forEach(a),Rl=i(F),ie=b(F,"LI",{});var He=x(ie);Ae=b(He,"P",{"data-svelte-h":!0}),T(Ae)!=="svelte-1jzjwm2"&&(Ae.innerHTML=Ta),Wl=i(He),$(me.$$.fragment,He),He.forEach(a),F.forEach(a),nl=i(t),ce=b(t,"P",{"data-svelte-h":!0}),T(ce)!=="svelte-hkenju"&&(ce.innerHTML=wa),rl=i(t),$(fe.$$.fragment,t),pl=i(t),de=b(t,"P",{"data-svelte-h":!0}),T(de)!=="svelte-1awed5n"&&(de.innerHTML=Ja),ol=i(t),$($e.$$.fragment,t),il=i(t),$(lt.$$.fragment,t),ml=i(t),ue=b(t,"P",{"data-svelte-h":!0}),T(ue)!=="svelte-1cvip2r"&&(ue.innerHTML=ka),cl=i(t),ge=b(t,"P",{"data-svelte-h":!0}),T(ge)!=="svelte-ajmll9"&&(ge.innerHTML=_a),fl=i(t),$(he.$$.fragment,t),dl=i(t),Me=b(t,"P",{"data-svelte-h":!0}),T(Me)!=="svelte-myeyeb"&&(Me.innerHTML=Ua),$l=i(t),z=b(t,"OL",{});var Y=x(z);ye=b(Y,"LI",{});var Ve=x(ye);Qe=b(Ve,"P",{"data-svelte-h":!0}),T(Qe)!=="svelte-1y6y9l8"&&(Qe.innerHTML=Za),Il=i(Ve),$(be.$$.fragment,Ve),Ve.forEach(a),Hl=i(Y),je=b(Y,"LI",{});var Xe=x(je);qe=b(Xe,"P",{"data-svelte-h":!0}),T(qe)!=="svelte-18oe8vk"&&(qe.textContent=Ca),Vl=i(Xe),$(Te.$$.fragment,Xe),Xe.forEach(a),Xl=i(Y),we=b(Y,"LI",{});var Fe=x(we);Se=b(Fe,"P",{"data-svelte-h":!0}),T(Se)!=="svelte-1vmtcn7"&&(Se.textContent=va),Fl=i(Fe),$(Je.$$.fragment,Fe),Fe.forEach(a),xl=i(Y),ke=b(Y,"LI",{});var yl=x(ke);Pe=b(yl,"P",{"data-svelte-h":!0}),T(Pe)!=="svelte-m3lu8g"&&(Pe.innerHTML=Ga),Nl=i(yl),$(_e.$$.fragment,yl),yl.forEach(a),zl=i(Y),Ue=b(Y,"LI",{});var bl=x(Ue);Oe=b(bl,"P",{"data-svelte-h":!0}),T(Oe)!=="svelte-ffpzwi"&&(Oe.innerHTML=Ra),El=i(bl),$(Ze.$$.fragment,bl),bl.forEach(a),Y.forEach(a),ul=i(t),$(Ce.$$.fragment,t),gl=i(t),ve=b(t,"P",{"data-svelte-h":!0}),T(ve)!=="svelte-vqs42a"&&(ve.textContent=Wa),hl=i(t),Ke=b(t,"P",{}),x(Ke).forEach(a),this.h()},h(){Ia(s,"name","hf:doc:metadata"),Ia(s,"content",Jn)},m(t,l){k(document.head,s),r(t,p,l),r(t,e,l),r(t,n,l),u(f,t,l),r(t,m,l),u(_,t,l),r(t,C,l),r(t,v,l),r(t,j,l),r(t,Z,l),r(t,Q,l),u(H,t,l),r(t,R,l),r(t,V,l),r(t,U,l),u(N,t,l),r(t,ts,l),u(at,t,l),r(t,es,l),u(nt,t,l),r(t,ss,l),r(t,rt,l),r(t,ls,l),u(q,t,l),r(t,as,l),r(t,pt,l),r(t,ns,l),r(t,ot,l),r(t,rs,l),u(it,t,l),r(t,ps,l),r(t,mt,l),r(t,os,l),u(ct,t,l),r(t,is,l),r(t,ft,l),r(t,ms,l),u(dt,t,l),r(t,cs,l),r(t,$t,l),r(t,fs,l),u(ut,t,l),r(t,ds,l),r(t,gt,l),r(t,$s,l),u(ht,t,l),r(t,us,l),r(t,Mt,l),r(t,gs,l),u(yt,t,l),r(t,hs,l),r(t,bt,l),r(t,Ms,l),u(jt,t,l),r(t,ys,l),r(t,Tt,l),r(t,bs,l),u(wt,t,l),r(t,js,l),r(t,Jt,l),r(t,Ts,l),u(kt,t,l),r(t,ws,l),u(S,t,l),r(t,Js,l),r(t,_t,l),r(t,ks,l),u(Ut,t,l),r(t,_s,l),r(t,Zt,l),r(t,Us,l),u(Ct,t,l),r(t,Zs,l),u(vt,t,l),r(t,Cs,l),r(t,Gt,l),r(t,vs,l),r(t,Rt,l),r(t,Gs,l),u(Wt,t,l),r(t,Rs,l),r(t,It,l),r(t,Ws,l),r(t,Ht,l),r(t,Is,l),u(Vt,t,l),r(t,Hs,l),r(t,Xt,l),r(t,Vs,l),u(Ft,t,l),r(t,Xs,l),r(t,xt,l),r(t,Fs,l),r(t,Nt,l),r(t,xs,l),r(t,zt,l),r(t,Ns,l),u(P,t,l),r(t,zs,l),u(O,t,l),r(t,Es,l),u(Et,t,l),r(t,Ys,l),u(D,t,l),r(t,Bs,l),u(K,t,l),r(t,Ls,l),u(Yt,t,l),r(t,As,l),u(tt,t,l),r(t,Qs,l),r(t,Bt,l),r(t,qs,l),u(et,t,l),r(t,Ss,l),u(Lt,t,l),r(t,Ps,l),r(t,At,l),r(t,Os,l),r(t,Qt,l),r(t,Ds,l),u(qt,t,l),r(t,Ks,l),u(st,t,l),r(t,tl,l),r(t,St,l),r(t,el,l),u(Pt,t,l),r(t,sl,l),r(t,Ot,l),r(t,ll,l),r(t,Dt,l),r(t,al,l),r(t,X,l),k(X,Kt),k(Kt,Ne),k(Kt,jl),u(te,Kt,null),k(X,Tl),k(X,ee),k(ee,ze),k(ee,wl),u(se,ee,null),k(X,Jl),k(X,le),k(le,Ee),k(le,kl),u(ae,le,null),k(X,_l),k(X,ne),k(ne,Ye),k(ne,Ul),u(re,ne,null),k(X,Zl),k(X,B),k(B,Be),k(B,Cl),u(pe,B,null),k(B,vl),k(B,Le),k(B,Gl),u(oe,B,null),k(X,Rl),k(X,ie),k(ie,Ae),k(ie,Wl),u(me,ie,null),r(t,nl,l),r(t,ce,l),r(t,rl,l),u(fe,t,l),r(t,pl,l),r(t,de,l),r(t,ol,l),u($e,t,l),r(t,il,l),u(lt,t,l),r(t,ml,l),r(t,ue,l),r(t,cl,l),r(t,ge,l),r(t,fl,l),u(he,t,l),r(t,dl,l),r(t,Me,l),r(t,$l,l),r(t,z,l),k(z,ye),k(ye,Qe),k(ye,Il),u(be,ye,null),k(z,Hl),k(z,je),k(je,qe),k(je,Vl),u(Te,je,null),k(z,Xl),k(z,we),k(we,Se),k(we,Fl),u(Je,we,null),k(z,xl),k(z,ke),k(ke,Pe),k(ke,Nl),u(_e,ke,null),k(z,zl),k(z,Ue),k(Ue,Oe),k(Ue,El),u(Ze,Ue,null),r(t,ul,l),u(Ce,t,l),r(t,gl,l),r(t,ve,l),r(t,hl,l),r(t,Ke,l),Ml=!0},p(t,[l]){const F={};l&2&&(F.$$scope={dirty:l,ctx:t}),N.$set(F);const Ge={};l&2&&(Ge.$$scope={dirty:l,ctx:t}),q.$set(Ge);const Re={};l&2&&(Re.$$scope={dirty:l,ctx:t}),S.$set(Re);const We={};l&2&&(We.$$scope={dirty:l,ctx:t}),P.$set(We);const Ie={};l&2&&(Ie.$$scope={dirty:l,ctx:t}),O.$set(Ie);const L={};l&2&&(L.$$scope={dirty:l,ctx:t}),D.$set(L);const He={};l&2&&(He.$$scope={dirty:l,ctx:t}),K.$set(He);const Y={};l&2&&(Y.$$scope={dirty:l,ctx:t}),tt.$set(Y);const Ve={};l&2&&(Ve.$$scope={dirty:l,ctx:t}),et.$set(Ve);const Xe={};l&2&&(Xe.$$scope={dirty:l,ctx:t}),st.$set(Xe);const Fe={};l&2&&(Fe.$$scope={dirty:l,ctx:t}),lt.$set(Fe)},i(t){Ml||(g(f.$$.fragment,t),g(_.$$.fragment,t),g(H.$$.fragment,t),g(N.$$.fragment,t),g(at.$$.fragment,t),g(nt.$$.fragment,t),g(q.$$.fragment,t),g(it.$$.fragment,t),g(ct.$$.fragment,t),g(dt.$$.fragment,t),g(ut.$$.fragment,t),g(ht.$$.fragment,t),g(yt.$$.fragment,t),g(jt.$$.fragment,t),g(wt.$$.fragment,t),g(kt.$$.fragment,t),g(S.$$.fragment,t),g(Ut.$$.fragment,t),g(Ct.$$.fragment,t),g(vt.$$.fragment,t),g(Wt.$$.fragment,t),g(Vt.$$.fragment,t),g(Ft.$$.fragment,t),g(P.$$.fragment,t),g(O.$$.fragment,t),g(Et.$$.fragment,t),g(D.$$.fragment,t),g(K.$$.fragment,t),g(Yt.$$.fragment,t),g(tt.$$.fragment,t),g(et.$$.fragment,t),g(Lt.$$.fragment,t),g(qt.$$.fragment,t),g(st.$$.fragment,t),g(Pt.$$.fragment,t),g(te.$$.fragment,t),g(se.$$.fragment,t),g(ae.$$.fragment,t),g(re.$$.fragment,t),g(pe.$$.fragment,t),g(oe.$$.fragment,t),g(me.$$.fragment,t),g(fe.$$.fragment,t),g($e.$$.fragment,t),g(lt.$$.fragment,t),g(he.$$.fragment,t),g(be.$$.fragment,t),g(Te.$$.fragment,t),g(Je.$$.fragment,t),g(_e.$$.fragment,t),g(Ze.$$.fragment,t),g(Ce.$$.fragment,t),Ml=!0)},o(t){h(f.$$.fragment,t),h(_.$$.fragment,t),h(H.$$.fragment,t),h(N.$$.fragment,t),h(at.$$.fragment,t),h(nt.$$.fragment,t),h(q.$$.fragment,t),h(it.$$.fragment,t),h(ct.$$.fragment,t),h(dt.$$.fragment,t),h(ut.$$.fragment,t),h(ht.$$.fragment,t),h(yt.$$.fragment,t),h(jt.$$.fragment,t),h(wt.$$.fragment,t),h(kt.$$.fragment,t),h(S.$$.fragment,t),h(Ut.$$.fragment,t),h(Ct.$$.fragment,t),h(vt.$$.fragment,t),h(Wt.$$.fragment,t),h(Vt.$$.fragment,t),h(Ft.$$.fragment,t),h(P.$$.fragment,t),h(O.$$.fragment,t),h(Et.$$.fragment,t),h(D.$$.fragment,t),h(K.$$.fragment,t),h(Yt.$$.fragment,t),h(tt.$$.fragment,t),h(et.$$.fragment,t),h(Lt.$$.fragment,t),h(qt.$$.fragment,t),h(st.$$.fragment,t),h(Pt.$$.fragment,t),h(te.$$.fragment,t),h(se.$$.fragment,t),h(ae.$$.fragment,t),h(re.$$.fragment,t),h(pe.$$.fragment,t),h(oe.$$.fragment,t),h(me.$$.fragment,t),h(fe.$$.fragment,t),h($e.$$.fragment,t),h(lt.$$.fragment,t),h(he.$$.fragment,t),h(be.$$.fragment,t),h(Te.$$.fragment,t),h(Je.$$.fragment,t),h(_e.$$.fragment,t),h(Ze.$$.fragment,t),h(Ce.$$.fragment,t),Ml=!1},d(t){t&&(a(p),a(e),a(n),a(m),a(C),a(v),a(j),a(Z),a(Q),a(R),a(V),a(U),a(ts),a(es),a(ss),a(rt),a(ls),a(as),a(pt),a(ns),a(ot),a(rs),a(ps),a(mt),a(os),a(is),a(ft),a(ms),a(cs),a($t),a(fs),a(ds),a(gt),a($s),a(us),a(Mt),a(gs),a(hs),a(bt),a(Ms),a(ys),a(Tt),a(bs),a(js),a(Jt),a(Ts),a(ws),a(Js),a(_t),a(ks),a(_s),a(Zt),a(Us),a(Zs),a(Cs),a(Gt),a(vs),a(Rt),a(Gs),a(Rs),a(It),a(Ws),a(Ht),a(Is),a(Hs),a(Xt),a(Vs),a(Xs),a(xt),a(Fs),a(Nt),a(xs),a(zt),a(Ns),a(zs),a(Es),a(Ys),a(Bs),a(Ls),a(As),a(Qs),a(Bt),a(qs),a(Ss),a(Ps),a(At),a(Os),a(Qt),a(Ds),a(Ks),a(tl),a(St),a(el),a(sl),a(Ot),a(ll),a(Dt),a(al),a(X),a(nl),a(ce),a(rl),a(pl),a(de),a(ol),a(il),a(ml),a(ue),a(cl),a(ge),a(fl),a(dl),a(Me),a($l),a(z),a(ul),a(gl),a(ve),a(hl),a(Ke)),a(s),M(f,t),M(_,t),M(H,t),M(N,t),M(at,t),M(nt,t),M(q,t),M(it,t),M(ct,t),M(dt,t),M(ut,t),M(ht,t),M(yt,t),M(jt,t),M(wt,t),M(kt,t),M(S,t),M(Ut,t),M(Ct,t),M(vt,t),M(Wt,t),M(Vt,t),M(Ft,t),M(P,t),M(O,t),M(Et,t),M(D,t),M(K,t),M(Yt,t),M(tt,t),M(et,t),M(Lt,t),M(qt,t),M(st,t),M(Pt,t),M(te),M(se),M(ae),M(re),M(pe),M(oe),M(me),M(fe,t),M($e,t),M(lt,t),M(he,t),M(be),M(Te),M(Je),M(_e),M(Ze),M(Ce,t)}}}const Jn='{"title":"둘러보기","local":"quick-tour","sections":[{"title":"파이프라인","local":"pipeline","sections":[{"title":"파이프라인에서 다른 모델과 토크나이저 사용하기","local":"use-another-model-and-tokenizer-in-the-pipeline","sections":[],"depth":3}],"depth":2},{"title":"AutoClass","local":"autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":3},{"title":"AutoModel","local":"automodel","sections":[],"depth":3},{"title":"모델 저장하기","local":"save-a-model","sections":[],"depth":3}],"depth":2},{"title":"커스텀 모델 구축하기","local":"custom-model-builds","sections":[],"depth":2},{"title":"Trainer - PyTorch에 최적화된 훈련 루프","local":"trainer-a-pytorch-optimized-training-loop","sections":[],"depth":2},{"title":"TensorFlow로 훈련시키기","local":"train-with-tensorflow","sections":[],"depth":2},{"title":"다음 단계는 무엇인가요?","local":"whats-next","sections":[],"depth":2}],"depth":1}';function kn(w){return Xa(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class In extends Fa{constructor(s){super(),xa(this,s,kn,wn,Va,{})}}export{In as component};
