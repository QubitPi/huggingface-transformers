import{s as k,n as U,o as q}from"../chunks/scheduler.56730f09.js";import{S as A,i as D,g as r,s as i,r as S,A as K,h as o,f as a,c as s,j as G,u as N,x as g,k as j,y as O,a as l,v as z,d as I,t as F,w as J}from"../chunks/index.1f144517.js";import{H as Q}from"../chunks/Heading.57d46534.js";function V(C){let n,x,v,b,p,_,h,M=`BERT와 같은 대규모 트랜스포머의 내부 동작을 조사하는 연구 분야가 점점 더 중요해지고 있습니다.
혹자는 “BERTology”라 칭하기도 합니다. 이 분야의 좋은 예시는 다음과 같습니다:`,P,f,R=`<li>BERT는 고전적인 NLP 파이프라인의 재발견 - Ian Tenney, Dipanjan Das, Ellie Pavlick:
<a href="https://arxiv.org/abs/1905.05950" rel="nofollow">https://arxiv.org/abs/1905.05950</a></li> <li>16개의 헤드가 정말로 1개보다 나은가? - Paul Michel, Omer Levy, Graham Neubig:
<a href="https://arxiv.org/abs/1905.10650" rel="nofollow">https://arxiv.org/abs/1905.10650</a></li> <li>BERT는 무엇을 보는가? BERT의 어텐션 분석 - Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D. Manning:
<a href="https://arxiv.org/abs/1906.04341" rel="nofollow">https://arxiv.org/abs/1906.04341</a></li> <li>CAT-probing: 프로그래밍 언어에 대해 사전훈련된 모델이 어떻게 코드 구조를 보는지 알아보기 위한 메트릭 기반 접근 방법:
<a href="https://arxiv.org/abs/2210.04633" rel="nofollow">https://arxiv.org/abs/2210.04633</a></li>`,y,m,B=`우리는 이 새로운 연구 분야의 발전을 돕기 위해, BERT/GPT/GPT-2 모델에 내부 표현을 살펴볼 수 있는 몇 가지 기능을 추가했습니다.
이 기능들은 주로 Paul Michel의 훌륭한 작업을 참고하여 개발되었습니다
(<a href="https://arxiv.org/abs/1905.10650" rel="nofollow">https://arxiv.org/abs/1905.10650</a>):`,E,u,H='<li>BERT/GPT/GPT-2의 모든 은닉 상태에 접근하기,</li> <li>BERT/GPT/GPT-2의 각 헤드의 모든 어텐션 가중치에 접근하기,</li> <li>헤드의 출력 값과 그래디언트를 검색하여 헤드 중요도 점수를 계산하고 <a href="https://arxiv.org/abs/1905.10650%EC%97%90%EC%84%9C" rel="nofollow">https://arxiv.org/abs/1905.10650에서</a> 설명된 대로 헤드를 제거하는 기능을 제공합니다.</li>',d,c,$='이러한 기능들을 이해하고 직접 사용해볼 수 있도록 <a href="https://github.com/huggingface/transformers/tree/main/examples/research_projects/bertology/run_bertology.py" rel="nofollow">bertology.py</a> 예제 스크립트를 추가했습니다. 이 예제 스크립트에서는 GLUE에 대해 사전훈련된 모델에서 정보를 추출하고 모델을 가지치기(prune)해봅니다.',L,T,w;return p=new Q({props:{title:"BERTology",local:"bertology",headingTag:"h1"}}),{c(){n=r("meta"),x=i(),v=r("p"),b=i(),S(p.$$.fragment),_=i(),h=r("p"),h.textContent=M,P=i(),f=r("ul"),f.innerHTML=R,y=i(),m=r("p"),m.innerHTML=B,E=i(),u=r("ul"),u.innerHTML=H,d=i(),c=r("p"),c.innerHTML=$,L=i(),T=r("p"),this.h()},l(t){const e=K("svelte-u9bgzb",document.head);n=o(e,"META",{name:!0,content:!0}),e.forEach(a),x=s(t),v=o(t,"P",{}),G(v).forEach(a),b=s(t),N(p.$$.fragment,t),_=s(t),h=o(t,"P",{"data-svelte-h":!0}),g(h)!=="svelte-1j2i4ka"&&(h.textContent=M),P=s(t),f=o(t,"UL",{"data-svelte-h":!0}),g(f)!=="svelte-7yh4qj"&&(f.innerHTML=R),y=s(t),m=o(t,"P",{"data-svelte-h":!0}),g(m)!=="svelte-qnfkt5"&&(m.innerHTML=B),E=s(t),u=o(t,"UL",{"data-svelte-h":!0}),g(u)!=="svelte-1btj3hc"&&(u.innerHTML=H),d=s(t),c=o(t,"P",{"data-svelte-h":!0}),g(c)!=="svelte-5ng9ah"&&(c.innerHTML=$),L=s(t),T=o(t,"P",{}),G(T).forEach(a),this.h()},h(){j(n,"name","hf:doc:metadata"),j(n,"content",W)},m(t,e){O(document.head,n),l(t,x,e),l(t,v,e),l(t,b,e),z(p,t,e),l(t,_,e),l(t,h,e),l(t,P,e),l(t,f,e),l(t,y,e),l(t,m,e),l(t,E,e),l(t,u,e),l(t,d,e),l(t,c,e),l(t,L,e),l(t,T,e),w=!0},p:U,i(t){w||(I(p.$$.fragment,t),w=!0)},o(t){F(p.$$.fragment,t),w=!1},d(t){t&&(a(x),a(v),a(b),a(_),a(h),a(P),a(f),a(y),a(m),a(E),a(u),a(d),a(c),a(L),a(T)),a(n),J(p,t)}}}const W='{"title":"BERTology","local":"bertology","sections":[],"depth":1}';function X(C){return q(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class et extends A{constructor(n){super(),D(this,n,X,V,k,{})}}export{et as component};
