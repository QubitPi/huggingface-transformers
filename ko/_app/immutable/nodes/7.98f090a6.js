import{s as Fe,o as Ge,n as ye}from"../chunks/scheduler.56730f09.js";import{S as Ve,i as Re,g as d,s as m,r as y,A as Xe,h as b,f as t,c as i,j as ke,u as j,x as T,k as We,y as Ae,a,v as M,d as w,t as v,w as Z}from"../chunks/index.1f144517.js";import{T as Je}from"../chunks/Tip.41e845e5.js";import{C as G}from"../chunks/CodeBlock.738eeccb.js";import{F as He,M as Ue}from"../chunks/Markdown.c541024b.js";import{H as D}from"../chunks/Heading.57d46534.js";function Ne(J){let s,u='아키텍처는 모델의 골격을 의미하며 체크포인트는 주어진 아키텍처에 대한 가중치입니다. 예를 들어, <a href="https://huggingface.co/google-bert/bert-base-uncased" rel="nofollow">BERT</a>는 아키텍처이고, <code>google-bert/bert-base-uncased</code>는 체크포인트입니다. 모델은 아키텍처 또는 체크포인트를 의미할 수 있는 일반적인 용어입니다.';return{c(){s=d("p"),s.innerHTML=u},l(n){s=b(n,"P",{"data-svelte-h":!0}),T(s)!=="svelte-t6wtei"&&(s.innerHTML=u)},m(n,p){a(n,s,p)},p:ye,d(n){n&&t(s)}}}function Ee(J){let s,u=`PyTorch모델의 경우 <code>from_pretrained()</code> 메서드는 내부적으로 피클을 사용하여 안전하지 않은 것으로 알려진 <code>torch.load()</code>를 사용합니다.
일반적으로 신뢰할 수 없는 소스에서 가져왔거나 변조되었을 수 있는 모델은 로드하지 마세요. 허깅 페이스 허브에서 호스팅되는 공개 모델의 경우 이러한 보안 위험이 부분적으로 완화되며, 각 커밋 시 멀웨어를 <a href="https://huggingface.co/docs/hub/security-malware" rel="nofollow">검사합니다</a>. GPG를 사용해 서명된 <a href="https://huggingface.co/docs/hub/security-gpg#signing-commits-with-gpg" rel="nofollow">커밋 검증</a>과 같은 모범사례는 <a href="https://huggingface.co/docs/hub/security" rel="nofollow">문서</a>를 참조하세요.`,n,p,f="텐서플로우와 Flax 체크포인트는 영향을 받지 않으며, <code>from_pretrained</code>메서드에 <code>from_tf</code> 와 <code>from_flax</code> 키워드 가변 인자를 사용하여 이 문제를 우회할 수 있습니다.";return{c(){s=d("p"),s.innerHTML=u,n=m(),p=d("p"),p.innerHTML=f},l(c){s=b(c,"P",{"data-svelte-h":!0}),T(s)!=="svelte-1u3kbez"&&(s.innerHTML=u),n=i(c),p=b(c,"P",{"data-svelte-h":!0}),T(p)!=="svelte-7z7rov"&&(p.innerHTML=f)},m(c,x){a(c,s,x),a(c,n,x),a(c,p,x)},p:ye,d(c){c&&(t(s),t(n),t(p))}}}function Ye(J){let s,u='마지막으로 AutoModelFor클래스를 사용하면 주어진 작업에 대해 미리 학습된 모델을 로드할 수 있습니다 (사용 가능한 작업의 전체 목록은 <a href="model_doc/auto">여기</a>를 참조하세요). 예를 들어, <code>AutoModelForSequenceClassification.from_pretrained()</code>를 사용하여 시퀀스 분류용 모델을 로드할 수 있습니다:',n,p,f,c,x="동일한 체크포인트를 쉽게 재사용하여 다른 작업에 아키텍처를 로드할 수 있습니다:",U,g,_,h,k,W,o='일반적으로 AutoTokenizer 클래스와 AutoModelFor 클래스를 사용하여 미리 학습된 모델 인스턴스를 로드하는 것이 좋습니다. 이렇게 하면 매번 올바른 아키텍처를 로드할 수 있습니다. 다음 <a href="preprocessing">튜토리얼</a>에서는 새롭게 로드한 토크나이저, 이미지 프로세서, 특징 추출기를 사용하여 미세 튜닝용 데이터 세트를 전처리하는 방법에 대해 알아봅니다.',$;return p=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),g=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclRva2VuQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),h=new Je({props:{warning:!0,$$slots:{default:[Ee]},$$scope:{ctx:J}}}),{c(){s=d("p"),s.innerHTML=u,n=m(),y(p.$$.fragment),f=m(),c=d("p"),c.textContent=x,U=m(),y(g.$$.fragment),_=m(),y(h.$$.fragment),k=m(),W=d("p"),W.innerHTML=o},l(r){s=b(r,"P",{"data-svelte-h":!0}),T(s)!=="svelte-18uszv6"&&(s.innerHTML=u),n=i(r),j(p.$$.fragment,r),f=i(r),c=b(r,"P",{"data-svelte-h":!0}),T(c)!=="svelte-7ro1yz"&&(c.textContent=x),U=i(r),j(g.$$.fragment,r),_=i(r),j(h.$$.fragment,r),k=i(r),W=b(r,"P",{"data-svelte-h":!0}),T(W)!=="svelte-4umuej"&&(W.innerHTML=o)},m(r,C){a(r,s,C),a(r,n,C),M(p,r,C),a(r,f,C),a(r,c,C),a(r,U,C),M(g,r,C),a(r,_,C),M(h,r,C),a(r,k,C),a(r,W,C),$=!0},p(r,C){const F={};C&2&&(F.$$scope={dirty:C,ctx:r}),h.$set(F)},i(r){$||(w(p.$$.fragment,r),w(g.$$.fragment,r),w(h.$$.fragment,r),$=!0)},o(r){v(p.$$.fragment,r),v(g.$$.fragment,r),v(h.$$.fragment,r),$=!1},d(r){r&&(t(s),t(n),t(f),t(c),t(U),t(_),t(k),t(W)),Z(p,r),Z(g,r),Z(h,r)}}}function ze(J){let s,u;return s=new Ue({props:{$$slots:{default:[Ye]},$$scope:{ctx:J}}}),{c(){y(s.$$.fragment)},l(n){j(s.$$.fragment,n)},m(n,p){M(s,n,p),u=!0},p(n,p){const f={};p&2&&(f.$$scope={dirty:p,ctx:n}),s.$set(f)},i(n){u||(w(s.$$.fragment,n),u=!0)},o(n){v(s.$$.fragment,n),u=!1},d(n){Z(s,n)}}}function Le(J){let s,u='마지막으로 <code>TFAutoModelFor</code> 클래스를 사용하면 주어진 작업에 대해 사전 훈련된 모델을 로드할 수 있습니다. (사용 가능한 작업의 전체 목록은 <a href="model_doc/auto">여기</a>를 참조하세요. 예를 들어, <code>TFAutoModelForSequenceClassification.from_pretrained()</code>로 시퀀스 분류를 위한 모델을 로드합니다:',n,p,f,c,x="쉽게 동일한 체크포인트를 재사용하여 다른 작업에 아키텍처를 로드할 수 있습니다:",U,g,_,h,k='일반적으로, <code>AutoTokenizer</code>클래스와 <code>TFAutoModelFor</code> 클래스를 사용하여 미리 학습된 모델 인스턴스를 로드하는 것이 좋습니다. 이렇게 하면 매번 올바른 아키텍처를 로드할 수 있습니다. 다음 <a href="preprocessing">튜토리얼</a>에서는 새롭게 로드한 토크나이저, 이미지 프로세서, 특징 추출기를 사용하여 미세 튜닝용 데이터 세트를 전처리하는 방법에 대해 알아봅니다.',W;return p=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VxdWVuY2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JTZXF1ZW5jZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSequenceClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSequenceClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),g=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yVG9rZW5DbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JUb2tlbkNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForTokenClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForTokenClassification.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),{c(){s=d("p"),s.innerHTML=u,n=m(),y(p.$$.fragment),f=m(),c=d("p"),c.textContent=x,U=m(),y(g.$$.fragment),_=m(),h=d("p"),h.innerHTML=k},l(o){s=b(o,"P",{"data-svelte-h":!0}),T(s)!=="svelte-xsgejq"&&(s.innerHTML=u),n=i(o),j(p.$$.fragment,o),f=i(o),c=b(o,"P",{"data-svelte-h":!0}),T(c)!=="svelte-1ilzt8b"&&(c.textContent=x),U=i(o),j(g.$$.fragment,o),_=i(o),h=b(o,"P",{"data-svelte-h":!0}),T(h)!=="svelte-1w046dp"&&(h.innerHTML=k)},m(o,$){a(o,s,$),a(o,n,$),M(p,o,$),a(o,f,$),a(o,c,$),a(o,U,$),M(g,o,$),a(o,_,$),a(o,h,$),W=!0},p:ye,i(o){W||(w(p.$$.fragment,o),w(g.$$.fragment,o),W=!0)},o(o){v(p.$$.fragment,o),v(g.$$.fragment,o),W=!1},d(o){o&&(t(s),t(n),t(f),t(c),t(U),t(_),t(h)),Z(p,o),Z(g,o)}}}function Pe(J){let s,u;return s=new Ue({props:{$$slots:{default:[Le]},$$scope:{ctx:J}}}),{c(){y(s.$$.fragment)},l(n){j(s.$$.fragment,n)},m(n,p){M(s,n,p),u=!0},p(n,p){const f={};p&2&&(f.$$scope={dirty:p,ctx:n}),s.$set(f)},i(n){u||(w(s.$$.fragment,n),u=!0)},o(n){v(s.$$.fragment,n),u=!1},d(n){Z(s,n)}}}function qe(J){let s,u,n,p,f,c,x,U=`트랜스포머 아키텍처가 매우 다양하기 때문에 체크포인트에 맞는 아키텍처를 생성하는 것이 어려울 수 있습니다. 라이브러리를 쉽고 간단하며 유연하게 사용하기 위한 Transformer 핵심 철학의 일환으로, <code>AutoClass</code>는 주어진 체크포인트에서 올바른 아키텍처를 자동으로 추론하여 로드합니다. <code>from_pretrained()</code> 메서드를 사용하면 모든 아키텍처에 대해 사전 학습된 모델을 빠르게 로드할 수 있으므로 모델을 처음부터 학습하는 데 시간과 리소스를 투입할 필요가 없습니다.
체크포인트에 구애받지 않는 코드를 생성한다는 것은 코드가 한 체크포인트에서 작동하면 아키텍처가 다르더라도 다른 체크포인트(유사한 작업에 대해 학습된 경우)에서도 작동한다는 것을 의미합니다.`,g,_,h,k,W="이 튜토리얼에서는 다음을 학습합니다:",o,$,r="<li>사전 학습된 토크나이저 로드하기.</li> <li>사전 학습된 이미지 프로세서 로드하기.</li> <li>사전 학습된 특징 추출기 로드하기.</li> <li>사전 훈련된 프로세서 로드하기.</li> <li>사전 학습된 모델 로드하기.</li>",C,F,ee,R,je=`거의 모든 NLP 작업은 토크나이저로 시작됩니다. 토크나이저는 사용자의 입력을 모델에서 처리할 수 있는 형식으로 변환합니다.
<code>AutoTokenizer.from_pretrained()</code>로 토크나이저를 로드합니다:`,te,X,se,A,Me="그리고 아래와 같이 입력을 토큰화합니다:",le,H,ae,N,ne,E,we="비전 작업의 경우 이미지 프로세서가 이미지를 올바른 입력 형식으로 처리합니다.",re,Y,pe,z,oe,L,ve="오디오 작업의 경우 특징 추출기가 오디오 신호를 올바른 입력 형식으로 처리합니다.",me,P,Ze="<code>AutoFeatureExtractor.from_pretrained()</code>로 특징 추출기를 로드합니다:",ie,q,ce,I,ue,Q,Ce="멀티모달 작업에는 두 가지 유형의 전처리 도구를 결합한 프로세서가 필요합니다. 예를 들어 LayoutLMV2 모델에는 이미지를 처리하는 이미지 프로세서와 텍스트를 처리하는 토크나이저가 필요하며, 프로세서는 이 두 가지를 결합합니다.",fe,B,Te="<code>AutoProcessor.from_pretrained()</code>로 프로세서를 로드합니다:",$e,S,de,K,be,V,he,O,ge;return f=new D({props:{title:"AutoClass로 사전 학습된 인스턴스 로드",local:"load-pretrained-instances-with-an-autoclass",headingTag:"h1"}}),_=new Je({props:{$$slots:{default:[Ne]},$$scope:{ctx:J}}}),F=new D({props:{title:"AutoTokenizer",local:"autotokenizer",headingTag:"h2"}}),X=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJnb29nbGUtYmVydCUyRmJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;google-bert/bert-base-uncased&quot;</span>)`,wrap:!1}}),H=new G({props:{code:"c2VxdWVuY2UlMjAlM0QlMjAlMjJJbiUyMGElMjBob2xlJTIwaW4lMjB0aGUlMjBncm91bmQlMjB0aGVyZSUyMGxpdmVkJTIwYSUyMGhvYmJpdC4lMjIlMEFwcmludCh0b2tlbml6ZXIoc2VxdWVuY2UpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>sequence = <span class="hljs-string">&quot;In a hole in the ground there lived a hobbit.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer(sequence))
{<span class="hljs-string">&#x27;input_ids&#x27;</span>: [<span class="hljs-number">101</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">4920</span>, <span class="hljs-number">1999</span>, <span class="hljs-number">1996</span>, <span class="hljs-number">2598</span>, <span class="hljs-number">2045</span>, <span class="hljs-number">2973</span>, <span class="hljs-number">1037</span>, <span class="hljs-number">7570</span>, <span class="hljs-number">10322</span>, <span class="hljs-number">4183</span>, <span class="hljs-number">1012</span>, <span class="hljs-number">102</span>], 
 <span class="hljs-string">&#x27;token_type_ids&#x27;</span>: [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], 
 <span class="hljs-string">&#x27;attention_mask&#x27;</span>: [<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>]}`,wrap:!1}}),N=new D({props:{title:"AutoImageProcessor",local:"autoimageprocessor",headingTag:"h2"}}),Y=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyZ29vZ2xlJTJGdml0LWJhc2UtcGF0Y2gxNi0yMjQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;google/vit-base-patch16-224&quot;</span>)`,wrap:!1}}),z=new D({props:{title:"AutoFeatureExtractor",local:"autofeatureextractor",headingTag:"h2"}}),q=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9GZWF0dXJlRXh0cmFjdG9yJTBBJTBBZmVhdHVyZV9leHRyYWN0b3IlMjAlM0QlMjBBdXRvRmVhdHVyZUV4dHJhY3Rvci5mcm9tX3ByZXRyYWluZWQoJTBBJTIwJTIwJTIwJTIwJTIyZWhjYWxhYnJlcyUyRndhdjJ2ZWMyLWxnLXhsc3ItZW4tc3BlZWNoLWVtb3Rpb24tcmVjb2duaXRpb24lMjIlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoFeatureExtractor

<span class="hljs-meta">&gt;&gt;&gt; </span>feature_extractor = AutoFeatureExtractor.from_pretrained(
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition&quot;</span>
<span class="hljs-meta">... </span>)`,wrap:!1}}),I=new D({props:{title:"AutoProcessor",local:"autoprocessor",headingTag:"h2"}}),S=new G({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Qcm9jZXNzb3IlMEElMEFwcm9jZXNzb3IlMjAlM0QlMjBBdXRvUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJtaWNyb3NvZnQlMkZsYXlvdXRsbXYyLWJhc2UtdW5jYXNlZCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>processor = AutoProcessor.from_pretrained(<span class="hljs-string">&quot;microsoft/layoutlmv2-base-uncased&quot;</span>)`,wrap:!1}}),K=new D({props:{title:"AutoModel",local:"automodel",headingTag:"h2"}}),V=new He({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[Pe],pytorch:[ze]},$$scope:{ctx:J}}}),{c(){s=d("meta"),u=m(),n=d("p"),p=m(),y(f.$$.fragment),c=m(),x=d("p"),x.innerHTML=U,g=m(),y(_.$$.fragment),h=m(),k=d("p"),k.textContent=W,o=m(),$=d("ul"),$.innerHTML=r,C=m(),y(F.$$.fragment),ee=m(),R=d("p"),R.innerHTML=je,te=m(),y(X.$$.fragment),se=m(),A=d("p"),A.textContent=Me,le=m(),y(H.$$.fragment),ae=m(),y(N.$$.fragment),ne=m(),E=d("p"),E.textContent=we,re=m(),y(Y.$$.fragment),pe=m(),y(z.$$.fragment),oe=m(),L=d("p"),L.textContent=ve,me=m(),P=d("p"),P.innerHTML=Ze,ie=m(),y(q.$$.fragment),ce=m(),y(I.$$.fragment),ue=m(),Q=d("p"),Q.textContent=Ce,fe=m(),B=d("p"),B.innerHTML=Te,$e=m(),y(S.$$.fragment),de=m(),y(K.$$.fragment),be=m(),y(V.$$.fragment),he=m(),O=d("p"),this.h()},l(e){const l=Xe("svelte-u9bgzb",document.head);s=b(l,"META",{name:!0,content:!0}),l.forEach(t),u=i(e),n=b(e,"P",{}),ke(n).forEach(t),p=i(e),j(f.$$.fragment,e),c=i(e),x=b(e,"P",{"data-svelte-h":!0}),T(x)!=="svelte-77k0i5"&&(x.innerHTML=U),g=i(e),j(_.$$.fragment,e),h=i(e),k=b(e,"P",{"data-svelte-h":!0}),T(k)!=="svelte-qqdsnz"&&(k.textContent=W),o=i(e),$=b(e,"UL",{"data-svelte-h":!0}),T($)!=="svelte-fay6vf"&&($.innerHTML=r),C=i(e),j(F.$$.fragment,e),ee=i(e),R=b(e,"P",{"data-svelte-h":!0}),T(R)!=="svelte-7pofg0"&&(R.innerHTML=je),te=i(e),j(X.$$.fragment,e),se=i(e),A=b(e,"P",{"data-svelte-h":!0}),T(A)!=="svelte-2tta70"&&(A.textContent=Me),le=i(e),j(H.$$.fragment,e),ae=i(e),j(N.$$.fragment,e),ne=i(e),E=b(e,"P",{"data-svelte-h":!0}),T(E)!=="svelte-34kd90"&&(E.textContent=we),re=i(e),j(Y.$$.fragment,e),pe=i(e),j(z.$$.fragment,e),oe=i(e),L=b(e,"P",{"data-svelte-h":!0}),T(L)!=="svelte-uavi10"&&(L.textContent=ve),me=i(e),P=b(e,"P",{"data-svelte-h":!0}),T(P)!=="svelte-1kkigej"&&(P.innerHTML=Ze),ie=i(e),j(q.$$.fragment,e),ce=i(e),j(I.$$.fragment,e),ue=i(e),Q=b(e,"P",{"data-svelte-h":!0}),T(Q)!=="svelte-55zai9"&&(Q.textContent=Ce),fe=i(e),B=b(e,"P",{"data-svelte-h":!0}),T(B)!=="svelte-r7eo2t"&&(B.innerHTML=Te),$e=i(e),j(S.$$.fragment,e),de=i(e),j(K.$$.fragment,e),be=i(e),j(V.$$.fragment,e),he=i(e),O=b(e,"P",{}),ke(O).forEach(t),this.h()},h(){We(s,"name","hf:doc:metadata"),We(s,"content",Ie)},m(e,l){Ae(document.head,s),a(e,u,l),a(e,n,l),a(e,p,l),M(f,e,l),a(e,c,l),a(e,x,l),a(e,g,l),M(_,e,l),a(e,h,l),a(e,k,l),a(e,o,l),a(e,$,l),a(e,C,l),M(F,e,l),a(e,ee,l),a(e,R,l),a(e,te,l),M(X,e,l),a(e,se,l),a(e,A,l),a(e,le,l),M(H,e,l),a(e,ae,l),M(N,e,l),a(e,ne,l),a(e,E,l),a(e,re,l),M(Y,e,l),a(e,pe,l),M(z,e,l),a(e,oe,l),a(e,L,l),a(e,me,l),a(e,P,l),a(e,ie,l),M(q,e,l),a(e,ce,l),M(I,e,l),a(e,ue,l),a(e,Q,l),a(e,fe,l),a(e,B,l),a(e,$e,l),M(S,e,l),a(e,de,l),M(K,e,l),a(e,be,l),M(V,e,l),a(e,he,l),a(e,O,l),ge=!0},p(e,[l]){const _e={};l&2&&(_e.$$scope={dirty:l,ctx:e}),_.$set(_e);const xe={};l&2&&(xe.$$scope={dirty:l,ctx:e}),V.$set(xe)},i(e){ge||(w(f.$$.fragment,e),w(_.$$.fragment,e),w(F.$$.fragment,e),w(X.$$.fragment,e),w(H.$$.fragment,e),w(N.$$.fragment,e),w(Y.$$.fragment,e),w(z.$$.fragment,e),w(q.$$.fragment,e),w(I.$$.fragment,e),w(S.$$.fragment,e),w(K.$$.fragment,e),w(V.$$.fragment,e),ge=!0)},o(e){v(f.$$.fragment,e),v(_.$$.fragment,e),v(F.$$.fragment,e),v(X.$$.fragment,e),v(H.$$.fragment,e),v(N.$$.fragment,e),v(Y.$$.fragment,e),v(z.$$.fragment,e),v(q.$$.fragment,e),v(I.$$.fragment,e),v(S.$$.fragment,e),v(K.$$.fragment,e),v(V.$$.fragment,e),ge=!1},d(e){e&&(t(u),t(n),t(p),t(c),t(x),t(g),t(h),t(k),t(o),t($),t(C),t(ee),t(R),t(te),t(se),t(A),t(le),t(ae),t(ne),t(E),t(re),t(pe),t(oe),t(L),t(me),t(P),t(ie),t(ce),t(ue),t(Q),t(fe),t(B),t($e),t(de),t(be),t(he),t(O)),t(s),Z(f,e),Z(_,e),Z(F,e),Z(X,e),Z(H,e),Z(N,e),Z(Y,e),Z(z,e),Z(q,e),Z(I,e),Z(S,e),Z(K,e),Z(V,e)}}}const Ie='{"title":"AutoClass로 사전 학습된 인스턴스 로드","local":"load-pretrained-instances-with-an-autoclass","sections":[{"title":"AutoTokenizer","local":"autotokenizer","sections":[],"depth":2},{"title":"AutoImageProcessor","local":"autoimageprocessor","sections":[],"depth":2},{"title":"AutoFeatureExtractor","local":"autofeatureextractor","sections":[],"depth":2},{"title":"AutoProcessor","local":"autoprocessor","sections":[],"depth":2},{"title":"AutoModel","local":"automodel","sections":[],"depth":2}],"depth":1}';function Qe(J){return Ge(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class tt extends Ve{constructor(s){super(),Re(this,s,Qe,qe,Fe,{})}}export{tt as component};
