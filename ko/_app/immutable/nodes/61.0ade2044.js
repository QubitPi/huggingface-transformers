import{s as Ye,o as Le,n as ss}from"../chunks/scheduler.56730f09.js";import{S as Se,i as De,g as T,s as o,r as f,A as Pe,h as J,f as a,c as i,j as Fe,u,x as g,k as Ne,y as Ke,a as n,v as h,d as j,t as w,w as y,m as Qe,n as qe}from"../chunks/index.1f144517.js";import{T as we}from"../chunks/Tip.41e845e5.js";import{Y as He}from"../chunks/Youtube.62e0f062.js";import{C as B}from"../chunks/CodeBlock.738eeccb.js";import{D as Oe}from"../chunks/DocNotebookDropdown.243c3df7.js";import{F as ye,M as Xs}from"../chunks/Markdown.c541024b.js";import{H as ks}from"../chunks/Heading.57d46534.js";function st(C){let l,m,t='<a href="../model_doc/albert">ALBERT</a>, <a href="../model_doc/bart">BART</a>, <a href="../model_doc/bert">BERT</a>, <a href="../model_doc/big_bird">BigBird</a>, <a href="../model_doc/bigbird_pegasus">BigBird-Pegasus</a>, <a href="../model_doc/bloom">BLOOM</a>, <a href="../model_doc/camembert">CamemBERT</a>, <a href="../model_doc/canine">CANINE</a>, <a href="../model_doc/convbert">ConvBERT</a>, <a href="../model_doc/data2vec-text">Data2VecText</a>, <a href="../model_doc/deberta">DeBERTa</a>, <a href="../model_doc/deberta-v2">DeBERTa-v2</a>, <a href="../model_doc/distilbert">DistilBERT</a>, <a href="../model_doc/electra">ELECTRA</a>, <a href="../model_doc/ernie">ERNIE</a>, <a href="../model_doc/ernie_m">ErnieM</a>, <a href="../model_doc/flaubert">FlauBERT</a>, <a href="../model_doc/fnet">FNet</a>, <a href="../model_doc/funnel">Funnel Transformer</a>, <a href="../model_doc/gptj">GPT-J</a>, <a href="../model_doc/ibert">I-BERT</a>, <a href="../model_doc/layoutlmv2">LayoutLMv2</a>, <a href="../model_doc/layoutlmv3">LayoutLMv3</a>, <a href="../model_doc/led">LED</a>, <a href="../model_doc/lilt">LiLT</a>, <a href="../model_doc/longformer">Longformer</a>, <a href="../model_doc/luke">LUKE</a>, <a href="../model_doc/lxmert">LXMERT</a>, <a href="../model_doc/markuplm">MarkupLM</a>, <a href="../model_doc/mbart">mBART</a>, <a href="../model_doc/mega">MEGA</a>, <a href="../model_doc/megatron-bert">Megatron-BERT</a>, <a href="../model_doc/mobilebert">MobileBERT</a>, <a href="../model_doc/mpnet">MPNet</a>, <a href="../model_doc/mvp">MVP</a>, <a href="../model_doc/nezha">Nezha</a>, <a href="../model_doc/nystromformer">Nyströmformer</a>, <a href="../model_doc/opt">OPT</a>, <a href="../model_doc/qdqbert">QDQBert</a>, <a href="../model_doc/reformer">Reformer</a>, <a href="../model_doc/rembert">RemBERT</a>, <a href="../model_doc/roberta">RoBERTa</a>, <a href="../model_doc/roberta-prelayernorm">RoBERTa-PreLayerNorm</a>, <a href="../model_doc/roc_bert">RoCBert</a>, <a href="../model_doc/roformer">RoFormer</a>, <a href="../model_doc/splinter">Splinter</a>, <a href="../model_doc/squeezebert">SqueezeBERT</a>, <a href="../model_doc/xlm">XLM</a>, <a href="../model_doc/xlm-roberta">XLM-RoBERTa</a>, <a href="../model_doc/xlm-roberta-xl">XLM-RoBERTa-XL</a>, <a href="../model_doc/xlnet">XLNet</a>, <a href="../model_doc/xmod">X-MOD</a>, <a href="../model_doc/yoso">YOSO</a>';return{c(){l=Qe(`이 튜토리얼에서 설명하는 태스크는 다음과 같은 모델 아키텍처에서 지원됩니다.

`),m=T("p"),m.innerHTML=t},l(c){l=qe(c,`이 튜토리얼에서 설명하는 태스크는 다음과 같은 모델 아키텍처에서 지원됩니다.

`),m=J(c,"P",{"data-svelte-h":!0}),g(m)!=="svelte-pkvvxe"&&(m.innerHTML=t)},m(c,d){n(c,l,d),n(c,m,d)},p:ss,d(c){c&&(a(l),a(m))}}}function et(C){let l,m;return l=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator()`,wrap:!1}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p:ss,i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function tt(C){let l,m;return l=new Xs({props:{$$slots:{default:[et]},$$scope:{ctx:C}}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p(t,c){const d={};c&2&&(d.$$scope={dirty:c,ctx:t}),l.$set(d)},i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function lt(C){let l,m;return l=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcihyZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p:ss,i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function at(C){let l,m;return l=new Xs({props:{$$slots:{default:[lt]},$$scope:{ctx:C}}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p(t,c){const d={};c&2&&(d.$$scope={dirty:c,ctx:t}),l.$set(d)},i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function nt(C){let l,m='<code>Trainer</code>를 이용해 모델을 미세 조정하는 것에 익숙하지 않다면, <a href="../training#train-with-pytorch-trainer">여기</a>에서 기초 튜토리얼을 살펴보세요!';return{c(){l=T("p"),l.innerHTML=m},l(t){l=J(t,"P",{"data-svelte-h":!0}),g(l)!=="svelte-1mkjug2"&&(l.innerHTML=m)},m(t,c){n(t,l,c)},p:ss,d(t){t&&a(l)}}}function pt(C){let l,m,t,c="이제 모델 훈련을 시작할 준비가 되었습니다! <code>AutoModelForQuestionAnswering</code>으로 DistilBERT를 가져옵니다:",d,I,W,k,Z="이제 세 단계만 남았습니다:",x,$,z="<li><code>TrainingArguments</code>에서 훈련 하이퍼파라미터를 정합니다. 꼭 필요한 매개변수는 모델을 저장할 위치를 지정하는 <code>output_dir</code> 입니다. <code>push_to_hub=True</code>로 설정해서 이 모델을 Hub로 푸시합니다 (모델을 업로드하려면 Hugging Face에 로그인해야 합니다).</li> <li>모델, 데이터 세트, 토크나이저, 데이터 콜레이터와 함께 <code>Trainer</code>에 훈련 인수들을 전달합니다.</li> <li><code>train()</code>을 호출해서 모델을 미세 조정합니다.</li>",G,b,v,R,V="훈련이 완료되면, <code>push_to_hub()</code> 매소드를 사용해 모델을 Hub에 공유해서 모든 사람들이 사용할 수 있게 공유해주세요:",A,U,X;return l=new we({props:{$$slots:{default:[nt]},$$scope:{ctx:C}}}),I=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclF1ZXN0aW9uQW5zd2VyaW5nJTJDJTIwVHJhaW5pbmdBcmd1bWVudHMlMkMlMjBUcmFpbmVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JRdWVzdGlvbkFuc3dlcmluZy5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),b=new B({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwZXZhbHVhdGlvbl9zdHJhdGVneSUzRCUyMmVwb2NoJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMHBlcl9kZXZpY2VfZXZhbF9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNEMyUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheSUzRDAuMDElMkMlMEElMjAlMjAlMjAlMjBwdXNoX3RvX2h1YiUzRFRydWUlMkMlMEEpJTBBJTBBdHJhaW5lciUyMCUzRCUyMFRyYWluZXIoJTBBJTIwJTIwJTIwJTIwbW9kZWwlM0Rtb2RlbCUyQyUwQSUyMCUyMCUyMCUyMGFyZ3MlM0R0cmFpbmluZ19hcmdzJTJDJTBBJTIwJTIwJTIwJTIwdHJhaW5fZGF0YXNldCUzRHRva2VuaXplZF9zcXVhZCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwZXZhbF9kYXRhc2V0JTNEdG9rZW5pemVkX3NxdWFkJTVCJTIydGVzdCUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHRva2VuaXplciUzRHRva2VuaXplciUyQyUwQSUyMCUyMCUyMCUyMGRhdGFfY29sbGF0b3IlM0RkYXRhX2NvbGxhdG9yJTJDJTBBKSUwQSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=tokenized_squad[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=tokenized_squad[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),U=new B({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){f(l.$$.fragment),m=o(),t=T("p"),t.innerHTML=c,d=o(),f(I.$$.fragment),W=o(),k=T("p"),k.textContent=Z,x=o(),$=T("ol"),$.innerHTML=z,G=o(),f(b.$$.fragment),v=o(),R=T("p"),R.innerHTML=V,A=o(),f(U.$$.fragment)},l(e){u(l.$$.fragment,e),m=i(e),t=J(e,"P",{"data-svelte-h":!0}),g(t)!=="svelte-1l92urq"&&(t.innerHTML=c),d=i(e),u(I.$$.fragment,e),W=i(e),k=J(e,"P",{"data-svelte-h":!0}),g(k)!=="svelte-1vwg7jz"&&(k.textContent=Z),x=i(e),$=J(e,"OL",{"data-svelte-h":!0}),g($)!=="svelte-11eqy5p"&&($.innerHTML=z),G=i(e),u(b.$$.fragment,e),v=i(e),R=J(e,"P",{"data-svelte-h":!0}),g(R)!=="svelte-1btg14f"&&(R.innerHTML=V),A=i(e),u(U.$$.fragment,e)},m(e,M){h(l,e,M),n(e,m,M),n(e,t,M),n(e,d,M),h(I,e,M),n(e,W,M),n(e,k,M),n(e,x,M),n(e,$,M),n(e,G,M),h(b,e,M),n(e,v,M),n(e,R,M),n(e,A,M),h(U,e,M),X=!0},p(e,M){const E={};M&2&&(E.$$scope={dirty:M,ctx:e}),l.$set(E)},i(e){X||(j(l.$$.fragment,e),j(I.$$.fragment,e),j(b.$$.fragment,e),j(U.$$.fragment,e),X=!0)},o(e){w(l.$$.fragment,e),w(I.$$.fragment,e),w(b.$$.fragment,e),w(U.$$.fragment,e),X=!1},d(e){e&&(a(m),a(t),a(d),a(W),a(k),a(x),a($),a(G),a(v),a(R),a(A)),y(l,e),y(I,e),y(b,e),y(U,e)}}}function rt(C){let l,m;return l=new Xs({props:{$$slots:{default:[pt]},$$scope:{ctx:C}}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p(t,c){const d={};c&2&&(d.$$scope={dirty:c,ctx:t}),l.$set(d)},i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function ot(C){let l,m='Keras로 모델을 미세 조정하는 것에 익숙하지 않다면, <a href="../training#train-a-tensorflow-model-with-keras">여기</a>에서 기초 튜토리얼을 살펴보세요!';return{c(){l=T("p"),l.innerHTML=m},l(t){l=J(t,"P",{"data-svelte-h":!0}),g(l)!=="svelte-1313y60"&&(l.innerHTML=m)},m(t,c){n(t,l,c)},p:ss,d(t){t&&a(l)}}}function it(C){let l,m,t,c,d,I="그 다음 <code>TFAutoModelForQuestionAnswering</code>으로 DistilBERT를 가져옵니다:",W,k,Z,x,$="<code>prepare_tf_dataset()</code>을 사용해서 데이터 세트를 <code>tf.data.Dataset</code> 형식으로 변환합니다:",z,G,b,v,R='<a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a>로 훈련할 모델을 설정합니다:',V,A,U,X,e="마지막으로 모델을 Hub로 푸시할 방법을 설정합니다. <code>PushToHubCallback</code>에서 모델과 토크나이저를 푸시할 경로를 설정합니다:",M,E,q,F,Bs='드디어 모델 훈련을 시작할 준비가 되었습니다! 훈련 데이터 세트와 평가 데이터 세트, 에폭 수, 콜백을 설정한 후 <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a>을 이용해 모델을 미세 조정합니다:',Y,N,L,H,xs="훈련이 완료되면 모델이 자동으로 Hub에 업로드되어 누구나 사용할 수 있습니다!",S;return l=new we({props:{$$slots:{default:[ot]},$$scope:{ctx:C}}}),t=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMEElMEFiYXRjaF9zaXplJTIwJTNEJTIwMTYlMEFudW1fZXBvY2hzJTIwJTNEJTIwMiUwQXRvdGFsX3RyYWluX3N0ZXBzJTIwJTNEJTIwKGxlbih0b2tlbml6ZWRfc3F1YWQlNUIlMjJ0cmFpbiUyMiU1RCklMjAlMkYlMkYlMjBiYXRjaF9zaXplKSUyMColMjBudW1fZXBvY2hzJTBBb3B0aW1pemVyJTJDJTIwc2NoZWR1bGUlMjAlM0QlMjBjcmVhdGVfb3B0aW1pemVyKCUwQSUyMCUyMCUyMCUyMGluaXRfbHIlM0QyZS01JTJDJTBBJTIwJTIwJTIwJTIwbnVtX3dhcm11cF9zdGVwcyUzRDAlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fc3RlcHMlM0R0b3RhbF90cmFpbl9zdGVwcyUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>batch_size = <span class="hljs-number">16</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>total_train_steps = (<span class="hljs-built_in">len</span>(tokenized_squad[<span class="hljs-string">&quot;train&quot;</span>]) // batch_size) * num_epochs
<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer, schedule = create_optimizer(
<span class="hljs-meta">... </span>    init_lr=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    num_warmup_steps=<span class="hljs-number">0</span>,
<span class="hljs-meta">... </span>    num_train_steps=total_train_steps,
<span class="hljs-meta">... </span>)`,wrap:!1}}),k=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmclMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmcoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGJlcnQtYmFzZS11bmNhc2VkJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),G=new B({props:{code:"dGZfdHJhaW5fc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMHRva2VuaXplZF9zcXVhZCU1QiUyMnRyYWluJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwc2h1ZmZsZSUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBjb2xsYXRlX2ZuJTNEZGF0YV9jb2xsYXRvciUyQyUwQSklMEElMEF0Zl92YWxpZGF0aW9uX3NldCUyMCUzRCUyMG1vZGVsLnByZXBhcmVfdGZfZGF0YXNldCglMEElMjAlMjAlMjAlMjB0b2tlbml6ZWRfc3F1YWQlNUIlMjJ0ZXN0JTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwc2h1ZmZsZSUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwY29sbGF0ZV9mbiUzRGRhdGFfY29sbGF0b3IlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_squad[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_validation_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    tokenized_squad[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),A=new B({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplcik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)`,wrap:!1}}),E=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBQdXNoVG9IdWJDYWxsYmFjayUwQSUwQWNhbGxiYWNrJTIwJTNEJTIwUHVzaFRvSHViQ2FsbGJhY2soJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMm15X2F3ZXNvbWVfcWFfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>)`,wrap:!1}}),N=new B({props:{code:"bW9kZWwuZml0KHglM0R0Zl90cmFpbl9zZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl92YWxpZGF0aW9uX3NldCUyQyUyMGVwb2NocyUzRDMlMkMlMjBjYWxsYmFja3MlM0QlNUJjYWxsYmFjayU1RCk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_validation_set, epochs=<span class="hljs-number">3</span>, callbacks=[callback])',wrap:!1}}),{c(){f(l.$$.fragment),m=Qe(`
TensorFlow를 이용한 모델을 미세 조정하려면 옵티마이저 함수, 학습률 스케쥴 및 몇 가지 훈련 하이퍼파라미터를 설정하는 것부터 시작해야합니다:

	`),f(t.$$.fragment),c=o(),d=T("p"),d.innerHTML=I,W=o(),f(k.$$.fragment),Z=o(),x=T("p"),x.innerHTML=$,z=o(),f(G.$$.fragment),b=o(),v=T("p"),v.innerHTML=R,V=o(),f(A.$$.fragment),U=o(),X=T("p"),X.innerHTML=e,M=o(),f(E.$$.fragment),q=o(),F=T("p"),F.innerHTML=Bs,Y=o(),f(N.$$.fragment),L=o(),H=T("p"),H.textContent=xs},l(r){u(l.$$.fragment,r),m=qe(r,`
TensorFlow를 이용한 모델을 미세 조정하려면 옵티마이저 함수, 학습률 스케쥴 및 몇 가지 훈련 하이퍼파라미터를 설정하는 것부터 시작해야합니다:

	`),u(t.$$.fragment,r),c=i(r),d=J(r,"P",{"data-svelte-h":!0}),g(d)!=="svelte-1bkfga3"&&(d.innerHTML=I),W=i(r),u(k.$$.fragment,r),Z=i(r),x=J(r,"P",{"data-svelte-h":!0}),g(x)!=="svelte-1nof74s"&&(x.innerHTML=$),z=i(r),u(G.$$.fragment,r),b=i(r),v=J(r,"P",{"data-svelte-h":!0}),g(v)!=="svelte-1ieukoa"&&(v.innerHTML=R),V=i(r),u(A.$$.fragment,r),U=i(r),X=J(r,"P",{"data-svelte-h":!0}),g(X)!=="svelte-ivpgxr"&&(X.innerHTML=e),M=i(r),u(E.$$.fragment,r),q=i(r),F=J(r,"P",{"data-svelte-h":!0}),g(F)!=="svelte-1fld86y"&&(F.innerHTML=Bs),Y=i(r),u(N.$$.fragment,r),L=i(r),H=J(r,"P",{"data-svelte-h":!0}),g(H)!=="svelte-ga84hg"&&(H.textContent=xs)},m(r,_){h(l,r,_),n(r,m,_),h(t,r,_),n(r,c,_),n(r,d,_),n(r,W,_),h(k,r,_),n(r,Z,_),n(r,x,_),n(r,z,_),h(G,r,_),n(r,b,_),n(r,v,_),n(r,V,_),h(A,r,_),n(r,U,_),n(r,X,_),n(r,M,_),h(E,r,_),n(r,q,_),n(r,F,_),n(r,Y,_),h(N,r,_),n(r,L,_),n(r,H,_),S=!0},p(r,_){const Q={};_&2&&(Q.$$scope={dirty:_,ctx:r}),l.$set(Q)},i(r){S||(j(l.$$.fragment,r),j(t.$$.fragment,r),j(k.$$.fragment,r),j(G.$$.fragment,r),j(A.$$.fragment,r),j(E.$$.fragment,r),j(N.$$.fragment,r),S=!0)},o(r){w(l.$$.fragment,r),w(t.$$.fragment,r),w(k.$$.fragment,r),w(G.$$.fragment,r),w(A.$$.fragment,r),w(E.$$.fragment,r),w(N.$$.fragment,r),S=!1},d(r){r&&(a(m),a(c),a(d),a(W),a(Z),a(x),a(z),a(b),a(v),a(V),a(U),a(X),a(M),a(q),a(F),a(Y),a(L),a(H)),y(l,r),y(t,r),y(k,r),y(G,r),y(A,r),y(E,r),y(N,r)}}}function mt(C){let l,m;return l=new Xs({props:{$$slots:{default:[it]},$$scope:{ctx:C}}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p(t,c){const d={};c&2&&(d.$$scope={dirty:c,ctx:t}),l.$set(d)},i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function ct(C){let l,m='질의 응답을 위해 모델을 미세 조정하는 방법에 대한 더 자세한 예시는 <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb" rel="nofollow">PyTorch notebook</a> 또는 <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering-tf.ipynb" rel="nofollow">TensorFlow notebook</a>을 참조하세요.';return{c(){l=T("p"),l.innerHTML=m},l(t){l=J(t,"P",{"data-svelte-h":!0}),g(l)!=="svelte-1ikgkjc"&&(l.innerHTML=m)},m(t,c){n(t,l,c)},p:ss,d(t){t&&a(l)}}}function Mt(C){let l,m="텍스트를 토큰화해서 PyTorch 텐서를 반환합니다:",t,c,d,I,W="모델에 입력을 전달하고 <code>logits</code>을 반환합니다:",k,Z,x,$,z="모델의 출력에서 시작 및 종료 위치가 어딘지 가장 높은 확률을 얻습니다:",G,b,v,R,V="예측된 토큰을 해독해서 답을 얻습니다:",A,U,X;return c=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihxdWVzdGlvbiUyQyUyMGNvbnRleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(question, context, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),Z=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclF1ZXN0aW9uQW5zd2VyaW5nJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JRdWVzdGlvbkFuc3dlcmluZy5mcm9tX3ByZXRyYWluZWQoJTIybXlfYXdlc29tZV9xYV9tb2RlbCUyMiklMEF3aXRoJTIwdG9yY2gubm9fZ3JhZCgpJTNBJTBBJTIwJTIwJTIwJTIwb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    outputs = model(**inputs)`,wrap:!1}}),b=new B({props:{code:"YW5zd2VyX3N0YXJ0X2luZGV4JTIwJTNEJTIwb3V0cHV0cy5zdGFydF9sb2dpdHMuYXJnbWF4KCklMEFhbnN3ZXJfZW5kX2luZGV4JTIwJTNEJTIwb3V0cHV0cy5lbmRfbG9naXRzLmFyZ21heCgp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>answer_start_index = outputs.start_logits.argmax()
<span class="hljs-meta">&gt;&gt;&gt; </span>answer_end_index = outputs.end_logits.argmax()`,wrap:!1}}),U=new B({props:{code:"cHJlZGljdF9hbnN3ZXJfdG9rZW5zJTIwJTNEJTIwaW5wdXRzLmlucHV0X2lkcyU1QjAlMkMlMjBhbnN3ZXJfc3RhcnRfaW5kZXglMjAlM0ElMjBhbnN3ZXJfZW5kX2luZGV4JTIwJTJCJTIwMSU1RCUwQXRva2VuaXplci5kZWNvZGUocHJlZGljdF9hbnN3ZXJfdG9rZW5zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predict_answer_tokens = inputs.input_ids[<span class="hljs-number">0</span>, answer_start_index : answer_end_index + <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predict_answer_tokens)
<span class="hljs-string">&#x27;176 billion parameters and can generate text in 46 languages natural languages and 13&#x27;</span>`,wrap:!1}}),{c(){l=T("p"),l.textContent=m,t=o(),f(c.$$.fragment),d=o(),I=T("p"),I.innerHTML=W,k=o(),f(Z.$$.fragment),x=o(),$=T("p"),$.textContent=z,G=o(),f(b.$$.fragment),v=o(),R=T("p"),R.textContent=V,A=o(),f(U.$$.fragment)},l(e){l=J(e,"P",{"data-svelte-h":!0}),g(l)!=="svelte-hm1s3x"&&(l.textContent=m),t=i(e),u(c.$$.fragment,e),d=i(e),I=J(e,"P",{"data-svelte-h":!0}),g(I)!=="svelte-kli2cc"&&(I.innerHTML=W),k=i(e),u(Z.$$.fragment,e),x=i(e),$=J(e,"P",{"data-svelte-h":!0}),g($)!=="svelte-1cy5gzu"&&($.textContent=z),G=i(e),u(b.$$.fragment,e),v=i(e),R=J(e,"P",{"data-svelte-h":!0}),g(R)!=="svelte-1hhfukj"&&(R.textContent=V),A=i(e),u(U.$$.fragment,e)},m(e,M){n(e,l,M),n(e,t,M),h(c,e,M),n(e,d,M),n(e,I,M),n(e,k,M),h(Z,e,M),n(e,x,M),n(e,$,M),n(e,G,M),h(b,e,M),n(e,v,M),n(e,R,M),n(e,A,M),h(U,e,M),X=!0},p:ss,i(e){X||(j(c.$$.fragment,e),j(Z.$$.fragment,e),j(b.$$.fragment,e),j(U.$$.fragment,e),X=!0)},o(e){w(c.$$.fragment,e),w(Z.$$.fragment,e),w(b.$$.fragment,e),w(U.$$.fragment,e),X=!1},d(e){e&&(a(l),a(t),a(d),a(I),a(k),a(x),a($),a(G),a(v),a(R),a(A)),y(c,e),y(Z,e),y(b,e),y(U,e)}}}function dt(C){let l,m;return l=new Xs({props:{$$slots:{default:[Mt]},$$scope:{ctx:C}}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p(t,c){const d={};c&2&&(d.$$scope={dirty:c,ctx:t}),l.$set(d)},i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function ft(C){let l,m="텍스트를 토큰화해서 TensorFlow 텐서를 반환합니다:",t,c,d,I,W="모델에 입력을 전달하고 <code>logits</code>을 반환합니다:",k,Z,x,$,z="모델의 출력에서 시작 및 종료 위치가 어딘지 가장 높은 확률을 얻습니다:",G,b,v,R,V="예측된 토큰을 해독해서 답을 얻습니다:",A,U,X;return c=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX3FhX21vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihxdWVzdGlvbiUyQyUyMHRleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(question, text, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),Z=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmclMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmcuZnJvbV9wcmV0cmFpbmVkKCUyMm15X2F3ZXNvbWVfcWFfbW9kZWwlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)`,wrap:!1}}),b=new B({props:{code:"YW5zd2VyX3N0YXJ0X2luZGV4JTIwJTNEJTIwaW50KHRmLm1hdGguYXJnbWF4KG91dHB1dHMuc3RhcnRfbG9naXRzJTJDJTIwYXhpcyUzRC0xKSU1QjAlNUQpJTBBYW5zd2VyX2VuZF9pbmRleCUyMCUzRCUyMGludCh0Zi5tYXRoLmFyZ21heChvdXRwdXRzLmVuZF9sb2dpdHMlMkMlMjBheGlzJTNELTEpJTVCMCU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>answer_start_index = <span class="hljs-built_in">int</span>(tf.math.argmax(outputs.start_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>answer_end_index = <span class="hljs-built_in">int</span>(tf.math.argmax(outputs.end_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])`,wrap:!1}}),U=new B({props:{code:"cHJlZGljdF9hbnN3ZXJfdG9rZW5zJTIwJTNEJTIwaW5wdXRzLmlucHV0X2lkcyU1QjAlMkMlMjBhbnN3ZXJfc3RhcnRfaW5kZXglMjAlM0ElMjBhbnN3ZXJfZW5kX2luZGV4JTIwJTJCJTIwMSU1RCUwQXRva2VuaXplci5kZWNvZGUocHJlZGljdF9hbnN3ZXJfdG9rZW5zKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predict_answer_tokens = inputs.input_ids[<span class="hljs-number">0</span>, answer_start_index : answer_end_index + <span class="hljs-number">1</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.decode(predict_answer_tokens)
<span class="hljs-string">&#x27;176 billion parameters and can generate text in 46 languages natural languages and 13&#x27;</span>`,wrap:!1}}),{c(){l=T("p"),l.textContent=m,t=o(),f(c.$$.fragment),d=o(),I=T("p"),I.innerHTML=W,k=o(),f(Z.$$.fragment),x=o(),$=T("p"),$.textContent=z,G=o(),f(b.$$.fragment),v=o(),R=T("p"),R.textContent=V,A=o(),f(U.$$.fragment)},l(e){l=J(e,"P",{"data-svelte-h":!0}),g(l)!=="svelte-e85p7z"&&(l.textContent=m),t=i(e),u(c.$$.fragment,e),d=i(e),I=J(e,"P",{"data-svelte-h":!0}),g(I)!=="svelte-kli2cc"&&(I.innerHTML=W),k=i(e),u(Z.$$.fragment,e),x=i(e),$=J(e,"P",{"data-svelte-h":!0}),g($)!=="svelte-1cy5gzu"&&($.textContent=z),G=i(e),u(b.$$.fragment,e),v=i(e),R=J(e,"P",{"data-svelte-h":!0}),g(R)!=="svelte-1hhfukj"&&(R.textContent=V),A=i(e),u(U.$$.fragment,e)},m(e,M){n(e,l,M),n(e,t,M),h(c,e,M),n(e,d,M),n(e,I,M),n(e,k,M),h(Z,e,M),n(e,x,M),n(e,$,M),n(e,G,M),h(b,e,M),n(e,v,M),n(e,R,M),n(e,A,M),h(U,e,M),X=!0},p:ss,i(e){X||(j(c.$$.fragment,e),j(Z.$$.fragment,e),j(b.$$.fragment,e),j(U.$$.fragment,e),X=!0)},o(e){w(c.$$.fragment,e),w(Z.$$.fragment,e),w(b.$$.fragment,e),w(U.$$.fragment,e),X=!1},d(e){e&&(a(l),a(t),a(d),a(I),a(k),a(x),a($),a(G),a(v),a(R),a(A)),y(c,e),y(Z,e),y(b,e),y(U,e)}}}function ut(C){let l,m;return l=new Xs({props:{$$slots:{default:[ft]},$$scope:{ctx:C}}}),{c(){f(l.$$.fragment)},l(t){u(l.$$.fragment,t)},m(t,c){h(l,t,c),m=!0},p(t,c){const d={};c&2&&(d.$$scope={dirty:c,ctx:t}),l.$set(d)},i(t){m||(j(l.$$.fragment,t),m=!0)},o(t){w(l.$$.fragment,t),m=!1},d(t){y(l,t)}}}function ht(C){let l,m,t,c,d,I,W,k,Z,x,$,z="질의 응답 태스크는 주어진 질문에 대한 답변을 제공합니다. Alexa, Siri 또는 Google과 같은 가상 비서에게 날씨가 어떤지 물어본 적이 있다면 질의 응답 모델을 사용해본 적이 있을 것입니다. 질의 응답 태스크에는 일반적으로 두 가지 유형이 있습니다.",G,b,v="<li>추출적(Extractive) 질의 응답: 주어진 문맥에서 답변을 추출합니다.</li> <li>생성적(Abstractive) 질의 응답: 문맥에서 질문에 올바르게 답하는 답변을 생성합니다.</li>",R,V,A="이 가이드는 다음과 같은 방법들을 보여줍니다.",U,X,e='<li>추출적 질의 응답을 하기 위해 <a href="https://huggingface.co/datasets/squad" rel="nofollow">SQuAD</a> 데이터 세트에서 <a href="https://huggingface.co/distilbert/distilbert-base-uncased" rel="nofollow">DistilBERT</a> 미세 조정하기</li> <li>추론에 미세 조정된 모델 사용하기</li>',M,E,q,F,Bs="시작하기 전에, 필요한 라이브러리가 모두 설치되어 있는지 확인하세요:",Y,N,L,H,xs="여러분의 모델을 업로드하고 커뮤니티에 공유할 수 있도록 Hugging Face 계정에 로그인하는 것이 좋습니다. 메시지가 표시되면 토큰을 입력해서 로그인합니다:",S,r,_,Q,vs,es,Te="먼저 🤗 Datasets 라이브러리에서 SQuAD 데이터 세트의 일부를 가져옵니다. 이렇게 하면 전체 데이터 세트로 훈련하며 더 많은 시간을 할애하기 전에 모든 것이 잘 작동하는지 실험하고 확인할 수 있습니다.",As,ts,Ws,ls,Je="데이터 세트의 분할된 <code>train</code>을 <code>train_test_split</code> 메소드를 사용해 훈련 데이터 세트와 테스트 데이터 세트로 나누어줍니다:",Vs,as,Es,ns,ge="그리고나서 예시로 데이터를 하나 살펴봅니다:",zs,ps,Fs,rs,be="이 중에서 몇 가지 중요한 항목이 있습니다:",Ns,os,$e="<li><code>answers</code>: 답안 토큰의 시작 위치와 답안 텍스트</li> <li><code>context</code>: 모델이 답을 추출하는데 필요한 배경 지식</li> <li><code>question</code>: 모델이 답해야 하는 질문</li>",Hs,is,Qs,ms,qs,cs,Ue="다음 단계에서는 <code>question</code> 및 <code>context</code> 항목을 처리하기 위해 DistilBERT 토크나이저를 가져옵니다:",Ys,Ms,Ls,ds,_e="질의 응답 태스크와 관련해서 특히 유의해야할 몇 가지 전처리 단계가 있습니다:",Ss,fs,Ce="<li>데이터 세트의 일부 예제에는 모델의 최대 입력 길이를 초과하는 매우 긴 <code>context</code>가 있을 수 있습니다. 긴 시퀀스를 다루기 위해서는, <code>truncation=&quot;only_second&quot;</code>로 설정해 <code>context</code>만 잘라내면 됩니다.</li> <li>그 다음, <code>return_offset_mapping=True</code>로 설정해 답변의 시작과 종료 위치를 원래의 <code>context</code>에 매핑합니다.</li> <li>매핑을 완료하면, 이제 답변에서 시작 토큰과 종료 토큰을 찾을 수 있습니다. 오프셋의 어느 부분이 <code>question</code>과 <code>context</code>에 해당하는지 찾을 수 있도록 <code>sequence_ids</code> 메소드를 사용하세요.</li>",Ds,us,Ie="다음은 <code>answer</code>의 시작 토큰과 종료 토큰을 잘라내서 <code>context</code>에 매핑하는 함수를 만드는 방법입니다:",Ps,hs,Ks,js,Ze="모든 데이터 세트에 전처리를 적용하려면, 🤗 Datasets <code>map</code> 함수를 사용하세요. <code>batched=True</code>로 설정해 데이터 세트의 여러 요소들을 한 번에 처리하면 <code>map</code> 함수의 속도를 빠르게 할 수 있습니다. 필요하지 않은 열은 모두 제거합니다:",Os,ws,se,ys,Re="이제 <code>DefaultDataCollator</code>를 이용해 예시 배치를 생성합니다. 🤗 Transformers의 다른 데이터 콜레이터(data collator)와 달리, <code>DefaultDataCollator</code>는 패딩과 같은 추가 전처리를 적용하지 않습니다:",ee,D,te,Ts,le,P,ae,K,ne,Js,pe,gs,ke="질의 응답을 평가하려면 상당한 양의 후처리가 필요합니다. 시간이 너무 많이 걸리지 않도록 이 가이드에서는 평가 단계를 생략합니다. <code>Trainer</code>는 훈련 과정에서 평가 손실(evaluation loss)을 계속 계산하기 때문에 모델의 성능을 대략적으로 알 수 있습니다.",re,bs,Xe='시간에 여유가 있고 질의 응답 모델을 평가하는 방법에 관심이 있다면 🤗 Hugging Face Course의 <a href="https://huggingface.co/course/chapter7/7?fw=pt#postprocessing" rel="nofollow">Question answering</a> 챕터를 살펴보세요!',oe,$s,ie,Us,Be="이제 모델을 미세 조정했으니 추론에 사용할 수 있습니다!",me,_s,xe="질문과 모델이 예측하기 원하는 문맥(context)를 생각해보세요:",ce,Cs,Me,Is,Ge="추론을 위해 미세 조정한 모델을 테스트하는 가장 쉬운 방법은 <code>pipeline()</code>을 사용하는 것 입니다. 모델을 사용해 질의 응답을 하기 위해서 <code>pipeline</code>을 인스턴스화하고 텍스트를 입력합니다:",de,Zs,fe,Rs,ve="원한다면 <code>pipeline</code>의 결과를 직접 복제할 수도 있습니다:",ue,O,he,Gs,je;return d=new ks({props:{title:"질의 응답(Question Answering)",local:"question-answering",headingTag:"h1"}}),W=new Oe({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/question_answering.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/question_answering.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/question_answering.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/question_answering.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/question_answering.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/question_answering.ipynb"}]}}),Z=new He({props:{id:"ajPx5LwJD-I"}}),E=new we({props:{$$slots:{default:[st]},$$scope:{ctx:C}}}),N=new B({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),r=new B({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),Q=new ks({props:{title:"SQuAD 데이터 세트 가져오기",local:"load-squad-dataset",headingTag:"h2"}}),ts=new B({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBc3F1YWQlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyc3F1YWQlMjIlMkMlMjBzcGxpdCUzRCUyMnRyYWluJTVCJTNBNTAwMCU1RCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>squad = load_dataset(<span class="hljs-string">&quot;squad&quot;</span>, split=<span class="hljs-string">&quot;train[:5000]&quot;</span>)`,wrap:!1}}),as=new B({props:{code:"c3F1YWQlMjAlM0QlMjBzcXVhZC50cmFpbl90ZXN0X3NwbGl0KHRlc3Rfc2l6ZSUzRDAuMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>squad = squad.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),ps=new B({props:{code:"c3F1YWQlNUIlMjJ0cmFpbiUyMiU1RCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>squad[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers&#x27;</span>: {<span class="hljs-string">&#x27;answer_start&#x27;</span>: [<span class="hljs-number">515</span>], <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&#x27;Saint Bernadette Soubirous&#x27;</span>]},
 <span class="hljs-string">&#x27;context&#x27;</span>: <span class="hljs-string">&#x27;Architecturally, the school has a Catholic character. Atop the Main Building\\&#x27;s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend &quot;Venite Ad Me Omnes&quot;. Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.&#x27;</span>,
 <span class="hljs-string">&#x27;id&#x27;</span>: <span class="hljs-string">&#x27;5733be284776f41900661182&#x27;</span>,
 <span class="hljs-string">&#x27;question&#x27;</span>: <span class="hljs-string">&#x27;To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;University_of_Notre_Dame&#x27;</span>
}`,wrap:!1}}),is=new ks({props:{title:"전처리",local:"preprocess",headingTag:"h2"}}),ms=new He({props:{id:"qgaM0weJHpA"}}),Ms=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)`,wrap:!1}}),hs=new B({props:{code:"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",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    questions = [q.strip() <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;question&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = tokenizer(
<span class="hljs-meta">... </span>        questions,
<span class="hljs-meta">... </span>        examples[<span class="hljs-string">&quot;context&quot;</span>],
<span class="hljs-meta">... </span>        max_length=<span class="hljs-number">384</span>,
<span class="hljs-meta">... </span>        truncation=<span class="hljs-string">&quot;only_second&quot;</span>,
<span class="hljs-meta">... </span>        return_offsets_mapping=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>        padding=<span class="hljs-string">&quot;max_length&quot;</span>,
<span class="hljs-meta">... </span>    )

<span class="hljs-meta">... </span>    offset_mapping = inputs.pop(<span class="hljs-string">&quot;offset_mapping&quot;</span>)
<span class="hljs-meta">... </span>    answers = examples[<span class="hljs-string">&quot;answers&quot;</span>]
<span class="hljs-meta">... </span>    start_positions = []
<span class="hljs-meta">... </span>    end_positions = []

<span class="hljs-meta">... </span>    <span class="hljs-keyword">for</span> i, offset <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(offset_mapping):
<span class="hljs-meta">... </span>        answer = answers[i]
<span class="hljs-meta">... </span>        start_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>]
<span class="hljs-meta">... </span>        end_char = answer[<span class="hljs-string">&quot;answer_start&quot;</span>][<span class="hljs-number">0</span>] + <span class="hljs-built_in">len</span>(answer[<span class="hljs-string">&quot;text&quot;</span>][<span class="hljs-number">0</span>])
<span class="hljs-meta">... </span>        sequence_ids = inputs.sequence_ids(i)

<span class="hljs-meta">... </span>        <span class="hljs-comment"># Find the start and end of the context</span>
<span class="hljs-meta">... </span>        idx = <span class="hljs-number">0</span>
<span class="hljs-meta">... </span>        <span class="hljs-keyword">while</span> sequence_ids[idx] != <span class="hljs-number">1</span>:
<span class="hljs-meta">... </span>            idx += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>        context_start = idx
<span class="hljs-meta">... </span>        <span class="hljs-keyword">while</span> sequence_ids[idx] == <span class="hljs-number">1</span>:
<span class="hljs-meta">... </span>            idx += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>        context_end = idx - <span class="hljs-number">1</span>

<span class="hljs-meta">... </span>        <span class="hljs-comment"># If the answer is not fully inside the context, label it (0, 0)</span>
<span class="hljs-meta">... </span>        <span class="hljs-keyword">if</span> offset[context_start][<span class="hljs-number">0</span>] &gt; end_char <span class="hljs-keyword">or</span> offset[context_end][<span class="hljs-number">1</span>] &lt; start_char:
<span class="hljs-meta">... </span>            start_positions.append(<span class="hljs-number">0</span>)
<span class="hljs-meta">... </span>            end_positions.append(<span class="hljs-number">0</span>)
<span class="hljs-meta">... </span>        <span class="hljs-keyword">else</span>:
<span class="hljs-meta">... </span>            <span class="hljs-comment"># Otherwise it&#x27;s the start and end token positions</span>
<span class="hljs-meta">... </span>            idx = context_start
<span class="hljs-meta">... </span>            <span class="hljs-keyword">while</span> idx &lt;= context_end <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">0</span>] &lt;= start_char:
<span class="hljs-meta">... </span>                idx += <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>            start_positions.append(idx - <span class="hljs-number">1</span>)

<span class="hljs-meta">... </span>            idx = context_end
<span class="hljs-meta">... </span>            <span class="hljs-keyword">while</span> idx &gt;= context_start <span class="hljs-keyword">and</span> offset[idx][<span class="hljs-number">1</span>] &gt;= end_char:
<span class="hljs-meta">... </span>                idx -= <span class="hljs-number">1</span>
<span class="hljs-meta">... </span>            end_positions.append(idx + <span class="hljs-number">1</span>)

<span class="hljs-meta">... </span>    inputs[<span class="hljs-string">&quot;start_positions&quot;</span>] = start_positions
<span class="hljs-meta">... </span>    inputs[<span class="hljs-string">&quot;end_positions&quot;</span>] = end_positions
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`,wrap:!1}}),ws=new B({props:{code:"dG9rZW5pemVkX3NxdWFkJTIwJTNEJTIwc3F1YWQubWFwKHByZXByb2Nlc3NfZnVuY3Rpb24lMkMlMjBiYXRjaGVkJTNEVHJ1ZSUyQyUyMHJlbW92ZV9jb2x1bW5zJTNEc3F1YWQlNUIlMjJ0cmFpbiUyMiU1RC5jb2x1bW5fbmFtZXMp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_squad = squad.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>, remove_columns=squad[<span class="hljs-string">&quot;train&quot;</span>].column_names)',wrap:!1}}),D=new ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[at],pytorch:[tt]},$$scope:{ctx:C}}}),Ts=new ks({props:{title:"훈련",local:"train",headingTag:"h2"}}),P=new ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[mt],pytorch:[rt]},$$scope:{ctx:C}}}),K=new we({props:{$$slots:{default:[ct]},$$scope:{ctx:C}}}),Js=new ks({props:{title:"평가",local:"evaluate",headingTag:"h2"}}),$s=new ks({props:{title:"추론",local:"inference",headingTag:"h2"}}),Cs=new B({props:{code:"cXVlc3Rpb24lMjAlM0QlMjAlMjJIb3clMjBtYW55JTIwcHJvZ3JhbW1pbmclMjBsYW5ndWFnZXMlMjBkb2VzJTIwQkxPT00lMjBzdXBwb3J0JTNGJTIyJTBBY29udGV4dCUyMCUzRCUyMCUyMkJMT09NJTIwaGFzJTIwMTc2JTIwYmlsbGlvbiUyMHBhcmFtZXRlcnMlMjBhbmQlMjBjYW4lMjBnZW5lcmF0ZSUyMHRleHQlMjBpbiUyMDQ2JTIwbGFuZ3VhZ2VzJTIwbmF0dXJhbCUyMGxhbmd1YWdlcyUyMGFuZCUyMDEzJTIwcHJvZ3JhbW1pbmclMjBsYW5ndWFnZXMuJTIy",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>question = <span class="hljs-string">&quot;How many programming languages does BLOOM support?&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>context = <span class="hljs-string">&quot;BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.&quot;</span>`,wrap:!1}}),Zs=new B({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBcXVlc3Rpb25fYW5zd2VyZXIlMjAlM0QlMjBwaXBlbGluZSglMjJxdWVzdGlvbi1hbnN3ZXJpbmclMjIlMkMlMjBtb2RlbCUzRCUyMm15X2F3ZXNvbWVfcWFfbW9kZWwlMjIpJTBBcXVlc3Rpb25fYW5zd2VyZXIocXVlc3Rpb24lM0RxdWVzdGlvbiUyQyUyMGNvbnRleHQlM0Rjb250ZXh0KQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>question_answerer = pipeline(<span class="hljs-string">&quot;question-answering&quot;</span>, model=<span class="hljs-string">&quot;my_awesome_qa_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>question_answerer(question=question, context=context)
{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.2058267742395401</span>,
 <span class="hljs-string">&#x27;start&#x27;</span>: <span class="hljs-number">10</span>,
 <span class="hljs-string">&#x27;end&#x27;</span>: <span class="hljs-number">95</span>,
 <span class="hljs-string">&#x27;answer&#x27;</span>: <span class="hljs-string">&#x27;176 billion parameters and can generate text in 46 languages natural languages and 13&#x27;</span>}`,wrap:!1}}),O=new ye({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ut],pytorch:[dt]},$$scope:{ctx:C}}}),{c(){l=T("meta"),m=o(),t=T("p"),c=o(),f(d.$$.fragment),I=o(),f(W.$$.fragment),k=o(),f(Z.$$.fragment),x=o(),$=T("p"),$.textContent=z,G=o(),b=T("ul"),b.innerHTML=v,R=o(),V=T("p"),V.textContent=A,U=o(),X=T("ol"),X.innerHTML=e,M=o(),f(E.$$.fragment),q=o(),F=T("p"),F.textContent=Bs,Y=o(),f(N.$$.fragment),L=o(),H=T("p"),H.textContent=xs,S=o(),f(r.$$.fragment),_=o(),f(Q.$$.fragment),vs=o(),es=T("p"),es.textContent=Te,As=o(),f(ts.$$.fragment),Ws=o(),ls=T("p"),ls.innerHTML=Je,Vs=o(),f(as.$$.fragment),Es=o(),ns=T("p"),ns.textContent=ge,zs=o(),f(ps.$$.fragment),Fs=o(),rs=T("p"),rs.textContent=be,Ns=o(),os=T("ul"),os.innerHTML=$e,Hs=o(),f(is.$$.fragment),Qs=o(),f(ms.$$.fragment),qs=o(),cs=T("p"),cs.innerHTML=Ue,Ys=o(),f(Ms.$$.fragment),Ls=o(),ds=T("p"),ds.textContent=_e,Ss=o(),fs=T("ol"),fs.innerHTML=Ce,Ds=o(),us=T("p"),us.innerHTML=Ie,Ps=o(),f(hs.$$.fragment),Ks=o(),js=T("p"),js.innerHTML=Ze,Os=o(),f(ws.$$.fragment),se=o(),ys=T("p"),ys.innerHTML=Re,ee=o(),f(D.$$.fragment),te=o(),f(Ts.$$.fragment),le=o(),f(P.$$.fragment),ae=o(),f(K.$$.fragment),ne=o(),f(Js.$$.fragment),pe=o(),gs=T("p"),gs.innerHTML=ke,re=o(),bs=T("p"),bs.innerHTML=Xe,oe=o(),f($s.$$.fragment),ie=o(),Us=T("p"),Us.textContent=Be,me=o(),_s=T("p"),_s.textContent=xe,ce=o(),f(Cs.$$.fragment),Me=o(),Is=T("p"),Is.innerHTML=Ge,de=o(),f(Zs.$$.fragment),fe=o(),Rs=T("p"),Rs.innerHTML=ve,ue=o(),f(O.$$.fragment),he=o(),Gs=T("p"),this.h()},l(s){const p=Pe("svelte-u9bgzb",document.head);l=J(p,"META",{name:!0,content:!0}),p.forEach(a),m=i(s),t=J(s,"P",{}),Fe(t).forEach(a),c=i(s),u(d.$$.fragment,s),I=i(s),u(W.$$.fragment,s),k=i(s),u(Z.$$.fragment,s),x=i(s),$=J(s,"P",{"data-svelte-h":!0}),g($)!=="svelte-egp0yq"&&($.textContent=z),G=i(s),b=J(s,"UL",{"data-svelte-h":!0}),g(b)!=="svelte-1l55cmw"&&(b.innerHTML=v),R=i(s),V=J(s,"P",{"data-svelte-h":!0}),g(V)!=="svelte-1a7n7l8"&&(V.textContent=A),U=i(s),X=J(s,"OL",{"data-svelte-h":!0}),g(X)!=="svelte-tct7qf"&&(X.innerHTML=e),M=i(s),u(E.$$.fragment,s),q=i(s),F=J(s,"P",{"data-svelte-h":!0}),g(F)!=="svelte-19ozuj4"&&(F.textContent=Bs),Y=i(s),u(N.$$.fragment,s),L=i(s),H=J(s,"P",{"data-svelte-h":!0}),g(H)!=="svelte-1tz3h56"&&(H.textContent=xs),S=i(s),u(r.$$.fragment,s),_=i(s),u(Q.$$.fragment,s),vs=i(s),es=J(s,"P",{"data-svelte-h":!0}),g(es)!=="svelte-ufwwq5"&&(es.textContent=Te),As=i(s),u(ts.$$.fragment,s),Ws=i(s),ls=J(s,"P",{"data-svelte-h":!0}),g(ls)!=="svelte-1mkzjhu"&&(ls.innerHTML=Je),Vs=i(s),u(as.$$.fragment,s),Es=i(s),ns=J(s,"P",{"data-svelte-h":!0}),g(ns)!=="svelte-iguerl"&&(ns.textContent=ge),zs=i(s),u(ps.$$.fragment,s),Fs=i(s),rs=J(s,"P",{"data-svelte-h":!0}),g(rs)!=="svelte-xbz2jo"&&(rs.textContent=be),Ns=i(s),os=J(s,"UL",{"data-svelte-h":!0}),g(os)!=="svelte-xcrfgi"&&(os.innerHTML=$e),Hs=i(s),u(is.$$.fragment,s),Qs=i(s),u(ms.$$.fragment,s),qs=i(s),cs=J(s,"P",{"data-svelte-h":!0}),g(cs)!=="svelte-1s1xwu7"&&(cs.innerHTML=Ue),Ys=i(s),u(Ms.$$.fragment,s),Ls=i(s),ds=J(s,"P",{"data-svelte-h":!0}),g(ds)!=="svelte-gwemrx"&&(ds.textContent=_e),Ss=i(s),fs=J(s,"OL",{"data-svelte-h":!0}),g(fs)!=="svelte-18o3dcu"&&(fs.innerHTML=Ce),Ds=i(s),us=J(s,"P",{"data-svelte-h":!0}),g(us)!=="svelte-16yk931"&&(us.innerHTML=Ie),Ps=i(s),u(hs.$$.fragment,s),Ks=i(s),js=J(s,"P",{"data-svelte-h":!0}),g(js)!=="svelte-10qnkwc"&&(js.innerHTML=Ze),Os=i(s),u(ws.$$.fragment,s),se=i(s),ys=J(s,"P",{"data-svelte-h":!0}),g(ys)!=="svelte-1i4emod"&&(ys.innerHTML=Re),ee=i(s),u(D.$$.fragment,s),te=i(s),u(Ts.$$.fragment,s),le=i(s),u(P.$$.fragment,s),ae=i(s),u(K.$$.fragment,s),ne=i(s),u(Js.$$.fragment,s),pe=i(s),gs=J(s,"P",{"data-svelte-h":!0}),g(gs)!=="svelte-h42vxk"&&(gs.innerHTML=ke),re=i(s),bs=J(s,"P",{"data-svelte-h":!0}),g(bs)!=="svelte-179emkt"&&(bs.innerHTML=Xe),oe=i(s),u($s.$$.fragment,s),ie=i(s),Us=J(s,"P",{"data-svelte-h":!0}),g(Us)!=="svelte-174wmmm"&&(Us.textContent=Be),me=i(s),_s=J(s,"P",{"data-svelte-h":!0}),g(_s)!=="svelte-19ecll8"&&(_s.textContent=xe),ce=i(s),u(Cs.$$.fragment,s),Me=i(s),Is=J(s,"P",{"data-svelte-h":!0}),g(Is)!=="svelte-18d8pbh"&&(Is.innerHTML=Ge),de=i(s),u(Zs.$$.fragment,s),fe=i(s),Rs=J(s,"P",{"data-svelte-h":!0}),g(Rs)!=="svelte-ckakkh"&&(Rs.innerHTML=ve),ue=i(s),u(O.$$.fragment,s),he=i(s),Gs=J(s,"P",{}),Fe(Gs).forEach(a),this.h()},h(){Ne(l,"name","hf:doc:metadata"),Ne(l,"content",jt)},m(s,p){Ke(document.head,l),n(s,m,p),n(s,t,p),n(s,c,p),h(d,s,p),n(s,I,p),h(W,s,p),n(s,k,p),h(Z,s,p),n(s,x,p),n(s,$,p),n(s,G,p),n(s,b,p),n(s,R,p),n(s,V,p),n(s,U,p),n(s,X,p),n(s,M,p),h(E,s,p),n(s,q,p),n(s,F,p),n(s,Y,p),h(N,s,p),n(s,L,p),n(s,H,p),n(s,S,p),h(r,s,p),n(s,_,p),h(Q,s,p),n(s,vs,p),n(s,es,p),n(s,As,p),h(ts,s,p),n(s,Ws,p),n(s,ls,p),n(s,Vs,p),h(as,s,p),n(s,Es,p),n(s,ns,p),n(s,zs,p),h(ps,s,p),n(s,Fs,p),n(s,rs,p),n(s,Ns,p),n(s,os,p),n(s,Hs,p),h(is,s,p),n(s,Qs,p),h(ms,s,p),n(s,qs,p),n(s,cs,p),n(s,Ys,p),h(Ms,s,p),n(s,Ls,p),n(s,ds,p),n(s,Ss,p),n(s,fs,p),n(s,Ds,p),n(s,us,p),n(s,Ps,p),h(hs,s,p),n(s,Ks,p),n(s,js,p),n(s,Os,p),h(ws,s,p),n(s,se,p),n(s,ys,p),n(s,ee,p),h(D,s,p),n(s,te,p),h(Ts,s,p),n(s,le,p),h(P,s,p),n(s,ae,p),h(K,s,p),n(s,ne,p),h(Js,s,p),n(s,pe,p),n(s,gs,p),n(s,re,p),n(s,bs,p),n(s,oe,p),h($s,s,p),n(s,ie,p),n(s,Us,p),n(s,me,p),n(s,_s,p),n(s,ce,p),h(Cs,s,p),n(s,Me,p),n(s,Is,p),n(s,de,p),h(Zs,s,p),n(s,fe,p),n(s,Rs,p),n(s,ue,p),h(O,s,p),n(s,he,p),n(s,Gs,p),je=!0},p(s,[p]){const Ae={};p&2&&(Ae.$$scope={dirty:p,ctx:s}),E.$set(Ae);const We={};p&2&&(We.$$scope={dirty:p,ctx:s}),D.$set(We);const Ve={};p&2&&(Ve.$$scope={dirty:p,ctx:s}),P.$set(Ve);const Ee={};p&2&&(Ee.$$scope={dirty:p,ctx:s}),K.$set(Ee);const ze={};p&2&&(ze.$$scope={dirty:p,ctx:s}),O.$set(ze)},i(s){je||(j(d.$$.fragment,s),j(W.$$.fragment,s),j(Z.$$.fragment,s),j(E.$$.fragment,s),j(N.$$.fragment,s),j(r.$$.fragment,s),j(Q.$$.fragment,s),j(ts.$$.fragment,s),j(as.$$.fragment,s),j(ps.$$.fragment,s),j(is.$$.fragment,s),j(ms.$$.fragment,s),j(Ms.$$.fragment,s),j(hs.$$.fragment,s),j(ws.$$.fragment,s),j(D.$$.fragment,s),j(Ts.$$.fragment,s),j(P.$$.fragment,s),j(K.$$.fragment,s),j(Js.$$.fragment,s),j($s.$$.fragment,s),j(Cs.$$.fragment,s),j(Zs.$$.fragment,s),j(O.$$.fragment,s),je=!0)},o(s){w(d.$$.fragment,s),w(W.$$.fragment,s),w(Z.$$.fragment,s),w(E.$$.fragment,s),w(N.$$.fragment,s),w(r.$$.fragment,s),w(Q.$$.fragment,s),w(ts.$$.fragment,s),w(as.$$.fragment,s),w(ps.$$.fragment,s),w(is.$$.fragment,s),w(ms.$$.fragment,s),w(Ms.$$.fragment,s),w(hs.$$.fragment,s),w(ws.$$.fragment,s),w(D.$$.fragment,s),w(Ts.$$.fragment,s),w(P.$$.fragment,s),w(K.$$.fragment,s),w(Js.$$.fragment,s),w($s.$$.fragment,s),w(Cs.$$.fragment,s),w(Zs.$$.fragment,s),w(O.$$.fragment,s),je=!1},d(s){s&&(a(m),a(t),a(c),a(I),a(k),a(x),a($),a(G),a(b),a(R),a(V),a(U),a(X),a(M),a(q),a(F),a(Y),a(L),a(H),a(S),a(_),a(vs),a(es),a(As),a(Ws),a(ls),a(Vs),a(Es),a(ns),a(zs),a(Fs),a(rs),a(Ns),a(os),a(Hs),a(Qs),a(qs),a(cs),a(Ys),a(Ls),a(ds),a(Ss),a(fs),a(Ds),a(us),a(Ps),a(Ks),a(js),a(Os),a(se),a(ys),a(ee),a(te),a(le),a(ae),a(ne),a(pe),a(gs),a(re),a(bs),a(oe),a(ie),a(Us),a(me),a(_s),a(ce),a(Me),a(Is),a(de),a(fe),a(Rs),a(ue),a(he),a(Gs)),a(l),y(d,s),y(W,s),y(Z,s),y(E,s),y(N,s),y(r,s),y(Q,s),y(ts,s),y(as,s),y(ps,s),y(is,s),y(ms,s),y(Ms,s),y(hs,s),y(ws,s),y(D,s),y(Ts,s),y(P,s),y(K,s),y(Js,s),y($s,s),y(Cs,s),y(Zs,s),y(O,s)}}}const jt='{"title":"질의 응답(Question Answering)","local":"question-answering","sections":[{"title":"SQuAD 데이터 세트 가져오기","local":"load-squad-dataset","sections":[],"depth":2},{"title":"전처리","local":"preprocess","sections":[],"depth":2},{"title":"훈련","local":"train","sections":[],"depth":2},{"title":"평가","local":"evaluate","sections":[],"depth":2},{"title":"추론","local":"inference","sections":[],"depth":2}],"depth":1}';function wt(C){return Le(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ct extends Se{constructor(l){super(),De(this,l,wt,ht,Ye,{})}}export{Ct as component};
