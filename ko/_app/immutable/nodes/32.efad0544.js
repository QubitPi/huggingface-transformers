import{s as _t,o as Tt,n as dt}from"../chunks/scheduler.56730f09.js";import{S as Pt,i as xt,g as o,s as r,r as E,A as vt,h as s,f as n,c as l,j as ht,u as H,x as m,k as $t,y as gt,a as i,v as q,d as X,t as S,w as z}from"../chunks/index.1f144517.js";import{T as Ct}from"../chunks/Tip.41e845e5.js";import{H as U}from"../chunks/Heading.57d46534.js";function yt(k){let a,_="PyTorch의 버전이 1.14.0 이상이라면, jit 모드는 jit.trace에서 dict 입력이 지원되므로, 모든 모델의 예측과 평가가 개선될 수 있습니다.",u,f,h="PyTorch의 버전이 1.14.0 미만이라면, 질의 응답 모델과 같이 forward 매개변수의 순서가 jit.trace의 튜플 입력 순서와 일치하는 모델에 득이 될 수 있습니다. 텍스트 분류 모델과 같이 forward 매개변수 순서가 jit.trace의 튜플 입력 순서와 다른 경우, jit.trace가 실패하며 예외가 발생합니다. 이때 예외상황을 사용자에게 알리기 위해 Logging이 사용됩니다.";return{c(){a=o("p"),a.textContent=_,u=r(),f=o("p"),f.textContent=h},l(p){a=s(p,"P",{"data-svelte-h":!0}),m(a)!=="svelte-16x55zk"&&(a.textContent=_),u=l(p),f=s(p,"P",{"data-svelte-h":!0}),m(f)!=="svelte-658865"&&(f.textContent=h)},m(p,c){i(p,a,c),i(p,u,c),i(p,f,c)},p:dt,d(p){p&&(n(a),n(u),n(f))}}}function wt(k){let a,_,u,f,h,p,c,it="이 가이드는 CPU에서 대규모 모델을 효율적으로 추론하는 방법에 중점을 두고 있습니다.",A,T,B,d,rt='우리는 최근 CPU에서 텍스트, 이미지 및 오디오 모델의 빠른 추론을 위해 <code>BetterTransformer</code>를 통합했습니다. 이 통합에 대한 더 자세한 내용은 <a href="https://huggingface.co/docs/optimum/bettertransformer/overview" rel="nofollow">이 문서</a>를 참조하세요.',F,P,N,x,lt="TorchScript는 PyTorch 코드에서 직렬화와 최적화가 가능한 모델을 생성할때 쓰입니다. TorchScript로 만들어진 프로그램은 기존 Python 프로세스에서 저장한 뒤, 종속성이 없는 새로운 프로세스로 가져올 수 있습니다. PyTorch의 기본 설정인 <code>eager</code> 모드와 비교했을때, <code>jit</code> 모드는 연산자 결합과 같은 최적화 방법론을 통해 모델 추론에서 대부분 더 나은 성능을 제공합니다.",G,v,at='TorchScript에 대한 친절한 소개는 <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#tracing-modules" rel="nofollow">PyTorch TorchScript 튜토리얼</a>을 참조하세요.',R,g,D,C,ot="Intel® Extension for PyTorch(IPEX)는 Transformers 계열 모델의 jit 모드에서 추가적인 최적화를 제공합니다. jit 모드와 더불어 Intel® Extension for PyTorch(IPEX)를 활용하시길 강력히 권장드립니다. Transformers 모델에서 자주 사용되는 일부 연산자 패턴은 이미 jit 모드 연산자 결합(operator fusion)의 형태로 Intel® Extension for PyTorch(IPEX)에서 지원되고 있습니다. Multi-head-attention, Concat Linear, Linear+Add, Linear+Gelu, Add+LayerNorm 결합 패턴 등이 이용 가능하며 활용했을 때 성능이 우수합니다. 연산자 결합의 이점은 사용자에게 고스란히 전달됩니다. 분석에 따르면, 질의 응답, 텍스트 분류 및 토큰 분류와 같은 가장 인기 있는 NLP 태스크 중 약 70%가 이러한 결합 패턴을 사용하여 Float32 정밀도와 BFloat16 혼합 정밀도 모두에서 성능상의 이점을 얻을 수 있습니다.",K,y,st='<a href="https://intel.github.io/intel-extension-for-pytorch/cpu/latest/tutorials/features/graph_optimization.html" rel="nofollow">IPEX 그래프 최적화</a>에 대한 자세한 정보를 확인하세요.',O,w,Q,L,pt='IPEX 배포 주기는 PyTorch를 따라서 이루어집니다. 자세한 정보는 <a href="https://intel.github.io/intel-extension-for-pytorch/" rel="nofollow">IPEX 설치 방법</a>을 확인하세요.',V,I,W,b,ft="평가 또는 예측을 위해 Trainer에서 JIT 모드를 사용하려면 Trainer의 명령 인수에 <code>jit_mode_eval</code>을 추가해야 합니다.",Y,$,Z,j,mt='<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/question-answering" rel="nofollow">Transformers 질의 응답</a>의 사용 사례 예시를 참조하세요.',tt,M,ct=`<li><p>CPU에서 jit 모드를 사용한 추론:</p> <pre>python run_qa.py \\
--model_name_or_path csarron/bert-base-uncased-squad-v1 \\
--dataset_name squad \\
--do_eval \\
--max_seq_length 384 \\
--doc_stride 128 \\
--output_dir /tmp/ \\
--no_cuda \\
<b>--jit_mode_eval </b></pre></li> <li><p>CPU에서 IPEX와 함께 jit 모드를 사용한 추론:</p> <pre>python run_qa.py \\
--model_name_or_path csarron/bert-base-uncased-squad-v1 \\
--dataset_name squad \\
--do_eval \\
--max_seq_length 384 \\
--doc_stride 128 \\
--output_dir /tmp/ \\
--no_cuda \\
<b>--use_ipex \\</b>
<b>--jit_mode_eval</b></pre></li>`,et,J,nt;return h=new U({props:{title:"CPU에서 효율적인 추론하기",local:"efficient-inference-on-cpu",headingTag:"h1"}}),T=new U({props:{title:"더 빠른 추론을 위한 BetterTransformer",local:"bettertransformer-for-faster-inference",headingTag:"h2"}}),P=new U({props:{title:"PyTorch JIT 모드 (TorchScript)",local:"pytorch-jitmode-torchscript",headingTag:"h2"}}),g=new U({props:{title:"JIT 모드와 함께하는 IPEX 그래프 최적화",local:"ipex-graph-optimization-with-jitmode",headingTag:"h3"}}),w=new U({props:{title:"IPEX 설치:",local:"ipex-installation",headingTag:"h4"}}),I=new U({props:{title:"JIT 모드 사용법",local:"usage-of-jitmode",headingTag:"h3"}}),$=new Ct({props:{warning:!0,$$slots:{default:[yt]},$$scope:{ctx:k}}}),{c(){a=o("meta"),_=r(),u=o("p"),f=r(),E(h.$$.fragment),p=r(),c=o("p"),c.textContent=it,A=r(),E(T.$$.fragment),B=r(),d=o("p"),d.innerHTML=rt,F=r(),E(P.$$.fragment),N=r(),x=o("p"),x.innerHTML=lt,G=r(),v=o("p"),v.innerHTML=at,R=r(),E(g.$$.fragment),D=r(),C=o("p"),C.textContent=ot,K=r(),y=o("p"),y.innerHTML=st,O=r(),E(w.$$.fragment),Q=r(),L=o("p"),L.innerHTML=pt,V=r(),E(I.$$.fragment),W=r(),b=o("p"),b.innerHTML=ft,Y=r(),E($.$$.fragment),Z=r(),j=o("p"),j.innerHTML=mt,tt=r(),M=o("ul"),M.innerHTML=ct,et=r(),J=o("p"),this.h()},l(t){const e=vt("svelte-u9bgzb",document.head);a=s(e,"META",{name:!0,content:!0}),e.forEach(n),_=l(t),u=s(t,"P",{}),ht(u).forEach(n),f=l(t),H(h.$$.fragment,t),p=l(t),c=s(t,"P",{"data-svelte-h":!0}),m(c)!=="svelte-17589kz"&&(c.textContent=it),A=l(t),H(T.$$.fragment,t),B=l(t),d=s(t,"P",{"data-svelte-h":!0}),m(d)!=="svelte-tutck2"&&(d.innerHTML=rt),F=l(t),H(P.$$.fragment,t),N=l(t),x=s(t,"P",{"data-svelte-h":!0}),m(x)!=="svelte-1o0woyz"&&(x.innerHTML=lt),G=l(t),v=s(t,"P",{"data-svelte-h":!0}),m(v)!=="svelte-pi9b65"&&(v.innerHTML=at),R=l(t),H(g.$$.fragment,t),D=l(t),C=s(t,"P",{"data-svelte-h":!0}),m(C)!=="svelte-9s4z7g"&&(C.textContent=ot),K=l(t),y=s(t,"P",{"data-svelte-h":!0}),m(y)!=="svelte-1prhbg8"&&(y.innerHTML=st),O=l(t),H(w.$$.fragment,t),Q=l(t),L=s(t,"P",{"data-svelte-h":!0}),m(L)!=="svelte-11ohqvl"&&(L.innerHTML=pt),V=l(t),H(I.$$.fragment,t),W=l(t),b=s(t,"P",{"data-svelte-h":!0}),m(b)!=="svelte-8lud22"&&(b.innerHTML=ft),Y=l(t),H($.$$.fragment,t),Z=l(t),j=s(t,"P",{"data-svelte-h":!0}),m(j)!=="svelte-1eo7s2"&&(j.innerHTML=mt),tt=l(t),M=s(t,"UL",{"data-svelte-h":!0}),m(M)!=="svelte-aucptx"&&(M.innerHTML=ct),et=l(t),J=s(t,"P",{}),ht(J).forEach(n),this.h()},h(){$t(a,"name","hf:doc:metadata"),$t(a,"content",Lt)},m(t,e){gt(document.head,a),i(t,_,e),i(t,u,e),i(t,f,e),q(h,t,e),i(t,p,e),i(t,c,e),i(t,A,e),q(T,t,e),i(t,B,e),i(t,d,e),i(t,F,e),q(P,t,e),i(t,N,e),i(t,x,e),i(t,G,e),i(t,v,e),i(t,R,e),q(g,t,e),i(t,D,e),i(t,C,e),i(t,K,e),i(t,y,e),i(t,O,e),q(w,t,e),i(t,Q,e),i(t,L,e),i(t,V,e),q(I,t,e),i(t,W,e),i(t,b,e),i(t,Y,e),q($,t,e),i(t,Z,e),i(t,j,e),i(t,tt,e),i(t,M,e),i(t,et,e),i(t,J,e),nt=!0},p(t,[e]){const ut={};e&2&&(ut.$$scope={dirty:e,ctx:t}),$.$set(ut)},i(t){nt||(X(h.$$.fragment,t),X(T.$$.fragment,t),X(P.$$.fragment,t),X(g.$$.fragment,t),X(w.$$.fragment,t),X(I.$$.fragment,t),X($.$$.fragment,t),nt=!0)},o(t){S(h.$$.fragment,t),S(T.$$.fragment,t),S(P.$$.fragment,t),S(g.$$.fragment,t),S(w.$$.fragment,t),S(I.$$.fragment,t),S($.$$.fragment,t),nt=!1},d(t){t&&(n(_),n(u),n(f),n(p),n(c),n(A),n(B),n(d),n(F),n(N),n(x),n(G),n(v),n(R),n(D),n(C),n(K),n(y),n(O),n(Q),n(L),n(V),n(W),n(b),n(Y),n(Z),n(j),n(tt),n(M),n(et),n(J)),n(a),z(h,t),z(T,t),z(P,t),z(g,t),z(w,t),z(I,t),z($,t)}}}const Lt='{"title":"CPU에서 효율적인 추론하기","local":"efficient-inference-on-cpu","sections":[{"title":"더 빠른 추론을 위한 BetterTransformer","local":"bettertransformer-for-faster-inference","sections":[],"depth":2},{"title":"PyTorch JIT 모드 (TorchScript)","local":"pytorch-jitmode-torchscript","sections":[{"title":"JIT 모드와 함께하는 IPEX 그래프 최적화","local":"ipex-graph-optimization-with-jitmode","sections":[{"title":"IPEX 설치:","local":"ipex-installation","sections":[],"depth":4}],"depth":3},{"title":"JIT 모드 사용법","local":"usage-of-jitmode","sections":[],"depth":3}],"depth":2}],"depth":1}';function It(k){return Tt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Ht extends Pt{constructor(a){super(),xt(this,a,It,wt,_t,{})}}export{Ht as component};
