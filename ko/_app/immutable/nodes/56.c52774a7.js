import{s as Dt,o as Kt,n as te}from"../chunks/scheduler.56730f09.js";import{S as Ot,i as es,g as j,s as m,r as u,A as ts,h as w,f as s,c as i,j as Nt,u as g,x as T,k as Lt,y as ss,a,v as M,d as y,t as $,w as b,m as St,n as Pt}from"../chunks/index.1f144517.js";import{T as wt}from"../chunks/Tip.41e845e5.js";import{Y as qt}from"../chunks/Youtube.62e0f062.js";import{C as I}from"../chunks/CodeBlock.738eeccb.js";import{D as ls}from"../chunks/DocNotebookDropdown.243c3df7.js";import{F as Tt,M as Re}from"../chunks/Markdown.c541024b.js";import{H as Xe}from"../chunks/Heading.57d46534.js";function as(k){let t,c,l='<a href="../model_doc/bart">BART</a>, <a href="../model_doc/bert">BERT</a>, <a href="../model_doc/bert-generation">Bert Generation</a>, <a href="../model_doc/big_bird">BigBird</a>, <a href="../model_doc/bigbird_pegasus">BigBird-Pegasus</a>, <a href="../model_doc/biogpt">BioGpt</a>, <a href="../model_doc/blenderbot">Blenderbot</a>, <a href="../model_doc/blenderbot-small">BlenderbotSmall</a>, <a href="../model_doc/bloom">BLOOM</a>, <a href="../model_doc/camembert">CamemBERT</a>, <a href="../model_doc/codegen">CodeGen</a>, <a href="../model_doc/cpmant">CPM-Ant</a>, <a href="../model_doc/ctrl">CTRL</a>, <a href="../model_doc/data2vec-text">Data2VecText</a>, <a href="../model_doc/electra">ELECTRA</a>, <a href="../model_doc/ernie">ERNIE</a>, <a href="../model_doc/git">GIT</a>, <a href="../model_doc/gpt-sw3">GPT-Sw3</a>, <a href="../model_doc/gpt2">OpenAI GPT-2</a>, <a href="../model_doc/gpt_bigcode">GPTBigCode</a>, <a href="../model_doc/gpt_neo">GPT Neo</a>, <a href="../model_doc/gpt_neox">GPT NeoX</a>, <a href="../model_doc/gpt_neox_japanese">GPT NeoX Japanese</a>, <a href="../model_doc/gptj">GPT-J</a>, <a href="../model_doc/llama">LLaMA</a>, <a href="../model_doc/marian">Marian</a>, <a href="../model_doc/mbart">mBART</a>, <a href="../model_doc/mega">MEGA</a>, <a href="../model_doc/megatron-bert">Megatron-BERT</a>, <a href="../model_doc/mvp">MVP</a>, <a href="../model_doc/open-llama">OpenLlama</a>, <a href="../model_doc/openai-gpt">OpenAI GPT</a>, <a href="../model_doc/opt">OPT</a>, <a href="../model_doc/pegasus">Pegasus</a>, <a href="../model_doc/plbart">PLBart</a>, <a href="../model_doc/prophetnet">ProphetNet</a>, <a href="../model_doc/qdqbert">QDQBert</a>, <a href="../model_doc/reformer">Reformer</a>, <a href="../model_doc/rembert">RemBERT</a>, <a href="../model_doc/roberta">RoBERTa</a>, <a href="../model_doc/roberta-prelayernorm">RoBERTa-PreLayerNorm</a>, <a href="../model_doc/roc_bert">RoCBert</a>, <a href="../model_doc/roformer">RoFormer</a>, <a href="../model_doc/rwkv">RWKV</a>, <a href="../model_doc/speech_to_text_2">Speech2Text2</a>, <a href="../model_doc/transfo-xl">Transformer-XL</a>, <a href="../model_doc/trocr">TrOCR</a>, <a href="../model_doc/xglm">XGLM</a>, <a href="../model_doc/xlm">XLM</a>, <a href="../model_doc/xlm-prophetnet">XLM-ProphetNet</a>, <a href="../model_doc/xlm-roberta">XLM-RoBERTa</a>, <a href="../model_doc/xlm-roberta-xl">XLM-RoBERTa-XL</a>, <a href="../model_doc/xlnet">XLNet</a>, <a href="../model_doc/xmod">X-MOD</a>';return{c(){t=St(`이 안내서의 단계와 동일한 방법으로 인과 언어 모델링을 위해 다른 아키텍처를 미세 조정할 수 있습니다.
다음 아키텍처 중 하나를 선택하세요:

`),c=j("p"),c.innerHTML=l},l(r){t=Pt(r,`이 안내서의 단계와 동일한 방법으로 인과 언어 모델링을 위해 다른 아키텍처를 미세 조정할 수 있습니다.
다음 아키텍처 중 하나를 선택하세요:

`),c=w(r,"P",{"data-svelte-h":!0}),T(c)!=="svelte-8bi7rm"&&(c.innerHTML=l)},m(r,f){a(r,t,f),a(r,c,f)},p:te,d(r){r&&(s(t),s(c))}}}function ns(k){let t,c="패딩 토큰으로 종결 토큰을 사용하고 <code>mlm=False</code>로 설정하세요. 이렇게 하면 입력을 오른쪽으로 한 칸씩 시프트한 값을 레이블로 사용합니다:",l,r,f;return r=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvckxhbmd1YWdlTW9kZWxpbmclMEElMEF0b2tlbml6ZXIucGFkX3Rva2VuJTIwJTNEJTIwdG9rZW5pemVyLmVvc190b2tlbiUwQWRhdGFfY29sbGF0b3IlMjAlM0QlMjBEYXRhQ29sbGF0b3JGb3JMYW5ndWFnZU1vZGVsaW5nKHRva2VuaXplciUzRHRva2VuaXplciUyQyUyMG1sbSUzREZhbHNlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.pad_token = tokenizer.eos_token
<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=<span class="hljs-literal">False</span>)`,wrap:!1}}),{c(){t=j("p"),t.innerHTML=c,l=m(),u(r.$$.fragment)},l(d){t=w(d,"P",{"data-svelte-h":!0}),T(t)!=="svelte-xhgrka"&&(t.innerHTML=c),l=i(d),g(r.$$.fragment,d)},m(d,G){a(d,t,G),a(d,l,G),M(r,d,G),f=!0},p:te,i(d){f||(y(r.$$.fragment,d),f=!0)},o(d){$(r.$$.fragment,d),f=!1},d(d){d&&(s(t),s(l)),b(r,d)}}}function ps(k){let t,c;return t=new Re({props:{$$slots:{default:[ns]},$$scope:{ctx:k}}}),{c(){u(t.$$.fragment)},l(l){g(t.$$.fragment,l)},m(l,r){M(t,l,r),c=!0},p(l,r){const f={};r&2&&(f.$$scope={dirty:r,ctx:l}),t.$set(f)},i(l){c||(y(t.$$.fragment,l),c=!0)},o(l){$(t.$$.fragment,l),c=!1},d(l){b(t,l)}}}function rs(k){let t,c="패딩 토큰으로 종결 토큰을 사용하고 <code>mlm=False</code>로 설정하세요. 이렇게 하면 입력을 오른쪽으로 한 칸씩 시프트한 값을 레이블로 사용합니다:",l,r,f;return r=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERhdGFDb2xsYXRvckZvckxhbmd1YWdlTW9kZWxpbmclMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGF0YUNvbGxhdG9yRm9yTGFuZ3VhZ2VNb2RlbGluZyh0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMjBtbG0lM0RGYWxzZSUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIydGYlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=<span class="hljs-literal">False</span>, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),{c(){t=j("p"),t.innerHTML=c,l=m(),u(r.$$.fragment)},l(d){t=w(d,"P",{"data-svelte-h":!0}),T(t)!=="svelte-xhgrka"&&(t.innerHTML=c),l=i(d),g(r.$$.fragment,d)},m(d,G){a(d,t,G),a(d,l,G),M(r,d,G),f=!0},p:te,i(d){f||(y(r.$$.fragment,d),f=!0)},o(d){$(r.$$.fragment,d),f=!1},d(d){d&&(s(t),s(l)),b(r,d)}}}function os(k){let t,c;return t=new Re({props:{$$slots:{default:[rs]},$$scope:{ctx:k}}}),{c(){u(t.$$.fragment)},l(l){g(t.$$.fragment,l)},m(l,r){M(t,l,r),c=!0},p(l,r){const f={};r&2&&(f.$$scope={dirty:r,ctx:l}),t.$set(f)},i(l){c||(y(t.$$.fragment,l),c=!0)},o(l){$(t.$$.fragment,l),c=!1},d(l){b(t,l)}}}function ms(k){let t,c='<code>Trainer</code>를 사용하여 모델을 미세 조정하는 방법을 잘 모르신다면 <a href="../training#train-with-pytorch-trainer">기본 튜토리얼</a>을 확인해보세요!';return{c(){t=j("p"),t.innerHTML=c},l(l){t=w(l,"P",{"data-svelte-h":!0}),T(t)!=="svelte-1n631xc"&&(t.innerHTML=c)},m(l,r){a(l,t,r)},p:te,d(l){l&&s(t)}}}function is(k){let t,c,l,r="이제 모델을 훈련하기 준비가 되었습니다! <code>AutoModelForCausalLM</code>를 사용하여 DistilGPT2를 불러옵니다:",f,d,G,Z,v="여기까지 진행하면 세 단계만 남았습니다:",V,C,X="<li><code>TrainingArguments</code>에서 훈련 하이퍼파라미터를 정의하세요. <code>output_dir</code>은 유일한 필수 매개변수로, 모델을 저장할 위치를 지정합니다. (먼저 Hugging Face에 로그인 필수) <code>push_to_hub=True</code>로 설정하여 이 모델을 허브에 업로드할 수 있습니다.</li> <li>훈련 인수를 <code>Trainer</code>에 모델, 데이터 세트 및 데이터 콜레이터와 함께 전달하세요.</li> <li><code>train()</code>을 호출하여 모델을 미세 조정하세요.</li>",R,_,W,p,J="훈련이 완료되면 <code>evaluate()</code> 메소드를 사용하여 모델을 평가하고 퍼플렉서티를 얻을 수 있습니다:",Y,E,z,N,L="그런 다음 <code>push_to_hub()</code> 메소드를 사용하여 모델을 허브에 공유하세요. 이렇게 하면 누구나 모델을 사용할 수 있습니다:",B,Q,F;return t=new wt({props:{$$slots:{default:[ms]},$$scope:{ctx:k}}}),d=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTJDJTIwVHJhaW5pbmdBcmd1bWVudHMlMkMlMjBUcmFpbmVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGdwdDIlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilbert/distilgpt2&quot;</span>)`,wrap:!1}}),_=new I({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX2VsaTVfY2xtLW1vZGVsJTIyJTJDJTBBJTIwJTIwJTIwJTIwZXZhbHVhdGlvbl9zdHJhdGVneSUzRCUyMmVwb2NoJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMEElMjAlMjAlMjAlMjB3ZWlnaHRfZGVjYXklM0QwLjAxJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0RsbV9kYXRhc2V0JTVCJTIydHJhaW4lMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0RsbV9kYXRhc2V0JTVCJTIydGVzdCUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMGRhdGFfY29sbGF0b3IlM0RkYXRhX2NvbGxhdG9yJTJDJTBBKSUwQSUwQXRyYWluZXIudHJhaW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">2e-5</span>,
<span class="hljs-meta">... </span>    weight_decay=<span class="hljs-number">0.01</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=lm_dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=lm_dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),E=new I({props:{code:"aW1wb3J0JTIwbWF0aCUwQSUwQWV2YWxfcmVzdWx0cyUyMCUzRCUyMHRyYWluZXIuZXZhbHVhdGUoKSUwQXByaW50KGYlMjJQZXJwbGV4aXR5JTNBJTIwJTdCbWF0aC5leHAoZXZhbF9yZXN1bHRzJTVCJ2V2YWxfbG9zcyclNUQpJTNBLjJmJTdEJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> math

<span class="hljs-meta">&gt;&gt;&gt; </span>eval_results = trainer.evaluate()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Perplexity: <span class="hljs-subst">{math.exp(eval_results[<span class="hljs-string">&#x27;eval_loss&#x27;</span>]):<span class="hljs-number">.2</span>f}</span>&quot;</span>)
Perplexity: <span class="hljs-number">49.61</span>`,wrap:!1}}),Q=new I({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){u(t.$$.fragment),c=m(),l=j("p"),l.innerHTML=r,f=m(),u(d.$$.fragment),G=m(),Z=j("p"),Z.textContent=v,V=m(),C=j("ol"),C.innerHTML=X,R=m(),u(_.$$.fragment),W=m(),p=j("p"),p.innerHTML=J,Y=m(),u(E.$$.fragment),z=m(),N=j("p"),N.innerHTML=L,B=m(),u(Q.$$.fragment)},l(h){g(t.$$.fragment,h),c=i(h),l=w(h,"P",{"data-svelte-h":!0}),T(l)!=="svelte-lq6v0y"&&(l.innerHTML=r),f=i(h),g(d.$$.fragment,h),G=i(h),Z=w(h,"P",{"data-svelte-h":!0}),T(Z)!=="svelte-scyina"&&(Z.textContent=v),V=i(h),C=w(h,"OL",{"data-svelte-h":!0}),T(C)!=="svelte-zqr9wu"&&(C.innerHTML=X),R=i(h),g(_.$$.fragment,h),W=i(h),p=w(h,"P",{"data-svelte-h":!0}),T(p)!=="svelte-amixb4"&&(p.innerHTML=J),Y=i(h),g(E.$$.fragment,h),z=i(h),N=w(h,"P",{"data-svelte-h":!0}),T(N)!=="svelte-1bxxjwl"&&(N.innerHTML=L),B=i(h),g(Q.$$.fragment,h)},m(h,U){M(t,h,U),a(h,c,U),a(h,l,U),a(h,f,U),M(d,h,U),a(h,G,U),a(h,Z,U),a(h,V,U),a(h,C,U),a(h,R,U),M(_,h,U),a(h,W,U),a(h,p,U),a(h,Y,U),M(E,h,U),a(h,z,U),a(h,N,U),a(h,B,U),M(Q,h,U),F=!0},p(h,U){const H={};U&2&&(H.$$scope={dirty:U,ctx:h}),t.$set(H)},i(h){F||(y(t.$$.fragment,h),y(d.$$.fragment,h),y(_.$$.fragment,h),y(E.$$.fragment,h),y(Q.$$.fragment,h),F=!0)},o(h){$(t.$$.fragment,h),$(d.$$.fragment,h),$(_.$$.fragment,h),$(E.$$.fragment,h),$(Q.$$.fragment,h),F=!1},d(h){h&&(s(c),s(l),s(f),s(G),s(Z),s(V),s(C),s(R),s(W),s(p),s(Y),s(z),s(N),s(B)),b(t,h),b(d,h),b(_,h),b(E,h),b(Q,h)}}}function cs(k){let t,c;return t=new Re({props:{$$slots:{default:[is]},$$scope:{ctx:k}}}),{c(){u(t.$$.fragment)},l(l){g(t.$$.fragment,l)},m(l,r){M(t,l,r),c=!0},p(l,r){const f={};r&2&&(f.$$scope={dirty:r,ctx:l}),t.$set(f)},i(l){c||(y(t.$$.fragment,l),c=!0)},o(l){$(t.$$.fragment,l),c=!1},d(l){b(t,l)}}}function hs(k){let t,c='Keras를 사용하여 모델을 미세 조정하는 방법에 익숙하지 않다면 <a href="../training#train-a-tensorflow-model-with-keras">기본 튜토리얼</a>을 확인해보세요!';return{c(){t=j("p"),t.innerHTML=c},l(l){t=w(l,"P",{"data-svelte-h":!0}),T(t)!=="svelte-1qjtntp"&&(t.innerHTML=c)},m(l,r){a(l,t,r)},p:te,d(l){l&&s(t)}}}function fs(k){let t,c,l,r,f,d="그런 다음 <code>TFAutoModelForCausalLM</code>를 사용하여 DistilGPT2를 불러옵니다:",G,Z,v,V,C="<code>prepare_tf_dataset()</code>을 사용하여 데이터 세트를 <code>tf.data.Dataset</code> 형식으로 변환하세요:",X,R,_,W,p='<a href="https://keras.io/api/models/model_training_apis/#compile-method" rel="nofollow"><code>compile</code></a>을 사용하여 모델을 훈련하기 위해 구성하세요. Transformers 모델은 모두 기본적인 작업 관련 손실 함수를 가지고 있으므로, 원한다면 별도로 지정하지 않아도 됩니다:',J,Y,E,z,N="<code>PushToHubCallback</code>에서 모델과 토크나이저를 업로드할 위치를 지정할 수 있습니다:",L,B,Q,F,h='마지막으로, 모델을 훈련하기 위해 <a href="https://keras.io/api/models/model_training_apis/#fit-method" rel="nofollow"><code>fit</code></a>을 호출하세요. 훈련 데이터 세트, 검증 데이터 세트, 에폭 수 및 콜백을 전달하세요:',U,H,S,A,Ve="훈련이 완료되면 모델이 자동으로 허브에 업로드되어 모두가 사용할 수 있습니다!",P;return t=new wt({props:{$$slots:{default:[hs]},$$scope:{ctx:k}}}),l=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMkMlMjBBZGFtV2VpZ2h0RGVjYXklMEElMEFvcHRpbWl6ZXIlMjAlM0QlMjBBZGFtV2VpZ2h0RGVjYXkobGVhcm5pbmdfcmF0ZSUzRDJlLTUlMkMlMjB3ZWlnaHRfZGVjYXlfcmF0ZSUzRDAuMDEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer, AdamWeightDecay

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer = AdamWeightDecay(learning_rate=<span class="hljs-number">2e-5</span>, weight_decay_rate=<span class="hljs-number">0.01</span>)`,wrap:!1}}),Z=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yQ2F1c2FsTE0lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKCUyMmRpc3RpbGJlcnQlMkZkaXN0aWxncHQyJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;distilbert/distilgpt2&quot;</span>)`,wrap:!1}}),R=new I({props:{code:"dGZfdHJhaW5fc2V0JTIwJTNEJTIwbW9kZWwucHJlcGFyZV90Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGxtX2RhdGFzZXQlNUIlMjJ0cmFpbiUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hfc2l6ZSUzRDE2JTJDJTBBJTIwJTIwJTIwJTIwY29sbGF0ZV9mbiUzRGRhdGFfY29sbGF0b3IlMkMlMEEpJTBBJTBBdGZfdGVzdF9zZXQlMjAlM0QlMjBtb2RlbC5wcmVwYXJlX3RmX2RhdGFzZXQoJTBBJTIwJTIwJTIwJTIwbG1fZGF0YXNldCU1QiUyMnRlc3QlMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBzaHVmZmxlJTNERmFsc2UlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBjb2xsYXRlX2ZuJTNEZGF0YV9jb2xsYXRvciUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    lm_dataset[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_test_set = model.prepare_tf_dataset(
<span class="hljs-meta">... </span>    lm_dataset[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),Y=new I({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplciklMjAlMjAlMjMlMjAlRUIlQjMlODQlRUIlOEYlODQlRUIlQTElOUMlMjBsb3NzJTIwJUVDJTlEJUI4JUVDJTlFJTkwJUVCJUE1JUJDJTIwJUVCJTg0JUEzJUVDJUE3JTgwJTIwJUVDJTk1JThBJUVDJTk1JTk4JUVDJTk2JUI0JUVDJTlBJTk0IQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf

<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)  <span class="hljs-comment"># 별도로 loss 인자를 넣지 않았어요!</span>`,wrap:!1}}),B=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBQdXNoVG9IdWJDYWxsYmFjayUwQSUwQWNhbGxiYWNrJTIwJTNEJTIwUHVzaFRvSHViQ2FsbGJhY2soJTBBJTIwJTIwJTIwJTIwb3V0cHV0X2RpciUzRCUyMm15X2F3ZXNvbWVfZWxpNV9jbG0tbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0R0b2tlbml6ZXIlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=tokenizer,
<span class="hljs-meta">... </span>)`,wrap:!1}}),H=new I({props:{code:"bW9kZWwuZml0KHglM0R0Zl90cmFpbl9zZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl90ZXN0X3NldCUyQyUyMGVwb2NocyUzRDMlMkMlMjBjYWxsYmFja3MlM0QlNUJjYWxsYmFjayU1RCk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(x=tf_train_set, validation_data=tf_test_set, epochs=<span class="hljs-number">3</span>, callbacks=[callback])',wrap:!1}}),{c(){u(t.$$.fragment),c=St(`
TensorFlow에서 모델을 미세 조정하려면, 먼저 옵티마이저 함수, 학습률 스케줄 및 일부 훈련 하이퍼파라미터를 설정하세요:

	`),u(l.$$.fragment),r=m(),f=j("p"),f.innerHTML=d,G=m(),u(Z.$$.fragment),v=m(),V=j("p"),V.innerHTML=C,X=m(),u(R.$$.fragment),_=m(),W=j("p"),W.innerHTML=p,J=m(),u(Y.$$.fragment),E=m(),z=j("p"),z.innerHTML=N,L=m(),u(B.$$.fragment),Q=m(),F=j("p"),F.innerHTML=h,U=m(),u(H.$$.fragment),S=m(),A=j("p"),A.textContent=Ve},l(o){g(t.$$.fragment,o),c=Pt(o,`
TensorFlow에서 모델을 미세 조정하려면, 먼저 옵티마이저 함수, 학습률 스케줄 및 일부 훈련 하이퍼파라미터를 설정하세요:

	`),g(l.$$.fragment,o),r=i(o),f=w(o,"P",{"data-svelte-h":!0}),T(f)!=="svelte-1xfjl2y"&&(f.innerHTML=d),G=i(o),g(Z.$$.fragment,o),v=i(o),V=w(o,"P",{"data-svelte-h":!0}),T(V)!=="svelte-57oj0z"&&(V.innerHTML=C),X=i(o),g(R.$$.fragment,o),_=i(o),W=w(o,"P",{"data-svelte-h":!0}),T(W)!=="svelte-bkxxon"&&(W.innerHTML=p),J=i(o),g(Y.$$.fragment,o),E=i(o),z=w(o,"P",{"data-svelte-h":!0}),T(z)!=="svelte-6m34m7"&&(z.innerHTML=N),L=i(o),g(B.$$.fragment,o),Q=i(o),F=w(o,"P",{"data-svelte-h":!0}),T(F)!=="svelte-az37qz"&&(F.innerHTML=h),U=i(o),g(H.$$.fragment,o),S=i(o),A=w(o,"P",{"data-svelte-h":!0}),T(A)!=="svelte-avna1r"&&(A.textContent=Ve)},m(o,x){M(t,o,x),a(o,c,x),M(l,o,x),a(o,r,x),a(o,f,x),a(o,G,x),M(Z,o,x),a(o,v,x),a(o,V,x),a(o,X,x),M(R,o,x),a(o,_,x),a(o,W,x),a(o,J,x),M(Y,o,x),a(o,E,x),a(o,z,x),a(o,L,x),M(B,o,x),a(o,Q,x),a(o,F,x),a(o,U,x),M(H,o,x),a(o,S,x),a(o,A,x),P=!0},p(o,x){const q={};x&2&&(q.$$scope={dirty:x,ctx:o}),t.$set(q)},i(o){P||(y(t.$$.fragment,o),y(l.$$.fragment,o),y(Z.$$.fragment,o),y(R.$$.fragment,o),y(Y.$$.fragment,o),y(B.$$.fragment,o),y(H.$$.fragment,o),P=!0)},o(o){$(t.$$.fragment,o),$(l.$$.fragment,o),$(Z.$$.fragment,o),$(R.$$.fragment,o),$(Y.$$.fragment,o),$(B.$$.fragment,o),$(H.$$.fragment,o),P=!1},d(o){o&&(s(c),s(r),s(f),s(G),s(v),s(V),s(X),s(_),s(W),s(J),s(E),s(z),s(L),s(Q),s(F),s(U),s(S),s(A)),b(t,o),b(l,o),b(Z,o),b(R,o),b(Y,o),b(B,o),b(H,o)}}}function ds(k){let t,c;return t=new Re({props:{$$slots:{default:[fs]},$$scope:{ctx:k}}}),{c(){u(t.$$.fragment)},l(l){g(t.$$.fragment,l)},m(l,r){M(t,l,r),c=!0},p(l,r){const f={};r&2&&(f.$$scope={dirty:r,ctx:l}),t.$set(f)},i(l){c||(y(t.$$.fragment,l),c=!0)},o(l){$(t.$$.fragment,l),c=!1},d(l){b(t,l)}}}function us(k){let t,c='인과 언어 모델링을 위해 모델을 미세 조정하는 더 자세한 예제는 해당하는 <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling.ipynb" rel="nofollow">PyTorch 노트북</a> 또는 <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/language_modeling-tf.ipynb" rel="nofollow">TensorFlow 노트북</a>을 참조하세요.';return{c(){t=j("p"),t.innerHTML=c},l(l){t=w(l,"P",{"data-svelte-h":!0}),T(t)!=="svelte-7gnqxq"&&(t.innerHTML=c)},m(l,r){a(l,t,r)},p:te,d(l){l&&s(t)}}}function gs(k){let t,c="텍스트를 토큰화하고 <code>input_ids</code>를 PyTorch 텐서로 반환하세요:",l,r,f,d,G='<code>generate()</code> 메소드를 사용하여 텍스트를 생성하세요. 생성을 제어하는 다양한 텍스트 생성 전략과 매개변수에 대한 자세한 내용은 <a href="../generation_strategies">텍스트 생성 전략</a> 페이지를 확인하세요.',Z,v,V,C,X="생성된 토큰 ID를 다시 텍스트로 디코딩하세요:",R,_,W;return r=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX2VsaTVfY2xtLW1vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihwcm9tcHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKS5pbnB1dF9pZHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>).input_ids`,wrap:!1}}),v=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckNhdXNhbExNJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JDYXVzYWxMTS5mcm9tX3ByZXRyYWluZWQoJTIybXlfYXdlc29tZV9lbGk1X2NsbS1tb2RlbCUyMiklMEFvdXRwdXRzJTIwJTNEJTIwbW9kZWwuZ2VuZXJhdGUoaW5wdXRzJTJDJTIwbWF4X25ld190b2tlbnMlM0QxMDAlMkMlMjBkb19zYW1wbGUlM0RUcnVlJTJDJTIwdG9wX2slM0Q1MCUyQyUyMHRvcF9wJTNEMC45NSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model.generate(inputs, max_new_tokens=<span class="hljs-number">100</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">50</span>, top_p=<span class="hljs-number">0.95</span>)`,wrap:!1}}),_=new I({props:{code:"dG9rZW5pemVyLmJhdGNoX2RlY29kZShvdXRwdXRzJTJDJTIwc2tpcF9zcGVjaWFsX3Rva2VucyUzRFRydWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(outputs, skip_special_tokens=<span class="hljs-literal">True</span>)
[<span class="hljs-string">&quot;Somatic hypermutation allows the immune system to react to drugs with the ability to adapt to a different environmental situation. In other words, a system of &#x27;hypermutation&#x27; can help the immune system to adapt to a different environmental situation or in some cases even a single life. In contrast, researchers at the University of Massachusetts-Boston have found that &#x27;hypermutation&#x27; is much stronger in mice than in humans but can be found in humans, and that it&#x27;s not completely unknown to the immune system. A study on how the immune system&quot;</span>]`,wrap:!1}}),{c(){t=j("p"),t.innerHTML=c,l=m(),u(r.$$.fragment),f=m(),d=j("p"),d.innerHTML=G,Z=m(),u(v.$$.fragment),V=m(),C=j("p"),C.textContent=X,R=m(),u(_.$$.fragment)},l(p){t=w(p,"P",{"data-svelte-h":!0}),T(t)!=="svelte-1b4fw1g"&&(t.innerHTML=c),l=i(p),g(r.$$.fragment,p),f=i(p),d=w(p,"P",{"data-svelte-h":!0}),T(d)!=="svelte-3u1s1i"&&(d.innerHTML=G),Z=i(p),g(v.$$.fragment,p),V=i(p),C=w(p,"P",{"data-svelte-h":!0}),T(C)!=="svelte-1wns5q7"&&(C.textContent=X),R=i(p),g(_.$$.fragment,p)},m(p,J){a(p,t,J),a(p,l,J),M(r,p,J),a(p,f,J),a(p,d,J),a(p,Z,J),M(v,p,J),a(p,V,J),a(p,C,J),a(p,R,J),M(_,p,J),W=!0},p:te,i(p){W||(y(r.$$.fragment,p),y(v.$$.fragment,p),y(_.$$.fragment,p),W=!0)},o(p){$(r.$$.fragment,p),$(v.$$.fragment,p),$(_.$$.fragment,p),W=!1},d(p){p&&(s(t),s(l),s(f),s(d),s(Z),s(V),s(C),s(R)),b(r,p),b(v,p),b(_,p)}}}function Ms(k){let t,c;return t=new Re({props:{$$slots:{default:[gs]},$$scope:{ctx:k}}}),{c(){u(t.$$.fragment)},l(l){g(t.$$.fragment,l)},m(l,r){M(t,l,r),c=!0},p(l,r){const f={};r&2&&(f.$$scope={dirty:r,ctx:l}),t.$set(f)},i(l){c||(y(t.$$.fragment,l),c=!0)},o(l){$(t.$$.fragment,l),c=!1},d(l){b(t,l)}}}function ys(k){let t,c="텍스트를 토큰화하고 <code>input_ids</code>를 TensorFlow 텐서로 반환하세요:",l,r,f,d,G='<code>generate()</code> 메소드를 사용하여 요약을 생성하세요. 생성을 제어하는 다양한 텍스트 생성 전략과 매개변수에 대한 자세한 내용은 <a href="../generation_strategies">텍스트 생성 전략</a> 페이지를 확인하세요.',Z,v,V,C,X="생성된 토큰 ID를 다시 텍스트로 디코딩하세요:",R,_,W;return r=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX2VsaTVfY2xtLW1vZGVsJTIyKSUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplcihwcm9tcHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKS5pbnB1dF9pZHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(prompt, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>).input_ids`,wrap:!1}}),v=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yQ2F1c2FsTE0lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yQ2F1c2FsTE0uZnJvbV9wcmV0cmFpbmVkKCUyMm15X2F3ZXNvbWVfZWxpNV9jbG0tbW9kZWwlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKGlucHV0X2lkcyUzRGlucHV0cyUyQyUyMG1heF9uZXdfdG9rZW5zJTNEMTAwJTJDJTIwZG9fc2FtcGxlJTNEVHJ1ZSUyQyUyMHRvcF9rJTNENTAlMkMlMjB0b3BfcCUzRDAuOTUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForCausalLM

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForCausalLM.from_pretrained(<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model.generate(input_ids=inputs, max_new_tokens=<span class="hljs-number">100</span>, do_sample=<span class="hljs-literal">True</span>, top_k=<span class="hljs-number">50</span>, top_p=<span class="hljs-number">0.95</span>)`,wrap:!1}}),_=new I({props:{code:"dG9rZW5pemVyLmJhdGNoX2RlY29kZShvdXRwdXRzJTJDJTIwc2tpcF9zcGVjaWFsX3Rva2VucyUzRFRydWUp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(outputs, skip_special_tokens=<span class="hljs-literal">True</span>)
[<span class="hljs-string">&#x27;Somatic hypermutation allows the immune system to detect the presence of other viruses as they become more prevalent. Therefore, researchers have identified a high proportion of human viruses. The proportion of virus-associated viruses in our study increases with age. Therefore, we propose a simple algorithm to detect the presence of these new viruses in our samples as a sign of improved immunity. A first study based on this algorithm, which will be published in Science on Friday, aims to show that this finding could translate into the development of a better vaccine that is more effective for&#x27;</span>]`,wrap:!1}}),{c(){t=j("p"),t.innerHTML=c,l=m(),u(r.$$.fragment),f=m(),d=j("p"),d.innerHTML=G,Z=m(),u(v.$$.fragment),V=m(),C=j("p"),C.textContent=X,R=m(),u(_.$$.fragment)},l(p){t=w(p,"P",{"data-svelte-h":!0}),T(t)!=="svelte-jhzp8k"&&(t.innerHTML=c),l=i(p),g(r.$$.fragment,p),f=i(p),d=w(p,"P",{"data-svelte-h":!0}),T(d)!=="svelte-170xtje"&&(d.innerHTML=G),Z=i(p),g(v.$$.fragment,p),V=i(p),C=w(p,"P",{"data-svelte-h":!0}),T(C)!=="svelte-1wns5q7"&&(C.textContent=X),R=i(p),g(_.$$.fragment,p)},m(p,J){a(p,t,J),a(p,l,J),M(r,p,J),a(p,f,J),a(p,d,J),a(p,Z,J),M(v,p,J),a(p,V,J),a(p,C,J),a(p,R,J),M(_,p,J),W=!0},p:te,i(p){W||(y(r.$$.fragment,p),y(v.$$.fragment,p),y(_.$$.fragment,p),W=!0)},o(p){$(r.$$.fragment,p),$(v.$$.fragment,p),$(_.$$.fragment,p),W=!1},d(p){p&&(s(t),s(l),s(f),s(d),s(Z),s(V),s(C),s(R)),b(r,p),b(v,p),b(_,p)}}}function $s(k){let t,c;return t=new Re({props:{$$slots:{default:[ys]},$$scope:{ctx:k}}}),{c(){u(t.$$.fragment)},l(l){g(t.$$.fragment,l)},m(l,r){M(t,l,r),c=!0},p(l,r){const f={};r&2&&(f.$$scope={dirty:r,ctx:l}),t.$set(f)},i(l){c||(y(t.$$.fragment,l),c=!0)},o(l){$(t.$$.fragment,l),c=!1},d(l){b(t,l)}}}function bs(k){let t,c,l,r,f,d,G,Z,v,V=`언어 모델링은 인과적 언어 모델링과 마스크드 언어 모델링, 두 가지 유형으로 나뉩니다. 이 가이드에서는 인과적 언어 모델링을 설명합니다.
인과 언어 모델은 텍스트 생성에 자주 사용됩니다. 또 창의적인 방향으로 응용할 수 있습니다.
직접 사용하며 재미있는 탐구를 해보거나, Copilot 또는 CodeParrot와 같은 지능형 코딩 어시스턴트의 기반이 되기도 합니다.`,C,X,R,_,W=`인과 언어 모델링은 토큰 시퀀스에서 다음 토큰을 예측하며, 모델은 왼쪽의 토큰에만 접근할 수 있습니다.
이는 모델이 미래의 토큰을 볼 수 없다는 것을 의미합니다. 인과 언어 모델의 예로 GPT-2가 있죠.`,p,J,Y="이 가이드에서는 다음 작업을 수행하는 방법을 안내합니다:",E,z,N='<li><a href="https://huggingface.co/distilbert/distilgpt2" rel="nofollow">DistilGPT2</a> 모델을 <a href="https://huggingface.co/datasets/eli5" rel="nofollow">ELI5</a> 데이터 세트의 <a href="https://www.reddit.com/r/askscience/" rel="nofollow">r/askscience</a> 하위 집합으로 미세 조정</li> <li>미세 조정된 모델을 추론에 사용</li>',L,B,Q,F,h="시작하기 전에 필요한 라이브러리가 모두 설치되어 있는지 확인하세요:",U,H,S,A,Ve="커뮤니티에 모델을 업로드하고 공유하기 위해 Hugging Face 계정에 로그인하는 것을 권장합니다. 알림이 표시되면 토큰을 입력하여 로그인하세요:",P,o,x,q,Be,se,Jt=`먼저, 🤗 Datasets 라이브러리에서 r/askscience의 작은 하위 집합인 ELI5 데이터 세트를 불러옵니다.
이를 통해 전체 데이터 세트에서 학습하는 데 더 많은 시간을 투자하기 전에, 실험해봄으로써 모든 것이 작동하는지 확인할 수 있습니다.`,ze,le,Fe,ae,_t="데이터 세트의 <code>train_asks</code> 분할을 <code>train_test_split</code> 메소드를 사용하여 학습 및 테스트 세트로 분할합니다:",He,ne,Ee,pe,xt="그런 다음 예제를 살펴보세요:",Qe,re,Ye,oe,Ut="많아 보일 수 있지만, 실제로는 <code>text</code> 필드만 중요합니다. 언어 모델링 작업의 장점은 레이블이 필요하지 않다는 것입니다. 다음 단어 <em>자체가</em> 레이블입니다. (이렇게 레이블을 제공하지 않아도 되는 학습을 비지도 학습이라고 일컫습니다)",Ae,me,Ne,ie,Le,ce,kt="다음 단계는 <code>text</code> 필드를 전처리하기 위해 DistilGPT2 토크나이저를 불러오는 것입니다.",qe,he,Se,fe,Gt='위의 예제에서 알 수 있듯이, <code>text</code> 필드는 <code>answers</code> 아래에 중첩되어 있습니다. 따라서 <a href="https://huggingface.co/docs/datasets/process#flatten" rel="nofollow"><code>flatten</code></a> 메소드를 사용하여 중첩 구조에서 <code>text</code> 하위 필드를 추출해야 합니다.',Pe,de,De,ue,vt="각 하위 필드는 이제 <code>answers</code> 접두사를 가진 별도의 열로 나뉘었으며, <code>text</code> 필드는 이제 리스트입니다. 각 문장을 개별적으로 토큰화하는 대신, 먼저 리스트를 문자열로 변환하여 한꺼번에 토큰화할 수 있습니다.",Ke,ge,Ct="다음은 문자열 리스트를 결합하고 결과를 토큰화하는 첫 번째 전처리 함수입니다:",Oe,Me,et,ye,It="이 전처리 함수를 전체 데이터 세트에 적용하려면 🤗 Datasets <code>map</code> 메소드를 사용하세요. <code>batched=True</code>로 설정하여 데이터셋의 여러 요소를 한 번에 처리하고, <code>num_proc</code>를 증가시켜 프로세스 수를 늘릴 수 있습니다. 필요 없는 열은 제거하세요:",tt,$e,st,be,Zt="이제 데이터 세트는 시퀀스가 토큰화됐지만, 일부 시퀀스는 모델의 최대 입력 길이보다 길 수 있습니다.",lt,je,Rt="이제 두 번째 전처리 함수를 사용하여",at,we,Vt="<li>모든 시퀀스를 연결하고,</li> <li><code>block_size</code>로 정의된 길이로 연결된 시퀀스를 여러 개의 짧은 묶음으로 나눕니다. 이 값은 최대 입력 길이와 GPU RAM을 고려해 충분히 짧아야 합니다.</li>",nt,Te,pt,Je,Wt="전체 데이터 세트에 <code>group_texts</code> 함수를 적용하세요:",rt,_e,ot,xe,Xt="그런 다음 <code>DataCollatorForLanguageModeling</code>을 사용하여 예제의 배치를 만듭니다. 데이터 세트 전체를 최대 길이로 패딩하는 것보다, 취합 단계에서 각 배치의 최대 길이로 문장을 <em>동적으로 패딩</em>하는 것이 더 효율적입니다.",mt,D,it,Ue,ct,K,ht,O,ft,ke,dt,Ge,Bt="좋아요, 이제 모델을 미세 조정했으므로 추론에 사용할 수 있습니다!",ut,ve,zt="생성할 텍스트를 위한 프롬프트를 만들어보세요:",gt,Ce,Mt,Ie,Ft="추론을 위해 미세 조정된 모델을 간단히 사용하는 가장 간단한 방법은 <code>pipeline()</code>에서 사용하는 것입니다. 모델과 함께 텍스트 생성을 위한 <code>pipeline</code>을 인스턴스화하고 텍스트를 전달하세요:",yt,Ze,$t,ee,bt,We,jt;return f=new Xe({props:{title:"인과 언어 모델링",local:"causal-language-modeling",headingTag:"h1"}}),G=new ls({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/language_modeling.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/language_modeling.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/language_modeling.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/language_modeling.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/language_modeling.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/language_modeling.ipynb"}]}}),X=new qt({props:{id:"Vpjb1lu0MDk"}}),B=new wt({props:{$$slots:{default:[as]},$$scope:{ctx:k}}}),H=new I({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),o=new I({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),q=new Xe({props:{title:"ELI5 데이터 세트 불러오기",local:"load-eli5-dataset",headingTag:"h2"}}),le=new I({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZWxpNSUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJlbGk1JTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbl9hc2tzJTVCJTNBNTAwMCU1RCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = load_dataset(<span class="hljs-string">&quot;eli5&quot;</span>, split=<span class="hljs-string">&quot;train_asks[:5000]&quot;</span>)`,wrap:!1}}),ne=new I({props:{code:"ZWxpNSUyMCUzRCUyMGVsaTUudHJhaW5fdGVzdF9zcGxpdCh0ZXN0X3NpemUlM0QwLjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = eli5.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),re=new I({props:{code:"ZWxpNSU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>eli5[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers&#x27;</span>: {<span class="hljs-string">&#x27;a_id&#x27;</span>: [<span class="hljs-string">&#x27;c3d1aib&#x27;</span>, <span class="hljs-string">&#x27;c3d4lya&#x27;</span>],
  <span class="hljs-string">&#x27;score&#x27;</span>: [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],
  <span class="hljs-string">&#x27;text&#x27;</span>: [<span class="hljs-string">&quot;The velocity needed to remain in orbit is equal to the square root of Newton&#x27;s constant times the mass of earth divided by the distance from the center of the earth. I don&#x27;t know the altitude of that specific mission, but they&#x27;re usually around 300 km. That means he&#x27;s going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up.&quot;</span>,
   <span class="hljs-string">&quot;Hope you don&#x27;t mind me asking another question, but why aren&#x27;t there any stars visible in this photo?&quot;</span>]},
 <span class="hljs-string">&#x27;answers_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: []},
 <span class="hljs-string">&#x27;document&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
 <span class="hljs-string">&#x27;q_id&#x27;</span>: <span class="hljs-string">&#x27;nyxfp&#x27;</span>,
 <span class="hljs-string">&#x27;selftext&#x27;</span>: <span class="hljs-string">&#x27;_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?&#x27;</span>,
 <span class="hljs-string">&#x27;selftext_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: [<span class="hljs-string">&#x27;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg&#x27;</span>]},
 <span class="hljs-string">&#x27;subreddit&#x27;</span>: <span class="hljs-string">&#x27;askscience&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Few questions about this space walk photograph.&#x27;</span>,
 <span class="hljs-string">&#x27;title_urls&#x27;</span>: {<span class="hljs-string">&#x27;url&#x27;</span>: []}}`,wrap:!1}}),me=new Xe({props:{title:"전처리",local:"preprocess",headingTag:"h2"}}),ie=new qt({props:{id:"ma1TrR7gE7I"}}),he=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0JTJGZGlzdGlsZ3B0MiUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilgpt2&quot;</span>)`,wrap:!1}}),de=new I({props:{code:"ZWxpNSUyMCUzRCUyMGVsaTUuZmxhdHRlbigpJTBBZWxpNSU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>eli5 = eli5.flatten()
<span class="hljs-meta">&gt;&gt;&gt; </span>eli5[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;answers.a_id&#x27;</span>: [<span class="hljs-string">&#x27;c3d1aib&#x27;</span>, <span class="hljs-string">&#x27;c3d4lya&#x27;</span>],
 <span class="hljs-string">&#x27;answers.score&#x27;</span>: [<span class="hljs-number">6</span>, <span class="hljs-number">3</span>],
 <span class="hljs-string">&#x27;answers.text&#x27;</span>: [<span class="hljs-string">&quot;The velocity needed to remain in orbit is equal to the square root of Newton&#x27;s constant times the mass of earth divided by the distance from the center of the earth. I don&#x27;t know the altitude of that specific mission, but they&#x27;re usually around 300 km. That means he&#x27;s going 7-8 km/s.\\n\\nIn space there are no other forces acting on either the shuttle or the guy, so they stay in the same position relative to each other. If he were to become unable to return to the ship, he would presumably run out of oxygen, or slowly fall into the atmosphere and burn up.&quot;</span>,
  <span class="hljs-string">&quot;Hope you don&#x27;t mind me asking another question, but why aren&#x27;t there any stars visible in this photo?&quot;</span>],
 <span class="hljs-string">&#x27;answers_urls.url&#x27;</span>: [],
 <span class="hljs-string">&#x27;document&#x27;</span>: <span class="hljs-string">&#x27;&#x27;</span>,
 <span class="hljs-string">&#x27;q_id&#x27;</span>: <span class="hljs-string">&#x27;nyxfp&#x27;</span>,
 <span class="hljs-string">&#x27;selftext&#x27;</span>: <span class="hljs-string">&#x27;_URL_0_\\n\\nThis was on the front page earlier and I have a few questions about it. Is it possible to calculate how fast the astronaut would be orbiting the earth? Also how does he stay close to the shuttle so that he can return safely, i.e is he orbiting at the same speed and can therefore stay next to it? And finally if his propulsion system failed, would he eventually re-enter the atmosphere and presumably die?&#x27;</span>,
 <span class="hljs-string">&#x27;selftext_urls.url&#x27;</span>: [<span class="hljs-string">&#x27;http://apod.nasa.gov/apod/image/1201/freeflyer_nasa_3000.jpg&#x27;</span>],
 <span class="hljs-string">&#x27;subreddit&#x27;</span>: <span class="hljs-string">&#x27;askscience&#x27;</span>,
 <span class="hljs-string">&#x27;title&#x27;</span>: <span class="hljs-string">&#x27;Few questions about this space walk photograph.&#x27;</span>,
 <span class="hljs-string">&#x27;title_urls.url&#x27;</span>: []}`,wrap:!1}}),Me=new I({props:{code:"ZGVmJTIwcHJlcHJvY2Vzc19mdW5jdGlvbihleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjByZXR1cm4lMjB0b2tlbml6ZXIoJTVCJTIyJTIwJTIyLmpvaW4oeCklMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlcyU1QiUyMmFuc3dlcnMudGV4dCUyMiU1RCU1RCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tokenizer([<span class="hljs-string">&quot; &quot;</span>.join(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;answers.text&quot;</span>]])`,wrap:!1}}),$e=new I({props:{code:"dG9rZW5pemVkX2VsaTUlMjAlM0QlMjBlbGk1Lm1hcCglMEElMjAlMjAlMjAlMjBwcmVwcm9jZXNzX2Z1bmN0aW9uJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hlZCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBudW1fcHJvYyUzRDQlMkMlMEElMjAlMjAlMjAlMjByZW1vdmVfY29sdW1ucyUzRGVsaTUlNUIlMjJ0cmFpbiUyMiU1RC5jb2x1bW5fbmFtZXMlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>tokenized_eli5 = eli5.<span class="hljs-built_in">map</span>(
<span class="hljs-meta">... </span>    preprocess_function,
<span class="hljs-meta">... </span>    batched=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    num_proc=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    remove_columns=eli5[<span class="hljs-string">&quot;train&quot;</span>].column_names,
<span class="hljs-meta">... </span>)`,wrap:!1}}),Te=new I({props:{code:"YmxvY2tfc2l6ZSUyMCUzRCUyMDEyOCUwQSUwQSUwQWRlZiUyMGdyb3VwX3RleHRzKGV4YW1wbGVzKSUzQSUwQSUyMCUyMCUyMCUyMCUyMyUyMENvbmNhdGVuYXRlJTIwYWxsJTIwdGV4dHMuJTBBJTIwJTIwJTIwJTIwY29uY2F0ZW5hdGVkX2V4YW1wbGVzJTIwJTNEJTIwJTdCayUzQSUyMHN1bShleGFtcGxlcyU1QmslNUQlMkMlMjAlNUIlNUQpJTIwZm9yJTIwayUyMGluJTIwZXhhbXBsZXMua2V5cygpJTdEJTBBJTIwJTIwJTIwJTIwdG90YWxfbGVuZ3RoJTIwJTNEJTIwbGVuKGNvbmNhdGVuYXRlZF9leGFtcGxlcyU1Qmxpc3QoZXhhbXBsZXMua2V5cygpKSU1QjAlNUQlNUQpJTBBJTIwJTIwJTIwJTIwJTIzJTIwV2UlMjBkcm9wJTIwdGhlJTIwc21hbGwlMjByZW1haW5kZXIlMkMlMjB3ZSUyMGNvdWxkJTIwYWRkJTIwcGFkZGluZyUyMGlmJTIwdGhlJTIwbW9kZWwlMjBzdXBwb3J0ZWQlMjBpdCUyMGluc3RlYWQlMjBvZiUyMHRoaXMlMjBkcm9wJTJDJTIweW91JTIwY2FuJTBBJTIwJTIwJTIwJTIwJTIzJTIwY3VzdG9taXplJTIwdGhpcyUyMHBhcnQlMjB0byUyMHlvdXIlMjBuZWVkcy4lMEElMjAlMjAlMjAlMjBpZiUyMHRvdGFsX2xlbmd0aCUyMCUzRSUzRCUyMGJsb2NrX3NpemUlM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjB0b3RhbF9sZW5ndGglMjAlM0QlMjAodG90YWxfbGVuZ3RoJTIwJTJGJTJGJTIwYmxvY2tfc2l6ZSklMjAqJTIwYmxvY2tfc2l6ZSUwQSUyMCUyMCUyMCUyMCUyMyUyMFNwbGl0JTIwYnklMjBjaHVua3MlMjBvZiUyMGJsb2NrX3NpemUuJTBBJTIwJTIwJTIwJTIwcmVzdWx0JTIwJTNEJTIwJTdCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwayUzQSUyMCU1QnQlNUJpJTIwJTNBJTIwaSUyMCUyQiUyMGJsb2NrX3NpemUlNUQlMjBmb3IlMjBpJTIwaW4lMjByYW5nZSgwJTJDJTIwdG90YWxfbGVuZ3RoJTJDJTIwYmxvY2tfc2l6ZSklNUQlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBmb3IlMjBrJTJDJTIwdCUyMGluJTIwY29uY2F0ZW5hdGVkX2V4YW1wbGVzLml0ZW1zKCklMEElMjAlMjAlMjAlMjAlN0QlMEElMjAlMjAlMjAlMjByZXN1bHQlNUIlMjJsYWJlbHMlMjIlNUQlMjAlM0QlMjByZXN1bHQlNUIlMjJpbnB1dF9pZHMlMjIlNUQuY29weSgpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwcmVzdWx0",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>block_size = <span class="hljs-number">128</span>


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    <span class="hljs-comment"># Concatenate all texts.</span>
<span class="hljs-meta">... </span>    concatenated_examples = {k: <span class="hljs-built_in">sum</span>(examples[k], []) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()}
<span class="hljs-meta">... </span>    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])
<span class="hljs-meta">... </span>    <span class="hljs-comment"># We drop the small remainder, we could add padding if the model supported it instead of this drop, you can</span>
<span class="hljs-meta">... </span>    <span class="hljs-comment"># customize this part to your needs.</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> total_length &gt;= block_size:
<span class="hljs-meta">... </span>        total_length = (total_length // block_size) * block_size
<span class="hljs-meta">... </span>    <span class="hljs-comment"># Split by chunks of block_size.</span>
<span class="hljs-meta">... </span>    result = {
<span class="hljs-meta">... </span>        k: [t[i : i + block_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, total_length, block_size)]
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> concatenated_examples.items()
<span class="hljs-meta">... </span>    }
<span class="hljs-meta">... </span>    result[<span class="hljs-string">&quot;labels&quot;</span>] = result[<span class="hljs-string">&quot;input_ids&quot;</span>].copy()
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> result`,wrap:!1}}),_e=new I({props:{code:"bG1fZGF0YXNldCUyMCUzRCUyMHRva2VuaXplZF9lbGk1Lm1hcChncm91cF90ZXh0cyUyQyUyMGJhdGNoZWQlM0RUcnVlJTJDJTIwbnVtX3Byb2MlM0Q0KQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>lm_dataset = tokenized_eli5.<span class="hljs-built_in">map</span>(group_texts, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">4</span>)',wrap:!1}}),D=new Tt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[os],pytorch:[ps]},$$scope:{ctx:k}}}),Ue=new Xe({props:{title:"훈련",local:"train",headingTag:"h2"}}),K=new Tt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ds],pytorch:[cs]},$$scope:{ctx:k}}}),O=new wt({props:{$$slots:{default:[us]},$$scope:{ctx:k}}}),ke=new Xe({props:{title:"추론",local:"inference",headingTag:"h2"}}),Ce=new I({props:{code:"cHJvbXB0JTIwJTNEJTIwJTIyU29tYXRpYyUyMGh5cGVybXV0YXRpb24lMjBhbGxvd3MlMjB0aGUlMjBpbW11bmUlMjBzeXN0ZW0lMjB0byUyMg==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>prompt = <span class="hljs-string">&quot;Somatic hypermutation allows the immune system to&quot;</span>',wrap:!1}}),Ze=new I({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBZ2VuZXJhdG9yJTIwJTNEJTIwcGlwZWxpbmUoJTIydGV4dC1nZW5lcmF0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJteV9hd2Vzb21lX2VsaTVfY2xtLW1vZGVsJTIyKSUwQWdlbmVyYXRvcihwcm9tcHQp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>generator = pipeline(<span class="hljs-string">&quot;text-generation&quot;</span>, model=<span class="hljs-string">&quot;my_awesome_eli5_clm-model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>generator(prompt)
[{<span class="hljs-string">&#x27;generated_text&#x27;</span>: <span class="hljs-string">&quot;Somatic hypermutation allows the immune system to be able to effectively reverse the damage caused by an infection.\\n\\n\\nThe damage caused by an infection is caused by the immune system&#x27;s ability to perform its own self-correcting tasks.&quot;</span>}]`,wrap:!1}}),ee=new Tt({props:{pytorch:!0,tensorflow:!0,jax:!1,$$slots:{tensorflow:[$s],pytorch:[Ms]},$$scope:{ctx:k}}}),{c(){t=j("meta"),c=m(),l=j("p"),r=m(),u(f.$$.fragment),d=m(),u(G.$$.fragment),Z=m(),v=j("p"),v.textContent=V,C=m(),u(X.$$.fragment),R=m(),_=j("p"),_.textContent=W,p=m(),J=j("p"),J.textContent=Y,E=m(),z=j("ol"),z.innerHTML=N,L=m(),u(B.$$.fragment),Q=m(),F=j("p"),F.textContent=h,U=m(),u(H.$$.fragment),S=m(),A=j("p"),A.textContent=Ve,P=m(),u(o.$$.fragment),x=m(),u(q.$$.fragment),Be=m(),se=j("p"),se.textContent=Jt,ze=m(),u(le.$$.fragment),Fe=m(),ae=j("p"),ae.innerHTML=_t,He=m(),u(ne.$$.fragment),Ee=m(),pe=j("p"),pe.textContent=xt,Qe=m(),u(re.$$.fragment),Ye=m(),oe=j("p"),oe.innerHTML=Ut,Ae=m(),u(me.$$.fragment),Ne=m(),u(ie.$$.fragment),Le=m(),ce=j("p"),ce.innerHTML=kt,qe=m(),u(he.$$.fragment),Se=m(),fe=j("p"),fe.innerHTML=Gt,Pe=m(),u(de.$$.fragment),De=m(),ue=j("p"),ue.innerHTML=vt,Ke=m(),ge=j("p"),ge.textContent=Ct,Oe=m(),u(Me.$$.fragment),et=m(),ye=j("p"),ye.innerHTML=It,tt=m(),u($e.$$.fragment),st=m(),be=j("p"),be.textContent=Zt,lt=m(),je=j("p"),je.textContent=Rt,at=m(),we=j("ul"),we.innerHTML=Vt,nt=m(),u(Te.$$.fragment),pt=m(),Je=j("p"),Je.innerHTML=Wt,rt=m(),u(_e.$$.fragment),ot=m(),xe=j("p"),xe.innerHTML=Xt,mt=m(),u(D.$$.fragment),it=m(),u(Ue.$$.fragment),ct=m(),u(K.$$.fragment),ht=m(),u(O.$$.fragment),ft=m(),u(ke.$$.fragment),dt=m(),Ge=j("p"),Ge.textContent=Bt,ut=m(),ve=j("p"),ve.textContent=zt,gt=m(),u(Ce.$$.fragment),Mt=m(),Ie=j("p"),Ie.innerHTML=Ft,yt=m(),u(Ze.$$.fragment),$t=m(),u(ee.$$.fragment),bt=m(),We=j("p"),this.h()},l(e){const n=ts("svelte-u9bgzb",document.head);t=w(n,"META",{name:!0,content:!0}),n.forEach(s),c=i(e),l=w(e,"P",{}),Nt(l).forEach(s),r=i(e),g(f.$$.fragment,e),d=i(e),g(G.$$.fragment,e),Z=i(e),v=w(e,"P",{"data-svelte-h":!0}),T(v)!=="svelte-zdtuex"&&(v.textContent=V),C=i(e),g(X.$$.fragment,e),R=i(e),_=w(e,"P",{"data-svelte-h":!0}),T(_)!=="svelte-611b95"&&(_.textContent=W),p=i(e),J=w(e,"P",{"data-svelte-h":!0}),T(J)!=="svelte-x18r2q"&&(J.textContent=Y),E=i(e),z=w(e,"OL",{"data-svelte-h":!0}),T(z)!=="svelte-uvx0a8"&&(z.innerHTML=N),L=i(e),g(B.$$.fragment,e),Q=i(e),F=w(e,"P",{"data-svelte-h":!0}),T(F)!=="svelte-1k0z9pm"&&(F.textContent=h),U=i(e),g(H.$$.fragment,e),S=i(e),A=w(e,"P",{"data-svelte-h":!0}),T(A)!=="svelte-tqxze0"&&(A.textContent=Ve),P=i(e),g(o.$$.fragment,e),x=i(e),g(q.$$.fragment,e),Be=i(e),se=w(e,"P",{"data-svelte-h":!0}),T(se)!=="svelte-8ukoq1"&&(se.textContent=Jt),ze=i(e),g(le.$$.fragment,e),Fe=i(e),ae=w(e,"P",{"data-svelte-h":!0}),T(ae)!=="svelte-12jrw1i"&&(ae.innerHTML=_t),He=i(e),g(ne.$$.fragment,e),Ee=i(e),pe=w(e,"P",{"data-svelte-h":!0}),T(pe)!=="svelte-12bood2"&&(pe.textContent=xt),Qe=i(e),g(re.$$.fragment,e),Ye=i(e),oe=w(e,"P",{"data-svelte-h":!0}),T(oe)!=="svelte-j851qf"&&(oe.innerHTML=Ut),Ae=i(e),g(me.$$.fragment,e),Ne=i(e),g(ie.$$.fragment,e),Le=i(e),ce=w(e,"P",{"data-svelte-h":!0}),T(ce)!=="svelte-vkts6u"&&(ce.innerHTML=kt),qe=i(e),g(he.$$.fragment,e),Se=i(e),fe=w(e,"P",{"data-svelte-h":!0}),T(fe)!=="svelte-cu6vm0"&&(fe.innerHTML=Gt),Pe=i(e),g(de.$$.fragment,e),De=i(e),ue=w(e,"P",{"data-svelte-h":!0}),T(ue)!=="svelte-16uyepd"&&(ue.innerHTML=vt),Ke=i(e),ge=w(e,"P",{"data-svelte-h":!0}),T(ge)!=="svelte-1n68t0t"&&(ge.textContent=Ct),Oe=i(e),g(Me.$$.fragment,e),et=i(e),ye=w(e,"P",{"data-svelte-h":!0}),T(ye)!=="svelte-321xw1"&&(ye.innerHTML=It),tt=i(e),g($e.$$.fragment,e),st=i(e),be=w(e,"P",{"data-svelte-h":!0}),T(be)!=="svelte-lan0yv"&&(be.textContent=Zt),lt=i(e),je=w(e,"P",{"data-svelte-h":!0}),T(je)!=="svelte-1mquexd"&&(je.textContent=Rt),at=i(e),we=w(e,"UL",{"data-svelte-h":!0}),T(we)!=="svelte-hoxk8w"&&(we.innerHTML=Vt),nt=i(e),g(Te.$$.fragment,e),pt=i(e),Je=w(e,"P",{"data-svelte-h":!0}),T(Je)!=="svelte-51k2an"&&(Je.innerHTML=Wt),rt=i(e),g(_e.$$.fragment,e),ot=i(e),xe=w(e,"P",{"data-svelte-h":!0}),T(xe)!=="svelte-n2vyhz"&&(xe.innerHTML=Xt),mt=i(e),g(D.$$.fragment,e),it=i(e),g(Ue.$$.fragment,e),ct=i(e),g(K.$$.fragment,e),ht=i(e),g(O.$$.fragment,e),ft=i(e),g(ke.$$.fragment,e),dt=i(e),Ge=w(e,"P",{"data-svelte-h":!0}),T(Ge)!=="svelte-jox0kl"&&(Ge.textContent=Bt),ut=i(e),ve=w(e,"P",{"data-svelte-h":!0}),T(ve)!=="svelte-itb1wv"&&(ve.textContent=zt),gt=i(e),g(Ce.$$.fragment,e),Mt=i(e),Ie=w(e,"P",{"data-svelte-h":!0}),T(Ie)!=="svelte-3cxlyd"&&(Ie.innerHTML=Ft),yt=i(e),g(Ze.$$.fragment,e),$t=i(e),g(ee.$$.fragment,e),bt=i(e),We=w(e,"P",{}),Nt(We).forEach(s),this.h()},h(){Lt(t,"name","hf:doc:metadata"),Lt(t,"content",js)},m(e,n){ss(document.head,t),a(e,c,n),a(e,l,n),a(e,r,n),M(f,e,n),a(e,d,n),M(G,e,n),a(e,Z,n),a(e,v,n),a(e,C,n),M(X,e,n),a(e,R,n),a(e,_,n),a(e,p,n),a(e,J,n),a(e,E,n),a(e,z,n),a(e,L,n),M(B,e,n),a(e,Q,n),a(e,F,n),a(e,U,n),M(H,e,n),a(e,S,n),a(e,A,n),a(e,P,n),M(o,e,n),a(e,x,n),M(q,e,n),a(e,Be,n),a(e,se,n),a(e,ze,n),M(le,e,n),a(e,Fe,n),a(e,ae,n),a(e,He,n),M(ne,e,n),a(e,Ee,n),a(e,pe,n),a(e,Qe,n),M(re,e,n),a(e,Ye,n),a(e,oe,n),a(e,Ae,n),M(me,e,n),a(e,Ne,n),M(ie,e,n),a(e,Le,n),a(e,ce,n),a(e,qe,n),M(he,e,n),a(e,Se,n),a(e,fe,n),a(e,Pe,n),M(de,e,n),a(e,De,n),a(e,ue,n),a(e,Ke,n),a(e,ge,n),a(e,Oe,n),M(Me,e,n),a(e,et,n),a(e,ye,n),a(e,tt,n),M($e,e,n),a(e,st,n),a(e,be,n),a(e,lt,n),a(e,je,n),a(e,at,n),a(e,we,n),a(e,nt,n),M(Te,e,n),a(e,pt,n),a(e,Je,n),a(e,rt,n),M(_e,e,n),a(e,ot,n),a(e,xe,n),a(e,mt,n),M(D,e,n),a(e,it,n),M(Ue,e,n),a(e,ct,n),M(K,e,n),a(e,ht,n),M(O,e,n),a(e,ft,n),M(ke,e,n),a(e,dt,n),a(e,Ge,n),a(e,ut,n),a(e,ve,n),a(e,gt,n),M(Ce,e,n),a(e,Mt,n),a(e,Ie,n),a(e,yt,n),M(Ze,e,n),a(e,$t,n),M(ee,e,n),a(e,bt,n),a(e,We,n),jt=!0},p(e,[n]){const Ht={};n&2&&(Ht.$$scope={dirty:n,ctx:e}),B.$set(Ht);const Et={};n&2&&(Et.$$scope={dirty:n,ctx:e}),D.$set(Et);const Qt={};n&2&&(Qt.$$scope={dirty:n,ctx:e}),K.$set(Qt);const Yt={};n&2&&(Yt.$$scope={dirty:n,ctx:e}),O.$set(Yt);const At={};n&2&&(At.$$scope={dirty:n,ctx:e}),ee.$set(At)},i(e){jt||(y(f.$$.fragment,e),y(G.$$.fragment,e),y(X.$$.fragment,e),y(B.$$.fragment,e),y(H.$$.fragment,e),y(o.$$.fragment,e),y(q.$$.fragment,e),y(le.$$.fragment,e),y(ne.$$.fragment,e),y(re.$$.fragment,e),y(me.$$.fragment,e),y(ie.$$.fragment,e),y(he.$$.fragment,e),y(de.$$.fragment,e),y(Me.$$.fragment,e),y($e.$$.fragment,e),y(Te.$$.fragment,e),y(_e.$$.fragment,e),y(D.$$.fragment,e),y(Ue.$$.fragment,e),y(K.$$.fragment,e),y(O.$$.fragment,e),y(ke.$$.fragment,e),y(Ce.$$.fragment,e),y(Ze.$$.fragment,e),y(ee.$$.fragment,e),jt=!0)},o(e){$(f.$$.fragment,e),$(G.$$.fragment,e),$(X.$$.fragment,e),$(B.$$.fragment,e),$(H.$$.fragment,e),$(o.$$.fragment,e),$(q.$$.fragment,e),$(le.$$.fragment,e),$(ne.$$.fragment,e),$(re.$$.fragment,e),$(me.$$.fragment,e),$(ie.$$.fragment,e),$(he.$$.fragment,e),$(de.$$.fragment,e),$(Me.$$.fragment,e),$($e.$$.fragment,e),$(Te.$$.fragment,e),$(_e.$$.fragment,e),$(D.$$.fragment,e),$(Ue.$$.fragment,e),$(K.$$.fragment,e),$(O.$$.fragment,e),$(ke.$$.fragment,e),$(Ce.$$.fragment,e),$(Ze.$$.fragment,e),$(ee.$$.fragment,e),jt=!1},d(e){e&&(s(c),s(l),s(r),s(d),s(Z),s(v),s(C),s(R),s(_),s(p),s(J),s(E),s(z),s(L),s(Q),s(F),s(U),s(S),s(A),s(P),s(x),s(Be),s(se),s(ze),s(Fe),s(ae),s(He),s(Ee),s(pe),s(Qe),s(Ye),s(oe),s(Ae),s(Ne),s(Le),s(ce),s(qe),s(Se),s(fe),s(Pe),s(De),s(ue),s(Ke),s(ge),s(Oe),s(et),s(ye),s(tt),s(st),s(be),s(lt),s(je),s(at),s(we),s(nt),s(pt),s(Je),s(rt),s(ot),s(xe),s(mt),s(it),s(ct),s(ht),s(ft),s(dt),s(Ge),s(ut),s(ve),s(gt),s(Mt),s(Ie),s(yt),s($t),s(bt),s(We)),s(t),b(f,e),b(G,e),b(X,e),b(B,e),b(H,e),b(o,e),b(q,e),b(le,e),b(ne,e),b(re,e),b(me,e),b(ie,e),b(he,e),b(de,e),b(Me,e),b($e,e),b(Te,e),b(_e,e),b(D,e),b(Ue,e),b(K,e),b(O,e),b(ke,e),b(Ce,e),b(Ze,e),b(ee,e)}}}const js='{"title":"인과 언어 모델링","local":"causal-language-modeling","sections":[{"title":"ELI5 데이터 세트 불러오기","local":"load-eli5-dataset","sections":[],"depth":2},{"title":"전처리","local":"preprocess","sections":[],"depth":2},{"title":"훈련","local":"train","sections":[],"depth":2},{"title":"추론","local":"inference","sections":[],"depth":2}],"depth":1}';function ws(k){return Kt(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Cs extends Ot{constructor(t){super(),es(this,t,ws,bs,Dt,{})}}export{Cs as component};
