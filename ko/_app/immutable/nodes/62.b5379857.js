import{s as Nl,o as Al,n as ss}from"../chunks/scheduler.56730f09.js";import{S as Hl,i as El,g as T,s as M,r as g,A as zl,h as b,f as e,c as i,j as Yl,u as h,x as I,k as Jl,y as Sl,a as t,v as J,d as w,t as U,w as f,m as Ll,n as Dl}from"../chunks/index.1f144517.js";import{T as wl}from"../chunks/Tip.41e845e5.js";import{Y as ql}from"../chunks/Youtube.62e0f062.js";import{C as x}from"../chunks/CodeBlock.738eeccb.js";import{D as Kl}from"../chunks/DocNotebookDropdown.243c3df7.js";import{F as is,M as os}from"../chunks/Markdown.c541024b.js";import{H as xs}from"../chunks/Heading.57d46534.js";function Pl(W){let a,o,l='<a href="../model_doc/beit">BEiT</a>, <a href="../model_doc/data2vec-vision">Data2VecVision</a>, <a href="../model_doc/dpt">DPT</a>, <a href="../model_doc/mobilenet_v2">MobileNetV2</a>, <a href="../model_doc/mobilevit">MobileViT</a>, <a href="../model_doc/mobilevitv2">MobileViTV2</a>, <a href="../model_doc/segformer">SegFormer</a>, <a href="../model_doc/upernet">UPerNet</a>';return{c(){a=Ll(`이 튜토리얼에서 설명하는 작업은 다음 모델 아키텍처에서 지원됩니다:

`),o=T("p"),o.innerHTML=l},l(c){a=Dl(c,`이 튜토리얼에서 설명하는 작업은 다음 모델 아키텍처에서 지원됩니다:

`),o=b(c,"P",{"data-svelte-h":!0}),I(o)!=="svelte-19l83ao"&&(o.innerHTML=l)},m(c,y){t(c,a,y),t(c,o,y)},p:ss,d(c){c&&(e(a),e(o))}}}function Ol(W){let a,o='이미지 데이터 세트에 데이터 증강을 적용하여 과적합에 대해 모델을 보다 강건하게 만드는 것이 일반적입니다. 이 가이드에서는 <a href="https://pytorch.org/vision/stable/index.html" rel="nofollow">torchvision</a>의 <a href="https://pytorch.org/vision/stable/generated/torchvision.transforms.ColorJitter.html" rel="nofollow"><code>ColorJitter</code></a>를 사용하여 이미지의 색상 속성을 임의로 변경합니다. 하지만, 자신이 원하는 이미지 라이브러리를 사용할 수도 있습니다.',l,c,y,$,R="이제 모델에 사용할 이미지와 주석을 준비하기 위해 두 개의 전처리 함수를 만듭니다. 이 함수들은 이미지를 <code>pixel_values</code>로, 주석을 <code>labels</code>로 변환합니다. 훈련 세트의 경우 이미지 프로세서에 이미지를 제공하기 전에 <code>jitter</code>를 적용합니다. 테스트 세트의 경우 이미지 프로세서는 <code>images</code>를 자르고 정규화하며, 테스트 중에는 데이터 증강이 적용되지 않으므로 <code>labels</code>만 자릅니다.",B,_,Z,C,Q="모든 데이터 세트에 <code>jitter</code>를 적용하려면, 🤗 Datasets <code>set_transform</code> 함수를 사용하세요. 즉시 변환이 적용되기 때문에 더 빠르고 디스크 공간을 덜 차지합니다:",v,d,V;return c=new x({props:{code:"ZnJvbSUyMHRvcmNodmlzaW9uLnRyYW5zZm9ybXMlMjBpbXBvcnQlMjBDb2xvckppdHRlciUwQSUwQWppdHRlciUyMCUzRCUyMENvbG9ySml0dGVyKGJyaWdodG5lc3MlM0QwLjI1JTJDJTIwY29udHJhc3QlM0QwLjI1JTJDJTIwc2F0dXJhdGlvbiUzRDAuMjUlMkMlMjBodWUlM0QwLjEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ColorJitter

<span class="hljs-meta">&gt;&gt;&gt; </span>jitter = ColorJitter(brightness=<span class="hljs-number">0.25</span>, contrast=<span class="hljs-number">0.25</span>, saturation=<span class="hljs-number">0.25</span>, hue=<span class="hljs-number">0.1</span>)`,wrap:!1}}),_=new x({props:{code:"ZGVmJTIwdHJhaW5fdHJhbnNmb3JtcyhleGFtcGxlX2JhdGNoKSUzQSUwQSUyMCUyMCUyMCUyMGltYWdlcyUyMCUzRCUyMCU1QmppdHRlcih4KSUyMGZvciUyMHglMjBpbiUyMGV4YW1wbGVfYmF0Y2glNUIlMjJpbWFnZSUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGxhYmVscyUyMCUzRCUyMCU1QnglMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlX2JhdGNoJTVCJTIyYW5ub3RhdGlvbiUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGlucHV0cyUyMCUzRCUyMGltYWdlX3Byb2Nlc3NvcihpbWFnZXMlMkMlMjBsYWJlbHMpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW5wdXRzJTBBJTBBJTBBZGVmJTIwdmFsX3RyYW5zZm9ybXMoZXhhbXBsZV9iYXRjaCklM0ElMEElMjAlMjAlMjAlMjBpbWFnZXMlMjAlM0QlMjAlNUJ4JTIwZm9yJTIweCUyMGluJTIwZXhhbXBsZV9iYXRjaCU1QiUyMmltYWdlJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwbGFiZWxzJTIwJTNEJTIwJTVCeCUyMGZvciUyMHglMjBpbiUyMGV4YW1wbGVfYmF0Y2glNUIlMjJhbm5vdGF0aW9uJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwaW5wdXRzJTIwJTNEJTIwaW1hZ2VfcHJvY2Vzc29yKGltYWdlcyUyQyUyMGxhYmVscyklMEElMjAlMjAlMjAlMjByZXR1cm4lMjBpbnB1dHM=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_transforms</span>(<span class="hljs-params">example_batch</span>):
<span class="hljs-meta">... </span>    images = [jitter(x) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    labels = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;annotation&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = image_processor(images, labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">val_transforms</span>(<span class="hljs-params">example_batch</span>):
<span class="hljs-meta">... </span>    images = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    labels = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;annotation&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = image_processor(images, labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`,wrap:!1}}),d=new x({props:{code:"dHJhaW5fZHMuc2V0X3RyYW5zZm9ybSh0cmFpbl90cmFuc2Zvcm1zKSUwQXRlc3RfZHMuc2V0X3RyYW5zZm9ybSh2YWxfdHJhbnNmb3Jtcyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>train_ds.set_transform(train_transforms)
<span class="hljs-meta">&gt;&gt;&gt; </span>test_ds.set_transform(val_transforms)`,wrap:!1}}),{c(){a=T("p"),a.innerHTML=o,l=M(),g(c.$$.fragment),y=M(),$=T("p"),$.innerHTML=R,B=M(),g(_.$$.fragment),Z=M(),C=T("p"),C.innerHTML=Q,v=M(),g(d.$$.fragment)},l(m){a=b(m,"P",{"data-svelte-h":!0}),I(a)!=="svelte-wfjux"&&(a.innerHTML=o),l=i(m),h(c.$$.fragment,m),y=i(m),$=b(m,"P",{"data-svelte-h":!0}),I($)!=="svelte-nni9bw"&&($.innerHTML=R),B=i(m),h(_.$$.fragment,m),Z=i(m),C=b(m,"P",{"data-svelte-h":!0}),I(C)!=="svelte-co6957"&&(C.innerHTML=Q),v=i(m),h(d.$$.fragment,m)},m(m,u){t(m,a,u),t(m,l,u),J(c,m,u),t(m,y,u),t(m,$,u),t(m,B,u),J(_,m,u),t(m,Z,u),t(m,C,u),t(m,v,u),J(d,m,u),V=!0},p:ss,i(m){V||(w(c.$$.fragment,m),w(_.$$.fragment,m),w(d.$$.fragment,m),V=!0)},o(m){U(c.$$.fragment,m),U(_.$$.fragment,m),U(d.$$.fragment,m),V=!1},d(m){m&&(e(a),e(l),e(y),e($),e(B),e(Z),e(C),e(v)),f(c,m),f(_,m),f(d,m)}}}function sa(W){let a,o;return a=new os({props:{$$slots:{default:[Ol]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function la(W){let a,o='이미지 데이터 세트에 데이터 증강을 적용하여 과적합에 대해 모델을 보다 강건하게 만드는 것이 일반적입니다. 이 가이드에서는 <a href="https://www.tensorflow.org/api_docs/python/tf/image" rel="nofollow"><code>tf.image</code></a>를 사용하여 이미지의 색상 속성을 임의로 변경합니다. 하지만, 자신이 원하는 이미지 라이브러리를 사용할 수도 있습니다.',l,c,y="별개의 두 변환 함수를 정의합니다:",$,R,B="<li>이미지 증강을 포함하는 학습 데이터 변환</li> <li>🤗 Transformers의 컴퓨터 비전 모델은 채널 우선 레이아웃을 기대하기 때문에, 이미지만 바꾸는 검증 데이터 변환</li>",_,Z,C,Q,v="그런 다음 모델을 위해 두 개의 전처리 함수를 만들어 이미지 및 주석 배치를 준비합니다. 이 함수들은 이미지 변환을 적용하고 이전에 로드한 <code>image_processor</code>를 사용하여 이미지를 <code>pixel_values</code>로, 주석을 <code>label</code>로 변환합니다. <code>ImageProcessor</code> 는 이미지의 크기 조정과 정규화도 처리합니다.",d,V,m,u,Y=`전체 데이터 집합에 전처리 변환을 적용하려면 🤗 Datasets <code>set_transform</code> 함수를 사용하세요.
즉시 변환이 적용되기 때문에 더 빠르고 디스크 공간을 덜 차지합니다:`,G,F,p;return Z=new x({props:{code:"aW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEElMEElMEFkZWYlMjBhdWdfdHJhbnNmb3JtcyhpbWFnZSklM0ElMEElMjAlMjAlMjAlMjBpbWFnZSUyMCUzRCUyMHRmLmtlcmFzLnV0aWxzLmltZ190b19hcnJheShpbWFnZSklMEElMjAlMjAlMjAlMjBpbWFnZSUyMCUzRCUyMHRmLmltYWdlLnJhbmRvbV9icmlnaHRuZXNzKGltYWdlJTJDJTIwMC4yNSklMEElMjAlMjAlMjAlMjBpbWFnZSUyMCUzRCUyMHRmLmltYWdlLnJhbmRvbV9jb250cmFzdChpbWFnZSUyQyUyMDAuNSUyQyUyMDIuMCklMEElMjAlMjAlMjAlMjBpbWFnZSUyMCUzRCUyMHRmLmltYWdlLnJhbmRvbV9zYXR1cmF0aW9uKGltYWdlJTJDJTIwMC43NSUyQyUyMDEuMjUpJTBBJTIwJTIwJTIwJTIwaW1hZ2UlMjAlM0QlMjB0Zi5pbWFnZS5yYW5kb21faHVlKGltYWdlJTJDJTIwMC4xKSUwQSUyMCUyMCUyMCUyMGltYWdlJTIwJTNEJTIwdGYudHJhbnNwb3NlKGltYWdlJTJDJTIwKDIlMkMlMjAwJTJDJTIwMSkpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW1hZ2UlMEElMEElMEFkZWYlMjB0cmFuc2Zvcm1zKGltYWdlKSUzQSUwQSUyMCUyMCUyMCUyMGltYWdlJTIwJTNEJTIwdGYua2VyYXMudXRpbHMuaW1nX3RvX2FycmF5KGltYWdlKSUwQSUyMCUyMCUyMCUyMGltYWdlJTIwJTNEJTIwdGYudHJhbnNwb3NlKGltYWdlJTJDJTIwKDIlMkMlMjAwJTJDJTIwMSkpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW1hZ2U=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">aug_transforms</span>(<span class="hljs-params">image</span>):
<span class="hljs-meta">... </span>    image = tf.keras.utils.img_to_array(image)
<span class="hljs-meta">... </span>    image = tf.image.random_brightness(image, <span class="hljs-number">0.25</span>)
<span class="hljs-meta">... </span>    image = tf.image.random_contrast(image, <span class="hljs-number">0.5</span>, <span class="hljs-number">2.0</span>)
<span class="hljs-meta">... </span>    image = tf.image.random_saturation(image, <span class="hljs-number">0.75</span>, <span class="hljs-number">1.25</span>)
<span class="hljs-meta">... </span>    image = tf.image.random_hue(image, <span class="hljs-number">0.1</span>)
<span class="hljs-meta">... </span>    image = tf.transpose(image, (<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> image


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">image</span>):
<span class="hljs-meta">... </span>    image = tf.keras.utils.img_to_array(image)
<span class="hljs-meta">... </span>    image = tf.transpose(image, (<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> image`,wrap:!1}}),V=new x({props:{code:"ZGVmJTIwdHJhaW5fdHJhbnNmb3JtcyhleGFtcGxlX2JhdGNoKSUzQSUwQSUyMCUyMCUyMCUyMGltYWdlcyUyMCUzRCUyMCU1QmF1Z190cmFuc2Zvcm1zKHguY29udmVydCglMjJSR0IlMjIpKSUyMGZvciUyMHglMjBpbiUyMGV4YW1wbGVfYmF0Y2glNUIlMjJpbWFnZSUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGxhYmVscyUyMCUzRCUyMCU1QnglMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlX2JhdGNoJTVCJTIyYW5ub3RhdGlvbiUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGlucHV0cyUyMCUzRCUyMGltYWdlX3Byb2Nlc3NvcihpbWFnZXMlMkMlMjBsYWJlbHMpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW5wdXRzJTBBJTBBJTBBZGVmJTIwdmFsX3RyYW5zZm9ybXMoZXhhbXBsZV9iYXRjaCklM0ElMEElMjAlMjAlMjAlMjBpbWFnZXMlMjAlM0QlMjAlNUJ0cmFuc2Zvcm1zKHguY29udmVydCglMjJSR0IlMjIpKSUyMGZvciUyMHglMjBpbiUyMGV4YW1wbGVfYmF0Y2glNUIlMjJpbWFnZSUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGxhYmVscyUyMCUzRCUyMCU1QnglMjBmb3IlMjB4JTIwaW4lMjBleGFtcGxlX2JhdGNoJTVCJTIyYW5ub3RhdGlvbiUyMiU1RCU1RCUwQSUyMCUyMCUyMCUyMGlucHV0cyUyMCUzRCUyMGltYWdlX3Byb2Nlc3NvcihpbWFnZXMlMkMlMjBsYWJlbHMpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwaW5wdXRz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_transforms</span>(<span class="hljs-params">example_batch</span>):
<span class="hljs-meta">... </span>    images = [aug_transforms(x.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    labels = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;annotation&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = image_processor(images, labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">val_transforms</span>(<span class="hljs-params">example_batch</span>):
<span class="hljs-meta">... </span>    images = [transforms(x.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    labels = [x <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;annotation&quot;</span>]]
<span class="hljs-meta">... </span>    inputs = image_processor(images, labels)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> inputs`,wrap:!1}}),F=new x({props:{code:"dHJhaW5fZHMuc2V0X3RyYW5zZm9ybSh0cmFpbl90cmFuc2Zvcm1zKSUwQXRlc3RfZHMuc2V0X3RyYW5zZm9ybSh2YWxfdHJhbnNmb3Jtcyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>train_ds.set_transform(train_transforms)
<span class="hljs-meta">&gt;&gt;&gt; </span>test_ds.set_transform(val_transforms)`,wrap:!1}}),{c(){a=T("p"),a.innerHTML=o,l=M(),c=T("p"),c.textContent=y,$=M(),R=T("ul"),R.innerHTML=B,_=M(),g(Z.$$.fragment),C=M(),Q=T("p"),Q.innerHTML=v,d=M(),g(V.$$.fragment),m=M(),u=T("p"),u.innerHTML=Y,G=M(),g(F.$$.fragment)},l(r){a=b(r,"P",{"data-svelte-h":!0}),I(a)!=="svelte-r0uin4"&&(a.innerHTML=o),l=i(r),c=b(r,"P",{"data-svelte-h":!0}),I(c)!=="svelte-163wstu"&&(c.textContent=y),$=i(r),R=b(r,"UL",{"data-svelte-h":!0}),I(R)!=="svelte-5sercd"&&(R.innerHTML=B),_=i(r),h(Z.$$.fragment,r),C=i(r),Q=b(r,"P",{"data-svelte-h":!0}),I(Q)!=="svelte-1p58cmv"&&(Q.innerHTML=v),d=i(r),h(V.$$.fragment,r),m=i(r),u=b(r,"P",{"data-svelte-h":!0}),I(u)!=="svelte-1trxcly"&&(u.innerHTML=Y),G=i(r),h(F.$$.fragment,r)},m(r,X){t(r,a,X),t(r,l,X),t(r,c,X),t(r,$,X),t(r,R,X),t(r,_,X),J(Z,r,X),t(r,C,X),t(r,Q,X),t(r,d,X),J(V,r,X),t(r,m,X),t(r,u,X),t(r,G,X),J(F,r,X),p=!0},p:ss,i(r){p||(w(Z.$$.fragment,r),w(V.$$.fragment,r),w(F.$$.fragment,r),p=!0)},o(r){U(Z.$$.fragment,r),U(V.$$.fragment,r),U(F.$$.fragment,r),p=!1},d(r){r&&(e(a),e(l),e(c),e($),e(R),e(_),e(C),e(Q),e(d),e(m),e(u),e(G)),f(Z,r),f(V,r),f(F,r)}}}function aa(W){let a,o;return a=new os({props:{$$slots:{default:[la]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function ea(W){let a,o;return a=new x({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBaW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdG9yY2glMjBpbXBvcnQlMjBubiUwQSUwQWRlZiUyMGNvbXB1dGVfbWV0cmljcyhldmFsX3ByZWQpJTNBJTBBJTIwJTIwJTIwJTIwd2l0aCUyMHRvcmNoLm5vX2dyYWQoKSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxvZ2l0cyUyQyUyMGxhYmVscyUyMCUzRCUyMGV2YWxfcHJlZCUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxvZ2l0c190ZW5zb3IlMjAlM0QlMjB0b3JjaC5mcm9tX251bXB5KGxvZ2l0cyklMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsb2dpdHNfdGVuc29yJTIwJTNEJTIwbm4uZnVuY3Rpb25hbC5pbnRlcnBvbGF0ZSglMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsb2dpdHNfdGVuc29yJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwc2l6ZSUzRGxhYmVscy5zaGFwZSU1Qi0yJTNBJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbW9kZSUzRCUyMmJpbGluZWFyJTIyJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwYWxpZ25fY29ybmVycyUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwKS5hcmdtYXgoZGltJTNEMSklMEElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBwcmVkX2xhYmVscyUyMCUzRCUyMGxvZ2l0c190ZW5zb3IuZGV0YWNoKCkuY3B1KCkubnVtcHkoKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG1ldHJpY3MlMjAlM0QlMjBtZXRyaWMuY29tcHV0ZSglMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBwcmVkaWN0aW9ucyUzRHByZWRfbGFiZWxzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcmVmZXJlbmNlcyUzRGxhYmVscyUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG51bV9sYWJlbHMlM0RudW1fbGFiZWxzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwaWdub3JlX2luZGV4JTNEMjU1JTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwcmVkdWNlX2xhYmVscyUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGZvciUyMGtleSUyQyUyMHZhbHVlJTIwaW4lMjBtZXRyaWNzLml0ZW1zKCklM0ElMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBpZiUyMGlzaW5zdGFuY2UodmFsdWUlMkMlMjBucC5uZGFycmF5KSUzQSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMG1ldHJpY3MlNUJrZXklNUQlMjAlM0QlMjB2YWx1ZS50b2xpc3QoKSUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHJldHVybiUyMG1ldHJpY3M=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    <span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>        logits, labels = eval_pred
<span class="hljs-meta">... </span>        logits_tensor = torch.from_numpy(logits)
<span class="hljs-meta">... </span>        logits_tensor = nn.functional.interpolate(
<span class="hljs-meta">... </span>            logits_tensor,
<span class="hljs-meta">... </span>            size=labels.shape[-<span class="hljs-number">2</span>:],
<span class="hljs-meta">... </span>            mode=<span class="hljs-string">&quot;bilinear&quot;</span>,
<span class="hljs-meta">... </span>            align_corners=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>        ).argmax(dim=<span class="hljs-number">1</span>)

<span class="hljs-meta">... </span>        pred_labels = logits_tensor.detach().cpu().numpy()
<span class="hljs-meta">... </span>        metrics = metric.compute(
<span class="hljs-meta">... </span>            predictions=pred_labels,
<span class="hljs-meta">... </span>            references=labels,
<span class="hljs-meta">... </span>            num_labels=num_labels,
<span class="hljs-meta">... </span>            ignore_index=<span class="hljs-number">255</span>,
<span class="hljs-meta">... </span>            reduce_labels=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>        )
<span class="hljs-meta">... </span>        <span class="hljs-keyword">for</span> key, value <span class="hljs-keyword">in</span> metrics.items():
<span class="hljs-meta">... </span>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(value, np.ndarray):
<span class="hljs-meta">... </span>                metrics[key] = value.tolist()
<span class="hljs-meta">... </span>        <span class="hljs-keyword">return</span> metrics`,wrap:!1}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p:ss,i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function ta(W){let a,o;return a=new os({props:{$$slots:{default:[ea]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function na(W){let a,o;return a=new x({props:{code:"ZGVmJTIwY29tcHV0ZV9tZXRyaWNzKGV2YWxfcHJlZCklM0ElMEElMjAlMjAlMjAlMjBsb2dpdHMlMkMlMjBsYWJlbHMlMjAlM0QlMjBldmFsX3ByZWQlMEElMjAlMjAlMjAlMjBsb2dpdHMlMjAlM0QlMjB0Zi50cmFuc3Bvc2UobG9naXRzJTJDJTIwcGVybSUzRCU1QjAlMkMlMjAyJTJDJTIwMyUyQyUyMDElNUQpJTBBJTIwJTIwJTIwJTIwbG9naXRzX3Jlc2l6ZWQlMjAlM0QlMjB0Zi5pbWFnZS5yZXNpemUoJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbG9naXRzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwc2l6ZSUzRHRmLnNoYXBlKGxhYmVscyklNUIxJTNBJTVEJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbWV0aG9kJTNEJTIyYmlsaW5lYXIlMjIlMkMlMEElMjAlMjAlMjAlMjApJTBBJTBBJTIwJTIwJTIwJTIwcHJlZF9sYWJlbHMlMjAlM0QlMjB0Zi5hcmdtYXgobG9naXRzX3Jlc2l6ZWQlMkMlMjBheGlzJTNELTEpJTBBJTIwJTIwJTIwJTIwbWV0cmljcyUyMCUzRCUyMG1ldHJpYy5jb21wdXRlKCUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHByZWRpY3Rpb25zJTNEcHJlZF9sYWJlbHMlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjByZWZlcmVuY2VzJTNEbGFiZWxzJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbnVtX2xhYmVscyUzRG51bV9sYWJlbHMlMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBpZ25vcmVfaW5kZXglM0QtMSUyQyUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMHJlZHVjZV9sYWJlbHMlM0RpbWFnZV9wcm9jZXNzb3IuZG9fcmVkdWNlX2xhYmVscyUyQyUwQSUyMCUyMCUyMCUyMCklMEElMEElMjAlMjAlMjAlMjBwZXJfY2F0ZWdvcnlfYWNjdXJhY3klMjAlM0QlMjBtZXRyaWNzLnBvcCglMjJwZXJfY2F0ZWdvcnlfYWNjdXJhY3klMjIpLnRvbGlzdCgpJTBBJTIwJTIwJTIwJTIwcGVyX2NhdGVnb3J5X2lvdSUyMCUzRCUyMG1ldHJpY3MucG9wKCUyMnBlcl9jYXRlZ29yeV9pb3UlMjIpLnRvbGlzdCgpJTBBJTBBJTIwJTIwJTIwJTIwbWV0cmljcy51cGRhdGUoJTdCZiUyMmFjY3VyYWN5XyU3QmlkMmxhYmVsJTVCaSU1RCU3RCUyMiUzQSUyMHYlMjBmb3IlMjBpJTJDJTIwdiUyMGluJTIwZW51bWVyYXRlKHBlcl9jYXRlZ29yeV9hY2N1cmFjeSklN0QpJTBBJTIwJTIwJTIwJTIwbWV0cmljcy51cGRhdGUoJTdCZiUyMmlvdV8lN0JpZDJsYWJlbCU1QmklNUQlN0QlMjIlM0ElMjB2JTIwZm9yJTIwaSUyQyUyMHYlMjBpbiUyMGVudW1lcmF0ZShwZXJfY2F0ZWdvcnlfaW91KSU3RCklMEElMjAlMjAlMjAlMjByZXR1cm4lMjAlN0IlMjJ2YWxfJTIyJTIwJTJCJTIwayUzQSUyMHYlMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwbWV0cmljcy5pdGVtcygpJTdE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    logits, labels = eval_pred
<span class="hljs-meta">... </span>    logits = tf.transpose(logits, perm=[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>])
<span class="hljs-meta">... </span>    logits_resized = tf.image.resize(
<span class="hljs-meta">... </span>        logits,
<span class="hljs-meta">... </span>        size=tf.shape(labels)[<span class="hljs-number">1</span>:],
<span class="hljs-meta">... </span>        method=<span class="hljs-string">&quot;bilinear&quot;</span>,
<span class="hljs-meta">... </span>    )

<span class="hljs-meta">... </span>    pred_labels = tf.argmax(logits_resized, axis=-<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    metrics = metric.compute(
<span class="hljs-meta">... </span>        predictions=pred_labels,
<span class="hljs-meta">... </span>        references=labels,
<span class="hljs-meta">... </span>        num_labels=num_labels,
<span class="hljs-meta">... </span>        ignore_index=-<span class="hljs-number">1</span>,
<span class="hljs-meta">... </span>        reduce_labels=image_processor.do_reduce_labels,
<span class="hljs-meta">... </span>    )

<span class="hljs-meta">... </span>    per_category_accuracy = metrics.pop(<span class="hljs-string">&quot;per_category_accuracy&quot;</span>).tolist()
<span class="hljs-meta">... </span>    per_category_iou = metrics.pop(<span class="hljs-string">&quot;per_category_iou&quot;</span>).tolist()

<span class="hljs-meta">... </span>    metrics.update({<span class="hljs-string">f&quot;accuracy_<span class="hljs-subst">{id2label[i]}</span>&quot;</span>: v <span class="hljs-keyword">for</span> i, v <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(per_category_accuracy)})
<span class="hljs-meta">... </span>    metrics.update({<span class="hljs-string">f&quot;iou_<span class="hljs-subst">{id2label[i]}</span>&quot;</span>: v <span class="hljs-keyword">for</span> i, v <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(per_category_iou)})
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> {<span class="hljs-string">&quot;val_&quot;</span> + k: v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> metrics.items()}`,wrap:!1}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p:ss,i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function pa(W){let a,o;return a=new os({props:{$$slots:{default:[na]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function ma(W){let a,o='만약 <code>Trainer</code>를 사용해 모델을 미세 조정하는 것에 익숙하지 않다면, <a href="../training#finetune-with-trainer">여기</a>에서 기본 튜토리얼을 살펴보세요!';return{c(){a=T("p"),a.innerHTML=o},l(l){a=b(l,"P",{"data-svelte-h":!0}),I(a)!=="svelte-3emgbb"&&(a.innerHTML=o)},m(l,c){t(l,a,c)},p:ss,d(l){l&&e(a)}}}function ca(W){let a,o,l,c="이제 모델 학습을 시작할 준비가 되었습니다! <code>AutoModelForSemanticSegmentation</code>로 SegFormer를 불러오고, 모델에 레이블 ID와 레이블 클래스 간의 매핑을 전달합니다:",y,$,R,B,_="이제 세 단계만 남았습니다:",Z,C,Q="<li>학습 하이퍼파라미터를 <code>TrainingArguments</code>에 정의합니다. <code>image</code> 열이 삭제되기 때문에 사용하지 않는 열을 제거하지 않는 것이 중요합니다. <code>image</code> 열이 없으면 <code>pixel_values</code>을 생성할 수 없습니다. 이런 경우를 방지하려면 <code>remove_unused_columns=False</code>로 설정하세요! 유일하게 필요한 다른 매개변수는 모델을 저장할 위치를 지정하는 <code>output_dir</code>입니다. <code>push_to_hub=True</code>를 설정하여 이 모델을 Hub에 푸시합니다(모델을 업로드하려면 Hugging Face에 로그인해야 합니다). 각 에포크가 끝날 때마다 <code>Trainer</code>가 IoU 메트릭을 평가하고 학습 체크포인트를 저장합니다.</li> <li>모델, 데이터 세트, 토크나이저, 데이터 콜레이터, <code>compute_metrics</code> 함수와 함께 학습 인자를 <code>Trainer</code>에 전달하세요.</li> <li>모델을 미세 조정하기 위해 <code>train()</code>를 호출하세요.</li>",v,d,V,m,u="학습이 완료되면, 누구나 모델을 사용할 수 있도록 <code>push_to_hub()</code> 메서드를 사용해 Hub에 모델을 공유하세요:",Y,G,F;return a=new wl({props:{$$slots:{default:[ma]},$$scope:{ctx:W}}}),$=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvclNlbWFudGljU2VnbWVudGF0aW9uJTJDJTIwVHJhaW5pbmdBcmd1bWVudHMlMkMlMjBUcmFpbmVyJTBBJTBBbW9kZWwlMjAlM0QlMjBBdXRvTW9kZWxGb3JTZW1hbnRpY1NlZ21lbnRhdGlvbi5mcm9tX3ByZXRyYWluZWQoY2hlY2twb2ludCUyQyUyMGlkMmxhYmVsJTNEaWQybGFiZWwlMkMlMjBsYWJlbDJpZCUzRGxhYmVsMmlkKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSemanticSegmentation, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSemanticSegmentation.from_pretrained(checkpoint, id2label=id2label, label2id=label2id)`,wrap:!1}}),d=new x({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJzZWdmb3JtZXItYjAtc2NlbmUtcGFyc2UtMTUwJTIyJTJDJTBBJTIwJTIwJTIwJTIwbGVhcm5pbmdfcmF0ZSUzRDZlLTUlMkMlMEElMjAlMjAlMjAlMjBudW1fdHJhaW5fZXBvY2hzJTNENTAlMkMlMEElMjAlMjAlMjAlMjBwZXJfZGV2aWNlX3RyYWluX2JhdGNoX3NpemUlM0QyJTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0QyJTJDJTBBJTIwJTIwJTIwJTIwc2F2ZV90b3RhbF9saW1pdCUzRDMlMkMlMEElMjAlMjAlMjAlMjBldmFsdWF0aW9uX3N0cmF0ZWd5JTNEJTIyc3RlcHMlMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIyc3RlcHMlMjIlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0ZXBzJTNEMjAlMkMlMEElMjAlMjAlMjAlMjBldmFsX3N0ZXBzJTNEMjAlMkMlMEElMjAlMjAlMjAlMjBsb2dnaW5nX3N0ZXBzJTNEMSUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfYWNjdW11bGF0aW9uX3N0ZXBzJTNENSUyQyUwQSUyMCUyMCUyMCUyMHJlbW92ZV91bnVzZWRfY29sdW1ucyUzREZhbHNlJTJDJTBBJTIwJTIwJTIwJTIwcHVzaF90b19odWIlM0RUcnVlJTJDJTBBKSUwQSUwQXRyYWluZXIlMjAlM0QlMjBUcmFpbmVyKCUwQSUyMCUyMCUyMCUyMG1vZGVsJTNEbW9kZWwlMkMlMEElMjAlMjAlMjAlMjBhcmdzJTNEdHJhaW5pbmdfYXJncyUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0R0cmFpbl9kcyUyQyUwQSUyMCUyMCUyMCUyMGV2YWxfZGF0YXNldCUzRHRlc3RfZHMlMkMlMEElMjAlMjAlMjAlMjBjb21wdXRlX21ldHJpY3MlM0Rjb21wdXRlX21ldHJpY3MlMkMlMEEpJTBBJTBBdHJhaW5lci50cmFpbigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;segformer-b0-scene-parse-150&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">6e-5</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">50</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">2</span>,
<span class="hljs-meta">... </span>    save_total_limit=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;steps&quot;</span>,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;steps&quot;</span>,
<span class="hljs-meta">... </span>    save_steps=<span class="hljs-number">20</span>,
<span class="hljs-meta">... </span>    eval_steps=<span class="hljs-number">20</span>,
<span class="hljs-meta">... </span>    logging_steps=<span class="hljs-number">1</span>,
<span class="hljs-meta">... </span>    eval_accumulation_steps=<span class="hljs-number">5</span>,
<span class="hljs-meta">... </span>    remove_unused_columns=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    train_dataset=train_ds,
<span class="hljs-meta">... </span>    eval_dataset=test_ds,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),G=new x({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){g(a.$$.fragment),o=M(),l=T("p"),l.innerHTML=c,y=M(),g($.$$.fragment),R=M(),B=T("p"),B.textContent=_,Z=M(),C=T("ol"),C.innerHTML=Q,v=M(),g(d.$$.fragment),V=M(),m=T("p"),m.innerHTML=u,Y=M(),g(G.$$.fragment)},l(p){h(a.$$.fragment,p),o=i(p),l=b(p,"P",{"data-svelte-h":!0}),I(l)!=="svelte-1j8jvu6"&&(l.innerHTML=c),y=i(p),h($.$$.fragment,p),R=i(p),B=b(p,"P",{"data-svelte-h":!0}),I(B)!=="svelte-1vwg7jz"&&(B.textContent=_),Z=i(p),C=b(p,"OL",{"data-svelte-h":!0}),I(C)!=="svelte-ds64a5"&&(C.innerHTML=Q),v=i(p),h(d.$$.fragment,p),V=i(p),m=b(p,"P",{"data-svelte-h":!0}),I(m)!=="svelte-sq2z1z"&&(m.innerHTML=u),Y=i(p),h(G.$$.fragment,p)},m(p,r){J(a,p,r),t(p,o,r),t(p,l,r),t(p,y,r),J($,p,r),t(p,R,r),t(p,B,r),t(p,Z,r),t(p,C,r),t(p,v,r),J(d,p,r),t(p,V,r),t(p,m,r),t(p,Y,r),J(G,p,r),F=!0},p(p,r){const X={};r&2&&(X.$$scope={dirty:r,ctx:p}),a.$set(X)},i(p){F||(w(a.$$.fragment,p),w($.$$.fragment,p),w(d.$$.fragment,p),w(G.$$.fragment,p),F=!0)},o(p){U(a.$$.fragment,p),U($.$$.fragment,p),U(d.$$.fragment,p),U(G.$$.fragment,p),F=!1},d(p){p&&(e(o),e(l),e(y),e(R),e(B),e(Z),e(C),e(v),e(V),e(m),e(Y)),f(a,p),f($,p),f(d,p),f(G,p)}}}function ra(W){let a,o;return a=new os({props:{$$slots:{default:[ca]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function Ma(W){let a,o='Keras로 모델을 미세 조정하는 데 익숙하지 않은 경우, 먼저 <a href="../training#train-a-tensorflow-model-with-keras">기본 튜토리얼</a>을 확인해보세요!';return{c(){a=T("p"),a.innerHTML=o},l(l){a=b(l,"P",{"data-svelte-h":!0}),I(a)!=="svelte-u4hk9"&&(a.innerHTML=o)},m(l,c){t(l,a,c)},p:ss,d(l){l&&e(a)}}}function ia(W){let a,o,l,c="TensorFlow에서 모델을 미세 조정하려면 다음 단계를 따르세요:",y,$,R="<li>학습 하이퍼파라미터를 정의하고 옵티마이저와 학습률 스케쥴러를 설정하세요.</li> <li>사전 학습된 모델을 인스턴스화하세요.</li> <li>🤗 Dataset을 <code>tf.data.Dataset</code>로 변환하세요.</li> <li>모델을 컴파일하세요.</li> <li>콜백을 추가하여 메트릭을 계산하고 🤗 Hub에 모델을 업로드하세요.</li> <li><code>fit()</code> 메서드를 사용하여 훈련을 실행하세요.</li>",B,_,Z="하이퍼파라미터, 옵티마이저, 학습률 스케쥴러를 정의하는 것으로 시작하세요:",C,Q,v,d,V="그런 다음 레이블 매핑과 함께 <code>TFAutoModelForSemanticSegmentation</code>을 사용하여 SegFormer를 불러오고 옵티마이저로 컴파일합니다. 트랜스포머 모델은 모두 디폴트로 태스크 관련 손실 함수가 있으므로 원치 않으면 지정할 필요가 없습니다:",m,u,Y,G,F="<code>to_tf_dataset</code> 와 <code>DefaultDataCollator</code>를 사용해 데이터 세트를 <code>tf.data.Dataset</code> 포맷으로 변환하세요:",p,r,X,E,S='예측으로 정확도를 계산하고 모델을 🤗 Hub로 푸시하려면 <a href="../main_classes/keras_callbacks">Keras callbacks</a>를 사용하세요. <code>compute_metrics</code> 함수를 <code>KerasMetricCallback</code>에 전달하고, 모델 업로드를 위해 <code>PushToHubCallback</code>를 사용하세요:',q,N,js,z,L="이제 모델을 훈련할 준비가 되었습니다! 훈련 및 검증 데이터 세트, 에포크 수와 함께 <code>fit()</code>을 호출하고, 콜백을 사용하여 모델을 미세 조정합니다:",K,A,P,H,Rs="축하합니다! 모델을 미세 조정하고 🤗 Hub에 공유했습니다. 이제 추론에 사용할 수 있습니다!",O;return a=new wl({props:{$$slots:{default:[Ma]},$$scope:{ctx:W}}}),Q=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMEElMEFiYXRjaF9zaXplJTIwJTNEJTIwMiUwQW51bV9lcG9jaHMlMjAlM0QlMjA1MCUwQW51bV90cmFpbl9zdGVwcyUyMCUzRCUyMGxlbih0cmFpbl9kcyklMjAqJTIwbnVtX2Vwb2NocyUwQWxlYXJuaW5nX3JhdGUlMjAlM0QlMjA2ZS01JTBBd2VpZ2h0X2RlY2F5X3JhdGUlMjAlM0QlMjAwLjAxJTBBJTBBb3B0aW1pemVyJTJDJTIwbHJfc2NoZWR1bGUlMjAlM0QlMjBjcmVhdGVfb3B0aW1pemVyKCUwQSUyMCUyMCUyMCUyMGluaXRfbHIlM0RsZWFybmluZ19yYXRlJTJDJTBBJTIwJTIwJTIwJTIwbnVtX3RyYWluX3N0ZXBzJTNEbnVtX3RyYWluX3N0ZXBzJTJDJTBBJTIwJTIwJTIwJTIwd2VpZ2h0X2RlY2F5X3JhdGUlM0R3ZWlnaHRfZGVjYXlfcmF0ZSUyQyUwQSUyMCUyMCUyMCUyMG51bV93YXJtdXBfc3RlcHMlM0QwJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>batch_size = <span class="hljs-number">2</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">50</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_train_steps = <span class="hljs-built_in">len</span>(train_ds) * num_epochs
<span class="hljs-meta">&gt;&gt;&gt; </span>learning_rate = <span class="hljs-number">6e-5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>weight_decay_rate = <span class="hljs-number">0.01</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer, lr_schedule = create_optimizer(
<span class="hljs-meta">... </span>    init_lr=learning_rate,
<span class="hljs-meta">... </span>    num_train_steps=num_train_steps,
<span class="hljs-meta">... </span>    weight_decay_rate=weight_decay_rate,
<span class="hljs-meta">... </span>    num_warmup_steps=<span class="hljs-number">0</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),u=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VtYW50aWNTZWdtZW50YXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VtYW50aWNTZWdtZW50YXRpb24uZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMGNoZWNrcG9pbnQlMkMlMEElMjAlMjAlMjAlMjBpZDJsYWJlbCUzRGlkMmxhYmVsJTJDJTBBJTIwJTIwJTIwJTIwbGFiZWwyaWQlM0RsYWJlbDJpZCUyQyUwQSklMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplciklMjAlMjAlMjMlMjAlRUMlODYlOTAlRUMlOEIlQTQlMjAlRUQlOTUlQTglRUMlODglOTglMjAlRUMlOUQlQjglRUMlOUUlOTAlRUElQjAlODAlMjAlRUMlOTclODYlRUMlOEElQjUlRUIlOEIlODglRUIlOEIlQTQh",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(
<span class="hljs-meta">... </span>    checkpoint,
<span class="hljs-meta">... </span>    id2label=id2label,
<span class="hljs-meta">... </span>    label2id=label2id,
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer)  <span class="hljs-comment"># 손실 함수 인자가 없습니다!</span>`,wrap:!1}}),r=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcihyZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKSUwQSUwQXRmX3RyYWluX2RhdGFzZXQlMjAlM0QlMjB0cmFpbl9kcy50b190Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGNvbHVtbnMlM0QlNUIlMjJwaXhlbF92YWx1ZXMlMjIlMkMlMjAlMjJsYWJlbCUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHNodWZmbGUlM0RUcnVlJTJDJTBBJTIwJTIwJTIwJTIwYmF0Y2hfc2l6ZSUzRGJhdGNoX3NpemUlMkMlMEElMjAlMjAlMjAlMjBjb2xsYXRlX2ZuJTNEZGF0YV9jb2xsYXRvciUyQyUwQSklMEElMEF0Zl9ldmFsX2RhdGFzZXQlMjAlM0QlMjB0ZXN0X2RzLnRvX3RmX2RhdGFzZXQoJTBBJTIwJTIwJTIwJTIwY29sdW1ucyUzRCU1QiUyMnBpeGVsX3ZhbHVlcyUyMiUyQyUyMCUyMmxhYmVsJTIyJTVEJTJDJTBBJTIwJTIwJTIwJTIwc2h1ZmZsZSUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBiYXRjaF9zaXplJTNEYmF0Y2hfc2l6ZSUyQyUwQSUyMCUyMCUyMCUyMGNvbGxhdGVfZm4lM0RkYXRhX2NvbGxhdG9yJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = train_ds.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;pixel_values&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=batch_size,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>tf_eval_dataset = test_ds.to_tf_dataset(
<span class="hljs-meta">... </span>    columns=[<span class="hljs-string">&quot;pixel_values&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>],
<span class="hljs-meta">... </span>    shuffle=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    batch_size=batch_size,
<span class="hljs-meta">... </span>    collate_fn=data_collator,
<span class="hljs-meta">... </span>)`,wrap:!1}}),N=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBLZXJhc01ldHJpY0NhbGxiYWNrJTJDJTIwUHVzaFRvSHViQ2FsbGJhY2slMEElMEFtZXRyaWNfY2FsbGJhY2slMjAlM0QlMjBLZXJhc01ldHJpY0NhbGxiYWNrKCUwQSUyMCUyMCUyMCUyMG1ldHJpY19mbiUzRGNvbXB1dGVfbWV0cmljcyUyQyUyMGV2YWxfZGF0YXNldCUzRHRmX2V2YWxfZGF0YXNldCUyQyUyMGJhdGNoX3NpemUlM0RiYXRjaF9zaXplJTJDJTIwbGFiZWxfY29scyUzRCU1QiUyMmxhYmVscyUyMiU1RCUwQSklMEElMEFwdXNoX3RvX2h1Yl9jYWxsYmFjayUyMCUzRCUyMFB1c2hUb0h1YkNhbGxiYWNrKG91dHB1dF9kaXIlM0QlMjJzY2VuZV9zZWdtZW50YXRpb24lMjIlMkMlMjB0b2tlbml6ZXIlM0RpbWFnZV9wcm9jZXNzb3IpJTBBJTBBY2FsbGJhY2tzJTIwJTNEJTIwJTVCbWV0cmljX2NhbGxiYWNrJTJDJTIwcHVzaF90b19odWJfY2FsbGJhY2slNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> KerasMetricCallback, PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>metric_callback = KerasMetricCallback(
<span class="hljs-meta">... </span>    metric_fn=compute_metrics, eval_dataset=tf_eval_dataset, batch_size=batch_size, label_cols=[<span class="hljs-string">&quot;labels&quot;</span>]
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>push_to_hub_callback = PushToHubCallback(output_dir=<span class="hljs-string">&quot;scene_segmentation&quot;</span>, tokenizer=image_processor)

<span class="hljs-meta">&gt;&gt;&gt; </span>callbacks = [metric_callback, push_to_hub_callback]`,wrap:!1}}),A=new x({props:{code:"bW9kZWwuZml0KCUwQSUyMCUyMCUyMCUyMHRmX3RyYWluX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl9ldmFsX2RhdGFzZXQlMkMlMEElMjAlMjAlMjAlMjBjYWxsYmFja3MlM0RjYWxsYmFja3MlMkMlMEElMjAlMjAlMjAlMjBlcG9jaHMlM0RudW1fZXBvY2hzJTJDJTBBKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(
<span class="hljs-meta">... </span>    tf_train_dataset,
<span class="hljs-meta">... </span>    validation_data=tf_eval_dataset,
<span class="hljs-meta">... </span>    callbacks=callbacks,
<span class="hljs-meta">... </span>    epochs=num_epochs,
<span class="hljs-meta">... </span>)`,wrap:!1}}),{c(){g(a.$$.fragment),o=M(),l=T("p"),l.textContent=c,y=M(),$=T("ol"),$.innerHTML=R,B=M(),_=T("p"),_.textContent=Z,C=M(),g(Q.$$.fragment),v=M(),d=T("p"),d.innerHTML=V,m=M(),g(u.$$.fragment),Y=M(),G=T("p"),G.innerHTML=F,p=M(),g(r.$$.fragment),X=M(),E=T("p"),E.innerHTML=S,q=M(),g(N.$$.fragment),js=M(),z=T("p"),z.innerHTML=L,K=M(),g(A.$$.fragment),P=M(),H=T("p"),H.textContent=Rs},l(j){h(a.$$.fragment,j),o=i(j),l=b(j,"P",{"data-svelte-h":!0}),I(l)!=="svelte-um2evk"&&(l.textContent=c),y=i(j),$=b(j,"OL",{"data-svelte-h":!0}),I($)!=="svelte-173h0e5"&&($.innerHTML=R),B=i(j),_=b(j,"P",{"data-svelte-h":!0}),I(_)!=="svelte-wcragq"&&(_.textContent=Z),C=i(j),h(Q.$$.fragment,j),v=i(j),d=b(j,"P",{"data-svelte-h":!0}),I(d)!=="svelte-nqumm8"&&(d.innerHTML=V),m=i(j),h(u.$$.fragment,j),Y=i(j),G=b(j,"P",{"data-svelte-h":!0}),I(G)!=="svelte-1qohu6b"&&(G.innerHTML=F),p=i(j),h(r.$$.fragment,j),X=i(j),E=b(j,"P",{"data-svelte-h":!0}),I(E)!=="svelte-1piamfe"&&(E.innerHTML=S),q=i(j),h(N.$$.fragment,j),js=i(j),z=b(j,"P",{"data-svelte-h":!0}),I(z)!=="svelte-1ud4ghv"&&(z.innerHTML=L),K=i(j),h(A.$$.fragment,j),P=i(j),H=b(j,"P",{"data-svelte-h":!0}),I(H)!=="svelte-1trgvwr"&&(H.textContent=Rs)},m(j,k){J(a,j,k),t(j,o,k),t(j,l,k),t(j,y,k),t(j,$,k),t(j,B,k),t(j,_,k),t(j,C,k),J(Q,j,k),t(j,v,k),t(j,d,k),t(j,m,k),J(u,j,k),t(j,Y,k),t(j,G,k),t(j,p,k),J(r,j,k),t(j,X,k),t(j,E,k),t(j,q,k),J(N,j,k),t(j,js,k),t(j,z,k),t(j,K,k),J(A,j,k),t(j,P,k),t(j,H,k),O=!0},p(j,k){const D={};k&2&&(D.$$scope={dirty:k,ctx:j}),a.$set(D)},i(j){O||(w(a.$$.fragment,j),w(Q.$$.fragment,j),w(u.$$.fragment,j),w(r.$$.fragment,j),w(N.$$.fragment,j),w(A.$$.fragment,j),O=!0)},o(j){U(a.$$.fragment,j),U(Q.$$.fragment,j),U(u.$$.fragment,j),U(r.$$.fragment,j),U(N.$$.fragment,j),U(A.$$.fragment,j),O=!1},d(j){j&&(e(o),e(l),e(y),e($),e(B),e(_),e(C),e(v),e(d),e(m),e(Y),e(G),e(p),e(X),e(E),e(q),e(js),e(z),e(K),e(P),e(H)),f(a,j),f(Q,j),f(u,j),f(r,j),f(N,j),f(A,j)}}}function oa(W){let a,o;return a=new os({props:{$$slots:{default:[ia]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function ja(W){let a,o="추론을 위해 미세 조정한 모델을 시험해 보는 가장 간단한 방법은 <code>pipeline()</code>에서 사용하는 것입니다. 모델을 사용하여 이미지 분할을 위한 <code>pipeline</code>을 인스턴스화하고 이미지를 전달합니다:",l,c,y,$,R="원하는 경우 <code>pipeline</code>의 결과를 수동으로 복제할 수도 있습니다. 이미지 프로세서로 이미지를 처리하고 <code>pixel_values</code>을 GPU에 배치합니다:",B,_,Z,C,Q="모델에 입력을 전달하고 <code>logits</code>를 반환합니다:",v,d,V,m,u="그런 다음 로짓의 크기를 원본 이미지 크기로 다시 조정합니다:",Y,G,F;return c=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBc2VnbWVudGVyJTIwJTNEJTIwcGlwZWxpbmUoJTIyaW1hZ2Utc2VnbWVudGF0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJteV9hd2Vzb21lX3NlZ19tb2RlbCUyMiklMEFzZWdtZW50ZXIoaW1hZ2Up",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>segmenter = pipeline(<span class="hljs-string">&quot;image-segmentation&quot;</span>, model=<span class="hljs-string">&quot;my_awesome_seg_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>segmenter(image)
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;wall&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062690</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;sky&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062A50</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;floor&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062B50</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;ceiling&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062A10</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;bed &#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062E90</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;windowpane&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062390</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;cabinet&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062550</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;chair&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062D90</span>&gt;},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-literal">None</span>,
  <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;armchair&#x27;</span>,
  <span class="hljs-string">&#x27;mask&#x27;</span>: &lt;PIL.Image.Image image mode=L size=640x427 at <span class="hljs-number">0x7FD5B2062E10</span>&gt;}]`,wrap:!1}}),_=new x({props:{code:"ZGV2aWNlJTIwJTNEJTIwdG9yY2guZGV2aWNlKCUyMmN1ZGElMjIlMjBpZiUyMHRvcmNoLmN1ZGEuaXNfYXZhaWxhYmxlKCklMjBlbHNlJTIwJTIyY3B1JTIyKSUyMCUyMCUyMyUyMCVFQSVCMCU4MCVFQiU4QSVBNSVFRCU5NSU5OCVFQiU4QiVBNCVFQiVBOSVCNCUyMEdQVSVFQiVBNSVCQyUyMCVFQyU4MiVBQyVFQyU5QSVBOSVFRCU5NSU5OCVFQSVCMyVBMCUyQyUyMCVFQSVCNyVCOCVFQiVBMCU4NyVFQyVBNyU4MCUyMCVFQyU5NSU4QSVFQiU4QiVBNCVFQiVBOSVCNCUyMENQVSVFQiVBNSVCQyUyMCVFQyU4MiVBQyVFQyU5QSVBOSVFRCU5NSU5OCVFQyU4NCVCOCVFQyU5QSU5NCUwQWVuY29kaW5nJTIwJTNEJTIwaW1hZ2VfcHJvY2Vzc29yKGltYWdlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMiklMEFwaXhlbF92YWx1ZXMlMjAlM0QlMjBlbmNvZGluZy5waXhlbF92YWx1ZXMudG8oZGV2aWNlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>device = torch.device(<span class="hljs-string">&quot;cuda&quot;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span>)  <span class="hljs-comment"># 가능하다면 GPU를 사용하고, 그렇지 않다면 CPU를 사용하세요</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>encoding = image_processor(image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>pixel_values = encoding.pixel_values.to(device)`,wrap:!1}}),d=new x({props:{code:"b3V0cHV0cyUyMCUzRCUyMG1vZGVsKHBpeGVsX3ZhbHVlcyUzRHBpeGVsX3ZhbHVlcyklMEFsb2dpdHMlMjAlM0QlMjBvdXRwdXRzLmxvZ2l0cy5jcHUoKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(pixel_values=pixel_values)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = outputs.logits.cpu()`,wrap:!1}}),G=new x({props:{code:"dXBzYW1wbGVkX2xvZ2l0cyUyMCUzRCUyMG5uLmZ1bmN0aW9uYWwuaW50ZXJwb2xhdGUoJTBBJTIwJTIwJTIwJTIwbG9naXRzJTJDJTBBJTIwJTIwJTIwJTIwc2l6ZSUzRGltYWdlLnNpemUlNUIlM0ElM0EtMSU1RCUyQyUwQSUyMCUyMCUyMCUyMG1vZGUlM0QlMjJiaWxpbmVhciUyMiUyQyUwQSUyMCUyMCUyMCUyMGFsaWduX2Nvcm5lcnMlM0RGYWxzZSUyQyUwQSklMEElMEFwcmVkX3NlZyUyMCUzRCUyMHVwc2FtcGxlZF9sb2dpdHMuYXJnbWF4KGRpbSUzRDEpJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>upsampled_logits = nn.functional.interpolate(
<span class="hljs-meta">... </span>    logits,
<span class="hljs-meta">... </span>    size=image.size[::-<span class="hljs-number">1</span>],
<span class="hljs-meta">... </span>    mode=<span class="hljs-string">&quot;bilinear&quot;</span>,
<span class="hljs-meta">... </span>    align_corners=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>pred_seg = upsampled_logits.argmax(dim=<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]`,wrap:!1}}),{c(){a=T("p"),a.innerHTML=o,l=M(),g(c.$$.fragment),y=M(),$=T("p"),$.innerHTML=R,B=M(),g(_.$$.fragment),Z=M(),C=T("p"),C.innerHTML=Q,v=M(),g(d.$$.fragment),V=M(),m=T("p"),m.textContent=u,Y=M(),g(G.$$.fragment)},l(p){a=b(p,"P",{"data-svelte-h":!0}),I(a)!=="svelte-v6d888"&&(a.innerHTML=o),l=i(p),h(c.$$.fragment,p),y=i(p),$=b(p,"P",{"data-svelte-h":!0}),I($)!=="svelte-112n7y6"&&($.innerHTML=R),B=i(p),h(_.$$.fragment,p),Z=i(p),C=b(p,"P",{"data-svelte-h":!0}),I(C)!=="svelte-t69k4k"&&(C.innerHTML=Q),v=i(p),h(d.$$.fragment,p),V=i(p),m=b(p,"P",{"data-svelte-h":!0}),I(m)!=="svelte-18ee243"&&(m.textContent=u),Y=i(p),h(G.$$.fragment,p)},m(p,r){t(p,a,r),t(p,l,r),J(c,p,r),t(p,y,r),t(p,$,r),t(p,B,r),J(_,p,r),t(p,Z,r),t(p,C,r),t(p,v,r),J(d,p,r),t(p,V,r),t(p,m,r),t(p,Y,r),J(G,p,r),F=!0},p:ss,i(p){F||(w(c.$$.fragment,p),w(_.$$.fragment,p),w(d.$$.fragment,p),w(G.$$.fragment,p),F=!0)},o(p){U(c.$$.fragment,p),U(_.$$.fragment,p),U(d.$$.fragment,p),U(G.$$.fragment,p),F=!1},d(p){p&&(e(a),e(l),e(y),e($),e(B),e(Z),e(C),e(v),e(V),e(m),e(Y)),f(c,p),f(_,p),f(d,p),f(G,p)}}}function ya(W){let a,o;return a=new os({props:{$$slots:{default:[ja]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function ga(W){let a,o="이미지 프로세서를 로드하여 이미지를 전처리하고 입력을 TensorFlow 텐서로 반환합니다:",l,c,y,$,R="모델에 입력을 전달하고 <code>logits</code>를 반환합니다:",B,_,Z,C,Q="그런 다음 로그를 원본 이미지 크기로 재조정하고 클래스 차원에 argmax를 적용합니다:",v,d,V;return c=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyTWFyaWFLJTJGc2NlbmVfc2VnbWVudGF0aW9uJTIyKSUwQWlucHV0cyUyMCUzRCUyMGltYWdlX3Byb2Nlc3NvcihpbWFnZSUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIydGYlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;MariaK/scene_segmentation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = image_processor(image, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),_=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9yU2VtYW50aWNTZWdtZW50YXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMFRGQXV0b01vZGVsRm9yU2VtYW50aWNTZWdtZW50YXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMk1hcmlhSyUyRnNjZW5lX3NlZ21lbnRhdGlvbiUyMiklMEFsb2dpdHMlMjAlM0QlMjBtb2RlbCgqKmlucHV0cykubG9naXRz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForSemanticSegmentation

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForSemanticSegmentation.from_pretrained(<span class="hljs-string">&quot;MariaK/scene_segmentation&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits`,wrap:!1}}),d=new x({props:{code:"bG9naXRzJTIwJTNEJTIwdGYudHJhbnNwb3NlKGxvZ2l0cyUyQyUyMCU1QjAlMkMlMjAyJTJDJTIwMyUyQyUyMDElNUQpJTBBJTBBdXBzYW1wbGVkX2xvZ2l0cyUyMCUzRCUyMHRmLmltYWdlLnJlc2l6ZSglMEElMjAlMjAlMjAlMjBsb2dpdHMlMkMlMEElMjAlMjAlMjAlMjAlMjMlMjAlNjBpbWFnZS5zaXplJTYwJUVBJUIwJTgwJTIwJUVCJTg0JTg4JUVCJUI5JTg0JUVDJTk5JTgwJTIwJUVCJTg2JTkyJUVDJTlEJUI0JUVCJUE1JUJDJTIwJUVCJUIwJTk4JUVEJTk5JTk4JUVEJTk1JTk4JUVBJUI4JUIwJTIwJUVCJTk1JThDJUVCJUFDJUI4JUVDJTk3JTkwJTIwJTYwaW1hZ2UlNjAlRUMlOUQlOTglMjAlRUIlQUElQTglRUMlOTYlOTElRUMlOUQlODQlMjAlRUIlQjAlOTglRUMlQTAlODQlRUMlOEIlOUMlRUQlODIlQjUlRUIlOEIlODglRUIlOEIlQTQlMEElMjAlMjAlMjAlMjBpbWFnZS5zaXplJTVCJTNBJTNBLTElNUQlMkMlMEEpJTBBJTBBcHJlZF9zZWclMjAlM0QlMjB0Zi5tYXRoLmFyZ21heCh1cHNhbXBsZWRfbG9naXRzJTJDJTIwYXhpcyUzRC0xKSU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>logits = tf.transpose(logits, [<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>upsampled_logits = tf.image.resize(
<span class="hljs-meta">... </span>    logits,
<span class="hljs-meta">... </span>    <span class="hljs-comment"># \`image.size\`가 너비와 높이를 반환하기 때문에 \`image\`의 모양을 반전시킵니다</span>
<span class="hljs-meta">... </span>    image.size[::-<span class="hljs-number">1</span>],
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>pred_seg = tf.math.argmax(upsampled_logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>]`,wrap:!1}}),{c(){a=T("p"),a.textContent=o,l=M(),g(c.$$.fragment),y=M(),$=T("p"),$.innerHTML=R,B=M(),g(_.$$.fragment),Z=M(),C=T("p"),C.textContent=Q,v=M(),g(d.$$.fragment)},l(m){a=b(m,"P",{"data-svelte-h":!0}),I(a)!=="svelte-k2y3aq"&&(a.textContent=o),l=i(m),h(c.$$.fragment,m),y=i(m),$=b(m,"P",{"data-svelte-h":!0}),I($)!=="svelte-t69k4k"&&($.innerHTML=R),B=i(m),h(_.$$.fragment,m),Z=i(m),C=b(m,"P",{"data-svelte-h":!0}),I(C)!=="svelte-1dmtoj2"&&(C.textContent=Q),v=i(m),h(d.$$.fragment,m)},m(m,u){t(m,a,u),t(m,l,u),J(c,m,u),t(m,y,u),t(m,$,u),t(m,B,u),J(_,m,u),t(m,Z,u),t(m,C,u),t(m,v,u),J(d,m,u),V=!0},p:ss,i(m){V||(w(c.$$.fragment,m),w(_.$$.fragment,m),w(d.$$.fragment,m),V=!0)},o(m){U(c.$$.fragment,m),U(_.$$.fragment,m),U(d.$$.fragment,m),V=!1},d(m){m&&(e(a),e(l),e(y),e($),e(B),e(Z),e(C),e(v)),f(c,m),f(_,m),f(d,m)}}}function ha(W){let a,o;return a=new os({props:{$$slots:{default:[ga]},$$scope:{ctx:W}}}),{c(){g(a.$$.fragment)},l(l){h(a.$$.fragment,l)},m(l,c){J(a,l,c),o=!0},p(l,c){const y={};c&2&&(y.$$scope={dirty:c,ctx:l}),a.$set(y)},i(l){o||(w(a.$$.fragment,l),o=!0)},o(l){U(a.$$.fragment,l),o=!1},d(l){f(a,l)}}}function Ja(W){let a,o,l,c,y,$,R,B,_,Z,C,Q=`의미적 분할(semantic segmentation)은 이미지의 각 픽셀에 레이블 또는 클래스를 할당합니다. 분할(segmentation)에는 여러 종류가 있으며, 의미적 분할의 경우 동일한 물체의 고유 인스턴스를 구분하지 않습니다. 두 물체 모두 동일한 레이블이 지정됩니다(예시로, “car-1” 과 “car-2” 대신 “car”로 지정합니다).
실생활에서 흔히 볼 수 있는 의미적 분할의 적용 사례로는 보행자와 중요한 교통 정보를 식별하는 자율 주행 자동차 학습, 의료 이미지의 세포와 이상 징후 식별, 그리고 위성 이미지의 환경 변화 모니터링등이 있습니다.`,v,d,V="이번 가이드에서 배울 내용은 다음과 같습니다:",m,u,Y='<li><a href="https://huggingface.co/datasets/scene_parse_150" rel="nofollow">SceneParse150</a> 데이터 세트를 이용해 <a href="https://huggingface.co/docs/transformers/main/en/model_doc/segformer#segformer" rel="nofollow">SegFormer</a> 미세 조정하기.</li> <li>미세 조정된 모델을 추론에 사용하기.</li>',G,F,p,r,X="시작하기 전에 필요한 모든 라이브러리가 설치되었는지 확인하세요:",E,S,q,N,js="커뮤니티에 모델을 업로드하고 공유할 수 있도록 Hugging Face 계정에 로그인하는 것을 권장합니다. 프롬프트가 나타나면 토큰을 입력하여 로그인하세요:",z,L,K,A,P,H,Rs="🤗 Datasets 라이브러리에서 SceneParse150 데이터 세트의 더 작은 부분 집합을 가져오는 것으로 시작합니다. 이렇게 하면 데이터 세트 전체에 대한 훈련에 많은 시간을 할애하기 전에 실험을 통해 모든 것이 제대로 작동하는지 확인할 수 있습니다.",O,j,k,D,Ul="데이터 세트의 <code>train</code>을 <code>train_test_split</code> 메소드를 사용하여 훈련 및 테스트 세트로 분할하세요:",Qs,ys,Fs,gs,fl="그리고 예시를 살펴보세요:",Xs,hs,Ys,Js,ul="<li><code>image</code>: 장면의 PIL 이미지입니다.</li> <li><code>annotation</code>: 분할 지도(segmentation map)의 PIL 이미지입니다. 모델의 타겟이기도 합니다.</li> <li><code>scene_category</code>: “주방” 또는 “사무실”과 같이 이미지 장면을 설명하는 카테고리 ID입니다. 이 가이드에서는 둘 다 PIL 이미지인 <code>image</code>와 <code>annotation</code>만을 사용합니다.</li>",Ns,ws,dl="나중에 모델을 설정할 때 유용하게 사용할 수 있도록 레이블 ID를 레이블 클래스에 매핑하는 사전도 만들고 싶을 것입니다. Hub에서 매핑을 다운로드하고 <code>id2label</code> 및 <code>label2id</code> 사전을 만드세요:",As,Us,Hs,fs,Es,us,Tl="다음 단계는 모델에 사용할 이미지와 주석을 준비하기 위해 SegFormer 이미지 프로세서를 불러오는 것입니다. 우리가 사용하는 데이터 세트와 같은 일부 데이터 세트는 배경 클래스로 제로 인덱스를 사용합니다. 하지만 배경 클래스는 150개의 클래스에 실제로는 포함되지 않기 때문에 <code>reduce_labels=True</code> 를 설정해 모든 레이블에서 배경 클래스를 제거해야 합니다. 제로 인덱스는 <code>255</code>로 대체되므로 SegFormer의 손실 함수에서 무시됩니다:",zs,ds,Ss,ls,Ls,as,Ds,Ts,qs,bs,bl='훈련 중에 메트릭을 포함하면 모델의 성능을 평가하는 데 도움이 되는 경우가 많습니다. 🤗 <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> 라이브러리를 사용하여 평가 방법을 빠르게 로드할 수 있습니다. 이 태스크에서는 <a href="https://huggingface.co/spaces/evaluate-metric/accuracy" rel="nofollow">mean Intersection over Union</a> (IoU) 메트릭을 로드하세요 (메트릭을 로드하고 계산하는 방법에 대해 자세히 알아보려면 🤗 Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">quick tour</a>를 살펴보세요).',Ks,$s,Ps,Cs,$l="그런 다음 메트릭을 <code>compute</code>하는 함수를 만듭니다. 예측을 먼저 로짓으로 변환한 다음, 레이블의 크기에 맞게 모양을 다시 지정해야 <code>compute</code>를 호출할 수 있습니다:",Os,es,sl,ts,ll,Is,Cl="이제 <code>compute_metrics</code> 함수를 사용할 준비가 되었습니다. 트레이닝을 설정할 때 이 함수로 돌아가게 됩니다.",al,_s,el,ns,tl,ps,nl,Ws,pl,Bs,Il="이제 모델을 미세 조정했으니 추론에 사용할 수 있습니다!",ml,Zs,_l="추론할 이미지를 로드하세요:",cl,ks,rl,ms,Wl='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-image.png" alt="Image of bedroom"/>',Ml,cs,il,rs,ol,Vs,Bl='결과를 시각화하려면 <a href="https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51" rel="nofollow">dataset color palette</a>를 각 클래스를 RGB 값에 매핑하는 <code>ade_palette()</code>로 로드합니다. 그런 다음 이미지와 예측된 분할 지도(segmentation map)을 결합하여 구성할 수 있습니다:',jl,Gs,yl,Ms,Zl='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-preds.png" alt="Image of bedroom overlaid with segmentation map"/>',gl,vs,hl;return y=new xs({props:{title:"의미적 분할(Semantic segmentation)",local:"semantic-segmentation",headingTag:"h1"}}),R=new Kl({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/semantic_segmentation.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/semantic_segmentation.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/semantic_segmentation.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/semantic_segmentation.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/semantic_segmentation.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/semantic_segmentation.ipynb"}]}}),_=new ql({props:{id:"dKE8SIt9C-w"}}),F=new wl({props:{$$slots:{default:[Pl]},$$scope:{ctx:W}}}),S=new x({props:{code:"cGlwJTIwaW5zdGFsbCUyMC1xJTIwZGF0YXNldHMlMjB0cmFuc2Zvcm1lcnMlMjBldmFsdWF0ZQ==",highlighted:"pip install -q datasets transformers evaluate",wrap:!1}}),L=new x({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),A=new xs({props:{title:"SceneParse150 데이터 세트 불러오기",local:"load-sceneparse150-dataset",headingTag:"h2"}}),j=new x({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZHMlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyc2NlbmVfcGFyc2VfMTUwJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiU1QiUzQTUwJTVEJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;scene_parse_150&quot;</span>, split=<span class="hljs-string">&quot;train[:50]&quot;</span>)`,wrap:!1}}),ys=new x({props:{code:"ZHMlMjAlM0QlMjBkcy50cmFpbl90ZXN0X3NwbGl0KHRlc3Rfc2l6ZSUzRDAuMiklMEF0cmFpbl9kcyUyMCUzRCUyMGRzJTVCJTIydHJhaW4lMjIlNUQlMEF0ZXN0X2RzJTIwJTNEJTIwZHMlNUIlMjJ0ZXN0JTIyJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = ds.train_test_split(test_size=<span class="hljs-number">0.2</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>train_ds = ds[<span class="hljs-string">&quot;train&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>test_ds = ds[<span class="hljs-string">&quot;test&quot;</span>]`,wrap:!1}}),hs=new x({props:{code:"dHJhaW5fZHMlNUIwJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>train_ds[<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x683 at <span class="hljs-number">0x7F9B0C201F90</span>&gt;,
 <span class="hljs-string">&#x27;annotation&#x27;</span>: &lt;PIL.PngImagePlugin.PngImageFile image mode=L size=512x683 at <span class="hljs-number">0x7F9B0C201DD0</span>&gt;,
 <span class="hljs-string">&#x27;scene_category&#x27;</span>: <span class="hljs-number">368</span>}`,wrap:!1}}),Us=new x({props:{code:"aW1wb3J0JTIwanNvbiUwQWZyb20lMjBodWdnaW5nZmFjZV9odWIlMjBpbXBvcnQlMjBjYWNoZWRfZG93bmxvYWQlMkMlMjBoZl9odWJfdXJsJTBBJTBBcmVwb19pZCUyMCUzRCUyMCUyMmh1Z2dpbmdmYWNlJTJGbGFiZWwtZmlsZXMlMjIlMEFmaWxlbmFtZSUyMCUzRCUyMCUyMmFkZTIway1pZDJsYWJlbC5qc29uJTIyJTBBaWQybGFiZWwlMjAlM0QlMjBqc29uLmxvYWQob3BlbihjYWNoZWRfZG93bmxvYWQoaGZfaHViX3VybChyZXBvX2lkJTJDJTIwZmlsZW5hbWUlMkMlMjByZXBvX3R5cGUlM0QlMjJkYXRhc2V0JTIyKSklMkMlMjAlMjJyJTIyKSklMEFpZDJsYWJlbCUyMCUzRCUyMCU3QmludChrKSUzQSUyMHYlMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwaWQybGFiZWwuaXRlbXMoKSU3RCUwQWxhYmVsMmlkJTIwJTNEJTIwJTdCdiUzQSUyMGslMjBmb3IlMjBrJTJDJTIwdiUyMGluJTIwaWQybGFiZWwuaXRlbXMoKSU3RCUwQW51bV9sYWJlbHMlMjAlM0QlMjBsZW4oaWQybGFiZWwp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> json
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> cached_download, hf_hub_url

<span class="hljs-meta">&gt;&gt;&gt; </span>repo_id = <span class="hljs-string">&quot;huggingface/label-files&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>filename = <span class="hljs-string">&quot;ade20k-id2label.json&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>id2label = json.load(<span class="hljs-built_in">open</span>(cached_download(hf_hub_url(repo_id, filename, repo_type=<span class="hljs-string">&quot;dataset&quot;</span>)), <span class="hljs-string">&quot;r&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>id2label = {<span class="hljs-built_in">int</span>(k): v <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}
<span class="hljs-meta">&gt;&gt;&gt; </span>label2id = {v: k <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> id2label.items()}
<span class="hljs-meta">&gt;&gt;&gt; </span>num_labels = <span class="hljs-built_in">len</span>(id2label)`,wrap:!1}}),fs=new xs({props:{title:"전처리하기[ preprocess",local:"전처리하기-preprocess",headingTag:"h2"}}),ds=new x({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWNoZWNrcG9pbnQlMjAlM0QlMjAlMjJudmlkaWElMkZtaXQtYjAlMjIlMEFpbWFnZV9wcm9jZXNzb3IlMjAlM0QlMjBBdXRvSW1hZ2VQcm9jZXNzb3IuZnJvbV9wcmV0cmFpbmVkKGNoZWNrcG9pbnQlMkMlMjByZWR1Y2VfbGFiZWxzJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>checkpoint = <span class="hljs-string">&quot;nvidia/mit-b0&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(checkpoint, reduce_labels=<span class="hljs-literal">True</span>)`,wrap:!1}}),ls=new is({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[sa]},$$scope:{ctx:W}}}),as=new is({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[aa]},$$scope:{ctx:W}}}),Ts=new xs({props:{title:"평가하기",local:"evaluate",headingTag:"h2"}}),$s=new x({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEFtZXRyaWMlMjAlM0QlMjBldmFsdWF0ZS5sb2FkKCUyMm1lYW5faW91JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>metric = evaluate.load(<span class="hljs-string">&quot;mean_iou&quot;</span>)`,wrap:!1}}),es=new is({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[ta]},$$scope:{ctx:W}}}),ts=new is({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[pa]},$$scope:{ctx:W}}}),_s=new xs({props:{title:"학습하기",local:"train",headingTag:"h2"}}),ns=new is({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[ra]},$$scope:{ctx:W}}}),ps=new is({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[oa]},$$scope:{ctx:W}}}),Ws=new xs({props:{title:"추론하기",local:"inference",headingTag:"h2"}}),ks=new x({props:{code:"aW1hZ2UlMjAlM0QlMjBkcyU1QjAlNUQlNUIlMjJpbWFnZSUyMiU1RCUwQWltYWdl",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>image = ds[<span class="hljs-number">0</span>][<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">&gt;&gt;&gt; </span>image`,wrap:!1}}),cs=new is({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[ya]},$$scope:{ctx:W}}}),rs=new is({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[ha]},$$scope:{ctx:W}}}),Gs=new x({props:{code:"aW1wb3J0JTIwbWF0cGxvdGxpYi5weXBsb3QlMjBhcyUyMHBsdCUwQWltcG9ydCUyMG51bXB5JTIwYXMlMjBucCUwQSUwQWNvbG9yX3NlZyUyMCUzRCUyMG5wLnplcm9zKChwcmVkX3NlZy5zaGFwZSU1QjAlNUQlMkMlMjBwcmVkX3NlZy5zaGFwZSU1QjElNUQlMkMlMjAzKSUyQyUyMGR0eXBlJTNEbnAudWludDgpJTBBcGFsZXR0ZSUyMCUzRCUyMG5wLmFycmF5KGFkZV9wYWxldHRlKCkpJTBBZm9yJTIwbGFiZWwlMkMlMjBjb2xvciUyMGluJTIwZW51bWVyYXRlKHBhbGV0dGUpJTNBJTBBJTIwJTIwJTIwJTIwY29sb3Jfc2VnJTVCcHJlZF9zZWclMjAlM0QlM0QlMjBsYWJlbCUyQyUyMCUzQSU1RCUyMCUzRCUyMGNvbG9yJTBBY29sb3Jfc2VnJTIwJTNEJTIwY29sb3Jfc2VnJTVCLi4uJTJDJTIwJTNBJTNBLTElNUQlMjAlMjAlMjMlMjBCR1IlRUIlQTElOUMlMjAlRUIlQjMlODAlRUQlOTklOTglMEElMEFpbWclMjAlM0QlMjBucC5hcnJheShpbWFnZSklMjAqJTIwMC41JTIwJTJCJTIwY29sb3Jfc2VnJTIwKiUyMDAuNSUyMCUyMCUyMyUyMCVFQiVCNiU4NCVFRCU5NSVBMCUyMCVFQyVBNyU4MCVFQiU4RiU4NCVFQyU5QyVCQyVFQiVBMSU5QyUyMCVFQyU5RCVCNCVFQiVBRiVCOCVFQyVBNyU4MCUyMCVFQSVCNSVBQyVFQyU4NCVCMSUwQWltZyUyMCUzRCUyMGltZy5hc3R5cGUobnAudWludDgpJTBBJTBBcGx0LmZpZ3VyZShmaWdzaXplJTNEKDE1JTJDJTIwMTApKSUwQXBsdC5pbXNob3coaW1nKSUwQXBsdC5zaG93KCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-meta">&gt;&gt;&gt; </span>color_seg = np.zeros((pred_seg.shape[<span class="hljs-number">0</span>], pred_seg.shape[<span class="hljs-number">1</span>], <span class="hljs-number">3</span>), dtype=np.uint8)
<span class="hljs-meta">&gt;&gt;&gt; </span>palette = np.array(ade_palette())
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> label, color <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(palette):
<span class="hljs-meta">... </span>    color_seg[pred_seg == label, :] = color
<span class="hljs-meta">&gt;&gt;&gt; </span>color_seg = color_seg[..., ::-<span class="hljs-number">1</span>]  <span class="hljs-comment"># BGR로 변환</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>img = np.array(image) * <span class="hljs-number">0.5</span> + color_seg * <span class="hljs-number">0.5</span>  <span class="hljs-comment"># 분할 지도으로 이미지 구성</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>img = img.astype(np.uint8)

<span class="hljs-meta">&gt;&gt;&gt; </span>plt.figure(figsize=(<span class="hljs-number">15</span>, <span class="hljs-number">10</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.imshow(img)
<span class="hljs-meta">&gt;&gt;&gt; </span>plt.show()`,wrap:!1}}),{c(){a=T("meta"),o=M(),l=T("p"),c=M(),g(y.$$.fragment),$=M(),g(R.$$.fragment),B=M(),g(_.$$.fragment),Z=M(),C=T("p"),C.textContent=Q,v=M(),d=T("p"),d.textContent=V,m=M(),u=T("ol"),u.innerHTML=Y,G=M(),g(F.$$.fragment),p=M(),r=T("p"),r.textContent=X,E=M(),g(S.$$.fragment),q=M(),N=T("p"),N.textContent=js,z=M(),g(L.$$.fragment),K=M(),g(A.$$.fragment),P=M(),H=T("p"),H.textContent=Rs,O=M(),g(j.$$.fragment),k=M(),D=T("p"),D.innerHTML=Ul,Qs=M(),g(ys.$$.fragment),Fs=M(),gs=T("p"),gs.textContent=fl,Xs=M(),g(hs.$$.fragment),Ys=M(),Js=T("ul"),Js.innerHTML=ul,Ns=M(),ws=T("p"),ws.innerHTML=dl,As=M(),g(Us.$$.fragment),Hs=M(),g(fs.$$.fragment),Es=M(),us=T("p"),us.innerHTML=Tl,zs=M(),g(ds.$$.fragment),Ss=M(),g(ls.$$.fragment),Ls=M(),g(as.$$.fragment),Ds=M(),g(Ts.$$.fragment),qs=M(),bs=T("p"),bs.innerHTML=bl,Ks=M(),g($s.$$.fragment),Ps=M(),Cs=T("p"),Cs.innerHTML=$l,Os=M(),g(es.$$.fragment),sl=M(),g(ts.$$.fragment),ll=M(),Is=T("p"),Is.innerHTML=Cl,al=M(),g(_s.$$.fragment),el=M(),g(ns.$$.fragment),tl=M(),g(ps.$$.fragment),nl=M(),g(Ws.$$.fragment),pl=M(),Bs=T("p"),Bs.textContent=Il,ml=M(),Zs=T("p"),Zs.textContent=_l,cl=M(),g(ks.$$.fragment),rl=M(),ms=T("div"),ms.innerHTML=Wl,Ml=M(),g(cs.$$.fragment),il=M(),g(rs.$$.fragment),ol=M(),Vs=T("p"),Vs.innerHTML=Bl,jl=M(),g(Gs.$$.fragment),yl=M(),Ms=T("div"),Ms.innerHTML=Zl,gl=M(),vs=T("p"),this.h()},l(s){const n=zl("svelte-u9bgzb",document.head);a=b(n,"META",{name:!0,content:!0}),n.forEach(e),o=i(s),l=b(s,"P",{}),Yl(l).forEach(e),c=i(s),h(y.$$.fragment,s),$=i(s),h(R.$$.fragment,s),B=i(s),h(_.$$.fragment,s),Z=i(s),C=b(s,"P",{"data-svelte-h":!0}),I(C)!=="svelte-1pm3sh7"&&(C.textContent=Q),v=i(s),d=b(s,"P",{"data-svelte-h":!0}),I(d)!=="svelte-pdyjx9"&&(d.textContent=V),m=i(s),u=b(s,"OL",{"data-svelte-h":!0}),I(u)!=="svelte-1r6ennb"&&(u.innerHTML=Y),G=i(s),h(F.$$.fragment,s),p=i(s),r=b(s,"P",{"data-svelte-h":!0}),I(r)!=="svelte-1aeak3y"&&(r.textContent=X),E=i(s),h(S.$$.fragment,s),q=i(s),N=b(s,"P",{"data-svelte-h":!0}),I(N)!=="svelte-1ylwhj7"&&(N.textContent=js),z=i(s),h(L.$$.fragment,s),K=i(s),h(A.$$.fragment,s),P=i(s),H=b(s,"P",{"data-svelte-h":!0}),I(H)!=="svelte-zqz01o"&&(H.textContent=Rs),O=i(s),h(j.$$.fragment,s),k=i(s),D=b(s,"P",{"data-svelte-h":!0}),I(D)!=="svelte-1amyql0"&&(D.innerHTML=Ul),Qs=i(s),h(ys.$$.fragment,s),Fs=i(s),gs=b(s,"P",{"data-svelte-h":!0}),I(gs)!=="svelte-1rb3v2y"&&(gs.textContent=fl),Xs=i(s),h(hs.$$.fragment,s),Ys=i(s),Js=b(s,"UL",{"data-svelte-h":!0}),I(Js)!=="svelte-9pyc0a"&&(Js.innerHTML=ul),Ns=i(s),ws=b(s,"P",{"data-svelte-h":!0}),I(ws)!=="svelte-1s2rnds"&&(ws.innerHTML=dl),As=i(s),h(Us.$$.fragment,s),Hs=i(s),h(fs.$$.fragment,s),Es=i(s),us=b(s,"P",{"data-svelte-h":!0}),I(us)!=="svelte-1aa89j5"&&(us.innerHTML=Tl),zs=i(s),h(ds.$$.fragment,s),Ss=i(s),h(ls.$$.fragment,s),Ls=i(s),h(as.$$.fragment,s),Ds=i(s),h(Ts.$$.fragment,s),qs=i(s),bs=b(s,"P",{"data-svelte-h":!0}),I(bs)!=="svelte-1am5yvm"&&(bs.innerHTML=bl),Ks=i(s),h($s.$$.fragment,s),Ps=i(s),Cs=b(s,"P",{"data-svelte-h":!0}),I(Cs)!=="svelte-1kp3i6f"&&(Cs.innerHTML=$l),Os=i(s),h(es.$$.fragment,s),sl=i(s),h(ts.$$.fragment,s),ll=i(s),Is=b(s,"P",{"data-svelte-h":!0}),I(Is)!=="svelte-100s3bb"&&(Is.innerHTML=Cl),al=i(s),h(_s.$$.fragment,s),el=i(s),h(ns.$$.fragment,s),tl=i(s),h(ps.$$.fragment,s),nl=i(s),h(Ws.$$.fragment,s),pl=i(s),Bs=b(s,"P",{"data-svelte-h":!0}),I(Bs)!=="svelte-174wmmm"&&(Bs.textContent=Il),ml=i(s),Zs=b(s,"P",{"data-svelte-h":!0}),I(Zs)!=="svelte-y0x66m"&&(Zs.textContent=_l),cl=i(s),h(ks.$$.fragment,s),rl=i(s),ms=b(s,"DIV",{class:!0,"data-svelte-h":!0}),I(ms)!=="svelte-11jfm1f"&&(ms.innerHTML=Wl),Ml=i(s),h(cs.$$.fragment,s),il=i(s),h(rs.$$.fragment,s),ol=i(s),Vs=b(s,"P",{"data-svelte-h":!0}),I(Vs)!=="svelte-1adsal6"&&(Vs.innerHTML=Bl),jl=i(s),h(Gs.$$.fragment,s),yl=i(s),Ms=b(s,"DIV",{class:!0,"data-svelte-h":!0}),I(Ms)!=="svelte-nsecok"&&(Ms.innerHTML=Zl),gl=i(s),vs=b(s,"P",{}),Yl(vs).forEach(e),this.h()},h(){Jl(a,"name","hf:doc:metadata"),Jl(a,"content",wa),Jl(ms,"class","flex justify-center"),Jl(Ms,"class","flex justify-center")},m(s,n){Sl(document.head,a),t(s,o,n),t(s,l,n),t(s,c,n),J(y,s,n),t(s,$,n),J(R,s,n),t(s,B,n),J(_,s,n),t(s,Z,n),t(s,C,n),t(s,v,n),t(s,d,n),t(s,m,n),t(s,u,n),t(s,G,n),J(F,s,n),t(s,p,n),t(s,r,n),t(s,E,n),J(S,s,n),t(s,q,n),t(s,N,n),t(s,z,n),J(L,s,n),t(s,K,n),J(A,s,n),t(s,P,n),t(s,H,n),t(s,O,n),J(j,s,n),t(s,k,n),t(s,D,n),t(s,Qs,n),J(ys,s,n),t(s,Fs,n),t(s,gs,n),t(s,Xs,n),J(hs,s,n),t(s,Ys,n),t(s,Js,n),t(s,Ns,n),t(s,ws,n),t(s,As,n),J(Us,s,n),t(s,Hs,n),J(fs,s,n),t(s,Es,n),t(s,us,n),t(s,zs,n),J(ds,s,n),t(s,Ss,n),J(ls,s,n),t(s,Ls,n),J(as,s,n),t(s,Ds,n),J(Ts,s,n),t(s,qs,n),t(s,bs,n),t(s,Ks,n),J($s,s,n),t(s,Ps,n),t(s,Cs,n),t(s,Os,n),J(es,s,n),t(s,sl,n),J(ts,s,n),t(s,ll,n),t(s,Is,n),t(s,al,n),J(_s,s,n),t(s,el,n),J(ns,s,n),t(s,tl,n),J(ps,s,n),t(s,nl,n),J(Ws,s,n),t(s,pl,n),t(s,Bs,n),t(s,ml,n),t(s,Zs,n),t(s,cl,n),J(ks,s,n),t(s,rl,n),t(s,ms,n),t(s,Ml,n),J(cs,s,n),t(s,il,n),J(rs,s,n),t(s,ol,n),t(s,Vs,n),t(s,jl,n),J(Gs,s,n),t(s,yl,n),t(s,Ms,n),t(s,gl,n),t(s,vs,n),hl=!0},p(s,[n]){const kl={};n&2&&(kl.$$scope={dirty:n,ctx:s}),F.$set(kl);const Vl={};n&2&&(Vl.$$scope={dirty:n,ctx:s}),ls.$set(Vl);const Gl={};n&2&&(Gl.$$scope={dirty:n,ctx:s}),as.$set(Gl);const xl={};n&2&&(xl.$$scope={dirty:n,ctx:s}),es.$set(xl);const Rl={};n&2&&(Rl.$$scope={dirty:n,ctx:s}),ts.$set(Rl);const vl={};n&2&&(vl.$$scope={dirty:n,ctx:s}),ns.$set(vl);const Ql={};n&2&&(Ql.$$scope={dirty:n,ctx:s}),ps.$set(Ql);const Fl={};n&2&&(Fl.$$scope={dirty:n,ctx:s}),cs.$set(Fl);const Xl={};n&2&&(Xl.$$scope={dirty:n,ctx:s}),rs.$set(Xl)},i(s){hl||(w(y.$$.fragment,s),w(R.$$.fragment,s),w(_.$$.fragment,s),w(F.$$.fragment,s),w(S.$$.fragment,s),w(L.$$.fragment,s),w(A.$$.fragment,s),w(j.$$.fragment,s),w(ys.$$.fragment,s),w(hs.$$.fragment,s),w(Us.$$.fragment,s),w(fs.$$.fragment,s),w(ds.$$.fragment,s),w(ls.$$.fragment,s),w(as.$$.fragment,s),w(Ts.$$.fragment,s),w($s.$$.fragment,s),w(es.$$.fragment,s),w(ts.$$.fragment,s),w(_s.$$.fragment,s),w(ns.$$.fragment,s),w(ps.$$.fragment,s),w(Ws.$$.fragment,s),w(ks.$$.fragment,s),w(cs.$$.fragment,s),w(rs.$$.fragment,s),w(Gs.$$.fragment,s),hl=!0)},o(s){U(y.$$.fragment,s),U(R.$$.fragment,s),U(_.$$.fragment,s),U(F.$$.fragment,s),U(S.$$.fragment,s),U(L.$$.fragment,s),U(A.$$.fragment,s),U(j.$$.fragment,s),U(ys.$$.fragment,s),U(hs.$$.fragment,s),U(Us.$$.fragment,s),U(fs.$$.fragment,s),U(ds.$$.fragment,s),U(ls.$$.fragment,s),U(as.$$.fragment,s),U(Ts.$$.fragment,s),U($s.$$.fragment,s),U(es.$$.fragment,s),U(ts.$$.fragment,s),U(_s.$$.fragment,s),U(ns.$$.fragment,s),U(ps.$$.fragment,s),U(Ws.$$.fragment,s),U(ks.$$.fragment,s),U(cs.$$.fragment,s),U(rs.$$.fragment,s),U(Gs.$$.fragment,s),hl=!1},d(s){s&&(e(o),e(l),e(c),e($),e(B),e(Z),e(C),e(v),e(d),e(m),e(u),e(G),e(p),e(r),e(E),e(q),e(N),e(z),e(K),e(P),e(H),e(O),e(k),e(D),e(Qs),e(Fs),e(gs),e(Xs),e(Ys),e(Js),e(Ns),e(ws),e(As),e(Hs),e(Es),e(us),e(zs),e(Ss),e(Ls),e(Ds),e(qs),e(bs),e(Ks),e(Ps),e(Cs),e(Os),e(sl),e(ll),e(Is),e(al),e(el),e(tl),e(nl),e(pl),e(Bs),e(ml),e(Zs),e(cl),e(rl),e(ms),e(Ml),e(il),e(ol),e(Vs),e(jl),e(yl),e(Ms),e(gl),e(vs)),e(a),f(y,s),f(R,s),f(_,s),f(F,s),f(S,s),f(L,s),f(A,s),f(j,s),f(ys,s),f(hs,s),f(Us,s),f(fs,s),f(ds,s),f(ls,s),f(as,s),f(Ts,s),f($s,s),f(es,s),f(ts,s),f(_s,s),f(ns,s),f(ps,s),f(Ws,s),f(ks,s),f(cs,s),f(rs,s),f(Gs,s)}}}const wa='{"title":"의미적 분할(Semantic segmentation)","local":"semantic-segmentation","sections":[{"title":"SceneParse150 데이터 세트 불러오기","local":"load-sceneparse150-dataset","sections":[],"depth":2},{"title":"전처리하기[ preprocess","local":"전처리하기-preprocess","sections":[],"depth":2},{"title":"평가하기","local":"evaluate","sections":[],"depth":2},{"title":"학습하기","local":"train","sections":[],"depth":2},{"title":"추론하기","local":"inference","sections":[],"depth":2}],"depth":1}';function Ua(W){return Al(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class _a extends Hl{constructor(a){super(),El(this,a,Ua,Ja,Nl,{})}}export{_a as component};
