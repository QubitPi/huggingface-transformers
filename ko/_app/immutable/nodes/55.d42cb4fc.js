import{s as La,o as Da,n as fs}from"../chunks/scheduler.56730f09.js";import{S as Pa,i as Ka,g as w,s as r,r as h,A as Oa,h as T,f as a,c as o,j as Aa,u as y,x as _,k as Ua,y as sl,a as l,v as j,d as u,t as b,w as g,m as al,n as ll}from"../chunks/index.1f144517.js";import{T as $a}from"../chunks/Tip.41e845e5.js";import{Y as tl}from"../chunks/Youtube.62e0f062.js";import{C as W}from"../chunks/CodeBlock.738eeccb.js";import{D as el}from"../chunks/DocNotebookDropdown.243c3df7.js";import{F as Fs,M as Bs}from"../chunks/Markdown.c541024b.js";import{H as xs}from"../chunks/Heading.57d46534.js";function nl(X){let t,f,e='<a href="../model_doc/beit">BEiT</a>, <a href="../model_doc/bit">BiT</a>, <a href="../model_doc/convnext">ConvNeXT</a>, <a href="../model_doc/convnextv2">ConvNeXTV2</a>, <a href="../model_doc/cvt">CvT</a>, <a href="../model_doc/data2vec-vision">Data2VecVision</a>, <a href="../model_doc/deit">DeiT</a>, <a href="../model_doc/dinat">DiNAT</a>, <a href="../model_doc/efficientformer">EfficientFormer</a>, <a href="../model_doc/efficientnet">EfficientNet</a>, <a href="../model_doc/focalnet">FocalNet</a>, <a href="../model_doc/imagegpt">ImageGPT</a>, <a href="../model_doc/levit">LeViT</a>, <a href="../model_doc/mobilenet_v1">MobileNetV1</a>, <a href="../model_doc/mobilenet_v2">MobileNetV2</a>, <a href="../model_doc/mobilevit">MobileViT</a>, <a href="../model_doc/nat">NAT</a>, <a href="../model_doc/perceiver">Perceiver</a>, <a href="../model_doc/poolformer">PoolFormer</a>, <a href="../model_doc/regnet">RegNet</a>, <a href="../model_doc/resnet">ResNet</a>, <a href="../model_doc/segformer">SegFormer</a>, <a href="../model_doc/swin">Swin Transformer</a>, <a href="../model_doc/swinv2">Swin Transformer V2</a>, <a href="../model_doc/van">VAN</a>, <a href="../model_doc/vit">ViT</a>, <a href="../model_doc/vit_hybrid">ViT Hybrid</a>, <a href="../model_doc/vit_msn">ViTMSN</a>';return{c(){t=al(`이 튜토리얼에서 설명하는 작업은 다음 모델 아키텍처에 의해 지원됩니다:

`),f=w("p"),f.innerHTML=e},l(i){t=ll(i,`이 튜토리얼에서 설명하는 작업은 다음 모델 아키텍처에 의해 지원됩니다:

`),f=T(i,"P",{"data-svelte-h":!0}),_(f)!=="svelte-14s7zdt"&&(f.innerHTML=e)},m(i,J){l(i,t,J),l(i,f,J)},p:fs,d(i){i&&(a(t),a(f))}}}function pl(X){let t,f='이미지에 몇 가지 이미지 변환을 적용하여 과적합에 대해 모델을 더 견고하게 만듭니다. 여기서 Torchvision의 <a href="https://pytorch.org/vision/stable/transforms.html" rel="nofollow"><code>transforms</code></a> 모듈을 사용하지만, 원하는 이미지 라이브러리를 사용할 수도 있습니다.',e,i,J="이미지의 임의 부분을 크롭하고 크기를 조정한 다음, 이미지 평균과 표준 편차로 정규화하세요:",C,R,v,Z,Y="그런 다음 전처리 함수를 만들어 변환을 적용하고 이미지의 <code>pixel_values</code>(모델에 대한 입력)를 반환하세요:",I,F,V,$,x="전체 데이터 세트에 전처리 기능을 적용하려면 🤗 Datasets <code>with_transform</code>을 사용합니다. 데이터 세트의 요소를 가져올 때 변환이 즉시 적용됩니다:",m,U,z,G,N="이제 <code>DefaultDataCollator</code>를 사용하여 예제 배치를 만듭니다. 🤗 Transformers의 다른 데이터 콜레이터와 달리, <code>DefaultDataCollator</code>는 패딩과 같은 추가적인 전처리를 적용하지 않습니다.",p,d,E;return R=new W({props:{code:"ZnJvbSUyMHRvcmNodmlzaW9uLnRyYW5zZm9ybXMlMjBpbXBvcnQlMjBSYW5kb21SZXNpemVkQ3JvcCUyQyUyMENvbXBvc2UlMkMlMjBOb3JtYWxpemUlMkMlMjBUb1RlbnNvciUwQSUwQW5vcm1hbGl6ZSUyMCUzRCUyME5vcm1hbGl6ZShtZWFuJTNEaW1hZ2VfcHJvY2Vzc29yLmltYWdlX21lYW4lMkMlMjBzdGQlM0RpbWFnZV9wcm9jZXNzb3IuaW1hZ2Vfc3RkKSUwQXNpemUlMjAlM0QlMjAoJTBBJTIwJTIwJTIwJTIwaW1hZ2VfcHJvY2Vzc29yLnNpemUlNUIlMjJzaG9ydGVzdF9lZGdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwaWYlMjAlMjJzaG9ydGVzdF9lZGdlJTIyJTIwaW4lMjBpbWFnZV9wcm9jZXNzb3Iuc2l6ZSUwQSUyMCUyMCUyMCUyMGVsc2UlMjAoaW1hZ2VfcHJvY2Vzc29yLnNpemUlNUIlMjJoZWlnaHQlMjIlNUQlMkMlMjBpbWFnZV9wcm9jZXNzb3Iuc2l6ZSU1QiUyMndpZHRoJTIyJTVEKSUwQSklMEFfdHJhbnNmb3JtcyUyMCUzRCUyMENvbXBvc2UoJTVCUmFuZG9tUmVzaXplZENyb3Aoc2l6ZSklMkMlMjBUb1RlbnNvcigpJTJDJTIwbm9ybWFsaXplJTVEKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> RandomResizedCrop, Compose, Normalize, ToTensor

<span class="hljs-meta">&gt;&gt;&gt; </span>normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)
<span class="hljs-meta">&gt;&gt;&gt; </span>size = (
<span class="hljs-meta">... </span>    image_processor.size[<span class="hljs-string">&quot;shortest_edge&quot;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;shortest_edge&quot;</span> <span class="hljs-keyword">in</span> image_processor.size
<span class="hljs-meta">... </span>    <span class="hljs-keyword">else</span> (image_processor.size[<span class="hljs-string">&quot;height&quot;</span>], image_processor.size[<span class="hljs-string">&quot;width&quot;</span>])
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])`,wrap:!1}}),F=new W({props:{code:"ZGVmJTIwdHJhbnNmb3JtcyhleGFtcGxlcyklM0ElMEElMjAlMjAlMjAlMjBleGFtcGxlcyU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1Ql90cmFuc2Zvcm1zKGltZy5jb252ZXJ0KCUyMlJHQiUyMikpJTIwZm9yJTIwaW1nJTIwaW4lMjBleGFtcGxlcyU1QiUyMmltYWdlJTIyJTVEJTVEJTBBJTIwJTIwJTIwJTIwZGVsJTIwZXhhbXBsZXMlNUIlMjJpbWFnZSUyMiU1RCUwQSUyMCUyMCUyMCUyMHJldHVybiUyMGV4YW1wbGVz",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">transforms</span>(<span class="hljs-params">examples</span>):
<span class="hljs-meta">... </span>    examples[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [_transforms(img.convert(<span class="hljs-string">&quot;RGB&quot;</span>)) <span class="hljs-keyword">for</span> img <span class="hljs-keyword">in</span> examples[<span class="hljs-string">&quot;image&quot;</span>]]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">del</span> examples[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> examples`,wrap:!1}}),U=new W({props:{code:"Zm9vZCUyMCUzRCUyMGZvb2Qud2l0aF90cmFuc2Zvcm0odHJhbnNmb3Jtcyk=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>food = food.with_transform(transforms)',wrap:!1}}),d=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcigp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator()`,wrap:!1}}),{c(){t=w("p"),t.innerHTML=f,e=r(),i=w("p"),i.textContent=J,C=r(),h(R.$$.fragment),v=r(),Z=w("p"),Z.innerHTML=Y,I=r(),h(F.$$.fragment),V=r(),$=w("p"),$.innerHTML=x,m=r(),h(U.$$.fragment),z=r(),G=w("p"),G.innerHTML=N,p=r(),h(d.$$.fragment)},l(M){t=T(M,"P",{"data-svelte-h":!0}),_(t)!=="svelte-1vagpvi"&&(t.innerHTML=f),e=o(M),i=T(M,"P",{"data-svelte-h":!0}),_(i)!=="svelte-10faf4m"&&(i.textContent=J),C=o(M),y(R.$$.fragment,M),v=o(M),Z=T(M,"P",{"data-svelte-h":!0}),_(Z)!=="svelte-1d0gj87"&&(Z.innerHTML=Y),I=o(M),y(F.$$.fragment,M),V=o(M),$=T(M,"P",{"data-svelte-h":!0}),_($)!=="svelte-aqavc3"&&($.innerHTML=x),m=o(M),y(U.$$.fragment,M),z=o(M),G=T(M,"P",{"data-svelte-h":!0}),_(G)!=="svelte-18366hl"&&(G.innerHTML=N),p=o(M),y(d.$$.fragment,M)},m(M,B){l(M,t,B),l(M,e,B),l(M,i,B),l(M,C,B),j(R,M,B),l(M,v,B),l(M,Z,B),l(M,I,B),j(F,M,B),l(M,V,B),l(M,$,B),l(M,m,B),j(U,M,B),l(M,z,B),l(M,G,B),l(M,p,B),j(d,M,B),E=!0},p:fs,i(M){E||(u(R.$$.fragment,M),u(F.$$.fragment,M),u(U.$$.fragment,M),u(d.$$.fragment,M),E=!0)},o(M){b(R.$$.fragment,M),b(F.$$.fragment,M),b(U.$$.fragment,M),b(d.$$.fragment,M),E=!1},d(M){M&&(a(t),a(e),a(i),a(C),a(v),a(Z),a(I),a(V),a($),a(m),a(z),a(G),a(p)),g(R,M),g(F,M),g(U,M),g(d,M)}}}function ml(X){let t,f;return t=new Bs({props:{$$slots:{default:[pl]},$$scope:{ctx:X}}}),{c(){h(t.$$.fragment)},l(e){y(t.$$.fragment,e)},m(e,i){j(t,e,i),f=!0},p(e,i){const J={};i&2&&(J.$$scope={dirty:i,ctx:e}),t.$set(J)},i(e){f||(u(t.$$.fragment,e),f=!0)},o(e){b(t.$$.fragment,e),f=!1},d(e){g(t,e)}}}function cl(X){let t,f=`과적합을 방지하고 모델을 보다 견고하게 만들기 위해 데이터 세트의 훈련 부분에 데이터 증강을 추가합니다.
여기서 Keras 전처리 레이어로 훈련 데이터에 대한 변환(데이터 증강 포함)과
검증 데이터에 대한 변환(중앙 크로핑, 크기 조정, 정규화만)을 정의합니다.
<code>tf.image</code> 또는 다른 원하는 라이브러리를 사용할 수 있습니다.`,e,i,J,C,R="다음으로 한 번에 하나의 이미지가 아니라 이미지 배치에 적절한 변환을 적용하는 함수를 만듭니다.",v,Z,Y,I,F="🤗 Datasets <code>set_transform</code>를 사용하여 즉시 변환을 적용하세요:",V,$,x,m,U=`최종 전처리 단계로 <code>DefaultDataCollator</code>를 사용하여 예제 배치를 만듭니다. 🤗 Transformers의 다른 데이터 콜레이터와 달리
<code>DefaultDataCollator</code>는 패딩과 같은 추가 전처리를 적용하지 않습니다.`,z,G,N;return i=new W({props:{code:"ZnJvbSUyMHRlbnNvcmZsb3clMjBpbXBvcnQlMjBrZXJhcyUwQWZyb20lMjB0ZW5zb3JmbG93LmtlcmFzJTIwaW1wb3J0JTIwbGF5ZXJzJTBBJTBBc2l6ZSUyMCUzRCUyMChpbWFnZV9wcm9jZXNzb3Iuc2l6ZSU1QiUyMmhlaWdodCUyMiU1RCUyQyUyMGltYWdlX3Byb2Nlc3Nvci5zaXplJTVCJTIyd2lkdGglMjIlNUQpJTBBJTBBdHJhaW5fZGF0YV9hdWdtZW50YXRpb24lMjAlM0QlMjBrZXJhcy5TZXF1ZW50aWFsKCUwQSUyMCUyMCUyMCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxheWVycy5SYW5kb21Dcm9wKHNpemUlNUIwJTVEJTJDJTIwc2l6ZSU1QjElNUQpJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbGF5ZXJzLlJlc2NhbGluZyhzY2FsZSUzRDEuMCUyMCUyRiUyMDEyNy41JTJDJTIwb2Zmc2V0JTNELTEpJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbGF5ZXJzLlJhbmRvbUZsaXAoJTIyaG9yaXpvbnRhbCUyMiklMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsYXllcnMuUmFuZG9tUm90YXRpb24oZmFjdG9yJTNEMC4wMiklMkMlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjBsYXllcnMuUmFuZG9tWm9vbShoZWlnaHRfZmFjdG9yJTNEMC4yJTJDJTIwd2lkdGhfZmFjdG9yJTNEMC4yKSUyQyUwQSUyMCUyMCUyMCUyMCU1RCUyQyUwQSUyMCUyMCUyMCUyMG5hbWUlM0QlMjJ0cmFpbl9kYXRhX2F1Z21lbnRhdGlvbiUyMiUyQyUwQSklMEElMEF2YWxfZGF0YV9hdWdtZW50YXRpb24lMjAlM0QlMjBrZXJhcy5TZXF1ZW50aWFsKCUwQSUyMCUyMCUyMCUyMCU1QiUwQSUyMCUyMCUyMCUyMCUyMCUyMCUyMCUyMGxheWVycy5DZW50ZXJDcm9wKHNpemUlNUIwJTVEJTJDJTIwc2l6ZSU1QjElNUQpJTJDJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwbGF5ZXJzLlJlc2NhbGluZyhzY2FsZSUzRDEuMCUyMCUyRiUyMDEyNy41JTJDJTIwb2Zmc2V0JTNELTEpJTJDJTBBJTIwJTIwJTIwJTIwJTVEJTJDJTBBJTIwJTIwJTIwJTIwbmFtZSUzRCUyMnZhbF9kYXRhX2F1Z21lbnRhdGlvbiUyMiUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow <span class="hljs-keyword">import</span> keras
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> layers

<span class="hljs-meta">&gt;&gt;&gt; </span>size = (image_processor.size[<span class="hljs-string">&quot;height&quot;</span>], image_processor.size[<span class="hljs-string">&quot;width&quot;</span>])

<span class="hljs-meta">&gt;&gt;&gt; </span>train_data_augmentation = keras.Sequential(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        layers.RandomCrop(size[<span class="hljs-number">0</span>], size[<span class="hljs-number">1</span>]),
<span class="hljs-meta">... </span>        layers.Rescaling(scale=<span class="hljs-number">1.0</span> / <span class="hljs-number">127.5</span>, offset=-<span class="hljs-number">1</span>),
<span class="hljs-meta">... </span>        layers.RandomFlip(<span class="hljs-string">&quot;horizontal&quot;</span>),
<span class="hljs-meta">... </span>        layers.RandomRotation(factor=<span class="hljs-number">0.02</span>),
<span class="hljs-meta">... </span>        layers.RandomZoom(height_factor=<span class="hljs-number">0.2</span>, width_factor=<span class="hljs-number">0.2</span>),
<span class="hljs-meta">... </span>    ],
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;train_data_augmentation&quot;</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>val_data_augmentation = keras.Sequential(
<span class="hljs-meta">... </span>    [
<span class="hljs-meta">... </span>        layers.CenterCrop(size[<span class="hljs-number">0</span>], size[<span class="hljs-number">1</span>]),
<span class="hljs-meta">... </span>        layers.Rescaling(scale=<span class="hljs-number">1.0</span> / <span class="hljs-number">127.5</span>, offset=-<span class="hljs-number">1</span>),
<span class="hljs-meta">... </span>    ],
<span class="hljs-meta">... </span>    name=<span class="hljs-string">&quot;val_data_augmentation&quot;</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),Z=new W({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBaW1wb3J0JTIwdGVuc29yZmxvdyUyMGFzJTIwdGYlMEFmcm9tJTIwUElMJTIwaW1wb3J0JTIwSW1hZ2UlMEElMEElMEFkZWYlMjBjb252ZXJ0X3RvX3RmX3RlbnNvcihpbWFnZSUzQSUyMEltYWdlKSUzQSUwQSUyMCUyMCUyMCUyMG5wX2ltYWdlJTIwJTNEJTIwbnAuYXJyYXkoaW1hZ2UpJTBBJTIwJTIwJTIwJTIwdGZfaW1hZ2UlMjAlM0QlMjB0Zi5jb252ZXJ0X3RvX3RlbnNvcihucF9pbWFnZSklMEElMjAlMjAlMjAlMjAlMjMlMjAlNjBleHBhbmRfZGltcygpJTYwJTIwaXMlMjB1c2VkJTIwdG8lMjBhZGQlMjBhJTIwYmF0Y2glMjBkaW1lbnNpb24lMjBzaW5jZSUwQSUyMCUyMCUyMCUyMCUyMyUyMHRoZSUyMFRGJTIwYXVnbWVudGF0aW9uJTIwbGF5ZXJzJTIwb3BlcmF0ZXMlMjBvbiUyMGJhdGNoZWQlMjBpbnB1dHMuJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwdGYuZXhwYW5kX2RpbXModGZfaW1hZ2UlMkMlMjAwKSUwQSUwQSUwQWRlZiUyMHByZXByb2Nlc3NfdHJhaW4oZXhhbXBsZV9iYXRjaCklM0ElMEElMjAlMjAlMjAlMjAlMjIlMjIlMjJBcHBseSUyMHRyYWluX3RyYW5zZm9ybXMlMjBhY3Jvc3MlMjBhJTIwYmF0Y2guJTIyJTIyJTIyJTBBJTIwJTIwJTIwJTIwaW1hZ2VzJTIwJTNEJTIwJTVCJTBBJTIwJTIwJTIwJTIwJTIwJTIwJTIwJTIwdHJhaW5fZGF0YV9hdWdtZW50YXRpb24oY29udmVydF90b190Zl90ZW5zb3IoaW1hZ2UuY29udmVydCglMjJSR0IlMjIpKSklMjBmb3IlMjBpbWFnZSUyMGluJTIwZXhhbXBsZV9iYXRjaCU1QiUyMmltYWdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwJTVEJTBBJTIwJTIwJTIwJTIwZXhhbXBsZV9iYXRjaCU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QnRmLnRyYW5zcG9zZSh0Zi5zcXVlZXplKGltYWdlKSklMjBmb3IlMjBpbWFnZSUyMGluJTIwaW1hZ2VzJTVEJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwZXhhbXBsZV9iYXRjaCUwQSUwQSUwQWRlZiUyMHByZXByb2Nlc3NfdmFsKGV4YW1wbGVfYmF0Y2gpJTNBJTBBJTIwJTIwJTIwJTIwJTIyJTIyJTIyQXBwbHklMjB2YWxfdHJhbnNmb3JtcyUyMGFjcm9zcyUyMGElMjBiYXRjaC4lMjIlMjIlMjIlMEElMjAlMjAlMjAlMjBpbWFnZXMlMjAlM0QlMjAlNUIlMEElMjAlMjAlMjAlMjAlMjAlMjAlMjAlMjB2YWxfZGF0YV9hdWdtZW50YXRpb24oY29udmVydF90b190Zl90ZW5zb3IoaW1hZ2UuY29udmVydCglMjJSR0IlMjIpKSklMjBmb3IlMjBpbWFnZSUyMGluJTIwZXhhbXBsZV9iYXRjaCU1QiUyMmltYWdlJTIyJTVEJTBBJTIwJTIwJTIwJTIwJTVEJTBBJTIwJTIwJTIwJTIwZXhhbXBsZV9iYXRjaCU1QiUyMnBpeGVsX3ZhbHVlcyUyMiU1RCUyMCUzRCUyMCU1QnRmLnRyYW5zcG9zZSh0Zi5zcXVlZXplKGltYWdlKSklMjBmb3IlMjBpbWFnZSUyMGluJTIwaW1hZ2VzJTVEJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwZXhhbXBsZV9iYXRjaA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">convert_to_tf_tensor</span>(<span class="hljs-params">image: Image</span>):
<span class="hljs-meta">... </span>    np_image = np.array(image)
<span class="hljs-meta">... </span>    tf_image = tf.convert_to_tensor(np_image)
<span class="hljs-meta">... </span>    <span class="hljs-comment"># \`expand_dims()\` is used to add a batch dimension since</span>
<span class="hljs-meta">... </span>    <span class="hljs-comment"># the TF augmentation layers operates on batched inputs.</span>
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> tf.expand_dims(tf_image, <span class="hljs-number">0</span>)


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_train</span>(<span class="hljs-params">example_batch</span>):
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;&quot;&quot;Apply train_transforms across a batch.&quot;&quot;&quot;</span>
<span class="hljs-meta">... </span>    images = [
<span class="hljs-meta">... </span>        train_data_augmentation(convert_to_tf_tensor(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>))) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>    example_batch[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [tf.transpose(tf.squeeze(image)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> images]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example_batch


<span class="hljs-meta">... </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_val</span>(<span class="hljs-params">example_batch</span>):
<span class="hljs-meta">... </span>    <span class="hljs-string">&quot;&quot;&quot;Apply val_transforms across a batch.&quot;&quot;&quot;</span>
<span class="hljs-meta">... </span>    images = [
<span class="hljs-meta">... </span>        val_data_augmentation(convert_to_tf_tensor(image.convert(<span class="hljs-string">&quot;RGB&quot;</span>))) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> example_batch[<span class="hljs-string">&quot;image&quot;</span>]
<span class="hljs-meta">... </span>    ]
<span class="hljs-meta">... </span>    example_batch[<span class="hljs-string">&quot;pixel_values&quot;</span>] = [tf.transpose(tf.squeeze(image)) <span class="hljs-keyword">for</span> image <span class="hljs-keyword">in</span> images]
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> example_batch`,wrap:!1}}),$=new W({props:{code:"Zm9vZCU1QiUyMnRyYWluJTIyJTVELnNldF90cmFuc2Zvcm0ocHJlcHJvY2Vzc190cmFpbiklMEFmb29kJTVCJTIydGVzdCUyMiU1RC5zZXRfdHJhbnNmb3JtKHByZXByb2Nlc3NfdmFsKQ==",highlighted:`food[<span class="hljs-string">&quot;train&quot;</span>].set_transform(preprocess_train)
food[<span class="hljs-string">&quot;test&quot;</span>].set_transform(preprocess_val)`,wrap:!1}}),G=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMERlZmF1bHREYXRhQ29sbGF0b3IlMEElMEFkYXRhX2NvbGxhdG9yJTIwJTNEJTIwRGVmYXVsdERhdGFDb2xsYXRvcihyZXR1cm5fdGVuc29ycyUzRCUyMnRmJTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DefaultDataCollator

<span class="hljs-meta">&gt;&gt;&gt; </span>data_collator = DefaultDataCollator(return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),{c(){t=w("p"),t.innerHTML=f,e=r(),h(i.$$.fragment),J=r(),C=w("p"),C.textContent=R,v=r(),h(Z.$$.fragment),Y=r(),I=w("p"),I.innerHTML=F,V=r(),h($.$$.fragment),x=r(),m=w("p"),m.innerHTML=U,z=r(),h(G.$$.fragment)},l(p){t=T(p,"P",{"data-svelte-h":!0}),_(t)!=="svelte-184q600"&&(t.innerHTML=f),e=o(p),y(i.$$.fragment,p),J=o(p),C=T(p,"P",{"data-svelte-h":!0}),_(C)!=="svelte-gi5xdk"&&(C.textContent=R),v=o(p),y(Z.$$.fragment,p),Y=o(p),I=T(p,"P",{"data-svelte-h":!0}),_(I)!=="svelte-1yygzze"&&(I.innerHTML=F),V=o(p),y($.$$.fragment,p),x=o(p),m=T(p,"P",{"data-svelte-h":!0}),_(m)!=="svelte-1cqrr7b"&&(m.innerHTML=U),z=o(p),y(G.$$.fragment,p)},m(p,d){l(p,t,d),l(p,e,d),j(i,p,d),l(p,J,d),l(p,C,d),l(p,v,d),j(Z,p,d),l(p,Y,d),l(p,I,d),l(p,V,d),j($,p,d),l(p,x,d),l(p,m,d),l(p,z,d),j(G,p,d),N=!0},p:fs,i(p){N||(u(i.$$.fragment,p),u(Z.$$.fragment,p),u($.$$.fragment,p),u(G.$$.fragment,p),N=!0)},o(p){b(i.$$.fragment,p),b(Z.$$.fragment,p),b($.$$.fragment,p),b(G.$$.fragment,p),N=!1},d(p){p&&(a(t),a(e),a(J),a(C),a(v),a(Y),a(I),a(V),a(x),a(m),a(z)),g(i,p),g(Z,p),g($,p),g(G,p)}}}function rl(X){let t,f;return t=new Bs({props:{$$slots:{default:[cl]},$$scope:{ctx:X}}}),{c(){h(t.$$.fragment)},l(e){y(t.$$.fragment,e)},m(e,i){j(t,e,i),f=!0},p(e,i){const J={};i&2&&(J.$$scope={dirty:i,ctx:e}),t.$set(J)},i(e){f||(u(t.$$.fragment,e),f=!0)},o(e){b(t.$$.fragment,e),f=!1},d(e){g(t,e)}}}function ol(X){let t,f='<code>Trainer</code>를 사용하여 모델을 미세 조정하는 방법에 익숙하지 않은 경우, <a href="../training#train-with-pytorch-trainer">여기</a>에서 기본 튜토리얼을 확인하세요!';return{c(){t=w("p"),t.innerHTML=f},l(e){t=T(e,"P",{"data-svelte-h":!0}),_(t)!=="svelte-16aei3v"&&(t.innerHTML=f)},m(e,i){l(e,t,i)},p:fs,d(e){e&&a(t)}}}function il(X){let t,f,e,i="이제 모델을 훈련시킬 준비가 되었습니다! <code>AutoModelForImageClassification</code>로 ViT를 가져옵니다. 예상되는 레이블 수, 레이블 매핑 및 레이블 수를 지정하세요:",J,C,R,v,Z="이제 세 단계만 거치면 끝입니다:",Y,I,F="<li><code>TrainingArguments</code>에서 훈련 하이퍼파라미터를 정의하세요. <code>image</code> 열이 삭제되기 때문에 미사용 열을 제거하지 않는 것이 중요합니다. <code>image</code> 열이 없으면 <code>pixel_values</code>을 생성할 수 없습니다. 이 동작을 방지하려면 <code>remove_unused_columns=False</code>로 설정하세요! 다른 유일한 필수 매개변수는 모델 저장 위치를 지정하는 <code>output_dir</code>입니다. <code>push_to_hub=True</code>로 설정하면 이 모델을 허브에 푸시합니다(모델을 업로드하려면 Hugging Face에 로그인해야 합니다). 각 에폭이 끝날 때마다, <code>Trainer</code>가 정확도를 평가하고 훈련 체크포인트를 저장합니다.</li> <li><code>Trainer</code>에 모델, 데이터 세트, 토크나이저, 데이터 콜레이터 및 <code>compute_metrics</code> 함수와 함께 훈련 인수를 전달하세요.</li> <li><code>train()</code>을 호출하여 모델을 미세 조정하세요.</li>",V,$,x,m,U="훈련이 완료되면, 모든 사람이 모델을 사용할 수 있도록 <code>push_to_hub()</code> 메소드로 모델을 허브에 공유하세요:",z,G,N;return t=new $a({props:{$$slots:{default:[ol]},$$scope:{ctx:X}}}),C=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24lMkMlMjBUcmFpbmluZ0FyZ3VtZW50cyUyQyUyMFRyYWluZXIlMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUwQSUyMCUyMCUyMCUyMGNoZWNrcG9pbnQlMkMlMEElMjAlMjAlMjAlMjBudW1fbGFiZWxzJTNEbGVuKGxhYmVscyklMkMlMEElMjAlMjAlMjAlMjBpZDJsYWJlbCUzRGlkMmxhYmVsJTJDJTBBJTIwJTIwJTIwJTIwbGFiZWwyaWQlM0RsYWJlbDJpZCUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForImageClassification, TrainingArguments, Trainer

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    checkpoint,
<span class="hljs-meta">... </span>    num_labels=<span class="hljs-built_in">len</span>(labels),
<span class="hljs-meta">... </span>    id2label=id2label,
<span class="hljs-meta">... </span>    label2id=label2id,
<span class="hljs-meta">... </span>)`,wrap:!1}}),$=new W({props:{code:"dHJhaW5pbmdfYXJncyUyMCUzRCUyMFRyYWluaW5nQXJndW1lbnRzKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJteV9hd2Vzb21lX2Zvb2RfbW9kZWwlMjIlMkMlMEElMjAlMjAlMjAlMjByZW1vdmVfdW51c2VkX2NvbHVtbnMlM0RGYWxzZSUyQyUwQSUyMCUyMCUyMCUyMGV2YWx1YXRpb25fc3RyYXRlZ3klM0QlMjJlcG9jaCUyMiUyQyUwQSUyMCUyMCUyMCUyMHNhdmVfc3RyYXRlZ3klM0QlMjJlcG9jaCUyMiUyQyUwQSUyMCUyMCUyMCUyMGxlYXJuaW5nX3JhdGUlM0Q1ZS01JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV90cmFpbl9iYXRjaF9zaXplJTNEMTYlMkMlMEElMjAlMjAlMjAlMjBncmFkaWVudF9hY2N1bXVsYXRpb25fc3RlcHMlM0Q0JTJDJTBBJTIwJTIwJTIwJTIwcGVyX2RldmljZV9ldmFsX2JhdGNoX3NpemUlM0QxNiUyQyUwQSUyMCUyMCUyMCUyMG51bV90cmFpbl9lcG9jaHMlM0QzJTJDJTBBJTIwJTIwJTIwJTIwd2FybXVwX3JhdGlvJTNEMC4xJTJDJTBBJTIwJTIwJTIwJTIwbG9nZ2luZ19zdGVwcyUzRDEwJTJDJTBBJTIwJTIwJTIwJTIwbG9hZF9iZXN0X21vZGVsX2F0X2VuZCUzRFRydWUlMkMlMEElMjAlMjAlMjAlMjBtZXRyaWNfZm9yX2Jlc3RfbW9kZWwlM0QlMjJhY2N1cmFjeSUyMiUyQyUwQSUyMCUyMCUyMCUyMHB1c2hfdG9faHViJTNEVHJ1ZSUyQyUwQSklMEElMEF0cmFpbmVyJTIwJTNEJTIwVHJhaW5lciglMEElMjAlMjAlMjAlMjBtb2RlbCUzRG1vZGVsJTJDJTBBJTIwJTIwJTIwJTIwYXJncyUzRHRyYWluaW5nX2FyZ3MlMkMlMEElMjAlMjAlMjAlMjBkYXRhX2NvbGxhdG9yJTNEZGF0YV9jb2xsYXRvciUyQyUwQSUyMCUyMCUyMCUyMHRyYWluX2RhdGFzZXQlM0Rmb29kJTVCJTIydHJhaW4lMjIlNUQlMkMlMEElMjAlMjAlMjAlMjBldmFsX2RhdGFzZXQlM0Rmb29kJTVCJTIydGVzdCUyMiU1RCUyQyUwQSUyMCUyMCUyMCUyMHRva2VuaXplciUzRGltYWdlX3Byb2Nlc3NvciUyQyUwQSUyMCUyMCUyMCUyMGNvbXB1dGVfbWV0cmljcyUzRGNvbXB1dGVfbWV0cmljcyUyQyUwQSklMEElMEF0cmFpbmVyLnRyYWluKCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>training_args = TrainingArguments(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;my_awesome_food_model&quot;</span>,
<span class="hljs-meta">... </span>    remove_unused_columns=<span class="hljs-literal">False</span>,
<span class="hljs-meta">... </span>    evaluation_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;epoch&quot;</span>,
<span class="hljs-meta">... </span>    learning_rate=<span class="hljs-number">5e-5</span>,
<span class="hljs-meta">... </span>    per_device_train_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    gradient_accumulation_steps=<span class="hljs-number">4</span>,
<span class="hljs-meta">... </span>    per_device_eval_batch_size=<span class="hljs-number">16</span>,
<span class="hljs-meta">... </span>    num_train_epochs=<span class="hljs-number">3</span>,
<span class="hljs-meta">... </span>    warmup_ratio=<span class="hljs-number">0.1</span>,
<span class="hljs-meta">... </span>    logging_steps=<span class="hljs-number">10</span>,
<span class="hljs-meta">... </span>    load_best_model_at_end=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>    metric_for_best_model=<span class="hljs-string">&quot;accuracy&quot;</span>,
<span class="hljs-meta">... </span>    push_to_hub=<span class="hljs-literal">True</span>,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer = Trainer(
<span class="hljs-meta">... </span>    model=model,
<span class="hljs-meta">... </span>    args=training_args,
<span class="hljs-meta">... </span>    data_collator=data_collator,
<span class="hljs-meta">... </span>    train_dataset=food[<span class="hljs-string">&quot;train&quot;</span>],
<span class="hljs-meta">... </span>    eval_dataset=food[<span class="hljs-string">&quot;test&quot;</span>],
<span class="hljs-meta">... </span>    tokenizer=image_processor,
<span class="hljs-meta">... </span>    compute_metrics=compute_metrics,
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.train()`,wrap:!1}}),G=new W({props:{code:"dHJhaW5lci5wdXNoX3RvX2h1Yigp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>trainer.push_to_hub()',wrap:!1}}),{c(){h(t.$$.fragment),f=r(),e=w("p"),e.innerHTML=i,J=r(),h(C.$$.fragment),R=r(),v=w("p"),v.textContent=Z,Y=r(),I=w("ol"),I.innerHTML=F,V=r(),h($.$$.fragment),x=r(),m=w("p"),m.innerHTML=U,z=r(),h(G.$$.fragment)},l(p){y(t.$$.fragment,p),f=o(p),e=T(p,"P",{"data-svelte-h":!0}),_(e)!=="svelte-uzdbrl"&&(e.innerHTML=i),J=o(p),y(C.$$.fragment,p),R=o(p),v=T(p,"P",{"data-svelte-h":!0}),_(v)!=="svelte-14zzcxs"&&(v.textContent=Z),Y=o(p),I=T(p,"OL",{"data-svelte-h":!0}),_(I)!=="svelte-ciflwy"&&(I.innerHTML=F),V=o(p),y($.$$.fragment,p),x=o(p),m=T(p,"P",{"data-svelte-h":!0}),_(m)!=="svelte-16dqz6f"&&(m.innerHTML=U),z=o(p),y(G.$$.fragment,p)},m(p,d){j(t,p,d),l(p,f,d),l(p,e,d),l(p,J,d),j(C,p,d),l(p,R,d),l(p,v,d),l(p,Y,d),l(p,I,d),l(p,V,d),j($,p,d),l(p,x,d),l(p,m,d),l(p,z,d),j(G,p,d),N=!0},p(p,d){const E={};d&2&&(E.$$scope={dirty:d,ctx:p}),t.$set(E)},i(p){N||(u(t.$$.fragment,p),u(C.$$.fragment,p),u($.$$.fragment,p),u(G.$$.fragment,p),N=!0)},o(p){b(t.$$.fragment,p),b(C.$$.fragment,p),b($.$$.fragment,p),b(G.$$.fragment,p),N=!1},d(p){p&&(a(f),a(e),a(J),a(R),a(v),a(Y),a(I),a(V),a(x),a(m),a(z)),g(t,p),g(C,p),g($,p),g(G,p)}}}function fl(X){let t,f;return t=new Bs({props:{$$slots:{default:[il]},$$scope:{ctx:X}}}),{c(){h(t.$$.fragment)},l(e){y(t.$$.fragment,e)},m(e,i){j(t,e,i),f=!0},p(e,i){const J={};i&2&&(J.$$scope={dirty:i,ctx:e}),t.$set(J)},i(e){f||(u(t.$$.fragment,e),f=!0)},o(e){b(t.$$.fragment,e),f=!1},d(e){g(t,e)}}}function Ml(X){let t,f='Keras를 사용하여 모델을 미세 조정하는 방법에 익숙하지 않은 경우, 먼저 <a href="./training#train-a-tensorflow-model-with-keras">기본 튜토리얼</a>을 확인하세요!';return{c(){t=w("p"),t.innerHTML=f},l(e){t=T(e,"P",{"data-svelte-h":!0}),_(t)!=="svelte-qz0oqm"&&(t.innerHTML=f)},m(e,i){l(e,t,i)},p:fs,d(e){e&&a(t)}}}function hl(X){let t,f,e,i="TensorFlow에서 모델을 미세 조정하려면 다음 단계를 따르세요:",J,C,R="<li>훈련 하이퍼파라미터를 정의하고 옵티마이저와 학습률 스케쥴을 설정합니다.</li> <li>사전 훈련된 모델을 인스턴스화합니다.</li> <li>🤗 Dataset을 <code>tf.data.Dataset</code>으로 변환합니다.</li> <li>모델을 컴파일합니다.</li> <li>콜백을 추가하고 훈련을 수행하기 위해 <code>fit()</code> 메소드를 사용합니다.</li> <li>커뮤니티와 공유하기 위해 모델을 🤗 Hub에 업로드합니다.</li>",v,Z,Y="하이퍼파라미터, 옵티마이저 및 학습률 스케쥴을 정의하는 것으로 시작합니다:",I,F,V,$,x="그런 다음 레이블 매핑과 함께 <code>TFAuto ModelForImageClassification</code>으로 ViT를 가져옵니다:",m,U,z,G,N="데이터 세트를 <code>to_tf_dataset</code>와 <code>data_collator</code>를 사용하여 <code>tf.data.Dataset</code> 형식으로 변환하세요:",p,d,E,M,B="<code>compile()</code>를 사용하여 훈련 모델을 구성하세요:",K,Q,Ms,L,D=`예측에서 정확도를 계산하고 모델을 🤗 Hub로 푸시하려면 <a href="../main_classes/keras_callbacks">Keras callbacks</a>를 사용하세요.
<code>compute_metrics</code> 함수를 <a href="../main_classes/keras_callbacks#transformers.KerasMetricCallback">KerasMetricCallback</a>에 전달하고,
<a href="../main_classes/keras_callbacks#transformers.PushToHubCallback">PushToHubCallback</a>을 사용하여 모델을 업로드합니다:`,O,H,ss,S,Ns=`이제 모델을 훈련할 준비가 되었습니다! 훈련 및 검증 데이터 세트, 에폭 수와 함께 <code>fit()</code>을 호출하고,
콜백을 사용하여 모델을 미세 조정합니다:`,as,q,ls,A,zs="축하합니다! 모델을 미세 조정하고 🤗 Hub에 공유했습니다. 이제 추론에 사용할 수 있습니다!",ts;return t=new $a({props:{$$slots:{default:[Ml]},$$scope:{ctx:X}}}),F=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMGNyZWF0ZV9vcHRpbWl6ZXIlMEElMEFiYXRjaF9zaXplJTIwJTNEJTIwMTYlMEFudW1fZXBvY2hzJTIwJTNEJTIwNSUwQW51bV90cmFpbl9zdGVwcyUyMCUzRCUyMGxlbihmb29kJTVCJTIydHJhaW4lMjIlNUQpJTIwKiUyMG51bV9lcG9jaHMlMEFsZWFybmluZ19yYXRlJTIwJTNEJTIwM2UtNSUwQXdlaWdodF9kZWNheV9yYXRlJTIwJTNEJTIwMC4wMSUwQSUwQW9wdGltaXplciUyQyUyMGxyX3NjaGVkdWxlJTIwJTNEJTIwY3JlYXRlX29wdGltaXplciglMEElMjAlMjAlMjAlMjBpbml0X2xyJTNEbGVhcm5pbmdfcmF0ZSUyQyUwQSUyMCUyMCUyMCUyMG51bV90cmFpbl9zdGVwcyUzRG51bV90cmFpbl9zdGVwcyUyQyUwQSUyMCUyMCUyMCUyMHdlaWdodF9kZWNheV9yYXRlJTNEd2VpZ2h0X2RlY2F5X3JhdGUlMkMlMEElMjAlMjAlMjAlMjBudW1fd2FybXVwX3N0ZXBzJTNEMCUyQyUwQSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> create_optimizer

<span class="hljs-meta">&gt;&gt;&gt; </span>batch_size = <span class="hljs-number">16</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_epochs = <span class="hljs-number">5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>num_train_steps = <span class="hljs-built_in">len</span>(food[<span class="hljs-string">&quot;train&quot;</span>]) * num_epochs
<span class="hljs-meta">&gt;&gt;&gt; </span>learning_rate = <span class="hljs-number">3e-5</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>weight_decay_rate = <span class="hljs-number">0.01</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>optimizer, lr_schedule = create_optimizer(
<span class="hljs-meta">... </span>    init_lr=learning_rate,
<span class="hljs-meta">... </span>    num_train_steps=num_train_steps,
<span class="hljs-meta">... </span>    weight_decay_rate=weight_decay_rate,
<span class="hljs-meta">... </span>    num_warmup_steps=<span class="hljs-number">0</span>,
<span class="hljs-meta">... </span>)`,wrap:!1}}),U=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9ySW1hZ2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JJbWFnZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMEElMjAlMjAlMjAlMjBjaGVja3BvaW50JTJDJTBBJTIwJTIwJTIwJTIwaWQybGFiZWwlM0RpZDJsYWJlbCUyQyUwQSUyMCUyMCUyMCUyMGxhYmVsMmlkJTNEbGFiZWwyaWQlMkMlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(
<span class="hljs-meta">... </span>    checkpoint,
<span class="hljs-meta">... </span>    id2label=id2label,
<span class="hljs-meta">... </span>    label2id=label2id,
<span class="hljs-meta">... </span>)`,wrap:!1}}),d=new W({props:{code:"JTIzJTIwY29udmVydGluZyUyMG91ciUyMHRyYWluJTIwZGF0YXNldCUyMHRvJTIwdGYuZGF0YS5EYXRhc2V0JTBBdGZfdHJhaW5fZGF0YXNldCUyMCUzRCUyMGZvb2QlNUIlMjJ0cmFpbiUyMiU1RC50b190Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGNvbHVtbnMlM0QlMjJwaXhlbF92YWx1ZXMlMjIlMkMlMjBsYWJlbF9jb2xzJTNEJTIybGFiZWwlMjIlMkMlMjBzaHVmZmxlJTNEVHJ1ZSUyQyUyMGJhdGNoX3NpemUlM0RiYXRjaF9zaXplJTJDJTIwY29sbGF0ZV9mbiUzRGRhdGFfY29sbGF0b3IlMEEpJTBBJTBBJTIzJTIwY29udmVydGluZyUyMG91ciUyMHRlc3QlMjBkYXRhc2V0JTIwdG8lMjB0Zi5kYXRhLkRhdGFzZXQlMEF0Zl9ldmFsX2RhdGFzZXQlMjAlM0QlMjBmb29kJTVCJTIydGVzdCUyMiU1RC50b190Zl9kYXRhc2V0KCUwQSUyMCUyMCUyMCUyMGNvbHVtbnMlM0QlMjJwaXhlbF92YWx1ZXMlMjIlMkMlMjBsYWJlbF9jb2xzJTNEJTIybGFiZWwlMjIlMkMlMjBzaHVmZmxlJTNEVHJ1ZSUyQyUyMGJhdGNoX3NpemUlM0RiYXRjaF9zaXplJTJDJTIwY29sbGF0ZV9mbiUzRGRhdGFfY29sbGF0b3IlMEEp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># converting our train dataset to tf.data.Dataset</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_train_dataset = food[<span class="hljs-string">&quot;train&quot;</span>].to_tf_dataset(
<span class="hljs-meta">... </span>    columns=<span class="hljs-string">&quot;pixel_values&quot;</span>, label_cols=<span class="hljs-string">&quot;label&quot;</span>, shuffle=<span class="hljs-literal">True</span>, batch_size=batch_size, collate_fn=data_collator
<span class="hljs-meta">... </span>)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># converting our test dataset to tf.data.Dataset</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>tf_eval_dataset = food[<span class="hljs-string">&quot;test&quot;</span>].to_tf_dataset(
<span class="hljs-meta">... </span>    columns=<span class="hljs-string">&quot;pixel_values&quot;</span>, label_cols=<span class="hljs-string">&quot;label&quot;</span>, shuffle=<span class="hljs-literal">True</span>, batch_size=batch_size, collate_fn=data_collator
<span class="hljs-meta">... </span>)`,wrap:!1}}),Q=new W({props:{code:"ZnJvbSUyMHRlbnNvcmZsb3cua2VyYXMubG9zc2VzJTIwaW1wb3J0JTIwU3BhcnNlQ2F0ZWdvcmljYWxDcm9zc2VudHJvcHklMEElMEFsb3NzJTIwJTNEJTIwdGYua2VyYXMubG9zc2VzLlNwYXJzZUNhdGVnb3JpY2FsQ3Jvc3NlbnRyb3B5KGZyb21fbG9naXRzJTNEVHJ1ZSklMEFtb2RlbC5jb21waWxlKG9wdGltaXplciUzRG9wdGltaXplciUyQyUyMGxvc3MlM0Rsb3NzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> tensorflow.keras.losses <span class="hljs-keyword">import</span> SparseCategoricalCrossentropy

<span class="hljs-meta">&gt;&gt;&gt; </span>loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model.<span class="hljs-built_in">compile</span>(optimizer=optimizer, loss=loss)`,wrap:!1}}),H=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5rZXJhc19jYWxsYmFja3MlMjBpbXBvcnQlMjBLZXJhc01ldHJpY0NhbGxiYWNrJTJDJTIwUHVzaFRvSHViQ2FsbGJhY2slMEElMEFtZXRyaWNfY2FsbGJhY2slMjAlM0QlMjBLZXJhc01ldHJpY0NhbGxiYWNrKG1ldHJpY19mbiUzRGNvbXB1dGVfbWV0cmljcyUyQyUyMGV2YWxfZGF0YXNldCUzRHRmX2V2YWxfZGF0YXNldCklMEFwdXNoX3RvX2h1Yl9jYWxsYmFjayUyMCUzRCUyMFB1c2hUb0h1YkNhbGxiYWNrKCUwQSUyMCUyMCUyMCUyMG91dHB1dF9kaXIlM0QlMjJmb29kX2NsYXNzaWZpZXIlMjIlMkMlMEElMjAlMjAlMjAlMjB0b2tlbml6ZXIlM0RpbWFnZV9wcm9jZXNzb3IlMkMlMEElMjAlMjAlMjAlMjBzYXZlX3N0cmF0ZWd5JTNEJTIybm8lMjIlMkMlMEEpJTBBY2FsbGJhY2tzJTIwJTNEJTIwJTVCbWV0cmljX2NhbGxiYWNrJTJDJTIwcHVzaF90b19odWJfY2FsbGJhY2slNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.keras_callbacks <span class="hljs-keyword">import</span> KerasMetricCallback, PushToHubCallback

<span class="hljs-meta">&gt;&gt;&gt; </span>metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_eval_dataset)
<span class="hljs-meta">&gt;&gt;&gt; </span>push_to_hub_callback = PushToHubCallback(
<span class="hljs-meta">... </span>    output_dir=<span class="hljs-string">&quot;food_classifier&quot;</span>,
<span class="hljs-meta">... </span>    tokenizer=image_processor,
<span class="hljs-meta">... </span>    save_strategy=<span class="hljs-string">&quot;no&quot;</span>,
<span class="hljs-meta">... </span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>callbacks = [metric_callback, push_to_hub_callback]`,wrap:!1}}),q=new W({props:{code:"bW9kZWwuZml0KHRmX3RyYWluX2RhdGFzZXQlMkMlMjB2YWxpZGF0aW9uX2RhdGElM0R0Zl9ldmFsX2RhdGFzZXQlMkMlMjBlcG9jaHMlM0RudW1fZXBvY2hzJTJDJTIwY2FsbGJhY2tzJTNEY2FsbGJhY2tzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>model.fit(tf_train_dataset, validation_data=tf_eval_dataset, epochs=num_epochs, callbacks=callbacks)
Epoch <span class="hljs-number">1</span>/<span class="hljs-number">5</span>
<span class="hljs-number">250</span>/<span class="hljs-number">250</span> [==============================] - 313s 1s/step - loss: <span class="hljs-number">2.5623</span> - val_loss: <span class="hljs-number">1.4161</span> - accuracy: <span class="hljs-number">0.9290</span>
Epoch <span class="hljs-number">2</span>/<span class="hljs-number">5</span>
<span class="hljs-number">250</span>/<span class="hljs-number">250</span> [==============================] - 265s 1s/step - loss: <span class="hljs-number">0.9181</span> - val_loss: <span class="hljs-number">0.6808</span> - accuracy: <span class="hljs-number">0.9690</span>
Epoch <span class="hljs-number">3</span>/<span class="hljs-number">5</span>
<span class="hljs-number">250</span>/<span class="hljs-number">250</span> [==============================] - 252s 1s/step - loss: <span class="hljs-number">0.3910</span> - val_loss: <span class="hljs-number">0.4303</span> - accuracy: <span class="hljs-number">0.9820</span>
Epoch <span class="hljs-number">4</span>/<span class="hljs-number">5</span>
<span class="hljs-number">250</span>/<span class="hljs-number">250</span> [==============================] - 251s 1s/step - loss: <span class="hljs-number">0.2028</span> - val_loss: <span class="hljs-number">0.3191</span> - accuracy: <span class="hljs-number">0.9900</span>
Epoch <span class="hljs-number">5</span>/<span class="hljs-number">5</span>
<span class="hljs-number">250</span>/<span class="hljs-number">250</span> [==============================] - 238s 949ms/step - loss: <span class="hljs-number">0.1232</span> - val_loss: <span class="hljs-number">0.3259</span> - accuracy: <span class="hljs-number">0.9890</span>`,wrap:!1}}),{c(){h(t.$$.fragment),f=r(),e=w("p"),e.textContent=i,J=r(),C=w("ol"),C.innerHTML=R,v=r(),Z=w("p"),Z.textContent=Y,I=r(),h(F.$$.fragment),V=r(),$=w("p"),$.innerHTML=x,m=r(),h(U.$$.fragment),z=r(),G=w("p"),G.innerHTML=N,p=r(),h(d.$$.fragment),E=r(),M=w("p"),M.innerHTML=B,K=r(),h(Q.$$.fragment),Ms=r(),L=w("p"),L.innerHTML=D,O=r(),h(H.$$.fragment),ss=r(),S=w("p"),S.innerHTML=Ns,as=r(),h(q.$$.fragment),ls=r(),A=w("p"),A.textContent=zs},l(c){y(t.$$.fragment,c),f=o(c),e=T(c,"P",{"data-svelte-h":!0}),_(e)!=="svelte-um2evk"&&(e.textContent=i),J=o(c),C=T(c,"OL",{"data-svelte-h":!0}),_(C)!=="svelte-4o84bf"&&(C.innerHTML=R),v=o(c),Z=T(c,"P",{"data-svelte-h":!0}),_(Z)!=="svelte-17oxi9w"&&(Z.textContent=Y),I=o(c),y(F.$$.fragment,c),V=o(c),$=T(c,"P",{"data-svelte-h":!0}),_($)!=="svelte-1s8k4gq"&&($.innerHTML=x),m=o(c),y(U.$$.fragment,c),z=o(c),G=T(c,"P",{"data-svelte-h":!0}),_(G)!=="svelte-f9923k"&&(G.innerHTML=N),p=o(c),y(d.$$.fragment,c),E=o(c),M=T(c,"P",{"data-svelte-h":!0}),_(M)!=="svelte-18yjhtp"&&(M.innerHTML=B),K=o(c),y(Q.$$.fragment,c),Ms=o(c),L=T(c,"P",{"data-svelte-h":!0}),_(L)!=="svelte-g7d2ol"&&(L.innerHTML=D),O=o(c),y(H.$$.fragment,c),ss=o(c),S=T(c,"P",{"data-svelte-h":!0}),_(S)!=="svelte-uh3niq"&&(S.innerHTML=Ns),as=o(c),y(q.$$.fragment,c),ls=o(c),A=T(c,"P",{"data-svelte-h":!0}),_(A)!=="svelte-1trgvwr"&&(A.textContent=zs)},m(c,k){j(t,c,k),l(c,f,k),l(c,e,k),l(c,J,k),l(c,C,k),l(c,v,k),l(c,Z,k),l(c,I,k),j(F,c,k),l(c,V,k),l(c,$,k),l(c,m,k),j(U,c,k),l(c,z,k),l(c,G,k),l(c,p,k),j(d,c,k),l(c,E,k),l(c,M,k),l(c,K,k),j(Q,c,k),l(c,Ms,k),l(c,L,k),l(c,O,k),j(H,c,k),l(c,ss,k),l(c,S,k),l(c,as,k),j(q,c,k),l(c,ls,k),l(c,A,k),ts=!0},p(c,k){const P={};k&2&&(P.$$scope={dirty:k,ctx:c}),t.$set(P)},i(c){ts||(u(t.$$.fragment,c),u(F.$$.fragment,c),u(U.$$.fragment,c),u(d.$$.fragment,c),u(Q.$$.fragment,c),u(H.$$.fragment,c),u(q.$$.fragment,c),ts=!0)},o(c){b(t.$$.fragment,c),b(F.$$.fragment,c),b(U.$$.fragment,c),b(d.$$.fragment,c),b(Q.$$.fragment,c),b(H.$$.fragment,c),b(q.$$.fragment,c),ts=!1},d(c){c&&(a(f),a(e),a(J),a(C),a(v),a(Z),a(I),a(V),a($),a(m),a(z),a(G),a(p),a(E),a(M),a(K),a(Ms),a(L),a(O),a(ss),a(S),a(as),a(ls),a(A)),g(t,c),g(F,c),g(U,c),g(d,c),g(Q,c),g(H,c),g(q,c)}}}function yl(X){let t,f;return t=new Bs({props:{$$slots:{default:[hl]},$$scope:{ctx:X}}}),{c(){h(t.$$.fragment)},l(e){y(t.$$.fragment,e)},m(e,i){j(t,e,i),f=!0},p(e,i){const J={};i&2&&(J.$$scope={dirty:i,ctx:e}),t.$set(J)},i(e){f||(u(t.$$.fragment,e),f=!0)},o(e){b(t.$$.fragment,e),f=!1},d(e){g(t,e)}}}function jl(X){let t,f='이미지 분류를 위한 모델을 미세 조정하는 자세한 예제는 다음 <a href="https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/image_classification.ipynb" rel="nofollow">PyTorch notebook</a>을 참조하세요.';return{c(){t=w("p"),t.innerHTML=f},l(e){t=T(e,"P",{"data-svelte-h":!0}),_(t)!=="svelte-16trkry"&&(t.innerHTML=f)},m(e,i){l(e,t,i)},p:fs,d(e){e&&a(t)}}}function ul(X){let t,f="이미지를 전처리하기 위해 이미지 프로세서를 가져오고 <code>input</code>을 PyTorch 텐서로 반환합니다:",e,i,J,C,R="입력을 모델에 전달하고 logits을 반환합니다:",v,Z,Y,I,F="확률이 가장 높은 예측 레이블을 가져오고, 모델의 <code>id2label</code> 매핑을 사용하여 레이블로 변환합니다:",V,$,x;return i=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQWltcG9ydCUyMHRvcmNoJTBBJTBBaW1hZ2VfcHJvY2Vzc29yJTIwJTNEJTIwQXV0b0ltYWdlUHJvY2Vzc29yLmZyb21fcHJldHJhaW5lZCglMjJteV9hd2Vzb21lX2Zvb2RfbW9kZWwlMjIpJTBBaW5wdXRzJTIwJTNEJTIwaW1hZ2VfcHJvY2Vzc29yKGltYWdlJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;my_awesome_food_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = image_processor(image, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)`,wrap:!1}}),Z=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24lMEElMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvckltYWdlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMm15X2F3ZXNvbWVfZm9vZF9tb2RlbCUyMiklMEF3aXRoJTIwdG9yY2gubm9fZ3JhZCgpJTNBJTBBJTIwJTIwJTIwJTIwbG9naXRzJTIwJTNEJTIwbW9kZWwoKippbnB1dHMpLmxvZ2l0cw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;my_awesome_food_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">with</span> torch.no_grad():
<span class="hljs-meta">... </span>    logits = model(**inputs).logits`,wrap:!1}}),$=new W({props:{code:"cHJlZGljdGVkX2xhYmVsJTIwJTNEJTIwbG9naXRzLmFyZ21heCgtMSkuaXRlbSgpJTBBbW9kZWwuY29uZmlnLmlkMmxhYmVsJTVCcHJlZGljdGVkX2xhYmVsJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_label = logits.argmax(-<span class="hljs-number">1</span>).item()
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.id2label[predicted_label]
<span class="hljs-string">&#x27;beignets&#x27;</span>`,wrap:!1}}),{c(){t=w("p"),t.innerHTML=f,e=r(),h(i.$$.fragment),J=r(),C=w("p"),C.textContent=R,v=r(),h(Z.$$.fragment),Y=r(),I=w("p"),I.innerHTML=F,V=r(),h($.$$.fragment)},l(m){t=T(m,"P",{"data-svelte-h":!0}),_(t)!=="svelte-13azkkh"&&(t.innerHTML=f),e=o(m),y(i.$$.fragment,m),J=o(m),C=T(m,"P",{"data-svelte-h":!0}),_(C)!=="svelte-b607m1"&&(C.textContent=R),v=o(m),y(Z.$$.fragment,m),Y=o(m),I=T(m,"P",{"data-svelte-h":!0}),_(I)!=="svelte-uzshui"&&(I.innerHTML=F),V=o(m),y($.$$.fragment,m)},m(m,U){l(m,t,U),l(m,e,U),j(i,m,U),l(m,J,U),l(m,C,U),l(m,v,U),j(Z,m,U),l(m,Y,U),l(m,I,U),l(m,V,U),j($,m,U),x=!0},p:fs,i(m){x||(u(i.$$.fragment,m),u(Z.$$.fragment,m),u($.$$.fragment,m),x=!0)},o(m){b(i.$$.fragment,m),b(Z.$$.fragment,m),b($.$$.fragment,m),x=!1},d(m){m&&(a(t),a(e),a(J),a(C),a(v),a(Y),a(I),a(V)),g(i,m),g(Z,m),g($,m)}}}function bl(X){let t,f;return t=new Bs({props:{$$slots:{default:[ul]},$$scope:{ctx:X}}}),{c(){h(t.$$.fragment)},l(e){y(t.$$.fragment,e)},m(e,i){j(t,e,i),f=!0},p(e,i){const J={};i&2&&(J.$$scope={dirty:i,ctx:e}),t.$set(J)},i(e){f||(u(t.$$.fragment,e),f=!0)},o(e){b(t.$$.fragment,e),f=!1},d(e){g(t,e)}}}function gl(X){let t,f="이미지를 전처리하기 위해 이미지 프로세서를 가져오고 <code>input</code>을 TensorFlow 텐서로 반환합니다:",e,i,J,C,R="입력을 모델에 전달하고 logits을 반환합니다:",v,Z,Y,I,F="확률이 가장 높은 예측 레이블을 가져오고, 모델의 <code>id2label</code> 매핑을 사용하여 레이블로 변환합니다:",V,$,x;return i=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoJTIyTWFyaWFLJTJGZm9vZF9jbGFzc2lmaWVyJTIyKSUwQWlucHV0cyUyMCUzRCUyMGltYWdlX3Byb2Nlc3NvcihpbWFnZSUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIydGYlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(<span class="hljs-string">&quot;MariaK/food_classifier&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = image_processor(image, return_tensors=<span class="hljs-string">&quot;tf&quot;</span>)`,wrap:!1}}),Z=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMFRGQXV0b01vZGVsRm9ySW1hZ2VDbGFzc2lmaWNhdGlvbiUwQSUwQW1vZGVsJTIwJTNEJTIwVEZBdXRvTW9kZWxGb3JJbWFnZUNsYXNzaWZpY2F0aW9uLmZyb21fcHJldHJhaW5lZCglMjJNYXJpYUslMkZmb29kX2NsYXNzaWZpZXIlMjIpJTBBbG9naXRzJTIwJTNEJTIwbW9kZWwoKippbnB1dHMpLmxvZ2l0cw==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> TFAutoModelForImageClassification

<span class="hljs-meta">&gt;&gt;&gt; </span>model = TFAutoModelForImageClassification.from_pretrained(<span class="hljs-string">&quot;MariaK/food_classifier&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>logits = model(**inputs).logits`,wrap:!1}}),$=new W({props:{code:"cHJlZGljdGVkX2NsYXNzX2lkJTIwJTNEJTIwaW50KHRmLm1hdGguYXJnbWF4KGxvZ2l0cyUyQyUyMGF4aXMlM0QtMSklNUIwJTVEKSUwQW1vZGVsLmNvbmZpZy5pZDJsYWJlbCU1QnByZWRpY3RlZF9jbGFzc19pZCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>predicted_class_id = <span class="hljs-built_in">int</span>(tf.math.argmax(logits, axis=-<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>])
<span class="hljs-meta">&gt;&gt;&gt; </span>model.config.id2label[predicted_class_id]
<span class="hljs-string">&#x27;beignets&#x27;</span>`,wrap:!1}}),{c(){t=w("p"),t.innerHTML=f,e=r(),h(i.$$.fragment),J=r(),C=w("p"),C.textContent=R,v=r(),h(Z.$$.fragment),Y=r(),I=w("p"),I.innerHTML=F,V=r(),h($.$$.fragment)},l(m){t=T(m,"P",{"data-svelte-h":!0}),_(t)!=="svelte-dkxdqj"&&(t.innerHTML=f),e=o(m),y(i.$$.fragment,m),J=o(m),C=T(m,"P",{"data-svelte-h":!0}),_(C)!=="svelte-b607m1"&&(C.textContent=R),v=o(m),y(Z.$$.fragment,m),Y=o(m),I=T(m,"P",{"data-svelte-h":!0}),_(I)!=="svelte-uzshui"&&(I.innerHTML=F),V=o(m),y($.$$.fragment,m)},m(m,U){l(m,t,U),l(m,e,U),j(i,m,U),l(m,J,U),l(m,C,U),l(m,v,U),j(Z,m,U),l(m,Y,U),l(m,I,U),l(m,V,U),j($,m,U),x=!0},p:fs,i(m){x||(u(i.$$.fragment,m),u(Z.$$.fragment,m),u($.$$.fragment,m),x=!0)},o(m){b(i.$$.fragment,m),b(Z.$$.fragment,m),b($.$$.fragment,m),x=!1},d(m){m&&(a(t),a(e),a(J),a(C),a(v),a(Y),a(I),a(V)),g(i,m),g(Z,m),g($,m)}}}function dl(X){let t,f;return t=new Bs({props:{$$slots:{default:[gl]},$$scope:{ctx:X}}}),{c(){h(t.$$.fragment)},l(e){y(t.$$.fragment,e)},m(e,i){j(t,e,i),f=!0},p(e,i){const J={};i&2&&(J.$$scope={dirty:i,ctx:e}),t.$set(J)},i(e){f||(u(t.$$.fragment,e),f=!0)},o(e){b(t.$$.fragment,e),f=!1},d(e){g(t,e)}}}function Jl(X){let t,f,e,i,J,C,R,v,Z,Y,I,F=`이미지 분류는 이미지에 레이블 또는 클래스를 할당합니다. 텍스트 또는 오디오 분류와 달리 입력은
이미지를 구성하는 픽셀 값입니다. 이미지 분류에는 자연재해 후 피해 감지, 농작물 건강 모니터링, 의료 이미지에서 질병의 징후 검사 지원 등
다양한 응용 사례가 있습니다.`,V,$,x="이 가이드에서는 다음을 설명합니다:",m,U,z='<li><a href="https://huggingface.co/datasets/food101" rel="nofollow">Food-101</a> 데이터 세트에서 <a href="model_doc/vit">ViT</a>를 미세 조정하여 이미지에서 식품 항목을 분류합니다.</li> <li>추론을 위해 미세 조정 모델을 사용합니다.</li>',G,N,p,d,E="시작하기 전에, 필요한 모든 라이브러리가 설치되어 있는지 확인하세요:",M,B,K,Q,Ms="Hugging Face 계정에 로그인하여 모델을 업로드하고 커뮤니티에 공유하는 것을 권장합니다. 메시지가 표시되면, 토큰을 입력하여 로그인하세요:",L,D,O,H,ss,S,Ns=`🤗 Datasets 라이브러리에서 Food-101 데이터 세트의 더 작은 부분 집합을 가져오는 것으로 시작합니다. 이렇게 하면 전체 데이터 세트에 대한
훈련에 많은 시간을 할애하기 전에 실험을 통해 모든 것이 제대로 작동하는지 확인할 수 있습니다.`,as,q,ls,A,zs="데이터 세트의 <code>train</code>을 <code>train_test_split</code> 메소드를 사용하여 훈련 및 테스트 세트로 분할하세요:",ts,c,k,P,_a="그리고 예시를 살펴보세요:",Qs,hs,Hs,ys,Za="데이터 세트의 각 예제에는 두 개의 필드가 있습니다:",Ss,js,Ca="<li><code>image</code>: 식품 항목의 PIL 이미지</li> <li><code>label</code>: 식품 항목의 레이블 클래스</li>",qs,us,Ia=`모델이 레이블 ID에서 레이블 이름을 쉽게 가져올 수 있도록
레이블 이름을 정수로 매핑하고, 정수를 레이블 이름으로 매핑하는 사전을 만드세요:`,As,bs,Ls,gs,ka="이제 레이블 ID를 레이블 이름으로 변환할 수 있습니다:",Ds,ds,Ps,Js,Ks,ws,va="다음 단계는 이미지를 텐서로 처리하기 위해 ViT 이미지 프로세서를 가져오는 것입니다:",Os,Ts,sa,es,aa,ns,la,$s,ta,Us,Ga=`훈련 중에 평가 지표를 포함하면 모델의 성능을 평가하는 데 도움이 되는 경우가 많습니다.
🤗 <a href="https://huggingface.co/docs/evaluate/index" rel="nofollow">Evaluate</a> 라이브러리로 평가 방법을 빠르게 가져올 수 있습니다. 이 작업에서는
<a href="https://huggingface.co/spaces/evaluate-metric/accuracy" rel="nofollow">accuracy</a> 평가 지표를 가져옵니다. (🤗 Evaluate <a href="https://huggingface.co/docs/evaluate/a_quick_tour" rel="nofollow">빠른 둘러보기</a>를 참조하여 평가 지표를 가져오고 계산하는 방법에 대해 자세히 알아보세요):`,ea,_s,na,Zs,Wa="그런 다음 예측과 레이블을 <code>compute</code>에 전달하여 정확도를 계산하는 함수를 만듭니다:",pa,Cs,ma,Is,Xa="이제 <code>compute_metrics</code> 함수를 사용할 준비가 되었으며, 훈련을 설정하면 이 함수로 되돌아올 것입니다.",ca,ks,ra,ps,oa,ms,ia,cs,fa,vs,Ma,Gs,Va="좋아요, 이제 모델을 미세 조정했으니 추론에 사용할 수 있습니다!",ha,Ws,Ra="추론을 수행하고자 하는 이미지를 가져와봅시다:",ya,Xs,ja,rs,Ya='<img src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png" alt="image of beignets"/>',ua,Vs,Fa="미세 조정 모델로 추론을 시도하는 가장 간단한 방법은 <code>pipeline()</code>을 사용하는 것입니다. 모델로 이미지 분류를 위한 <code>pipeline</code>을 인스턴스화하고 이미지를 전달합니다:",ba,Rs,ga,Ys,xa="원한다면, <code>pipeline</code>의 결과를 수동으로 복제할 수도 있습니다:",da,os,Ja,is,wa,Es,Ta;return J=new xs({props:{title:"이미지 분류",local:"image-classification",headingTag:"h1"}}),R=new el({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/image_classification.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/image_classification.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/image_classification.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/image_classification.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/image_classification.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/image_classification.ipynb"}]}}),Z=new tl({props:{id:"tjAIM7BOYhw"}}),N=new $a({props:{$$slots:{default:[nl]},$$scope:{ctx:X}}}),B=new W({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyUyMGRhdGFzZXRzJTIwZXZhbHVhdGU=",highlighted:"pip install transformers datasets evaluate",wrap:!1}}),D=new W({props:{code:"ZnJvbSUyMGh1Z2dpbmdmYWNlX2h1YiUyMGltcG9ydCUyMG5vdGVib29rX2xvZ2luJTBBJTBBbm90ZWJvb2tfbG9naW4oKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> huggingface_hub <span class="hljs-keyword">import</span> notebook_login

<span class="hljs-meta">&gt;&gt;&gt; </span>notebook_login()`,wrap:!1}}),H=new xs({props:{title:"Food-101 데이터 세트 가져오기",local:"load-food101-dataset",headingTag:"h2"}}),q=new W({props:{code:"ZnJvbSUyMGRhdGFzZXRzJTIwaW1wb3J0JTIwbG9hZF9kYXRhc2V0JTBBJTBBZm9vZCUyMCUzRCUyMGxvYWRfZGF0YXNldCglMjJmb29kMTAxJTIyJTJDJTIwc3BsaXQlM0QlMjJ0cmFpbiU1QiUzQTUwMDAlNUQlMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset

<span class="hljs-meta">&gt;&gt;&gt; </span>food = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;train[:5000]&quot;</span>)`,wrap:!1}}),c=new W({props:{code:"Zm9vZCUyMCUzRCUyMGZvb2QudHJhaW5fdGVzdF9zcGxpdCh0ZXN0X3NpemUlM0QwLjIp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>food = food.train_test_split(test_size=<span class="hljs-number">0.2</span>)',wrap:!1}}),hs=new W({props:{code:"Zm9vZCU1QiUyMnRyYWluJTIyJTVEJTVCMCU1RA==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>food[<span class="hljs-string">&quot;train&quot;</span>][<span class="hljs-number">0</span>]
{<span class="hljs-string">&#x27;image&#x27;</span>: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=512x512 at <span class="hljs-number">0x7F52AFC8AC50</span>&gt;,
 <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-number">79</span>}`,wrap:!1}}),bs=new W({props:{code:"bGFiZWxzJTIwJTNEJTIwZm9vZCU1QiUyMnRyYWluJTIyJTVELmZlYXR1cmVzJTVCJTIybGFiZWwlMjIlNUQubmFtZXMlMEFsYWJlbDJpZCUyQyUyMGlkMmxhYmVsJTIwJTNEJTIwZGljdCgpJTJDJTIwZGljdCgpJTBBZm9yJTIwaSUyQyUyMGxhYmVsJTIwaW4lMjBlbnVtZXJhdGUobGFiZWxzKSUzQSUwQSUyMCUyMCUyMCUyMGxhYmVsMmlkJTVCbGFiZWwlNUQlMjAlM0QlMjBzdHIoaSklMEElMjAlMjAlMjAlMjBpZDJsYWJlbCU1QnN0cihpKSU1RCUyMCUzRCUyMGxhYmVs",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>labels = food[<span class="hljs-string">&quot;train&quot;</span>].features[<span class="hljs-string">&quot;label&quot;</span>].names
<span class="hljs-meta">&gt;&gt;&gt; </span>label2id, id2label = <span class="hljs-built_in">dict</span>(), <span class="hljs-built_in">dict</span>()
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">for</span> i, label <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(labels):
<span class="hljs-meta">... </span>    label2id[label] = <span class="hljs-built_in">str</span>(i)
<span class="hljs-meta">... </span>    id2label[<span class="hljs-built_in">str</span>(i)] = label`,wrap:!1}}),ds=new W({props:{code:"aWQybGFiZWwlNUJzdHIoNzkpJTVE",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>id2label[<span class="hljs-built_in">str</span>(<span class="hljs-number">79</span>)]
<span class="hljs-string">&#x27;prime_rib&#x27;</span>`,wrap:!1}}),Js=new xs({props:{title:"전처리",local:"preprocess",headingTag:"h2"}}),Ts=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9JbWFnZVByb2Nlc3NvciUwQSUwQWNoZWNrcG9pbnQlMjAlM0QlMjAlMjJnb29nbGUlMkZ2aXQtYmFzZS1wYXRjaDE2LTIyNC1pbjIxayUyMiUwQWltYWdlX3Byb2Nlc3NvciUyMCUzRCUyMEF1dG9JbWFnZVByb2Nlc3Nvci5mcm9tX3ByZXRyYWluZWQoY2hlY2twb2ludCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoImageProcessor

<span class="hljs-meta">&gt;&gt;&gt; </span>checkpoint = <span class="hljs-string">&quot;google/vit-base-patch16-224-in21k&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>image_processor = AutoImageProcessor.from_pretrained(checkpoint)`,wrap:!1}}),es=new Fs({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[ml]},$$scope:{ctx:X}}}),ns=new Fs({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[rl]},$$scope:{ctx:X}}}),$s=new xs({props:{title:"평가",local:"evaluate",headingTag:"h2"}}),_s=new W({props:{code:"aW1wb3J0JTIwZXZhbHVhdGUlMEElMEFhY2N1cmFjeSUyMCUzRCUyMGV2YWx1YXRlLmxvYWQoJTIyYWNjdXJhY3klMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> evaluate

<span class="hljs-meta">&gt;&gt;&gt; </span>accuracy = evaluate.load(<span class="hljs-string">&quot;accuracy&quot;</span>)`,wrap:!1}}),Cs=new W({props:{code:"aW1wb3J0JTIwbnVtcHklMjBhcyUyMG5wJTBBJTBBJTBBZGVmJTIwY29tcHV0ZV9tZXRyaWNzKGV2YWxfcHJlZCklM0ElMEElMjAlMjAlMjAlMjBwcmVkaWN0aW9ucyUyQyUyMGxhYmVscyUyMCUzRCUyMGV2YWxfcHJlZCUwQSUyMCUyMCUyMCUyMHByZWRpY3Rpb25zJTIwJTNEJTIwbnAuYXJnbWF4KHByZWRpY3Rpb25zJTJDJTIwYXhpcyUzRDEpJTBBJTIwJTIwJTIwJTIwcmV0dXJuJTIwYWNjdXJhY3kuY29tcHV0ZShwcmVkaWN0aW9ucyUzRHByZWRpY3Rpb25zJTJDJTIwcmVmZXJlbmNlcyUzRGxhYmVscyk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np


<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
<span class="hljs-meta">... </span>    predictions, labels = eval_pred
<span class="hljs-meta">... </span>    predictions = np.argmax(predictions, axis=<span class="hljs-number">1</span>)
<span class="hljs-meta">... </span>    <span class="hljs-keyword">return</span> accuracy.compute(predictions=predictions, references=labels)`,wrap:!1}}),ks=new xs({props:{title:"훈련",local:"train",headingTag:"h2"}}),ps=new Fs({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[fl]},$$scope:{ctx:X}}}),ms=new Fs({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[yl]},$$scope:{ctx:X}}}),cs=new $a({props:{$$slots:{default:[jl]},$$scope:{ctx:X}}}),vs=new xs({props:{title:"추론",local:"inference",headingTag:"h2"}}),Xs=new W({props:{code:"ZHMlMjAlM0QlMjBsb2FkX2RhdGFzZXQoJTIyZm9vZDEwMSUyMiUyQyUyMHNwbGl0JTNEJTIydmFsaWRhdGlvbiU1QiUzQTEwJTVEJTIyKSUwQWltYWdlJTIwJTNEJTIwZHMlNUIlMjJpbWFnZSUyMiU1RCU1QjAlNUQ=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>ds = load_dataset(<span class="hljs-string">&quot;food101&quot;</span>, split=<span class="hljs-string">&quot;validation[:10]&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>image = ds[<span class="hljs-string">&quot;image&quot;</span>][<span class="hljs-number">0</span>]`,wrap:!1}}),Rs=new W({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMHBpcGVsaW5lJTBBJTBBY2xhc3NpZmllciUyMCUzRCUyMHBpcGVsaW5lKCUyMmltYWdlLWNsYXNzaWZpY2F0aW9uJTIyJTJDJTIwbW9kZWwlM0QlMjJteV9hd2Vzb21lX2Zvb2RfbW9kZWwlMjIpJTBBY2xhc3NpZmllcihpbWFnZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> pipeline

<span class="hljs-meta">&gt;&gt;&gt; </span>classifier = pipeline(<span class="hljs-string">&quot;image-classification&quot;</span>, model=<span class="hljs-string">&quot;my_awesome_food_model&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>classifier(image)
[{<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.31856709718704224</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;beignets&#x27;</span>},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.015232225880026817</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;bruschetta&#x27;</span>},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.01519392803311348</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;chicken_wings&#x27;</span>},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.013022331520915031</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;pork_chop&#x27;</span>},
 {<span class="hljs-string">&#x27;score&#x27;</span>: <span class="hljs-number">0.012728818692266941</span>, <span class="hljs-string">&#x27;label&#x27;</span>: <span class="hljs-string">&#x27;prime_rib&#x27;</span>}]`,wrap:!1}}),os=new Fs({props:{pytorch:!0,tensorflow:!1,jax:!1,$$slots:{pytorch:[bl]},$$scope:{ctx:X}}}),is=new Fs({props:{pytorch:!1,tensorflow:!0,jax:!1,$$slots:{tensorflow:[dl]},$$scope:{ctx:X}}}),{c(){t=w("meta"),f=r(),e=w("p"),i=r(),h(J.$$.fragment),C=r(),h(R.$$.fragment),v=r(),h(Z.$$.fragment),Y=r(),I=w("p"),I.textContent=F,V=r(),$=w("p"),$.textContent=x,m=r(),U=w("ol"),U.innerHTML=z,G=r(),h(N.$$.fragment),p=r(),d=w("p"),d.textContent=E,M=r(),h(B.$$.fragment),K=r(),Q=w("p"),Q.textContent=Ms,L=r(),h(D.$$.fragment),O=r(),h(H.$$.fragment),ss=r(),S=w("p"),S.textContent=Ns,as=r(),h(q.$$.fragment),ls=r(),A=w("p"),A.innerHTML=zs,ts=r(),h(c.$$.fragment),k=r(),P=w("p"),P.textContent=_a,Qs=r(),h(hs.$$.fragment),Hs=r(),ys=w("p"),ys.textContent=Za,Ss=r(),js=w("ul"),js.innerHTML=Ca,qs=r(),us=w("p"),us.textContent=Ia,As=r(),h(bs.$$.fragment),Ls=r(),gs=w("p"),gs.textContent=ka,Ds=r(),h(ds.$$.fragment),Ps=r(),h(Js.$$.fragment),Ks=r(),ws=w("p"),ws.textContent=va,Os=r(),h(Ts.$$.fragment),sa=r(),h(es.$$.fragment),aa=r(),h(ns.$$.fragment),la=r(),h($s.$$.fragment),ta=r(),Us=w("p"),Us.innerHTML=Ga,ea=r(),h(_s.$$.fragment),na=r(),Zs=w("p"),Zs.innerHTML=Wa,pa=r(),h(Cs.$$.fragment),ma=r(),Is=w("p"),Is.innerHTML=Xa,ca=r(),h(ks.$$.fragment),ra=r(),h(ps.$$.fragment),oa=r(),h(ms.$$.fragment),ia=r(),h(cs.$$.fragment),fa=r(),h(vs.$$.fragment),Ma=r(),Gs=w("p"),Gs.textContent=Va,ha=r(),Ws=w("p"),Ws.textContent=Ra,ya=r(),h(Xs.$$.fragment),ja=r(),rs=w("div"),rs.innerHTML=Ya,ua=r(),Vs=w("p"),Vs.innerHTML=Fa,ba=r(),h(Rs.$$.fragment),ga=r(),Ys=w("p"),Ys.innerHTML=xa,da=r(),h(os.$$.fragment),Ja=r(),h(is.$$.fragment),wa=r(),Es=w("p"),this.h()},l(s){const n=Oa("svelte-u9bgzb",document.head);t=T(n,"META",{name:!0,content:!0}),n.forEach(a),f=o(s),e=T(s,"P",{}),Aa(e).forEach(a),i=o(s),y(J.$$.fragment,s),C=o(s),y(R.$$.fragment,s),v=o(s),y(Z.$$.fragment,s),Y=o(s),I=T(s,"P",{"data-svelte-h":!0}),_(I)!=="svelte-1op3s0b"&&(I.textContent=F),V=o(s),$=T(s,"P",{"data-svelte-h":!0}),_($)!=="svelte-19dumbs"&&($.textContent=x),m=o(s),U=T(s,"OL",{"data-svelte-h":!0}),_(U)!=="svelte-93mkx2"&&(U.innerHTML=z),G=o(s),y(N.$$.fragment,s),p=o(s),d=T(s,"P",{"data-svelte-h":!0}),_(d)!=="svelte-1bc8bfk"&&(d.textContent=E),M=o(s),y(B.$$.fragment,s),K=o(s),Q=T(s,"P",{"data-svelte-h":!0}),_(Q)!=="svelte-1hhyu5y"&&(Q.textContent=Ms),L=o(s),y(D.$$.fragment,s),O=o(s),y(H.$$.fragment,s),ss=o(s),S=T(s,"P",{"data-svelte-h":!0}),_(S)!=="svelte-k4g7mc"&&(S.textContent=Ns),as=o(s),y(q.$$.fragment,s),ls=o(s),A=T(s,"P",{"data-svelte-h":!0}),_(A)!=="svelte-1amyql0"&&(A.innerHTML=zs),ts=o(s),y(c.$$.fragment,s),k=o(s),P=T(s,"P",{"data-svelte-h":!0}),_(P)!=="svelte-1rb3v2y"&&(P.textContent=_a),Qs=o(s),y(hs.$$.fragment,s),Hs=o(s),ys=T(s,"P",{"data-svelte-h":!0}),_(ys)!=="svelte-7crmck"&&(ys.textContent=Za),Ss=o(s),js=T(s,"UL",{"data-svelte-h":!0}),_(js)!=="svelte-yxm734"&&(js.innerHTML=Ca),qs=o(s),us=T(s,"P",{"data-svelte-h":!0}),_(us)!=="svelte-1lustc3"&&(us.textContent=Ia),As=o(s),y(bs.$$.fragment,s),Ls=o(s),gs=T(s,"P",{"data-svelte-h":!0}),_(gs)!=="svelte-135k07i"&&(gs.textContent=ka),Ds=o(s),y(ds.$$.fragment,s),Ps=o(s),y(Js.$$.fragment,s),Ks=o(s),ws=T(s,"P",{"data-svelte-h":!0}),_(ws)!=="svelte-1x7s0ft"&&(ws.textContent=va),Os=o(s),y(Ts.$$.fragment,s),sa=o(s),y(es.$$.fragment,s),aa=o(s),y(ns.$$.fragment,s),la=o(s),y($s.$$.fragment,s),ta=o(s),Us=T(s,"P",{"data-svelte-h":!0}),_(Us)!=="svelte-h5ivt1"&&(Us.innerHTML=Ga),ea=o(s),y(_s.$$.fragment,s),na=o(s),Zs=T(s,"P",{"data-svelte-h":!0}),_(Zs)!=="svelte-tpx6n8"&&(Zs.innerHTML=Wa),pa=o(s),y(Cs.$$.fragment,s),ma=o(s),Is=T(s,"P",{"data-svelte-h":!0}),_(Is)!=="svelte-1tfmmd0"&&(Is.innerHTML=Xa),ca=o(s),y(ks.$$.fragment,s),ra=o(s),y(ps.$$.fragment,s),oa=o(s),y(ms.$$.fragment,s),ia=o(s),y(cs.$$.fragment,s),fa=o(s),y(vs.$$.fragment,s),Ma=o(s),Gs=T(s,"P",{"data-svelte-h":!0}),_(Gs)!=="svelte-1annmqf"&&(Gs.textContent=Va),ha=o(s),Ws=T(s,"P",{"data-svelte-h":!0}),_(Ws)!=="svelte-gvr8fy"&&(Ws.textContent=Ra),ya=o(s),y(Xs.$$.fragment,s),ja=o(s),rs=T(s,"DIV",{class:!0,"data-svelte-h":!0}),_(rs)!=="svelte-pnh0xy"&&(rs.innerHTML=Ya),ua=o(s),Vs=T(s,"P",{"data-svelte-h":!0}),_(Vs)!=="svelte-7ivah3"&&(Vs.innerHTML=Fa),ba=o(s),y(Rs.$$.fragment,s),ga=o(s),Ys=T(s,"P",{"data-svelte-h":!0}),_(Ys)!=="svelte-1smgeha"&&(Ys.innerHTML=xa),da=o(s),y(os.$$.fragment,s),Ja=o(s),y(is.$$.fragment,s),wa=o(s),Es=T(s,"P",{}),Aa(Es).forEach(a),this.h()},h(){Ua(t,"name","hf:doc:metadata"),Ua(t,"content",wl),Ua(rs,"class","flex justify-center")},m(s,n){sl(document.head,t),l(s,f,n),l(s,e,n),l(s,i,n),j(J,s,n),l(s,C,n),j(R,s,n),l(s,v,n),j(Z,s,n),l(s,Y,n),l(s,I,n),l(s,V,n),l(s,$,n),l(s,m,n),l(s,U,n),l(s,G,n),j(N,s,n),l(s,p,n),l(s,d,n),l(s,M,n),j(B,s,n),l(s,K,n),l(s,Q,n),l(s,L,n),j(D,s,n),l(s,O,n),j(H,s,n),l(s,ss,n),l(s,S,n),l(s,as,n),j(q,s,n),l(s,ls,n),l(s,A,n),l(s,ts,n),j(c,s,n),l(s,k,n),l(s,P,n),l(s,Qs,n),j(hs,s,n),l(s,Hs,n),l(s,ys,n),l(s,Ss,n),l(s,js,n),l(s,qs,n),l(s,us,n),l(s,As,n),j(bs,s,n),l(s,Ls,n),l(s,gs,n),l(s,Ds,n),j(ds,s,n),l(s,Ps,n),j(Js,s,n),l(s,Ks,n),l(s,ws,n),l(s,Os,n),j(Ts,s,n),l(s,sa,n),j(es,s,n),l(s,aa,n),j(ns,s,n),l(s,la,n),j($s,s,n),l(s,ta,n),l(s,Us,n),l(s,ea,n),j(_s,s,n),l(s,na,n),l(s,Zs,n),l(s,pa,n),j(Cs,s,n),l(s,ma,n),l(s,Is,n),l(s,ca,n),j(ks,s,n),l(s,ra,n),j(ps,s,n),l(s,oa,n),j(ms,s,n),l(s,ia,n),j(cs,s,n),l(s,fa,n),j(vs,s,n),l(s,Ma,n),l(s,Gs,n),l(s,ha,n),l(s,Ws,n),l(s,ya,n),j(Xs,s,n),l(s,ja,n),l(s,rs,n),l(s,ua,n),l(s,Vs,n),l(s,ba,n),j(Rs,s,n),l(s,ga,n),l(s,Ys,n),l(s,da,n),j(os,s,n),l(s,Ja,n),j(is,s,n),l(s,wa,n),l(s,Es,n),Ta=!0},p(s,[n]){const Ba={};n&2&&(Ba.$$scope={dirty:n,ctx:s}),N.$set(Ba);const Na={};n&2&&(Na.$$scope={dirty:n,ctx:s}),es.$set(Na);const za={};n&2&&(za.$$scope={dirty:n,ctx:s}),ns.$set(za);const Ea={};n&2&&(Ea.$$scope={dirty:n,ctx:s}),ps.$set(Ea);const Qa={};n&2&&(Qa.$$scope={dirty:n,ctx:s}),ms.$set(Qa);const Ha={};n&2&&(Ha.$$scope={dirty:n,ctx:s}),cs.$set(Ha);const Sa={};n&2&&(Sa.$$scope={dirty:n,ctx:s}),os.$set(Sa);const qa={};n&2&&(qa.$$scope={dirty:n,ctx:s}),is.$set(qa)},i(s){Ta||(u(J.$$.fragment,s),u(R.$$.fragment,s),u(Z.$$.fragment,s),u(N.$$.fragment,s),u(B.$$.fragment,s),u(D.$$.fragment,s),u(H.$$.fragment,s),u(q.$$.fragment,s),u(c.$$.fragment,s),u(hs.$$.fragment,s),u(bs.$$.fragment,s),u(ds.$$.fragment,s),u(Js.$$.fragment,s),u(Ts.$$.fragment,s),u(es.$$.fragment,s),u(ns.$$.fragment,s),u($s.$$.fragment,s),u(_s.$$.fragment,s),u(Cs.$$.fragment,s),u(ks.$$.fragment,s),u(ps.$$.fragment,s),u(ms.$$.fragment,s),u(cs.$$.fragment,s),u(vs.$$.fragment,s),u(Xs.$$.fragment,s),u(Rs.$$.fragment,s),u(os.$$.fragment,s),u(is.$$.fragment,s),Ta=!0)},o(s){b(J.$$.fragment,s),b(R.$$.fragment,s),b(Z.$$.fragment,s),b(N.$$.fragment,s),b(B.$$.fragment,s),b(D.$$.fragment,s),b(H.$$.fragment,s),b(q.$$.fragment,s),b(c.$$.fragment,s),b(hs.$$.fragment,s),b(bs.$$.fragment,s),b(ds.$$.fragment,s),b(Js.$$.fragment,s),b(Ts.$$.fragment,s),b(es.$$.fragment,s),b(ns.$$.fragment,s),b($s.$$.fragment,s),b(_s.$$.fragment,s),b(Cs.$$.fragment,s),b(ks.$$.fragment,s),b(ps.$$.fragment,s),b(ms.$$.fragment,s),b(cs.$$.fragment,s),b(vs.$$.fragment,s),b(Xs.$$.fragment,s),b(Rs.$$.fragment,s),b(os.$$.fragment,s),b(is.$$.fragment,s),Ta=!1},d(s){s&&(a(f),a(e),a(i),a(C),a(v),a(Y),a(I),a(V),a($),a(m),a(U),a(G),a(p),a(d),a(M),a(K),a(Q),a(L),a(O),a(ss),a(S),a(as),a(ls),a(A),a(ts),a(k),a(P),a(Qs),a(Hs),a(ys),a(Ss),a(js),a(qs),a(us),a(As),a(Ls),a(gs),a(Ds),a(Ps),a(Ks),a(ws),a(Os),a(sa),a(aa),a(la),a(ta),a(Us),a(ea),a(na),a(Zs),a(pa),a(ma),a(Is),a(ca),a(ra),a(oa),a(ia),a(fa),a(Ma),a(Gs),a(ha),a(Ws),a(ya),a(ja),a(rs),a(ua),a(Vs),a(ba),a(ga),a(Ys),a(da),a(Ja),a(wa),a(Es)),a(t),g(J,s),g(R,s),g(Z,s),g(N,s),g(B,s),g(D,s),g(H,s),g(q,s),g(c,s),g(hs,s),g(bs,s),g(ds,s),g(Js,s),g(Ts,s),g(es,s),g(ns,s),g($s,s),g(_s,s),g(Cs,s),g(ks,s),g(ps,s),g(ms,s),g(cs,s),g(vs,s),g(Xs,s),g(Rs,s),g(os,s),g(is,s)}}}const wl='{"title":"이미지 분류","local":"image-classification","sections":[{"title":"Food-101 데이터 세트 가져오기","local":"load-food101-dataset","sections":[],"depth":2},{"title":"전처리","local":"preprocess","sections":[],"depth":2},{"title":"평가","local":"evaluate","sections":[],"depth":2},{"title":"훈련","local":"train","sections":[],"depth":2},{"title":"추론","local":"inference","sections":[],"depth":2}],"depth":1}';function Tl(X){return Da(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class Gl extends Pa{constructor(t){super(),Ka(this,t,Tl,Jl,La,{})}}export{Gl as component};
