import{s as he,n as _e,o as de}from"../chunks/scheduler.56730f09.js";import{S as xe,i as ve,g as a,s as n,r as ae,A as Te,h as o,f as l,c as s,j as oe,u as re,x as r,k as X,y as Le,a as i,v as fe,d as pe,t as ce,w as ue}from"../chunks/index.1f144517.js";import{H as me}from"../chunks/Heading.57d46534.js";function we(Y){let f,$,P,g,c,b,u,B="🤗 Transformers는 다음과 같은 목적으로 만들어진 독자적인 라이브러리입니다:",k,m,D="<li>대규모 Transformers 모델을 사용하거나 연구하거나 확장하려는 기계 학습 연구원 및 교육자를 위한 것입니다.</li> <li>모델을 미세 조정하거나 제작용으로 사용하고자 하는 실전 개발자를 위한 것입니다.</li> <li>특정 기계 학습 작업을 해결하기 위해 사전훈련된 모델을 다운로드하고 사용하기만 하려는 엔지니어를 위한 것입니다.</li>",F,h,G="이 라이브러리는 두 가지 주요 목표를 가지고 설계되었습니다:",U,_,Q="<li>사용하기 쉽고 빠르게 만드는 것:</li>",z,d,V='<li>학습해야 할 사용자 대상 추상화의 수를 제한했습니다. 실제로 거의 추상화가 없으며, 각 모델을 사용하기 위해 필요한 세 가지 표준 클래스인 <a href="main_classes/configuration">configuration</a>, <a href="main_classes/model">models</a> 및 전처리 클래스인 (<a href="main_classes/tokenizer">tokenizer</a>는 NLP용, <a href="main_classes/image_processor">image processor</a>는 비전용, <a href="main_classes/feature_extractor">feature extractor</a>는 오디오용, <a href="main_classes/processors">processor</a>는 멀티모달 입력용)만 사용합니다.</li> <li>이러한 클래스는 공통적인 <code>from_pretrained()</code> 메서드를 사용하여 미리 훈련된 인스턴스에서 간단하고 통일된 방식으로 초기화할 수 있습니다. 이 메소드는 미리 훈련된 체크포인트에서 관련 클래스 인스턴스와 관련 데이터(구성의 하이퍼파라미터, 토크나이저의 어휘, 모델의 가중치)를 (필요한 경우) 다운로드하고 캐시하며 가져옵니다. 체크포인트는 <a href="https://huggingface.co/models" rel="nofollow">Hugging Face Hub</a>에서 제공되거나 사용자 자체의 저장된 체크포인트에서 제공됩니다.</li> <li>이 세 가지 기본 클래스 위에 라이브러리는 <code>pipeline()</code> API를 제공하여 주어진 작업에 대해 모델을 빠르게 추론하는 데 사용하고, <code>Trainer</code>를 제공하여 PyTorch 모델을 빠르게 훈련하거나 미세 조정할 수 있도록 합니다(모든 TensorFlow 모델은 <code>Keras.fit</code>과 호환됩니다).</li> <li>결과적으로, 이 라이브러리는 신경망을 구축하기 위한 모듈식 도구 상자가 아닙니다. 라이브러리를 확장하거나 구축하려면 일반적인 Python, PyTorch, TensorFlow, Keras 모듈을 사용하고 라이브러리의 기본 클래스를 상속하여 모델 로딩 및 저장과 같은 기능을 재사용하면 됩니다. 모델에 대한 코딩 철학에 대해 더 자세히 알고 싶다면 <a href="https://huggingface.co/blog/transformers-design-philosophy" rel="nofollow">Repeat Yourself</a> 블로그 글을 확인해보세요.</li>',A,p,W="<li>원래 모델과 가능한 한 근접한 성능을 제공하는 최신 모델을 제공하는 것:</li>",q,x,Z="<li>각 아키텍처에 대해 공식 저자가 제공한 결과를 재현하는 적어도 한 가지 예제를 제공합니다.</li> <li>코드는 원래 코드와 가능한 한 유사하게 유지되므로 PyTorch 코드는 TensorFlow 코드로 변환되어 <em>pytorchic</em>하지 않을 수 있고, 그 반대의 경우도 마찬가지입니다.</li>",E,v,ee="기타 목표 몇 가지:",I,T,te="<li><p>모델의 내부를 가능한 일관되게 노출시키기:</p> <ul><li>전체 은닉 상태와 어텐션 가중치에 대한 액세스를 단일 API를 사용하여 제공합니다.</li> <li>전처리 클래스 및 기본 모델 API는 모델 간에 쉽게 전환할 수 있도록 표준화되어 있습니다.</li></ul></li> <li><p>미세 조정 및 모델 탐색을 위한 유망한 도구들을 주관적으로 선택하기:</p> <ul><li>미세 조정을 위해 어휘 및 임베딩에 새로운 토큰을 간단하고 일관된 방식으로 추가하는 방법을 제공합니다.</li> <li>Transformer 헤드를 마스킹하고 가지치기하는 간단한 방법을 제공합니다.</li></ul></li> <li><p>PyTorch, TensorFlow 2.0 및 Flax 간에 쉽게 전환할 수 있도록 하여 하나의 프레임워크로 훈련하고 다른 프레임워크로 추론할 수 있게 합니다.</p></li>",K,L,S,w,le="이 라이브러리는 각 모델에 대해 세 가지 유형의 클래스를 기반으로 구축되었습니다:",j,C,ie='<li><strong>모델 클래스</strong>는 라이브러리에서 제공하는 사전 훈련된 가중치와 함께 작동하는 PyTorch 모델(<a href="https://pytorch.org/docs/stable/nn.html#torch.nn.Module" rel="nofollow">torch.nn.Module</a>), Keras 모델(<a href="https://www.tensorflow.org/api_docs/python/tf/keras/Model" rel="nofollow">tf.keras.Model</a>), JAX/Flax 모델(<a href="https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html" rel="nofollow">flax.linen.Module</a>)일 수 있습니다.</li> <li><strong>구성 클래스</strong>는 모델을 구축하는 데 필요한 하이퍼파라미터(예: 레이어 수 및 은닉 크기)를 저장합니다. 구성 클래스를 직접 인스턴스화할 필요는 없습니다. 특히, 수정 없이 고 사전 학습된 모델을 사용하는 경우 모델을 생성하면 모델의 일부인 구성을 자동으로 인스턴스화됩니다.</li> <li><strong>전처리 클래스</strong>는 원시 데이터를 모델이 수용하는 형식으로 변환합니다. <a href="main_classes/tokenizer">Tokenizer</a>는 각 모델의 어휘를 저장하고, 문자열을 토큰 임베딩 인덱스 리스트로 인코딩하고 디코딩하기 위한 메소드를 제공합니다. <a href="main_classes/image_processor">Image processors</a>는 비전 입력을 전처리하고, <a href="main_classes/feature_extractor">feature extractors</a>는 오디오 입력을 전처리하며, <a href="main_classes/processors">processor</a>는 멀티모달 입력을 처리합니다.</li>',O,M,ne="모든 이러한 클래스는 사전 훈련된 인스턴스에서 인스턴스화하고 로컬로 저장하며, 세 가지 메소드를 사용하여 Hub에서 공유할 수 있습니다:",R,H,se='<li><code>from_pretrained()</code> 메소드를 사용하면 라이브러리 자체에서 제공하는 사전 훈련된 버전(지원되는 모델은 <a href="https://huggingface.co/models" rel="nofollow">Model Hub</a>에서 찾을 수 있음)이나 사용자가 로컬로 저장한 경우(또는 서버에 저장한 경우)의 모델, 구성 및 전처리 클래스를 인스턴스화할 수 있습니다.</li> <li><code>save_pretrained()</code> 메소드를 사용하면 모델, 구성 및 전처리 클래스를 로컬로 저장하여 <code>from_pretrained()</code>를 사용하여 다시 가져올 수 있습니다.</li> <li><code>push_to_hub()</code> 메소드를 사용하면 모델, 구성 및 전처리 클래스를 Hub에 공유하여 모두에게 쉽게 접근할 수 있습니다.</li>',J,y,N;return c=new me({props:{title:"이념과 목표",local:"philosophy",headingTag:"h1"}}),L=new me({props:{title:"주요 개념",local:"main-concepts",headingTag:"h2"}}),{c(){f=a("meta"),$=n(),P=a("p"),g=n(),ae(c.$$.fragment),b=n(),u=a("p"),u.textContent=B,k=n(),m=a("ul"),m.innerHTML=D,F=n(),h=a("p"),h.textContent=G,U=n(),_=a("ol"),_.innerHTML=Q,z=n(),d=a("ul"),d.innerHTML=V,A=n(),p=a("ol"),p.innerHTML=W,q=n(),x=a("ul"),x.innerHTML=Z,E=n(),v=a("p"),v.textContent=ee,I=n(),T=a("ul"),T.innerHTML=te,K=n(),ae(L.$$.fragment),S=n(),w=a("p"),w.textContent=le,j=n(),C=a("ul"),C.innerHTML=ie,O=n(),M=a("p"),M.textContent=ne,R=n(),H=a("ul"),H.innerHTML=se,J=n(),y=a("p"),this.h()},l(e){const t=Te("svelte-u9bgzb",document.head);f=o(t,"META",{name:!0,content:!0}),t.forEach(l),$=s(e),P=o(e,"P",{}),oe(P).forEach(l),g=s(e),re(c.$$.fragment,e),b=s(e),u=o(e,"P",{"data-svelte-h":!0}),r(u)!=="svelte-1f7nmur"&&(u.textContent=B),k=s(e),m=o(e,"UL",{"data-svelte-h":!0}),r(m)!=="svelte-1yszd7n"&&(m.innerHTML=D),F=s(e),h=o(e,"P",{"data-svelte-h":!0}),r(h)!=="svelte-9trlgi"&&(h.textContent=G),U=s(e),_=o(e,"OL",{"data-svelte-h":!0}),r(_)!=="svelte-dq04yw"&&(_.innerHTML=Q),z=s(e),d=o(e,"UL",{"data-svelte-h":!0}),r(d)!=="svelte-1v94o3c"&&(d.innerHTML=V),A=s(e),p=o(e,"OL",{start:!0,"data-svelte-h":!0}),r(p)!=="svelte-1g3xmxn"&&(p.innerHTML=W),q=s(e),x=o(e,"UL",{"data-svelte-h":!0}),r(x)!=="svelte-sw04jb"&&(x.innerHTML=Z),E=s(e),v=o(e,"P",{"data-svelte-h":!0}),r(v)!=="svelte-1iw1iaa"&&(v.textContent=ee),I=s(e),T=o(e,"UL",{"data-svelte-h":!0}),r(T)!=="svelte-yeg31c"&&(T.innerHTML=te),K=s(e),re(L.$$.fragment,e),S=s(e),w=o(e,"P",{"data-svelte-h":!0}),r(w)!=="svelte-n4fqn2"&&(w.textContent=le),j=s(e),C=o(e,"UL",{"data-svelte-h":!0}),r(C)!=="svelte-qibpts"&&(C.innerHTML=ie),O=s(e),M=o(e,"P",{"data-svelte-h":!0}),r(M)!=="svelte-qhary9"&&(M.textContent=ne),R=s(e),H=o(e,"UL",{"data-svelte-h":!0}),r(H)!=="svelte-10fnv0u"&&(H.innerHTML=se),J=s(e),y=o(e,"P",{}),oe(y).forEach(l),this.h()},h(){X(f,"name","hf:doc:metadata"),X(f,"content",Ce),X(p,"start","2")},m(e,t){Le(document.head,f),i(e,$,t),i(e,P,t),i(e,g,t),fe(c,e,t),i(e,b,t),i(e,u,t),i(e,k,t),i(e,m,t),i(e,F,t),i(e,h,t),i(e,U,t),i(e,_,t),i(e,z,t),i(e,d,t),i(e,A,t),i(e,p,t),i(e,q,t),i(e,x,t),i(e,E,t),i(e,v,t),i(e,I,t),i(e,T,t),i(e,K,t),fe(L,e,t),i(e,S,t),i(e,w,t),i(e,j,t),i(e,C,t),i(e,O,t),i(e,M,t),i(e,R,t),i(e,H,t),i(e,J,t),i(e,y,t),N=!0},p:_e,i(e){N||(pe(c.$$.fragment,e),pe(L.$$.fragment,e),N=!0)},o(e){ce(c.$$.fragment,e),ce(L.$$.fragment,e),N=!1},d(e){e&&(l($),l(P),l(g),l(b),l(u),l(k),l(m),l(F),l(h),l(U),l(_),l(z),l(d),l(A),l(p),l(q),l(x),l(E),l(v),l(I),l(T),l(K),l(S),l(w),l(j),l(C),l(O),l(M),l(R),l(H),l(J),l(y)),l(f),ue(c,e),ue(L,e)}}}const Ce='{"title":"이념과 목표","local":"philosophy","sections":[{"title":"주요 개념","local":"main-concepts","sections":[],"depth":2}],"depth":1}';function Me(Y){return de(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class $e extends xe{constructor(f){super(),ve(this,f,Me,we,he,{})}}export{$e as component};
