import{s as Ie,o as He,n as Fe}from"../chunks/scheduler.56730f09.js";import{S as ze,i as Le,g as p,s as n,r as m,A as Qe,h as i,f as l,c as a,j as Ge,u as r,x as o,k as Ve,y as Oe,a as s,v as u,d as c,t as f,w as d}from"../chunks/index.1f144517.js";import{T as Ye}from"../chunks/Tip.41e845e5.js";import{C as M}from"../chunks/CodeBlock.738eeccb.js";import{H as ft}from"../chunks/Heading.57d46534.js";function Se(bt){let b,y="<code>tranformers.onnx</code>는 더 이상 유지되지 않습니다. 위에서 설명한 대로 🤗 Optimum을 사용하여 모델을 내보내세요. 이 섹션은 향후 버전에서 제거될 예정입니다.";return{c(){b=p("p"),b.innerHTML=y},l(T){b=i(T,"P",{"data-svelte-h":!0}),o(b)!=="svelte-xr1ro1"&&(b.innerHTML=y)},m(T,ct){s(T,b,ct)},p:Fe,d(T){T&&l(b)}}}function qe(bt){let b,y,T,ct,h,Mt,J,re="🤗 Transformers 모델을 제품 환경에서 배포하기 위해서는 모델을 직렬화된 형식으로 내보내고 특정 런타임과 하드웨어에서 로드하고 실행할 수 있으면 유용합니다.",Tt,w,ue="🤗 Optimum은 Transformers의 확장으로, PyTorch 또는 TensorFlow에서 모델을 ONNX와 TFLite와 같은 직렬화된 형식으로 내보낼 수 있도록 하는 <code>exporters</code> 모듈을 통해 제공됩니다. 🤗 Optimum은 또한 성능 최적화 도구 세트를 제공하여 특정 하드웨어에서 모델을 훈련하고 실행할 때 최대 효율성을 달성할 수 있습니다.",gt,$,ce='이 안내서는 🤗 Optimum을 사용하여 🤗 Transformers 모델을 ONNX로 내보내는 방법을 보여줍니다. TFLite로 모델을 내보내는 안내서는 <a href="tflite">TFLite로 내보내기 페이지</a>를 참조하세요.',yt,x,ht,N,fe='<a href="http://onnx.ai" rel="nofollow">ONNX (Open Neural Network eXchange)</a>는 PyTorch와 TensorFlow를 포함한 다양한 프레임워크에서 심층 학습 모델을 나타내는 데 사용되는 공통 연산자 세트와 공통 파일 형식을 정의하는 오픈 표준입니다. 모델이 ONNX 형식으로 내보내지면 이러한 연산자를 사용하여 신경망을 통해 데이터가 흐르는 흐름을 나타내는 계산 그래프(일반적으로 <em>중간 표현</em>이라고 함)가 구성됩니다.',Jt,X,de="표준화된 연산자와 데이터 유형을 가진 그래프를 노출함으로써, ONNX는 프레임워크 간에 쉽게 전환할 수 있습니다. 예를 들어, PyTorch에서 훈련된 모델을 ONNX 형식으로 내보내고 TensorFlow에서 가져올 수 있습니다(그 반대도 가능합니다).",wt,j,be="ONNX 형식으로 내보낸 모델은 다음과 같이 사용할 수 있습니다:",$t,U,Me='<li><a href="https://huggingface.co/docs/optimum/onnxruntime/usage_guides/optimization" rel="nofollow">그래프 최적화</a> 및 <a href="https://huggingface.co/docs/optimum/onnxruntime/usage_guides/quantization" rel="nofollow">양자화</a>와 같은 기법을 사용하여 추론을 위해 최적화됩니다.</li> <li>ONNX Runtime을 통해 실행할 수 있습니다. <a href="https://huggingface.co/docs/optimum/onnxruntime/package_reference/modeling_ort" rel="nofollow"><code>ORTModelForXXX</code> 클래스들</a>을 통해 동일한 <code>AutoModel</code> API를 따릅니다. 이 API는 🤗 Transformers에서 사용하는 것과 동일합니다.</li> <li><a href="https://huggingface.co/docs/optimum/main/en/onnxruntime/usage_guides/pipelines" rel="nofollow">최적화된 추론 파이프라인</a>을 사용할 수 있습니다. 이는 🤗 Transformers의 <code>pipeline()</code> 함수와 동일한 API를 가지고 있습니다.</li>',xt,C,Te="🤗 Optimum은 구성 객체를 활용하여 ONNX 내보내기를 지원합니다. 이러한 구성 객체는 여러 모델 아키텍처에 대해 미리 준비되어 있으며 다른 아키텍처에 쉽게 확장할 수 있도록 설계되었습니다.",Nt,Z,ge='미리 준비된 구성 목록은 <a href="https://huggingface.co/docs/optimum/exporters/onnx/overview" rel="nofollow">🤗 Optimum 문서</a>를 참조하세요.',Xt,v,ye="🤗 Transformers 모델을 ONNX로 내보내는 두 가지 방법이 있습니다. 여기에서 두 가지 방법을 모두 보여줍니다:",jt,_,he="<li>🤗 Optimum을 사용하여 CLI로 내보내기</li> <li><code>optimum.onnxruntime</code>을 사용하여 🤗 Optimum으로 ONNX로 내보내기</li>",Ut,W,Ct,R,Je="🤗 Transformers 모델을 ONNX로 내보내려면 먼저 추가 종속성을 설치하세요:",Zt,B,vt,k,we='사용 가능한 모든 인수를 확인하려면 <a href="https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/export_a_model#exporting-a-model-to-onnx-using-the-cli" rel="nofollow">🤗 Optimum 문서</a>를 참조하거나 명령줄에서 도움말을 보세요.',_t,G,Wt,V,$e="예를 들어, 🤗 Hub에서 <code>distilbert/distilbert-base-uncased-distilled-squad</code>와 같은 모델의 체크포인트를 내보내려면 다음 명령을 실행하세요:",Rt,I,Bt,H,xe="위와 같이 진행 상황을 나타내는 로그가 표시되고 결과인 <code>model.onnx</code>가 저장된 위치가 표시됩니다.",kt,F,Gt,z,Ne='위의 예제는 🤗 Hub에서 체크포인트를 내보내는 것을 설명합니다. 로컬 모델을 내보낼 때에는 모델의 가중치와 토크나이저 파일을 동일한 디렉토리(<code>local_path</code>)에 저장했는지 확인하세요. CLI를 사용할 때에는 🤗 Hub의 체크포인트 이름 대신 <code>model</code> 인수에 <code>local_path</code>를 전달하고 <code>--task</code> 인수를 제공하세요. 지원되는 작업의 목록은 <a href="https://huggingface.co/docs/optimum/exporters/task_manager" rel="nofollow">🤗 Optimum 문서</a>를 참조하세요. <code>task</code> 인수가 제공되지 않으면 작업에 특화된 헤드 없이 모델 아키텍처로 기본 설정됩니다.',Vt,L,It,Q,Xe='그 결과로 생성된 <code>model.onnx</code> 파일은 ONNX 표준을 지원하는 많은 <a href="https://onnx.ai/supported-tools.html#deployModel" rel="nofollow">가속기</a> 중 하나에서 실행할 수 있습니다. 예를 들어, <a href="https://onnxruntime.ai/" rel="nofollow">ONNX Runtime</a>을 사용하여 모델을 로드하고 실행할 수 있습니다:',Ht,O,Ft,Y,je='Hub의 TensorFlow 체크포인트에 대해서도 동일한 프로세스가 적용됩니다. 예를 들어, <a href="https://huggingface.co/keras-io" rel="nofollow">Keras organization</a>에서 순수한 TensorFlow 체크포인트를 내보내는 방법은 다음과 같습니다:',zt,S,Lt,q,Qt,E,Ue="CLI 대신에 <code>optimum.onnxruntime</code>을 사용하여 프로그래밍 방식으로 🤗 Transformers 모델을 ONNX로 내보낼 수도 있습니다. 다음과 같이 진행하세요:",Ot,P,Yt,A,St,K,Ce='현재 내보낼 수 없는 모델을 지원하기 위해 기여하려면, 먼저 <a href="https://huggingface.co/docs/optimum/exporters/onnx/overview" rel="nofollow"><code>optimum.exporters.onnx</code></a>에서 지원되는지 확인한 후 지원되지 않는 경우에는 <a href="https://huggingface.co/docs/optimum/exporters/onnx/usage_guides/contribute" rel="nofollow">🤗 Optimum에 기여</a>하세요.',qt,D,Et,g,Pt,tt,Ze="🤗 Transformers 모델을 ONNX로 내보내려면 추가 종속성을 설치하세요:",At,et,Kt,lt,ve="<code>transformers.onnx</code> 패키지를 Python 모듈로 사용하여 준비된 구성을 사용하여 체크포인트를 내보냅니다:",Dt,st,te,nt,_e="이렇게 하면 <code>--model</code> 인수에 정의된 체크포인트의 ONNX 그래프가 내보내집니다. 🤗 Hub에서 제공하는 체크포인트나 로컬에 저장된 체크포인트를 전달할 수 있습니다. 결과로 생성된 <code>model.onnx</code> 파일은 ONNX 표준을 지원하는 많은 가속기 중 하나에서 실행할 수 있습니다. 예를 들어, 다음과 같이 ONNX Runtime을 사용하여 모델을 로드하고 실행할 수 있습니다:",ee,at,le,pt,We="필요한 출력 이름(예: <code>[&quot;last_hidden_state&quot;]</code>)은 각 모델의 ONNX 구성을 확인하여 얻을 수 있습니다. 예를 들어, DistilBERT의 경우 다음과 같습니다:",se,it,ne,ot,Re="Hub의 TensorFlow 체크포인트에 대해서도 동일한 프로세스가 적용됩니다. 예를 들어, 다음과 같이 순수한 TensorFlow 체크포인트를 내보냅니다:",ae,mt,pe,rt,Be="로컬에 저장된 모델을 내보내려면 모델의 가중치 파일과 토크나이저 파일을 동일한 디렉토리에 저장한 다음, transformers.onnx 패키지의 —model 인수를 원하는 디렉토리로 지정하여 ONNX로 내보냅니다:",ie,ut,oe,dt,me;return h=new ft({props:{title:"ONNX로 내보내기",local:"export-to-onnx",headingTag:"h1"}}),x=new ft({props:{title:"ONNX로 내보내기",local:"export-to-onnx",headingTag:"h2"}}),W=new ft({props:{title:"CLI를 사용하여 🤗 Transformers 모델을 ONNX로 내보내기",local:"exporting-a-transformers-model-to-onnx-with-cli",headingTag:"h3"}}),B=new M({props:{code:"cGlwJTIwaW5zdGFsbCUyMG9wdGltdW0lNUJleHBvcnRlcnMlNUQ=",highlighted:"pip install optimum[exporters]",wrap:!1}}),G=new M({props:{code:"b3B0aW11bS1jbGklMjBleHBvcnQlMjBvbm54JTIwLS1oZWxw",highlighted:'optimum-cli <span class="hljs-built_in">export</span> onnx --<span class="hljs-built_in">help</span>',wrap:!1}}),I=new M({props:{code:"b3B0aW11bS1jbGklMjBleHBvcnQlMjBvbm54JTIwLS1tb2RlbCUyMGRpc3RpbGJlcnQlMkZkaXN0aWxiZXJ0LWJhc2UtdW5jYXNlZC1kaXN0aWxsZWQtc3F1YWQlMjBkaXN0aWxiZXJ0X2Jhc2VfdW5jYXNlZF9zcXVhZF9vbm54JTJG",highlighted:'optimum-cli <span class="hljs-built_in">export</span> onnx --model distilbert/distilbert-base-uncased-distilled-squad distilbert_base_uncased_squad_onnx/',wrap:!1}}),F=new M({props:{code:"VmFsaWRhdGluZyUyME9OTlglMjBtb2RlbCUyMGRpc3RpbGJlcnRfYmFzZV91bmNhc2VkX3NxdWFkX29ubnglMkZtb2RlbC5vbm54Li4uJTBBJTA5LSU1QiVFMiU5QyU5MyU1RCUyME9OTlglMjBtb2RlbCUyMG91dHB1dCUyMG5hbWVzJTIwbWF0Y2glMjByZWZlcmVuY2UlMjBtb2RlbCUyMChzdGFydF9sb2dpdHMlMkMlMjBlbmRfbG9naXRzKSUwQSUwOS0lMjBWYWxpZGF0aW5nJTIwT05OWCUyME1vZGVsJTIwb3V0cHV0JTIwJTIyc3RhcnRfbG9naXRzJTIyJTNBJTBBJTA5JTA5LSU1QiVFMiU5QyU5MyU1RCUyMCgyJTJDJTIwMTYpJTIwbWF0Y2hlcyUyMCgyJTJDJTIwMTYpJTBBJTA5JTA5LSU1QiVFMiU5QyU5MyU1RCUyMGFsbCUyMHZhbHVlcyUyMGNsb3NlJTIwKGF0b2wlM0ElMjAwLjAwMDEpJTBBJTA5LSUyMFZhbGlkYXRpbmclMjBPTk5YJTIwTW9kZWwlMjBvdXRwdXQlMjAlMjJlbmRfbG9naXRzJTIyJTNBJTBBJTA5JTA5LSU1QiVFMiU5QyU5MyU1RCUyMCgyJTJDJTIwMTYpJTIwbWF0Y2hlcyUyMCgyJTJDJTIwMTYpJTBBJTA5JTA5LSU1QiVFMiU5QyU5MyU1RCUyMGFsbCUyMHZhbHVlcyUyMGNsb3NlJTIwKGF0b2wlM0ElMjAwLjAwMDEpJTBBVGhlJTIwT05OWCUyMGV4cG9ydCUyMHN1Y2NlZWRlZCUyMGFuZCUyMHRoZSUyMGV4cG9ydGVkJTIwbW9kZWwlMjB3YXMlMjBzYXZlZCUyMGF0JTNBJTIwZGlzdGlsYmVydF9iYXNlX3VuY2FzZWRfc3F1YWRfb25ueA==",highlighted:`Validating ONNX model distilbert_base_uncased_squad_onnx/model.onnx...
	-[✓] ONNX model output names match reference model (start_logits, end_logits)
	- Validating ONNX Model output <span class="hljs-string">&quot;start_logits&quot;</span>:
		-[✓] (2, 16) matches (2, 16)
		-[✓] all values close (atol: 0.0001)
	- Validating ONNX Model output <span class="hljs-string">&quot;end_logits&quot;</span>:
		-[✓] (2, 16) matches (2, 16)
		-[✓] all values close (atol: 0.0001)
The ONNX <span class="hljs-built_in">export</span> succeeded and the exported model was saved at: distilbert_base_uncased_squad_onnx`,wrap:!1}}),L=new M({props:{code:"b3B0aW11bS1jbGklMjBleHBvcnQlMjBvbm54JTIwLS1tb2RlbCUyMGxvY2FsX3BhdGglMjAtLXRhc2slMjBxdWVzdGlvbi1hbnN3ZXJpbmclMjBkaXN0aWxiZXJ0X2Jhc2VfdW5jYXNlZF9zcXVhZF9vbm54JTJG",highlighted:'optimum-cli <span class="hljs-built_in">export</span> onnx --model local_path --task question-answering distilbert_base_uncased_squad_onnx/',wrap:!1}}),O=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEFmcm9tJTIwb3B0aW11bS5vbm54cnVudGltZSUyMGltcG9ydCUyME9SVE1vZGVsRm9yUXVlc3Rpb25BbnN3ZXJpbmclMEElMEF0b2tlbml6ZXIlMjAlM0QlMjBBdXRvVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJkaXN0aWxiZXJ0X2Jhc2VfdW5jYXNlZF9zcXVhZF9vbm54JTIyKSUwQW1vZGVsJTIwJTNEJTIwT1JUTW9kZWxGb3JRdWVzdGlvbkFuc3dlcmluZy5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydF9iYXNlX3VuY2FzZWRfc3F1YWRfb25ueCUyMiklMEFpbnB1dHMlMjAlM0QlMjB0b2tlbml6ZXIoJTIyV2hhdCUyMGFtJTIwSSUyMHVzaW5nJTNGJTIyJTJDJTIwJTIyVXNpbmclMjBEaXN0aWxCRVJUJTIwd2l0aCUyME9OTlglMjBSdW50aW1lISUyMiUyQyUyMHJldHVybl90ZW5zb3JzJTNEJTIycHQlMjIpJTBBb3V0cHV0cyUyMCUzRCUyMG1vZGVsKCoqaW5wdXRzKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTModelForQuestionAnswering

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert_base_uncased_squad_onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = ORTModelForQuestionAnswering.from_pretrained(<span class="hljs-string">&quot;distilbert_base_uncased_squad_onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;What am I using?&quot;</span>, <span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(**inputs)`,wrap:!1}}),S=new M({props:{code:"b3B0aW11bS1jbGklMjBleHBvcnQlMjBvbm54JTIwLS1tb2RlbCUyMGtlcmFzLWlvJTJGdHJhbnNmb3JtZXJzLXFhJTIwZGlzdGlsYmVydF9iYXNlX2Nhc2VkX3NxdWFkX29ubnglMkY=",highlighted:'optimum-cli <span class="hljs-built_in">export</span> onnx --model keras-io/transformers-qa distilbert_base_cased_squad_onnx/',wrap:!1}}),q=new ft({props:{title:"optimum.onnxruntime 을 사용하여 🤗 Transformers 모델을 ONNX로 내보내기",local:"exporting-a-transformers-model-to-onnx-with-optimumonnxruntime",headingTag:"h3"}}),P=new M({props:{code:"ZnJvbSUyMG9wdGltdW0ub25ueHJ1bnRpbWUlMjBpbXBvcnQlMjBPUlRNb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24lMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwQXV0b1Rva2VuaXplciUwQSUwQW1vZGVsX2NoZWNrcG9pbnQlMjAlM0QlMjAlMjJkaXN0aWxiZXJ0X2Jhc2VfdW5jYXNlZF9zcXVhZCUyMiUwQXNhdmVfZGlyZWN0b3J5JTIwJTNEJTIwJTIyb25ueCUyRiUyMiUwQSUwQSUyMyUyMExvYWQlMjBhJTIwbW9kZWwlMjBmcm9tJTIwdHJhbnNmb3JtZXJzJTIwYW5kJTIwZXhwb3J0JTIwaXQlMjB0byUyME9OTlglMEFvcnRfbW9kZWwlMjAlM0QlMjBPUlRNb2RlbEZvclNlcXVlbmNlQ2xhc3NpZmljYXRpb24uZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2NoZWNrcG9pbnQlMkMlMjBleHBvcnQlM0RUcnVlKSUwQXRva2VuaXplciUyMCUzRCUyMEF1dG9Ub2tlbml6ZXIuZnJvbV9wcmV0cmFpbmVkKG1vZGVsX2NoZWNrcG9pbnQpJTBBJTBBJTIzJTIwU2F2ZSUyMHRoZSUyMG9ubnglMjBtb2RlbCUyMGFuZCUyMHRva2VuaXplciUwQW9ydF9tb2RlbC5zYXZlX3ByZXRyYWluZWQoc2F2ZV9kaXJlY3RvcnkpJTBBdG9rZW5pemVyLnNhdmVfcHJldHJhaW5lZChzYXZlX2RpcmVjdG9yeSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> optimum.onnxruntime <span class="hljs-keyword">import</span> ORTModelForSequenceClassification
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>model_checkpoint = <span class="hljs-string">&quot;distilbert_base_uncased_squad&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>save_directory = <span class="hljs-string">&quot;onnx/&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Load a model from transformers and export it to ONNX</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_model = ORTModelForSequenceClassification.from_pretrained(model_checkpoint, export=<span class="hljs-literal">True</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># Save the onnx model and tokenizer</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>ort_model.save_pretrained(save_directory)
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.save_pretrained(save_directory)`,wrap:!1}}),A=new ft({props:{title:"지원되지 않는 아키텍처의 모델 내보내기",local:"exporting-a-model-for-an-unsupported-architecture",headingTag:"h3"}}),D=new ft({props:{title:"transformers.onnx 를 사용하여 모델 내보내기",local:"exporting-a-model-with-transformersonnx",headingTag:"h3"}}),g=new Ye({props:{warning:!0,$$slots:{default:[Se]},$$scope:{ctx:bt}}}),et=new M({props:{code:"cGlwJTIwaW5zdGFsbCUyMHRyYW5zZm9ybWVycyU1Qm9ubnglNUQ=",highlighted:"pip install transformers[onnx]",wrap:!1}}),st=new M({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0RkaXN0aWxiZXJ0JTJGZGlzdGlsYmVydC1iYXNlLXVuY2FzZWQlMjBvbm54JTJG",highlighted:"python -m transformers.onnx --model=distilbert/distilbert-base-uncased onnx/",wrap:!1}}),at=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMEFmcm9tJTIwb25ueHJ1bnRpbWUlMjBpbXBvcnQlMjBJbmZlcmVuY2VTZXNzaW9uJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZGlzdGlsYmVydCUyRmRpc3RpbGJlcnQtYmFzZS11bmNhc2VkJTIyKSUwQXNlc3Npb24lMjAlM0QlMjBJbmZlcmVuY2VTZXNzaW9uKCUyMm9ubnglMkZtb2RlbC5vbm54JTIyKSUwQSUyMyUyME9OTlglMjBSdW50aW1lJTIwZXhwZWN0cyUyME51bVB5JTIwYXJyYXlzJTIwYXMlMjBpbnB1dCUwQWlucHV0cyUyMCUzRCUyMHRva2VuaXplciglMjJVc2luZyUyMERpc3RpbEJFUlQlMjB3aXRoJTIwT05OWCUyMFJ1bnRpbWUhJTIyJTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJucCUyMiklMEFvdXRwdXRzJTIwJTNEJTIwc2Vzc2lvbi5ydW4ob3V0cHV0X25hbWVzJTNEJTVCJTIybGFzdF9oaWRkZW5fc3RhdGUlMjIlNUQlMkMlMjBpbnB1dF9mZWVkJTNEZGljdChpbnB1dHMpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> onnxruntime <span class="hljs-keyword">import</span> InferenceSession

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;distilbert/distilbert-base-uncased&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>session = InferenceSession(<span class="hljs-string">&quot;onnx/model.onnx&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># ONNX Runtime expects NumPy arrays as input</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>inputs = tokenizer(<span class="hljs-string">&quot;Using DistilBERT with ONNX Runtime!&quot;</span>, return_tensors=<span class="hljs-string">&quot;np&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = session.run(output_names=[<span class="hljs-string">&quot;last_hidden_state&quot;</span>], input_feed=<span class="hljs-built_in">dict</span>(inputs))`,wrap:!1}}),it=new M({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycy5tb2RlbHMuZGlzdGlsYmVydCUyMGltcG9ydCUyMERpc3RpbEJlcnRDb25maWclMkMlMjBEaXN0aWxCZXJ0T25ueENvbmZpZyUwQSUwQWNvbmZpZyUyMCUzRCUyMERpc3RpbEJlcnRDb25maWcoKSUwQW9ubnhfY29uZmlnJTIwJTNEJTIwRGlzdGlsQmVydE9ubnhDb25maWcoY29uZmlnKSUwQXByaW50KGxpc3Qob25ueF9jb25maWcub3V0cHV0cy5rZXlzKCkpKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers.models.distilbert <span class="hljs-keyword">import</span> DistilBertConfig, DistilBertOnnxConfig

<span class="hljs-meta">&gt;&gt;&gt; </span>config = DistilBertConfig()
<span class="hljs-meta">&gt;&gt;&gt; </span>onnx_config = DistilBertOnnxConfig(config)
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(<span class="hljs-built_in">list</span>(onnx_config.outputs.keys()))
[<span class="hljs-string">&quot;last_hidden_state&quot;</span>]`,wrap:!1}}),mt=new M({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0RrZXJhcy1pbyUyRnRyYW5zZm9ybWVycy1xYSUyMG9ubnglMkY=",highlighted:"python -m transformers.onnx --model=keras-io/transformers-qa onnx/",wrap:!1}}),ut=new M({props:{code:"cHl0aG9uJTIwLW0lMjB0cmFuc2Zvcm1lcnMub25ueCUyMC0tbW9kZWwlM0Rsb2NhbC1wdC1jaGVja3BvaW50JTIwb25ueCUyRg==",highlighted:"python -m transformers.onnx --model=local-pt-checkpoint onnx/",wrap:!1}}),{c(){b=p("meta"),y=n(),T=p("p"),ct=n(),m(h.$$.fragment),Mt=n(),J=p("p"),J.textContent=re,Tt=n(),w=p("p"),w.innerHTML=ue,gt=n(),$=p("p"),$.innerHTML=ce,yt=n(),m(x.$$.fragment),ht=n(),N=p("p"),N.innerHTML=fe,Jt=n(),X=p("p"),X.textContent=de,wt=n(),j=p("p"),j.textContent=be,$t=n(),U=p("ul"),U.innerHTML=Me,xt=n(),C=p("p"),C.textContent=Te,Nt=n(),Z=p("p"),Z.innerHTML=ge,Xt=n(),v=p("p"),v.textContent=ye,jt=n(),_=p("ul"),_.innerHTML=he,Ut=n(),m(W.$$.fragment),Ct=n(),R=p("p"),R.textContent=Je,Zt=n(),m(B.$$.fragment),vt=n(),k=p("p"),k.innerHTML=we,_t=n(),m(G.$$.fragment),Wt=n(),V=p("p"),V.innerHTML=$e,Rt=n(),m(I.$$.fragment),Bt=n(),H=p("p"),H.innerHTML=xe,kt=n(),m(F.$$.fragment),Gt=n(),z=p("p"),z.innerHTML=Ne,Vt=n(),m(L.$$.fragment),It=n(),Q=p("p"),Q.innerHTML=Xe,Ht=n(),m(O.$$.fragment),Ft=n(),Y=p("p"),Y.innerHTML=je,zt=n(),m(S.$$.fragment),Lt=n(),m(q.$$.fragment),Qt=n(),E=p("p"),E.innerHTML=Ue,Ot=n(),m(P.$$.fragment),Yt=n(),m(A.$$.fragment),St=n(),K=p("p"),K.innerHTML=Ce,qt=n(),m(D.$$.fragment),Et=n(),m(g.$$.fragment),Pt=n(),tt=p("p"),tt.textContent=Ze,At=n(),m(et.$$.fragment),Kt=n(),lt=p("p"),lt.innerHTML=ve,Dt=n(),m(st.$$.fragment),te=n(),nt=p("p"),nt.innerHTML=_e,ee=n(),m(at.$$.fragment),le=n(),pt=p("p"),pt.innerHTML=We,se=n(),m(it.$$.fragment),ne=n(),ot=p("p"),ot.textContent=Re,ae=n(),m(mt.$$.fragment),pe=n(),rt=p("p"),rt.textContent=Be,ie=n(),m(ut.$$.fragment),oe=n(),dt=p("p"),this.h()},l(t){const e=Qe("svelte-u9bgzb",document.head);b=i(e,"META",{name:!0,content:!0}),e.forEach(l),y=a(t),T=i(t,"P",{}),Ge(T).forEach(l),ct=a(t),r(h.$$.fragment,t),Mt=a(t),J=i(t,"P",{"data-svelte-h":!0}),o(J)!=="svelte-aze92"&&(J.textContent=re),Tt=a(t),w=i(t,"P",{"data-svelte-h":!0}),o(w)!=="svelte-3cx834"&&(w.innerHTML=ue),gt=a(t),$=i(t,"P",{"data-svelte-h":!0}),o($)!=="svelte-mb67vh"&&($.innerHTML=ce),yt=a(t),r(x.$$.fragment,t),ht=a(t),N=i(t,"P",{"data-svelte-h":!0}),o(N)!=="svelte-1b2u1gc"&&(N.innerHTML=fe),Jt=a(t),X=i(t,"P",{"data-svelte-h":!0}),o(X)!=="svelte-1glfzyz"&&(X.textContent=de),wt=a(t),j=i(t,"P",{"data-svelte-h":!0}),o(j)!=="svelte-1573zuq"&&(j.textContent=be),$t=a(t),U=i(t,"UL",{"data-svelte-h":!0}),o(U)!=="svelte-156rzm1"&&(U.innerHTML=Me),xt=a(t),C=i(t,"P",{"data-svelte-h":!0}),o(C)!=="svelte-14j10fa"&&(C.textContent=Te),Nt=a(t),Z=i(t,"P",{"data-svelte-h":!0}),o(Z)!=="svelte-1kj3x7c"&&(Z.innerHTML=ge),Xt=a(t),v=i(t,"P",{"data-svelte-h":!0}),o(v)!=="svelte-1ivz9lg"&&(v.textContent=ye),jt=a(t),_=i(t,"UL",{"data-svelte-h":!0}),o(_)!=="svelte-6mp210"&&(_.innerHTML=he),Ut=a(t),r(W.$$.fragment,t),Ct=a(t),R=i(t,"P",{"data-svelte-h":!0}),o(R)!=="svelte-1f07m0b"&&(R.textContent=Je),Zt=a(t),r(B.$$.fragment,t),vt=a(t),k=i(t,"P",{"data-svelte-h":!0}),o(k)!=="svelte-52xcpg"&&(k.innerHTML=we),_t=a(t),r(G.$$.fragment,t),Wt=a(t),V=i(t,"P",{"data-svelte-h":!0}),o(V)!=="svelte-14l0cnq"&&(V.innerHTML=$e),Rt=a(t),r(I.$$.fragment,t),Bt=a(t),H=i(t,"P",{"data-svelte-h":!0}),o(H)!=="svelte-5tiubv"&&(H.innerHTML=xe),kt=a(t),r(F.$$.fragment,t),Gt=a(t),z=i(t,"P",{"data-svelte-h":!0}),o(z)!=="svelte-n4znt9"&&(z.innerHTML=Ne),Vt=a(t),r(L.$$.fragment,t),It=a(t),Q=i(t,"P",{"data-svelte-h":!0}),o(Q)!=="svelte-lnydei"&&(Q.innerHTML=Xe),Ht=a(t),r(O.$$.fragment,t),Ft=a(t),Y=i(t,"P",{"data-svelte-h":!0}),o(Y)!=="svelte-srud4c"&&(Y.innerHTML=je),zt=a(t),r(S.$$.fragment,t),Lt=a(t),r(q.$$.fragment,t),Qt=a(t),E=i(t,"P",{"data-svelte-h":!0}),o(E)!=="svelte-1c9bubw"&&(E.innerHTML=Ue),Ot=a(t),r(P.$$.fragment,t),Yt=a(t),r(A.$$.fragment,t),St=a(t),K=i(t,"P",{"data-svelte-h":!0}),o(K)!=="svelte-si8xut"&&(K.innerHTML=Ce),qt=a(t),r(D.$$.fragment,t),Et=a(t),r(g.$$.fragment,t),Pt=a(t),tt=i(t,"P",{"data-svelte-h":!0}),o(tt)!=="svelte-10vc2cl"&&(tt.textContent=Ze),At=a(t),r(et.$$.fragment,t),Kt=a(t),lt=i(t,"P",{"data-svelte-h":!0}),o(lt)!=="svelte-1spy8c0"&&(lt.innerHTML=ve),Dt=a(t),r(st.$$.fragment,t),te=a(t),nt=i(t,"P",{"data-svelte-h":!0}),o(nt)!=="svelte-aeykkq"&&(nt.innerHTML=_e),ee=a(t),r(at.$$.fragment,t),le=a(t),pt=i(t,"P",{"data-svelte-h":!0}),o(pt)!=="svelte-1g467oj"&&(pt.innerHTML=We),se=a(t),r(it.$$.fragment,t),ne=a(t),ot=i(t,"P",{"data-svelte-h":!0}),o(ot)!=="svelte-1fschrn"&&(ot.textContent=Re),ae=a(t),r(mt.$$.fragment,t),pe=a(t),rt=i(t,"P",{"data-svelte-h":!0}),o(rt)!=="svelte-md25sr"&&(rt.textContent=Be),ie=a(t),r(ut.$$.fragment,t),oe=a(t),dt=i(t,"P",{}),Ge(dt).forEach(l),this.h()},h(){Ve(b,"name","hf:doc:metadata"),Ve(b,"content",Ee)},m(t,e){Oe(document.head,b),s(t,y,e),s(t,T,e),s(t,ct,e),u(h,t,e),s(t,Mt,e),s(t,J,e),s(t,Tt,e),s(t,w,e),s(t,gt,e),s(t,$,e),s(t,yt,e),u(x,t,e),s(t,ht,e),s(t,N,e),s(t,Jt,e),s(t,X,e),s(t,wt,e),s(t,j,e),s(t,$t,e),s(t,U,e),s(t,xt,e),s(t,C,e),s(t,Nt,e),s(t,Z,e),s(t,Xt,e),s(t,v,e),s(t,jt,e),s(t,_,e),s(t,Ut,e),u(W,t,e),s(t,Ct,e),s(t,R,e),s(t,Zt,e),u(B,t,e),s(t,vt,e),s(t,k,e),s(t,_t,e),u(G,t,e),s(t,Wt,e),s(t,V,e),s(t,Rt,e),u(I,t,e),s(t,Bt,e),s(t,H,e),s(t,kt,e),u(F,t,e),s(t,Gt,e),s(t,z,e),s(t,Vt,e),u(L,t,e),s(t,It,e),s(t,Q,e),s(t,Ht,e),u(O,t,e),s(t,Ft,e),s(t,Y,e),s(t,zt,e),u(S,t,e),s(t,Lt,e),u(q,t,e),s(t,Qt,e),s(t,E,e),s(t,Ot,e),u(P,t,e),s(t,Yt,e),u(A,t,e),s(t,St,e),s(t,K,e),s(t,qt,e),u(D,t,e),s(t,Et,e),u(g,t,e),s(t,Pt,e),s(t,tt,e),s(t,At,e),u(et,t,e),s(t,Kt,e),s(t,lt,e),s(t,Dt,e),u(st,t,e),s(t,te,e),s(t,nt,e),s(t,ee,e),u(at,t,e),s(t,le,e),s(t,pt,e),s(t,se,e),u(it,t,e),s(t,ne,e),s(t,ot,e),s(t,ae,e),u(mt,t,e),s(t,pe,e),s(t,rt,e),s(t,ie,e),u(ut,t,e),s(t,oe,e),s(t,dt,e),me=!0},p(t,[e]){const ke={};e&2&&(ke.$$scope={dirty:e,ctx:t}),g.$set(ke)},i(t){me||(c(h.$$.fragment,t),c(x.$$.fragment,t),c(W.$$.fragment,t),c(B.$$.fragment,t),c(G.$$.fragment,t),c(I.$$.fragment,t),c(F.$$.fragment,t),c(L.$$.fragment,t),c(O.$$.fragment,t),c(S.$$.fragment,t),c(q.$$.fragment,t),c(P.$$.fragment,t),c(A.$$.fragment,t),c(D.$$.fragment,t),c(g.$$.fragment,t),c(et.$$.fragment,t),c(st.$$.fragment,t),c(at.$$.fragment,t),c(it.$$.fragment,t),c(mt.$$.fragment,t),c(ut.$$.fragment,t),me=!0)},o(t){f(h.$$.fragment,t),f(x.$$.fragment,t),f(W.$$.fragment,t),f(B.$$.fragment,t),f(G.$$.fragment,t),f(I.$$.fragment,t),f(F.$$.fragment,t),f(L.$$.fragment,t),f(O.$$.fragment,t),f(S.$$.fragment,t),f(q.$$.fragment,t),f(P.$$.fragment,t),f(A.$$.fragment,t),f(D.$$.fragment,t),f(g.$$.fragment,t),f(et.$$.fragment,t),f(st.$$.fragment,t),f(at.$$.fragment,t),f(it.$$.fragment,t),f(mt.$$.fragment,t),f(ut.$$.fragment,t),me=!1},d(t){t&&(l(y),l(T),l(ct),l(Mt),l(J),l(Tt),l(w),l(gt),l($),l(yt),l(ht),l(N),l(Jt),l(X),l(wt),l(j),l($t),l(U),l(xt),l(C),l(Nt),l(Z),l(Xt),l(v),l(jt),l(_),l(Ut),l(Ct),l(R),l(Zt),l(vt),l(k),l(_t),l(Wt),l(V),l(Rt),l(Bt),l(H),l(kt),l(Gt),l(z),l(Vt),l(It),l(Q),l(Ht),l(Ft),l(Y),l(zt),l(Lt),l(Qt),l(E),l(Ot),l(Yt),l(St),l(K),l(qt),l(Et),l(Pt),l(tt),l(At),l(Kt),l(lt),l(Dt),l(te),l(nt),l(ee),l(le),l(pt),l(se),l(ne),l(ot),l(ae),l(pe),l(rt),l(ie),l(oe),l(dt)),l(b),d(h,t),d(x,t),d(W,t),d(B,t),d(G,t),d(I,t),d(F,t),d(L,t),d(O,t),d(S,t),d(q,t),d(P,t),d(A,t),d(D,t),d(g,t),d(et,t),d(st,t),d(at,t),d(it,t),d(mt,t),d(ut,t)}}}const Ee='{"title":"ONNX로 내보내기","local":"export-to-onnx","sections":[{"title":"ONNX로 내보내기","local":"export-to-onnx","sections":[{"title":"CLI를 사용하여 🤗 Transformers 모델을 ONNX로 내보내기","local":"exporting-a-transformers-model-to-onnx-with-cli","sections":[],"depth":3},{"title":"optimum.onnxruntime 을 사용하여 🤗 Transformers 모델을 ONNX로 내보내기","local":"exporting-a-transformers-model-to-onnx-with-optimumonnxruntime","sections":[],"depth":3},{"title":"지원되지 않는 아키텍처의 모델 내보내기","local":"exporting-a-model-for-an-unsupported-architecture","sections":[],"depth":3},{"title":"transformers.onnx 를 사용하여 모델 내보내기","local":"exporting-a-model-with-transformersonnx","sections":[],"depth":3}],"depth":2}],"depth":1}';function Pe(bt){return He(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class ll extends ze{constructor(b){super(),Le(this,b,Pe,qe,Ie,{})}}export{ll as component};
