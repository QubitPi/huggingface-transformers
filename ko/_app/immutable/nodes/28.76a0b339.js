import{s as el,n as tl,o as ll}from"../chunks/scheduler.56730f09.js";import{S as sl,i as nl,g as i,s as n,r as p,A as al,h as o,f as l,c as a,j as St,u as r,x as m,k as Kt,y as il,a as s,v as g,d as u,t as M,w as c}from"../chunks/index.1f144517.js";import{C as J}from"../chunks/CodeBlock.738eeccb.js";import{D as ol}from"../chunks/DocNotebookDropdown.243c3df7.js";import{H as d}from"../chunks/Heading.57d46534.js";function ml(ft){let b,Te,be,fe,T,Ue,f,ye,U,Ut=`🤗 Transformers에는 여러 종류의 다국어(multilingual) 모델이 있으며, 단일 언어(monolingual) 모델과 추론 시 사용법이 다릅니다.
그렇다고 해서 <em>모든</em> 다국어 모델의 사용법이 다른 것은 아닙니다.`,he,y,yt=`<a href="https://huggingface.co/google-bert/bert-base-multilingual-uncased" rel="nofollow">google-bert/bert-base-multilingual-uncased</a>와 같은 몇몇 모델은 단일 언어 모델처럼 사용할 수 있습니다.
이번 가이드에서 다국어 모델의 추론 시 사용 방법을 알아볼 것입니다.`,$e,h,ke,$,ht=`XLM에는 10가지 체크포인트(checkpoint)가 있는데, 이 중 하나만 단일 언어입니다.
나머지 체크포인트 9개는 언어 임베딩을 사용하는 체크포인트와 그렇지 않은 체크포인트의 두 가지 범주로 나눌 수 있습니다.`,je,k,we,j,$t="다음 XLM 모델은 추론 시에 언어 임베딩을 사용합니다:",xe,w,kt="<li><code>FacebookAI/xlm-mlm-ende-1024</code> (마스킹된 언어 모델링, 영어-독일어)</li> <li><code>FacebookAI/xlm-mlm-enfr-1024</code> (마스킹된 언어 모델링, 영어-프랑스어)</li> <li><code>FacebookAI/xlm-mlm-enro-1024</code> (마스킹된 언어 모델링, 영어-루마니아어)</li> <li><code>FacebookAI/xlm-mlm-xnli15-1024</code> (마스킹된 언어 모델링, XNLI 데이터 세트에서 제공하는 15개 국어)</li> <li><code>FacebookAI/xlm-mlm-tlm-xnli15-1024</code> (마스킹된 언어 모델링 + 번역, XNLI 데이터 세트에서 제공하는 15개 국어)</li> <li><code>FacebookAI/xlm-clm-enfr-1024</code> (Causal language modeling, 영어-프랑스어)</li> <li><code>FacebookAI/xlm-clm-ende-1024</code> (Causal language modeling, 영어-독일어)</li>",Ie,x,jt=`언어 임베딩은 모델에 전달된 <code>input_ids</code>와 동일한 shape의 텐서로 표현됩니다.
이러한 텐서의 값은 사용된 언어에 따라 다르며 토크나이저의 <code>lang2id</code> 및 <code>id2lang</code> 속성에 의해 식별됩니다.`,ve,I,wt="다음 예제에서는 <code>FacebookAI/xlm-clm-enfr-1024</code> 체크포인트(코잘 언어 모델링(causal language modeling), 영어-프랑스어)를 가져옵니다:",Ce,v,Ze,C,xt="토크나이저의 <code>lang2id</code> 속성은 모델의 언어와 해당 ID를 표시합니다:",_e,Z,Re,_,It="다음으로, 예제 입력을 만듭니다:",Ve,R,Xe,V,vt=`언어 ID를 <code>&quot;en&quot;</code>으로 설정해 언어 임베딩을 정의합니다.
언어 임베딩은 영어의 언어 ID인 <code>0</code>으로 채워진 텐서입니다.
이 텐서는 <code>input_ids</code>와 같은 크기여야 합니다.`,Ge,X,Qe,G,Ct="이제 <code>input_ids</code>와 언어 임베딩을 모델로 전달합니다:",We,Q,Le,W,Zt='<a href="https://github.com/huggingface/transformers/tree/main/examples/pytorch/text-generation/run_generation.py" rel="nofollow">run_generation.py</a> 스크립트로 <code>xlm-clm</code> 체크포인트를 사용해 텍스트와 언어 임베딩을 생성할 수 있습니다.',Ee,L,Fe,E,_t="다음 XLM 모델은 추론 시에 언어 임베딩이 필요하지 않습니다:",Be,F,Rt="<li><code>FacebookAI/xlm-mlm-17-1280</code> (마스킹된 언어 모델링, 17개 국어)</li> <li><code>FacebookAI/xlm-mlm-100-1280</code> (마스킹된 언어 모델링, 100개 국어)</li>",He,B,Vt="이전의 XLM 체크포인트와 달리 이 모델은 일반 문장 표현에 사용됩니다.",qe,H,ze,q,Xt="다음 BERT 모델은 다국어 태스크에 사용할 수 있습니다:",Ae,z,Gt="<li><code>google-bert/bert-base-multilingual-uncased</code> (마스킹된 언어 모델링 + 다음 문장 예측, 102개 국어)</li> <li><code>google-bert/bert-base-multilingual-cased</code> (마스킹된 언어 모델링 + 다음 문장 예측, 104개 국어)</li>",Ye,A,Qt=`이러한 모델은 추론 시에 언어 임베딩이 필요하지 않습니다.
문맥에서 언어를 식별하고, 식별된 언어로 추론합니다.`,Ne,Y,De,N,Wt="다음 XLM-RoBERTa 또한 다국어 다국어 태스크에 사용할 수 있습니다:",Oe,D,Lt="<li><code>FacebookAI/xlm-roberta-base</code> (마스킹된 언어 모델링, 100개 국어)</li> <li><code>FacebookAI/xlm-roberta-large</code> (마스킹된 언어 모델링, 100개 국어)</li>",Pe,O,Et=`XLM-RoBERTa는 100개 국어에 대해 새로 생성되고 정제된 2.5TB 규모의 CommonCrawl 데이터로 학습되었습니다.
이전에 공개된 mBERT나 XLM과 같은 다국어 모델에 비해 분류, 시퀀스 라벨링, 질의 응답과 같은 다운스트림(downstream) 작업에서 이점이 있습니다.`,Se,P,Ke,S,Ft="다음 M2M100 모델 또한 다국어 다국어 태스크에 사용할 수 있습니다:",et,K,Bt="<li><code>facebook/m2m100_418M</code> (번역)</li> <li><code>facebook/m2m100_1.2B</code> (번역)</li>",tt,ee,Ht=`이 예제에서는 <code>facebook/m2m100_418M</code> 체크포인트를 가져와서 중국어를 영어로 번역합니다.
토크나이저에서 번역 대상 언어(source language)를 설정할 수 있습니다:`,lt,te,st,le,qt="문장을 토큰화합니다:",nt,se,at,ne,zt=`M2M100은 번역을 진행하기 위해 첫 번째로 생성되는 토큰은 번역할 언어(target language) ID로 강제 지정합니다.
영어로 번역하기 위해 <code>generate</code> 메소드에서 <code>forced_bos_token_id</code>를 <code>en</code>으로 설정합니다:`,it,ae,ot,ie,mt,oe,At="다음 MBart 모델 또한 다국어 태스크에 사용할 수 있습니다:",pt,me,Yt="<li><code>facebook/mbart-large-50-one-to-many-mmt</code> (일대다 다국어 번역, 50개 국어)</li> <li><code>facebook/mbart-large-50-many-to-many-mmt</code> (다대다 다국어 번역, 50개 국어)</li> <li><code>facebook/mbart-large-50-many-to-one-mmt</code> (다대일 다국어 번역, 50개 국어)</li> <li><code>facebook/mbart-large-50</code> (다국어 번역, 50개 국어)</li> <li><code>facebook/mbart-large-cc25</code></li>",rt,pe,Nt=`이 예제에서는 핀란드어를 영어로 번역하기 위해 <code>facebook/mbart-large-50-many-to-many-mmt</code> 체크포인트를 가져옵니다.
토크나이저에서 번역 대상 언어(source language)를 설정할 수 있습니다:`,gt,re,ut,ge,Dt="문장을 토큰화합니다:",Mt,ue,ct,Me,Ot=`MBart는 번역을 진행하기 위해 첫 번째로 생성되는 토큰은 번역할 언어(target language) ID로 강제 지정합니다.
영어로 번역하기 위해 <code>generate</code> 메소드에서 <code>forced_bos_token_id</code>를 <code>en</code>으로 설정합니다:`,Jt,ce,bt,Je,Pt="<code>facebook/mbart-large-50-many-to-one-mmt</code> 체크포인트를 사용하고 있다면, 첫 번째로 생성되는 토큰을 번역할 언어(target language) ID로 강제 지정할 필요는 없습니다.",dt,de,Tt;return T=new d({props:{title:"다국어 모델 추론하기",local:"multilingual-models-for-inference",headingTag:"h1"}}),f=new ol({props:{classNames:"absolute z-10 right-0 top-0",options:[{label:"Mixed",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/multilingual.ipynb"},{label:"PyTorch",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://colab.research.google.com/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/multilingual.ipynb"},{label:"Mixed",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/multilingual.ipynb"},{label:"PyTorch",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/pytorch/multilingual.ipynb"},{label:"TensorFlow",value:"https://studiolab.sagemaker.aws/import/github/huggingface/notebooks/blob/main/transformers_doc/ko/tensorflow/multilingual.ipynb"}]}}),h=new d({props:{title:"XLM",local:"xlm",headingTag:"h2"}}),k=new d({props:{title:"언어 임베딩을 사용하는 XLM",local:"xlm-with-language-embeddings",headingTag:"h3"}}),v=new J({props:{code:"aW1wb3J0JTIwdG9yY2glMEFmcm9tJTIwdHJhbnNmb3JtZXJzJTIwaW1wb3J0JTIwWExNVG9rZW5pemVyJTJDJTIwWExNV2l0aExNSGVhZE1vZGVsJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwWExNVG9rZW5pemVyLmZyb21fcHJldHJhaW5lZCglMjJGYWNlYm9va0FJJTJGeGxtLWNsbS1lbmZyLTEwMjQlMjIpJTBBbW9kZWwlMjAlM0QlMjBYTE1XaXRoTE1IZWFkTW9kZWwuZnJvbV9wcmV0cmFpbmVkKCUyMkZhY2Vib29rQUklMkZ4bG0tY2xtLWVuZnItMTAyNCUyMik=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> torch
<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> XLMTokenizer, XLMWithLMHeadModel

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = XLMTokenizer.from_pretrained(<span class="hljs-string">&quot;FacebookAI/xlm-clm-enfr-1024&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = XLMWithLMHeadModel.from_pretrained(<span class="hljs-string">&quot;FacebookAI/xlm-clm-enfr-1024&quot;</span>)`,wrap:!1}}),Z=new J({props:{code:"cHJpbnQodG9rZW5pemVyLmxhbmcyaWQp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-built_in">print</span>(tokenizer.lang2id)
{<span class="hljs-string">&#x27;en&#x27;</span>: <span class="hljs-number">0</span>, <span class="hljs-string">&#x27;fr&#x27;</span>: <span class="hljs-number">1</span>}`,wrap:!1}}),R=new J({props:{code:"aW5wdXRfaWRzJTIwJTNEJTIwdG9yY2gudGVuc29yKCU1QnRva2VuaXplci5lbmNvZGUoJTIyV2lraXBlZGlhJTIwd2FzJTIwdXNlZCUyMHRvJTIyKSU1RCklMjAlMjAlMjMlMjAlRUIlQjAlQjAlRUMlQjklOTglMjAlRUQlODElQUMlRUElQjglQjAlRUIlOEElOTQlMjAxJUVDJTlFJTg1JUVCJThCJTg4JUVCJThCJUE0",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>input_ids = torch.tensor([tokenizer.encode(<span class="hljs-string">&quot;Wikipedia was used to&quot;</span>)])  <span class="hljs-comment"># 배치 크기는 1입니다</span>',wrap:!1}}),X=new J({props:{code:"bGFuZ3VhZ2VfaWQlMjAlM0QlMjB0b2tlbml6ZXIubGFuZzJpZCU1QiUyMmVuJTIyJTVEJTIwJTIwJTIzJTIwMCUwQWxhbmdzJTIwJTNEJTIwdG9yY2gudGVuc29yKCU1Qmxhbmd1YWdlX2lkJTVEJTIwKiUyMGlucHV0X2lkcy5zaGFwZSU1QjElNUQpJTIwJTIwJTIzJTIwdG9yY2gudGVuc29yKCU1QjAlMkMlMjAwJTJDJTIwMCUyQyUyMC4uLiUyQyUyMDAlNUQpJTBBJTBBJTIzJTIwKGJhdGNoX3NpemUlMkMlMjBzZXF1ZW5jZV9sZW5ndGgpJTIwc2hhcGUlRUMlOUQlOTglMjAlRUQlODUlOTAlRUMlODQlOUMlRUElQjAlODAlMjAlRUIlOTAlOTglRUIlOEYlODQlRUIlQTElOUQlMjAlRUIlQTclOEMlRUIlOTMlQUQlRUIlOEIlODglRUIlOEIlQTQuJTBBbGFuZ3MlMjAlM0QlMjBsYW5ncy52aWV3KDElMkMlMjAtMSklMjAlMjAlMjMlMjAlRUMlOUQlQjQlRUMlQTAlOUMlMjAlNUIxJTJDJTIwc2VxdWVuY2VfbGVuZ3RoJTVEJTIwc2hhcGUlRUMlOUQlQjQlMjAlRUIlOTAlOTglRUMlOTclODglRUMlOEElQjUlRUIlOEIlODglRUIlOEIlQTQoJUVCJUIwJUIwJUVDJUI5JTk4JTIwJUVEJTgxJUFDJUVBJUI4JUIwJUVCJThBJTk0JTIwMSVFQyU5RSU4NSVFQiU4QiU4OCVFQiU4QiVBNCk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>language_id = tokenizer.lang2id[<span class="hljs-string">&quot;en&quot;</span>]  <span class="hljs-comment"># 0</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = torch.tensor([language_id] * input_ids.shape[<span class="hljs-number">1</span>])  <span class="hljs-comment"># torch.tensor([0, 0, 0, ..., 0])</span>

<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-comment"># (batch_size, sequence_length) shape의 텐서가 되도록 만듭니다.</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>langs = langs.view(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># 이제 [1, sequence_length] shape이 되었습니다(배치 크기는 1입니다)</span>`,wrap:!1}}),Q=new J({props:{code:"b3V0cHV0cyUyMCUzRCUyMG1vZGVsKGlucHV0X2lkcyUyQyUyMGxhbmdzJTNEbGFuZ3Mp",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>outputs = model(input_ids, langs=langs)',wrap:!1}}),L=new d({props:{title:"언어 임베딩을 사용하지 않는 XLM",local:"xlm-without-language-embeddings",headingTag:"h3"}}),H=new d({props:{title:"BERT",local:"bert",headingTag:"h2"}}),Y=new d({props:{title:"XLM-RoBERTa",local:"xlmroberta",headingTag:"h2"}}),P=new d({props:{title:"M2M100",local:"m2m100",headingTag:"h2"}}),te=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyME0yTTEwMEZvckNvbmRpdGlvbmFsR2VuZXJhdGlvbiUyQyUyME0yTTEwMFRva2VuaXplciUwQSUwQWVuX3RleHQlMjAlM0QlMjAlMjJEbyUyMG5vdCUyMG1lZGRsZSUyMGluJTIwdGhlJTIwYWZmYWlycyUyMG9mJTIwd2l6YXJkcyUyQyUyMGZvciUyMHRoZXklMjBhcmUlMjBzdWJ0bGUlMjBhbmQlMjBxdWljayUyMHRvJTIwYW5nZXIuJTIyJTBBY2hpbmVzZV90ZXh0JTIwJTNEJTIwJTIyJUU0JUI4JThEJUU4JUE2JTgxJUU2JThGJTkyJUU2JTg5JThCJUU1JUI3JUFCJUU1JUI4JUFCJUU3JTlBJTg0JUU0JUJBJThCJUU1JThCJTk5JTJDJTIwJUU1JTlCJUEwJUU3JTgyJUJBJUU0JUJCJTk2JUU1JTgwJTkxJUU2JTk4JUFGJUU1JUJFJUFFJUU1JUE2JTk5JUU3JTlBJTg0JTJDJTIwJUU1JUJFJTg4JUU1JUJGJUFCJUU1JUIwJUIxJUU2JTlDJTgzJUU3JTk5JUJDJUU2JTgwJTkyLiUyMiUwQSUwQXRva2VuaXplciUyMCUzRCUyME0yTTEwMFRva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZtMm0xMDBfNDE4TSUyMiUyQyUyMHNyY19sYW5nJTNEJTIyemglMjIpJTBBbW9kZWwlMjAlM0QlMjBNMk0xMDBGb3JDb25kaXRpb25hbEdlbmVyYXRpb24uZnJvbV9wcmV0cmFpbmVkKCUyMmZhY2Vib29rJTJGbTJtMTAwXzQxOE0lMjIp",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> M2M100ForConditionalGeneration, M2M100Tokenizer

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>chinese_text = <span class="hljs-string">&quot;不要插手巫師的事務, 因為他們是微妙的, 很快就會發怒.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = M2M100Tokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>, src_lang=<span class="hljs-string">&quot;zh&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = M2M100ForConditionalGeneration.from_pretrained(<span class="hljs-string">&quot;facebook/m2m100_418M&quot;</span>)`,wrap:!1}}),se=new J({props:{code:"ZW5jb2RlZF96aCUyMCUzRCUyMHRva2VuaXplcihjaGluZXNlX3RleHQlMkMlMjByZXR1cm5fdGVuc29ycyUzRCUyMnB0JTIyKQ==",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_zh = tokenizer(chinese_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)',wrap:!1}}),ae=new J({props:{code:"Z2VuZXJhdGVkX3Rva2VucyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqZW5jb2RlZF96aCUyQyUyMGZvcmNlZF9ib3NfdG9rZW5faWQlM0R0b2tlbml6ZXIuZ2V0X2xhbmdfaWQoJTIyZW4lMjIpKSUwQXRva2VuaXplci5iYXRjaF9kZWNvZGUoZ2VuZXJhdGVkX3Rva2VucyUyQyUyMHNraXBfc3BlY2lhbF90b2tlbnMlM0RUcnVlKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_zh, forced_bos_token_id=tokenizer.get_lang_id(<span class="hljs-string">&quot;en&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&#x27;Do not interfere with the matters of the witches, because they are delicate and will soon be angry.&#x27;</span>`,wrap:!1}}),ie=new d({props:{title:"MBart",local:"mbart",headingTag:"h2"}}),re=new J({props:{code:"ZnJvbSUyMHRyYW5zZm9ybWVycyUyMGltcG9ydCUyMEF1dG9Ub2tlbml6ZXIlMkMlMjBBdXRvTW9kZWxGb3JTZXEyU2VxTE0lMEElMEFlbl90ZXh0JTIwJTNEJTIwJTIyRG8lMjBub3QlMjBtZWRkbGUlMjBpbiUyMHRoZSUyMGFmZmFpcnMlMjBvZiUyMHdpemFyZHMlMkMlMjBmb3IlMjB0aGV5JTIwYXJlJTIwc3VidGxlJTIwYW5kJTIwcXVpY2slMjB0byUyMGFuZ2VyLiUyMiUwQWZpX3RleHQlMjAlM0QlMjAlMjIlQzMlODRsJUMzJUE0JTIwc2VrYWFubnUlMjB2ZWxob2plbiUyMGFzaW9paGluJTJDJTIwc2lsbCVDMyVBNCUyMG5lJTIwb3ZhdCUyMGhpZW5vdmFyYWlzaWElMjBqYSUyMG5vcGVhc3RpJTIwdmloYWlzaWEuJTIyJTBBJTBBdG9rZW5pemVyJTIwJTNEJTIwQXV0b1Rva2VuaXplci5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZtYmFydC1sYXJnZS01MC1tYW55LXRvLW1hbnktbW10JTIyJTJDJTIwc3JjX2xhbmclM0QlMjJmaV9GSSUyMiklMEFtb2RlbCUyMCUzRCUyMEF1dG9Nb2RlbEZvclNlcTJTZXFMTS5mcm9tX3ByZXRyYWluZWQoJTIyZmFjZWJvb2slMkZtYmFydC1sYXJnZS01MC1tYW55LXRvLW1hbnktbW10JTIyKQ==",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer, AutoModelForSeq2SeqLM

<span class="hljs-meta">&gt;&gt;&gt; </span>en_text = <span class="hljs-string">&quot;Do not meddle in the affairs of wizards, for they are subtle and quick to anger.&quot;</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>fi_text = <span class="hljs-string">&quot;Älä sekaannu velhojen asioihin, sillä ne ovat hienovaraisia ja nopeasti vihaisia.&quot;</span>

<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer = AutoTokenizer.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>, src_lang=<span class="hljs-string">&quot;fi_FI&quot;</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>model = AutoModelForSeq2SeqLM.from_pretrained(<span class="hljs-string">&quot;facebook/mbart-large-50-many-to-many-mmt&quot;</span>)`,wrap:!1}}),ue=new J({props:{code:"ZW5jb2RlZF9lbiUyMCUzRCUyMHRva2VuaXplcihlbl90ZXh0JTJDJTIwcmV0dXJuX3RlbnNvcnMlM0QlMjJwdCUyMik=",highlighted:'<span class="hljs-meta">&gt;&gt;&gt; </span>encoded_en = tokenizer(en_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)',wrap:!1}}),ce=new J({props:{code:"Z2VuZXJhdGVkX3Rva2VucyUyMCUzRCUyMG1vZGVsLmdlbmVyYXRlKCoqZW5jb2RlZF9lbiUyQyUyMGZvcmNlZF9ib3NfdG9rZW5faWQlM0R0b2tlbml6ZXIubGFuZ19jb2RlX3RvX2lkKCUyMmVuX1hYJTIyKSklMEF0b2tlbml6ZXIuYmF0Y2hfZGVjb2RlKGdlbmVyYXRlZF90b2tlbnMlMkMlMjBza2lwX3NwZWNpYWxfdG9rZW5zJTNEVHJ1ZSk=",highlighted:`<span class="hljs-meta">&gt;&gt;&gt; </span>generated_tokens = model.generate(**encoded_en, forced_bos_token_id=tokenizer.lang_code_to_id(<span class="hljs-string">&quot;en_XX&quot;</span>))
<span class="hljs-meta">&gt;&gt;&gt; </span>tokenizer.batch_decode(generated_tokens, skip_special_tokens=<span class="hljs-literal">True</span>)
<span class="hljs-string">&quot;Don&#x27;t interfere with the wizard&#x27;s affairs, because they are subtle, will soon get angry.&quot;</span>`,wrap:!1}}),{c(){b=i("meta"),Te=n(),be=i("p"),fe=n(),p(T.$$.fragment),Ue=n(),p(f.$$.fragment),ye=n(),U=i("p"),U.innerHTML=Ut,he=n(),y=i("p"),y.innerHTML=yt,$e=n(),p(h.$$.fragment),ke=n(),$=i("p"),$.textContent=ht,je=n(),p(k.$$.fragment),we=n(),j=i("p"),j.textContent=$t,xe=n(),w=i("ul"),w.innerHTML=kt,Ie=n(),x=i("p"),x.innerHTML=jt,ve=n(),I=i("p"),I.innerHTML=wt,Ce=n(),p(v.$$.fragment),Ze=n(),C=i("p"),C.innerHTML=xt,_e=n(),p(Z.$$.fragment),Re=n(),_=i("p"),_.textContent=It,Ve=n(),p(R.$$.fragment),Xe=n(),V=i("p"),V.innerHTML=vt,Ge=n(),p(X.$$.fragment),Qe=n(),G=i("p"),G.innerHTML=Ct,We=n(),p(Q.$$.fragment),Le=n(),W=i("p"),W.innerHTML=Zt,Ee=n(),p(L.$$.fragment),Fe=n(),E=i("p"),E.textContent=_t,Be=n(),F=i("ul"),F.innerHTML=Rt,He=n(),B=i("p"),B.textContent=Vt,qe=n(),p(H.$$.fragment),ze=n(),q=i("p"),q.textContent=Xt,Ae=n(),z=i("ul"),z.innerHTML=Gt,Ye=n(),A=i("p"),A.textContent=Qt,Ne=n(),p(Y.$$.fragment),De=n(),N=i("p"),N.textContent=Wt,Oe=n(),D=i("ul"),D.innerHTML=Lt,Pe=n(),O=i("p"),O.textContent=Et,Se=n(),p(P.$$.fragment),Ke=n(),S=i("p"),S.textContent=Ft,et=n(),K=i("ul"),K.innerHTML=Bt,tt=n(),ee=i("p"),ee.innerHTML=Ht,lt=n(),p(te.$$.fragment),st=n(),le=i("p"),le.textContent=qt,nt=n(),p(se.$$.fragment),at=n(),ne=i("p"),ne.innerHTML=zt,it=n(),p(ae.$$.fragment),ot=n(),p(ie.$$.fragment),mt=n(),oe=i("p"),oe.textContent=At,pt=n(),me=i("ul"),me.innerHTML=Yt,rt=n(),pe=i("p"),pe.innerHTML=Nt,gt=n(),p(re.$$.fragment),ut=n(),ge=i("p"),ge.textContent=Dt,Mt=n(),p(ue.$$.fragment),ct=n(),Me=i("p"),Me.innerHTML=Ot,Jt=n(),p(ce.$$.fragment),bt=n(),Je=i("p"),Je.innerHTML=Pt,dt=n(),de=i("p"),this.h()},l(e){const t=al("svelte-u9bgzb",document.head);b=o(t,"META",{name:!0,content:!0}),t.forEach(l),Te=a(e),be=o(e,"P",{}),St(be).forEach(l),fe=a(e),r(T.$$.fragment,e),Ue=a(e),r(f.$$.fragment,e),ye=a(e),U=o(e,"P",{"data-svelte-h":!0}),m(U)!=="svelte-1qyjud1"&&(U.innerHTML=Ut),he=a(e),y=o(e,"P",{"data-svelte-h":!0}),m(y)!=="svelte-1dm3zii"&&(y.innerHTML=yt),$e=a(e),r(h.$$.fragment,e),ke=a(e),$=o(e,"P",{"data-svelte-h":!0}),m($)!=="svelte-d0lwem"&&($.textContent=ht),je=a(e),r(k.$$.fragment,e),we=a(e),j=o(e,"P",{"data-svelte-h":!0}),m(j)!=="svelte-1mrvoju"&&(j.textContent=$t),xe=a(e),w=o(e,"UL",{"data-svelte-h":!0}),m(w)!=="svelte-xty113"&&(w.innerHTML=kt),Ie=a(e),x=o(e,"P",{"data-svelte-h":!0}),m(x)!=="svelte-jhaqr8"&&(x.innerHTML=jt),ve=a(e),I=o(e,"P",{"data-svelte-h":!0}),m(I)!=="svelte-8i1x81"&&(I.innerHTML=wt),Ce=a(e),r(v.$$.fragment,e),Ze=a(e),C=o(e,"P",{"data-svelte-h":!0}),m(C)!=="svelte-m3urb"&&(C.innerHTML=xt),_e=a(e),r(Z.$$.fragment,e),Re=a(e),_=o(e,"P",{"data-svelte-h":!0}),m(_)!=="svelte-xaqytr"&&(_.textContent=It),Ve=a(e),r(R.$$.fragment,e),Xe=a(e),V=o(e,"P",{"data-svelte-h":!0}),m(V)!=="svelte-15t64om"&&(V.innerHTML=vt),Ge=a(e),r(X.$$.fragment,e),Qe=a(e),G=o(e,"P",{"data-svelte-h":!0}),m(G)!=="svelte-13hhwrg"&&(G.innerHTML=Ct),We=a(e),r(Q.$$.fragment,e),Le=a(e),W=o(e,"P",{"data-svelte-h":!0}),m(W)!=="svelte-11on0v7"&&(W.innerHTML=Zt),Ee=a(e),r(L.$$.fragment,e),Fe=a(e),E=o(e,"P",{"data-svelte-h":!0}),m(E)!=="svelte-ugy4tb"&&(E.textContent=_t),Be=a(e),F=o(e,"UL",{"data-svelte-h":!0}),m(F)!=="svelte-14eckio"&&(F.innerHTML=Rt),He=a(e),B=o(e,"P",{"data-svelte-h":!0}),m(B)!=="svelte-10uilok"&&(B.textContent=Vt),qe=a(e),r(H.$$.fragment,e),ze=a(e),q=o(e,"P",{"data-svelte-h":!0}),m(q)!=="svelte-17m07ks"&&(q.textContent=Xt),Ae=a(e),z=o(e,"UL",{"data-svelte-h":!0}),m(z)!=="svelte-7ugqvx"&&(z.innerHTML=Gt),Ye=a(e),A=o(e,"P",{"data-svelte-h":!0}),m(A)!=="svelte-1g2xdg6"&&(A.textContent=Qt),Ne=a(e),r(Y.$$.fragment,e),De=a(e),N=o(e,"P",{"data-svelte-h":!0}),m(N)!=="svelte-1qq64rp"&&(N.textContent=Wt),Oe=a(e),D=o(e,"UL",{"data-svelte-h":!0}),m(D)!=="svelte-18hzxmq"&&(D.innerHTML=Lt),Pe=a(e),O=o(e,"P",{"data-svelte-h":!0}),m(O)!=="svelte-1k6xl52"&&(O.textContent=Et),Se=a(e),r(P.$$.fragment,e),Ke=a(e),S=o(e,"P",{"data-svelte-h":!0}),m(S)!=="svelte-170tekz"&&(S.textContent=Ft),et=a(e),K=o(e,"UL",{"data-svelte-h":!0}),m(K)!=="svelte-nhn2xp"&&(K.innerHTML=Bt),tt=a(e),ee=o(e,"P",{"data-svelte-h":!0}),m(ee)!=="svelte-1v6yjg7"&&(ee.innerHTML=Ht),lt=a(e),r(te.$$.fragment,e),st=a(e),le=o(e,"P",{"data-svelte-h":!0}),m(le)!=="svelte-1sem8ou"&&(le.textContent=qt),nt=a(e),r(se.$$.fragment,e),at=a(e),ne=o(e,"P",{"data-svelte-h":!0}),m(ne)!=="svelte-bfy9qc"&&(ne.innerHTML=zt),it=a(e),r(ae.$$.fragment,e),ot=a(e),r(ie.$$.fragment,e),mt=a(e),oe=o(e,"P",{"data-svelte-h":!0}),m(oe)!=="svelte-1qf6ghx"&&(oe.textContent=At),pt=a(e),me=o(e,"UL",{"data-svelte-h":!0}),m(me)!=="svelte-q5sfdy"&&(me.innerHTML=Yt),rt=a(e),pe=o(e,"P",{"data-svelte-h":!0}),m(pe)!=="svelte-1xo0fvw"&&(pe.innerHTML=Nt),gt=a(e),r(re.$$.fragment,e),ut=a(e),ge=o(e,"P",{"data-svelte-h":!0}),m(ge)!=="svelte-1sem8ou"&&(ge.textContent=Dt),Mt=a(e),r(ue.$$.fragment,e),ct=a(e),Me=o(e,"P",{"data-svelte-h":!0}),m(Me)!=="svelte-19syhrh"&&(Me.innerHTML=Ot),Jt=a(e),r(ce.$$.fragment,e),bt=a(e),Je=o(e,"P",{"data-svelte-h":!0}),m(Je)!=="svelte-jdtdeh"&&(Je.innerHTML=Pt),dt=a(e),de=o(e,"P",{}),St(de).forEach(l),this.h()},h(){Kt(b,"name","hf:doc:metadata"),Kt(b,"content",pl)},m(e,t){il(document.head,b),s(e,Te,t),s(e,be,t),s(e,fe,t),g(T,e,t),s(e,Ue,t),g(f,e,t),s(e,ye,t),s(e,U,t),s(e,he,t),s(e,y,t),s(e,$e,t),g(h,e,t),s(e,ke,t),s(e,$,t),s(e,je,t),g(k,e,t),s(e,we,t),s(e,j,t),s(e,xe,t),s(e,w,t),s(e,Ie,t),s(e,x,t),s(e,ve,t),s(e,I,t),s(e,Ce,t),g(v,e,t),s(e,Ze,t),s(e,C,t),s(e,_e,t),g(Z,e,t),s(e,Re,t),s(e,_,t),s(e,Ve,t),g(R,e,t),s(e,Xe,t),s(e,V,t),s(e,Ge,t),g(X,e,t),s(e,Qe,t),s(e,G,t),s(e,We,t),g(Q,e,t),s(e,Le,t),s(e,W,t),s(e,Ee,t),g(L,e,t),s(e,Fe,t),s(e,E,t),s(e,Be,t),s(e,F,t),s(e,He,t),s(e,B,t),s(e,qe,t),g(H,e,t),s(e,ze,t),s(e,q,t),s(e,Ae,t),s(e,z,t),s(e,Ye,t),s(e,A,t),s(e,Ne,t),g(Y,e,t),s(e,De,t),s(e,N,t),s(e,Oe,t),s(e,D,t),s(e,Pe,t),s(e,O,t),s(e,Se,t),g(P,e,t),s(e,Ke,t),s(e,S,t),s(e,et,t),s(e,K,t),s(e,tt,t),s(e,ee,t),s(e,lt,t),g(te,e,t),s(e,st,t),s(e,le,t),s(e,nt,t),g(se,e,t),s(e,at,t),s(e,ne,t),s(e,it,t),g(ae,e,t),s(e,ot,t),g(ie,e,t),s(e,mt,t),s(e,oe,t),s(e,pt,t),s(e,me,t),s(e,rt,t),s(e,pe,t),s(e,gt,t),g(re,e,t),s(e,ut,t),s(e,ge,t),s(e,Mt,t),g(ue,e,t),s(e,ct,t),s(e,Me,t),s(e,Jt,t),g(ce,e,t),s(e,bt,t),s(e,Je,t),s(e,dt,t),s(e,de,t),Tt=!0},p:tl,i(e){Tt||(u(T.$$.fragment,e),u(f.$$.fragment,e),u(h.$$.fragment,e),u(k.$$.fragment,e),u(v.$$.fragment,e),u(Z.$$.fragment,e),u(R.$$.fragment,e),u(X.$$.fragment,e),u(Q.$$.fragment,e),u(L.$$.fragment,e),u(H.$$.fragment,e),u(Y.$$.fragment,e),u(P.$$.fragment,e),u(te.$$.fragment,e),u(se.$$.fragment,e),u(ae.$$.fragment,e),u(ie.$$.fragment,e),u(re.$$.fragment,e),u(ue.$$.fragment,e),u(ce.$$.fragment,e),Tt=!0)},o(e){M(T.$$.fragment,e),M(f.$$.fragment,e),M(h.$$.fragment,e),M(k.$$.fragment,e),M(v.$$.fragment,e),M(Z.$$.fragment,e),M(R.$$.fragment,e),M(X.$$.fragment,e),M(Q.$$.fragment,e),M(L.$$.fragment,e),M(H.$$.fragment,e),M(Y.$$.fragment,e),M(P.$$.fragment,e),M(te.$$.fragment,e),M(se.$$.fragment,e),M(ae.$$.fragment,e),M(ie.$$.fragment,e),M(re.$$.fragment,e),M(ue.$$.fragment,e),M(ce.$$.fragment,e),Tt=!1},d(e){e&&(l(Te),l(be),l(fe),l(Ue),l(ye),l(U),l(he),l(y),l($e),l(ke),l($),l(je),l(we),l(j),l(xe),l(w),l(Ie),l(x),l(ve),l(I),l(Ce),l(Ze),l(C),l(_e),l(Re),l(_),l(Ve),l(Xe),l(V),l(Ge),l(Qe),l(G),l(We),l(Le),l(W),l(Ee),l(Fe),l(E),l(Be),l(F),l(He),l(B),l(qe),l(ze),l(q),l(Ae),l(z),l(Ye),l(A),l(Ne),l(De),l(N),l(Oe),l(D),l(Pe),l(O),l(Se),l(Ke),l(S),l(et),l(K),l(tt),l(ee),l(lt),l(st),l(le),l(nt),l(at),l(ne),l(it),l(ot),l(mt),l(oe),l(pt),l(me),l(rt),l(pe),l(gt),l(ut),l(ge),l(Mt),l(ct),l(Me),l(Jt),l(bt),l(Je),l(dt),l(de)),l(b),c(T,e),c(f,e),c(h,e),c(k,e),c(v,e),c(Z,e),c(R,e),c(X,e),c(Q,e),c(L,e),c(H,e),c(Y,e),c(P,e),c(te,e),c(se,e),c(ae,e),c(ie,e),c(re,e),c(ue,e),c(ce,e)}}}const pl='{"title":"다국어 모델 추론하기","local":"multilingual-models-for-inference","sections":[{"title":"XLM","local":"xlm","sections":[{"title":"언어 임베딩을 사용하는 XLM","local":"xlm-with-language-embeddings","sections":[],"depth":3},{"title":"언어 임베딩을 사용하지 않는 XLM","local":"xlm-without-language-embeddings","sections":[],"depth":3}],"depth":2},{"title":"BERT","local":"bert","sections":[],"depth":2},{"title":"XLM-RoBERTa","local":"xlmroberta","sections":[],"depth":2},{"title":"M2M100","local":"m2m100","sections":[],"depth":2},{"title":"MBart","local":"mbart","sections":[],"depth":2}],"depth":1}';function rl(ft){return ll(()=>{new URLSearchParams(window.location.search).get("fw")}),[]}class bl extends sl{constructor(b){super(),nl(this,b,rl,ml,el,{})}}export{bl as component};
